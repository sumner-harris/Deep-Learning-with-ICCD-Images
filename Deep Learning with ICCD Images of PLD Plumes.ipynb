{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aea88c4b",
   "metadata": {},
   "source": [
    "# Deep learning with ICCD images of plasma plumes generated during pulsed laser deposition\n",
    "\n",
    "#### Sumner B. Harris\n",
    "\n",
    "This notebook is designed to provide a functional example of using (2+1)D CNNs to extract deep features from ICCD image sequences for real-time anomaly detection or prediction of materials properties during pulsed laser deposition (PLD).\n",
    "\n",
    "Start by importing the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24f3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some basics\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Import our custom helper module\n",
    "import ICCDutils\n",
    "\n",
    "# Import Torch stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca40a001",
   "metadata": {},
   "source": [
    "## Next, we will build our dataset class\n",
    "\n",
    "This class is used to generate our training and validation sets as well as augment the data during each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6332414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLDdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe, transform, target_params, augment=True):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get growth parameters\n",
    "        params = torch.tensor([self.df.loc[idx,'P'],self.df.loc[idx,'T'],self.df.loc[idx,'E1'],self.df.loc[idx,'E2']],dtype=torch.float32)\n",
    "        \n",
    "        # get targets\n",
    "        if target_params == 'anomaly':\n",
    "            target = torch.tensor([self.df.loc[idx,'P'],self.df.loc[idx,'E1'],self.df.loc[idx,'E2']],dtype=torch.float32)\n",
    "        if target_params == 'growth':\n",
    "            target = torch.tensor([self.df.loc[idx,'s0'],self.df.loc[idx,'s1'],self.df.loc[idx,'J']],dtype=torch.float32)\n",
    "\n",
    "        # get ICCD image sequence\n",
    "        image1 = torch.tensor(self.df.loc[idx,'ICCD'],dtype=torch.float32)\n",
    "\n",
    "        if self.augment:\n",
    "            image1 = self.transform(image1)      \n",
    "            # add measurement noise to parameters for augmentation\n",
    "            params[0] = params[0] + torch.randn(1)*2*np.sqrt(params[0]*0.00125) # account for 2 sigma, 0.25% baratron accuracy\n",
    "            params[1] = params[1] + torch.randn(1)*2*np.sqrt(params[1]*0.0075)# account for 2 sigma, 1.5% temperature\n",
    "            params[2] = params[2] + torch.randn(1)*2*np.sqrt(params[2]*0.0075)# account for 2 sigma, 1.5% laser stability accuracy\n",
    "            params[3] = params[3] + torch.randn(1)*2*np.sqrt(params[3]*0.0075)# account for 2 sigma, 1.5% laser stability accuracy\n",
    "\n",
    "        return image1, params, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e6002",
   "metadata": {},
   "source": [
    "## Set up a function to load data and generate the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d1eb5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datafile, target, normalize_PTE1E2, train_percent=70):\n",
    "    # Create a transform for the ICCD images\n",
    "    transform = transforms.RandomAffine(180,\n",
    "                                    translate=(0.1,0.1),\n",
    "                                    shear=10,\n",
    "                                    scale=(0.8,1.2))\n",
    "    \n",
    "    # load the full data from the json file\n",
    "    df = ICCDutils.load_df(datafile, normalize_PTE1E2=normalize_PTE1E2)\n",
    "    \n",
    "    train_number = int(len(df)*train_percent/100)\n",
    "    val_number = len(df)-train_number\n",
    "    print('Total number of samples: {}'.format(len(df)))\n",
    "    print('Number of training samples: {}\\nNumber of validation samples: {}'.format(train_number, val_number))\n",
    "    \n",
    "    # instantiate the PLDdataset class\n",
    "    dataset = PLDdataset(df, transform, target)\n",
    "    \n",
    "    # set a seed for reproducibility\n",
    "    generator = torch.Generator().manual_seed(42)\n",
    "    \n",
    "    # randomly split the data into training and validation sets\n",
    "    train_data, val_data = random_split(dataset,[train_number,val_number],generator=generator)\n",
    "    \n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed0dad",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bff2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedICCDNet(nn.Module):\n",
    "    def __init__(self,features='Mixed',\n",
    "                 l1=64,l2=32,param_l1=48,param_out=32,c1=16,c2=24,c3=32):\n",
    "        super(MixedICCDNet, self).__init__()\n",
    "        self.features = features\n",
    "        # ICCD imaging feature inputs, the full image size is BATCH,C,frames,H,W where it is N,50,40,40\n",
    "        self.ICCD_features_ = nn.Sequential(\n",
    "            #Spatial convolution\n",
    "            nn.Conv3d(1,64, kernel_size=(1,3,3), stride=(1,1,1), padding=(0,1,1)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            #Temportal convolution\n",
    "            nn.Conv3d(64,64,kernel_size=(3,1,1), stride=(1,1,1), padding=(1,0,0)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "\n",
    "            #Downsample\n",
    "            nn.AvgPool3d(kernel_size=(2,2,2),stride=(2,2,2)),\n",
    "\n",
    "            #Spatial convolution\n",
    "            nn.Conv3d(64,128, kernel_size=(1,3,3), stride=(1,1,1), padding=(0,1,1)),\n",
    "            nn.BatchNorm3d(128),\n",
    "            #Temportal convolution\n",
    "            nn.Conv3d(128,128,kernel_size=(3,1,1), stride=(1,1,1), padding=(1,0,0)),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "\n",
    "            #Downsample\n",
    "            nn.AvgPool3d(kernel_size=(2,2,2),stride=(2,2,2)),\n",
    "\n",
    "            #Spatial convolution\n",
    "            nn.Conv3d(128,256, kernel_size=(1,3,3), stride=(1,1,1), padding=(0,1,1)),\n",
    "            nn.BatchNorm3d(256),\n",
    "            #Temportal convolution\n",
    "            nn.Conv3d(256,256,kernel_size=(3,1,1), stride=(1,1,1), padding=(1,0,0)),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "\n",
    "            #Downsample\n",
    "            nn.AvgPool3d(kernel_size=(2,2,2),stride=(2,2,2)),\n",
    "\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(256*6*5*5,l1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(l1,l2),\n",
    "            nn.LeakyReLU(inplace=True))\n",
    "        \n",
    "        if features =='ICCD':\n",
    "            self.ICCD_features_.add_module('out',nn.Linear(l2,3))\n",
    "        \n",
    "        \n",
    "        self.parameter_features = nn.Sequential(\n",
    "            nn.Linear(4,param_l1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(param_l1,param_out),\n",
    "            nn.LeakyReLU(inplace=True))\n",
    "        \n",
    "        if features =='Params':\n",
    "            self.parameter_features.add_module('out',nn.Linear(param_out,3))\n",
    "        \n",
    "        self.combined_features_ = nn.Sequential(\n",
    "            nn.Linear(l2+param_out,c1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(c1,c2),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(c2,c3),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(c3,3),\n",
    "        )\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        if self.features=='Mixed':\n",
    "            x=self.ICCD_features_(x)\n",
    "            y=self.parameter_features(y)\n",
    "            x=x.view(x.shape[0],-1)\n",
    "            y=y.view(y.shape[0],-1)        \n",
    "            z = torch.cat((x,y),1)\n",
    "            z = self.combined_features_(z)        \n",
    "            return z\n",
    "        if self.features=='ICCD':\n",
    "            x=self.ICCD_features_(x)\n",
    "            return x\n",
    "        if self.features=='Params':\n",
    "            y=self.parameter_features(y)\n",
    "            return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773be3a3",
   "metadata": {},
   "source": [
    "# Set up the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a8751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,val_loader,n_epochs,learning_rate,L2, ICCD_checkpoint=None, MLP_checkpoint=None):\n",
    "        \n",
    "    if ICCD_checkpoint != None:\n",
    "        weights = torch.load(ICCD_checkpoint)\n",
    "        model.load_state_dict(weights,strict=False)\n",
    "        #Freeze all layers in the ICCD_features_ part\n",
    "        for param in model.ICCD_features_.parameters():\n",
    "            param.requires_grad = False\n",
    "        print('Loaded and froze ICCD layers...')\n",
    "        for param in model.ICCD_features_.parameters():\n",
    "            if param.requires_grad:\n",
    "                print('ERROR:Found trainable in ICCD')\n",
    "        \n",
    "    if MLP_checkpoint != None:\n",
    "        weights = torch.load(MLP_checkpoint)\n",
    "        model.load_state_dict(weights,strict=False)\n",
    "        #Freeze all layers in the parameter_features part\n",
    "        for param in model.parameter_features.parameters():\n",
    "            param.requires_grad = False\n",
    "        print('Loaded and froze parameter MLP layers...')\n",
    "        for param in model.parameter_features.parameters():\n",
    "            if param.requires_grad:\n",
    "                print('ERROR:Found trainable in MLP')\n",
    "\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    r2_list = []\n",
    "    best_R2 = 0.0\n",
    "\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        print('Using GPU.')\n",
    "        device = \"cuda:0\"    \n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print('Using multiple GPUs.')\n",
    "            model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer=optim.Adam(model.parameters(),lr=learning_rate,amsgrad=True,weight_decay=L2)\n",
    "\n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        loss_train = 0.0\n",
    "        for id_batch, (image,params,target) in enumerate(train_loader):\n",
    "            image = image.to(device)\n",
    "            params = params.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(image,params)\n",
    "            loss = loss_fn(y_pred, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        train_pred, train_actuals = y_pred.cpu(), target.cpu()\n",
    "        train_loss_list.append(loss_train/len(train_loader))\n",
    "        print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch,\n",
    "                                                              loss_train / len(train_loader)))\n",
    "\n",
    "        size = len(val_loader.dataset)\n",
    "        num_batches = len(val_loader)\n",
    "        val_loss = 0.0\n",
    "        for (image,params,target) in val_loader:\n",
    "            with torch.no_grad():\n",
    "                image = image.to(device)\n",
    "                params = params.to(device)\n",
    "                target = target.to(device)\n",
    "                pred = model(image, params)\n",
    "                val_loss += loss_fn(pred, target).item()\n",
    "\n",
    "                r2_1 = pearsonr(target[:,0].cpu(), pred[:,0].cpu())[0]**2\n",
    "                r2_2 = pearsonr(target[:,1].cpu(), pred[:,1].cpu())[0]**2\n",
    "                r2_3 = pearsonr(target[:,2].cpu(), pred[:,2].cpu())[0]**2\n",
    "                meanR2 = np.array([r2_1,r2_2,r2_3]).mean()\n",
    "                print('R2 values {:.4f}, {:.4f}, {:.4f}; mean R2={:.4f}'.format(r2_1,r2_2,r2_3, meanR2))\n",
    "                r2_list.append([r2_1,r2_2,r2_3,meanR2])\n",
    "\n",
    "        if meanR2>best_R2:\n",
    "            print('New best, saving checkpoint...')\n",
    "            best_R2 = meanR2\n",
    "            best_val_predictions, best_val_actuals = pred.cpu().detach(), target.cpu().detach()\n",
    "            best_train_predictions, best_train_actuals = train_pred.cpu().detach(), train_actuals.cpu().detach()\n",
    "            torch.save(model.state_dict(), '{}.model'.format(checkpoint_name))\n",
    "\n",
    "        val_loss /= num_batches\n",
    "        val_loss_list.append(val_loss)\n",
    "        print(f\"Validation Error: Avg loss: {val_loss:>8f} \\n\")\n",
    "        \n",
    "    return (train_loss_list, val_loss_list, r2_list, best_R2, best_val_predictions,\\\n",
    "                best_val_actuals,best_train_predictions, best_train_actuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6fcdc5",
   "metadata": {},
   "source": [
    "# Set up and train the model for anomaly prediction\n",
    "\n",
    "The cell below loads the data, defines the predition target, and splits into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e05c8dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 127\n",
      "Number of training samples: 88\n",
      "Number of validation samples: 39\n"
     ]
    }
   ],
   "source": [
    "datafile = 'PLD data.json'\n",
    "\n",
    "# set the target to anomaly to train for P, E1, and E2.\n",
    "# set the target to 'growth' to train for s0, s1, and J\n",
    "target_params = 'anomaly'\n",
    "\n",
    "BATCH_SIZE = 88\n",
    "\n",
    "#############################\n",
    "if target_params == 'anomaly':\n",
    "    normalize_PTE1E2 = False\n",
    "else:\n",
    "    normalize_PTE1E2 = True\n",
    "\n",
    "train_data, val_data = load_data(datafile, target_params, normalize_PTE1E2=normalize_PTE1E2, train_percent=70)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8589c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU.\n",
      "2023-11-08 13:18:14.079274 Epoch 1, Training loss 30717.013671875\n",
      "R2 values 0.0012, 0.0054, 0.0364; mean R2=0.0143\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 29909.894531 \n",
      "\n",
      "2023-11-08 13:18:14.577725 Epoch 2, Training loss 29090.1796875\n",
      "R2 values 0.1304, 0.0672, 0.0029; mean R2=0.0668\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 27701.900391 \n",
      "\n",
      "2023-11-08 13:18:15.077937 Epoch 3, Training loss 27017.28515625\n",
      "R2 values 0.2074, 0.0142, 0.2475; mean R2=0.1564\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 25310.962891 \n",
      "\n",
      "2023-11-08 13:18:15.569007 Epoch 4, Training loss 24721.265625\n",
      "R2 values 0.1696, 0.0088, 0.0086; mean R2=0.0624\n",
      "Validation Error: Avg loss: 22766.197266 \n",
      "\n",
      "2023-11-08 13:18:16.037194 Epoch 5, Training loss 22336.765625\n",
      "R2 values 0.1350, 0.0012, 0.0093; mean R2=0.0485\n",
      "Validation Error: Avg loss: 20019.904297 \n",
      "\n",
      "2023-11-08 13:18:16.493083 Epoch 6, Training loss 19659.015625\n",
      "R2 values 0.2437, 0.0041, 0.1962; mean R2=0.1480\n",
      "Validation Error: Avg loss: 17314.019531 \n",
      "\n",
      "2023-11-08 13:18:17.260401 Epoch 7, Training loss 17187.205078125\n",
      "R2 values 0.3589, 0.0160, 0.1227; mean R2=0.1659\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 14422.163086 \n",
      "\n",
      "2023-11-08 13:18:18.058050 Epoch 8, Training loss 14522.720703125\n",
      "R2 values 0.1894, 0.1611, 0.0036; mean R2=0.1180\n",
      "Validation Error: Avg loss: 11998.209961 \n",
      "\n",
      "2023-11-08 13:18:18.530167 Epoch 9, Training loss 12178.6806640625\n",
      "R2 values 0.3867, 0.0586, 0.0233; mean R2=0.1562\n",
      "Validation Error: Avg loss: 9509.163086 \n",
      "\n",
      "2023-11-08 13:18:19.007086 Epoch 10, Training loss 10023.330078125\n",
      "R2 values 0.3055, 0.0149, 0.1170; mean R2=0.1458\n",
      "Validation Error: Avg loss: 7856.901855 \n",
      "\n",
      "2023-11-08 13:18:19.470165 Epoch 11, Training loss 8338.9912109375\n",
      "R2 values 0.5348, 0.0003, 0.1801; mean R2=0.2384\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 6165.605469 \n",
      "\n",
      "2023-11-08 13:18:19.947611 Epoch 12, Training loss 6800.05712890625\n",
      "R2 values 0.5288, 0.0048, 0.0688; mean R2=0.2008\n",
      "Validation Error: Avg loss: 4707.965332 \n",
      "\n",
      "2023-11-08 13:18:20.410584 Epoch 13, Training loss 6104.88037109375\n",
      "R2 values 0.4690, 0.0001, 0.0030; mean R2=0.1574\n",
      "Validation Error: Avg loss: 4611.690430 \n",
      "\n",
      "2023-11-08 13:18:20.915663 Epoch 14, Training loss 6041.54638671875\n",
      "R2 values 0.1932, 0.0194, 0.0719; mean R2=0.0948\n",
      "Validation Error: Avg loss: 5937.847168 \n",
      "\n",
      "2023-11-08 13:18:21.459669 Epoch 15, Training loss 6351.9150390625\n",
      "R2 values 0.1191, 0.0018, 0.0567; mean R2=0.0592\n",
      "Validation Error: Avg loss: 6795.540527 \n",
      "\n",
      "2023-11-08 13:18:21.928425 Epoch 16, Training loss 7058.8466796875\n",
      "R2 values 0.1466, 0.0404, 0.0002; mean R2=0.0624\n",
      "Validation Error: Avg loss: 6737.024902 \n",
      "\n",
      "2023-11-08 13:18:22.388666 Epoch 17, Training loss 7505.38427734375\n",
      "R2 values 0.2746, 0.0600, 0.0000; mean R2=0.1116\n",
      "Validation Error: Avg loss: 6084.211426 \n",
      "\n",
      "2023-11-08 13:18:22.867968 Epoch 18, Training loss 7380.62890625\n",
      "R2 values 0.4701, 0.0034, 0.0267; mean R2=0.1667\n",
      "Validation Error: Avg loss: 5153.184082 \n",
      "\n",
      "2023-11-08 13:18:23.330401 Epoch 19, Training loss 6510.6884765625\n",
      "R2 values 0.3693, 0.0298, 0.0005; mean R2=0.1332\n",
      "Validation Error: Avg loss: 5344.333496 \n",
      "\n",
      "2023-11-08 13:18:23.794947 Epoch 20, Training loss 6151.72119140625\n",
      "R2 values 0.4516, 0.0127, 0.0815; mean R2=0.1819\n",
      "Validation Error: Avg loss: 4642.331543 \n",
      "\n",
      "2023-11-08 13:18:24.311624 Epoch 21, Training loss 5958.9990234375\n",
      "R2 values 0.5064, 0.0066, 0.0263; mean R2=0.1798\n",
      "Validation Error: Avg loss: 4614.147461 \n",
      "\n",
      "2023-11-08 13:18:24.772761 Epoch 22, Training loss 5192.55224609375\n",
      "R2 values 0.4744, 0.0103, 0.0052; mean R2=0.1633\n",
      "Validation Error: Avg loss: 4775.607910 \n",
      "\n",
      "2023-11-08 13:18:25.249078 Epoch 23, Training loss 5473.48388671875\n",
      "R2 values 0.5758, 0.0004, 0.0622; mean R2=0.2128\n",
      "Validation Error: Avg loss: 4585.729492 \n",
      "\n",
      "2023-11-08 13:18:25.714931 Epoch 24, Training loss 5602.75390625\n",
      "R2 values 0.5598, 0.0067, 0.0419; mean R2=0.2028\n",
      "Validation Error: Avg loss: 4599.890137 \n",
      "\n",
      "2023-11-08 13:18:26.178830 Epoch 25, Training loss 5472.22705078125\n",
      "R2 values 0.5723, 0.0035, 0.0262; mean R2=0.2007\n",
      "Validation Error: Avg loss: 4342.958984 \n",
      "\n",
      "2023-11-08 13:18:26.644107 Epoch 26, Training loss 4941.88232421875\n",
      "R2 values 0.4845, 0.0808, 0.0007; mean R2=0.1887\n",
      "Validation Error: Avg loss: 4372.158203 \n",
      "\n",
      "2023-11-08 13:18:27.107807 Epoch 27, Training loss 5031.2607421875\n",
      "R2 values 0.6283, 0.0230, 0.0452; mean R2=0.2321\n",
      "Validation Error: Avg loss: 3940.788330 \n",
      "\n",
      "2023-11-08 13:18:27.588079 Epoch 28, Training loss 4516.28125\n",
      "R2 values 0.3702, 0.1047, 0.0614; mean R2=0.1788\n",
      "Validation Error: Avg loss: 4896.439941 \n",
      "\n",
      "2023-11-08 13:18:28.054515 Epoch 29, Training loss 5317.603515625\n",
      "R2 values 0.4026, 0.0727, 0.0098; mean R2=0.1617\n",
      "Validation Error: Avg loss: 4697.650879 \n",
      "\n",
      "2023-11-08 13:18:28.527275 Epoch 30, Training loss 4940.6845703125\n",
      "R2 values 0.3681, 0.1832, 0.0026; mean R2=0.1846\n",
      "Validation Error: Avg loss: 4783.239746 \n",
      "\n",
      "2023-11-08 13:18:29.003131 Epoch 31, Training loss 5227.5126953125\n",
      "R2 values 0.4494, 0.0330, 0.0169; mean R2=0.1664\n",
      "Validation Error: Avg loss: 4383.201660 \n",
      "\n",
      "2023-11-08 13:18:29.466696 Epoch 32, Training loss 4789.126953125\n",
      "R2 values 0.5121, 0.0129, 0.1175; mean R2=0.2142\n",
      "Validation Error: Avg loss: 4096.890137 \n",
      "\n",
      "2023-11-08 13:18:29.931288 Epoch 33, Training loss 4622.40771484375\n",
      "R2 values 0.4571, 0.0072, 0.0864; mean R2=0.1836\n",
      "Validation Error: Avg loss: 4277.652344 \n",
      "\n",
      "2023-11-08 13:18:30.428946 Epoch 34, Training loss 4506.390625\n",
      "R2 values 0.4389, 0.0109, 0.0343; mean R2=0.1614\n",
      "Validation Error: Avg loss: 4354.653809 \n",
      "\n",
      "2023-11-08 13:18:31.062785 Epoch 35, Training loss 4711.1220703125\n",
      "R2 values 0.5059, 0.0127, 0.0137; mean R2=0.1774\n",
      "Validation Error: Avg loss: 4012.343750 \n",
      "\n",
      "2023-11-08 13:18:31.529829 Epoch 36, Training loss 4890.0146484375\n",
      "R2 values 0.5950, 0.0068, 0.0144; mean R2=0.2054\n",
      "Validation Error: Avg loss: 3617.192383 \n",
      "\n",
      "2023-11-08 13:18:32.022324 Epoch 37, Training loss 4661.34619140625\n",
      "R2 values 0.4622, 0.0077, 0.0215; mean R2=0.1638\n",
      "Validation Error: Avg loss: 4262.279297 \n",
      "\n",
      "2023-11-08 13:18:32.499561 Epoch 38, Training loss 4444.23974609375\n",
      "R2 values 0.5072, 0.0215, 0.0133; mean R2=0.1806\n",
      "Validation Error: Avg loss: 4004.199707 \n",
      "\n",
      "2023-11-08 13:18:32.970075 Epoch 39, Training loss 4958.4130859375\n",
      "R2 values 0.4848, 0.0043, 0.0040; mean R2=0.1644\n",
      "Validation Error: Avg loss: 4096.639648 \n",
      "\n",
      "2023-11-08 13:18:33.445842 Epoch 40, Training loss 4591.08740234375\n",
      "R2 values 0.5185, 0.0257, 0.0019; mean R2=0.1820\n",
      "Validation Error: Avg loss: 3897.142334 \n",
      "\n",
      "2023-11-08 13:18:33.908856 Epoch 41, Training loss 4280.30615234375\n",
      "R2 values 0.4952, 0.0163, 0.0094; mean R2=0.1736\n",
      "Validation Error: Avg loss: 4144.258789 \n",
      "\n",
      "2023-11-08 13:18:34.371931 Epoch 42, Training loss 4068.0478515625\n",
      "R2 values 0.5951, 0.0093, 0.0281; mean R2=0.2109\n",
      "Validation Error: Avg loss: 3827.792236 \n",
      "\n",
      "2023-11-08 13:18:34.833400 Epoch 43, Training loss 4603.509765625\n",
      "R2 values 0.5281, 0.0187, 0.0353; mean R2=0.1940\n",
      "Validation Error: Avg loss: 3852.119873 \n",
      "\n",
      "2023-11-08 13:18:35.322911 Epoch 44, Training loss 4384.71044921875\n",
      "R2 values 0.4881, 0.0000, 0.0366; mean R2=0.1749\n",
      "Validation Error: Avg loss: 4023.232910 \n",
      "\n",
      "2023-11-08 13:18:35.793249 Epoch 45, Training loss 4081.021484375\n",
      "R2 values 0.5383, 0.0089, 0.1136; mean R2=0.2203\n",
      "Validation Error: Avg loss: 3743.336670 \n",
      "\n",
      "2023-11-08 13:18:36.270100 Epoch 46, Training loss 4118.38525390625\n",
      "R2 values 0.4852, 0.0013, 0.0574; mean R2=0.1813\n",
      "Validation Error: Avg loss: 4105.441895 \n",
      "\n",
      "2023-11-08 13:18:36.729815 Epoch 47, Training loss 4162.6142578125\n",
      "R2 values 0.6080, 0.0104, 0.0572; mean R2=0.2252\n",
      "Validation Error: Avg loss: 3504.143799 \n",
      "\n",
      "2023-11-08 13:18:37.193619 Epoch 48, Training loss 4151.47265625\n",
      "R2 values 0.6298, 0.0030, 0.0185; mean R2=0.2171\n",
      "Validation Error: Avg loss: 3474.970459 \n",
      "\n",
      "2023-11-08 13:18:37.669165 Epoch 49, Training loss 4324.9775390625\n",
      "R2 values 0.5399, 0.0023, 0.0302; mean R2=0.1908\n",
      "Validation Error: Avg loss: 3692.798828 \n",
      "\n",
      "2023-11-08 13:18:38.140114 Epoch 50, Training loss 4351.8818359375\n",
      "R2 values 0.5263, 0.0038, 0.0090; mean R2=0.1797\n",
      "Validation Error: Avg loss: 3761.497070 \n",
      "\n",
      "2023-11-08 13:18:38.617655 Epoch 51, Training loss 4081.245361328125\n",
      "R2 values 0.6143, 0.0078, 0.0874; mean R2=0.2365\n",
      "Validation Error: Avg loss: 3309.134277 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:18:39.081006 Epoch 52, Training loss 4403.92724609375\n",
      "R2 values 0.5499, 0.0285, 0.0691; mean R2=0.2158\n",
      "Validation Error: Avg loss: 3635.217773 \n",
      "\n",
      "2023-11-08 13:18:39.551528 Epoch 53, Training loss 3630.735595703125\n",
      "R2 values 0.5450, 0.0014, 0.0614; mean R2=0.2026\n",
      "Validation Error: Avg loss: 3649.206299 \n",
      "\n",
      "2023-11-08 13:18:40.022471 Epoch 54, Training loss 3816.208251953125\n",
      "R2 values 0.6058, 0.0046, 0.0470; mean R2=0.2191\n",
      "Validation Error: Avg loss: 3417.552002 \n",
      "\n",
      "2023-11-08 13:18:40.517059 Epoch 55, Training loss 3984.17578125\n",
      "R2 values 0.5431, 0.0041, 0.0421; mean R2=0.1964\n",
      "Validation Error: Avg loss: 3652.958252 \n",
      "\n",
      "2023-11-08 13:18:41.016945 Epoch 56, Training loss 3909.110107421875\n",
      "R2 values 0.5797, 0.0707, 0.0964; mean R2=0.2489\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 3433.231445 \n",
      "\n",
      "2023-11-08 13:18:41.531908 Epoch 57, Training loss 3770.818115234375\n",
      "R2 values 0.6503, 0.0223, 0.0736; mean R2=0.2487\n",
      "Validation Error: Avg loss: 3255.695557 \n",
      "\n",
      "2023-11-08 13:18:42.056531 Epoch 58, Training loss 3600.679931640625\n",
      "R2 values 0.5892, 0.0152, 0.0978; mean R2=0.2341\n",
      "Validation Error: Avg loss: 3488.927979 \n",
      "\n",
      "2023-11-08 13:18:42.534698 Epoch 59, Training loss 4147.38037109375\n",
      "R2 values 0.4672, 0.0092, 0.0562; mean R2=0.1775\n",
      "Validation Error: Avg loss: 4063.218262 \n",
      "\n",
      "2023-11-08 13:18:43.012166 Epoch 60, Training loss 4149.28466796875\n",
      "R2 values 0.5215, 0.0002, 0.0480; mean R2=0.1899\n",
      "Validation Error: Avg loss: 3741.680176 \n",
      "\n",
      "2023-11-08 13:18:43.487040 Epoch 61, Training loss 3981.30126953125\n",
      "R2 values 0.6338, 0.0395, 0.1489; mean R2=0.2740\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 3089.754395 \n",
      "\n",
      "2023-11-08 13:18:43.996266 Epoch 62, Training loss 3851.20751953125\n",
      "R2 values 0.5761, 0.0062, 0.0615; mean R2=0.2146\n",
      "Validation Error: Avg loss: 3459.607178 \n",
      "\n",
      "2023-11-08 13:18:44.473797 Epoch 63, Training loss 3544.80126953125\n",
      "R2 values 0.5231, 0.0060, 0.0472; mean R2=0.1921\n",
      "Validation Error: Avg loss: 3724.298096 \n",
      "\n",
      "2023-11-08 13:18:44.950999 Epoch 64, Training loss 3844.289794921875\n",
      "R2 values 0.5212, 0.0125, 0.0394; mean R2=0.1910\n",
      "Validation Error: Avg loss: 3768.793457 \n",
      "\n",
      "2023-11-08 13:18:45.482363 Epoch 65, Training loss 3497.016845703125\n",
      "R2 values 0.6480, 0.1196, 0.1342; mean R2=0.3006\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 3241.537842 \n",
      "\n",
      "2023-11-08 13:18:46.021538 Epoch 66, Training loss 3651.116943359375\n",
      "R2 values 0.6641, 0.0074, 0.0755; mean R2=0.2490\n",
      "Validation Error: Avg loss: 3048.068359 \n",
      "\n",
      "2023-11-08 13:18:46.504040 Epoch 67, Training loss 3527.20654296875\n",
      "R2 values 0.6948, 0.0802, 0.1383; mean R2=0.3044\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2763.405029 \n",
      "\n",
      "2023-11-08 13:18:47.019737 Epoch 68, Training loss 3498.17138671875\n",
      "R2 values 0.6406, 0.0446, 0.0811; mean R2=0.2554\n",
      "Validation Error: Avg loss: 3089.328125 \n",
      "\n",
      "2023-11-08 13:18:47.506106 Epoch 69, Training loss 3248.276123046875\n",
      "R2 values 0.6059, 0.0157, 0.1559; mean R2=0.2591\n",
      "Validation Error: Avg loss: 3176.806396 \n",
      "\n",
      "2023-11-08 13:18:47.992500 Epoch 70, Training loss 3465.448486328125\n",
      "R2 values 0.6046, 0.0505, 0.2312; mean R2=0.2955\n",
      "Validation Error: Avg loss: 3200.735352 \n",
      "\n",
      "2023-11-08 13:18:48.481529 Epoch 71, Training loss 3445.3798828125\n",
      "R2 values 0.5470, 0.0045, 0.0911; mean R2=0.2142\n",
      "Validation Error: Avg loss: 3549.877930 \n",
      "\n",
      "2023-11-08 13:18:48.959506 Epoch 72, Training loss 3654.1103515625\n",
      "R2 values 0.6914, 0.0218, 0.0937; mean R2=0.2689\n",
      "Validation Error: Avg loss: 2782.458740 \n",
      "\n",
      "2023-11-08 13:18:49.448571 Epoch 73, Training loss 3200.679931640625\n",
      "R2 values 0.5662, 0.0312, 0.1531; mean R2=0.2502\n",
      "Validation Error: Avg loss: 3396.622314 \n",
      "\n",
      "2023-11-08 13:18:49.944665 Epoch 74, Training loss 3614.27587890625\n",
      "R2 values 0.5748, 0.0146, 0.0374; mean R2=0.2090\n",
      "Validation Error: Avg loss: 3401.145264 \n",
      "\n",
      "2023-11-08 13:18:50.437667 Epoch 75, Training loss 3328.3740234375\n",
      "R2 values 0.6255, 0.0072, 0.0582; mean R2=0.2303\n",
      "Validation Error: Avg loss: 3087.281738 \n",
      "\n",
      "2023-11-08 13:18:50.941078 Epoch 76, Training loss 3256.512939453125\n",
      "R2 values 0.6938, 0.0198, 0.0955; mean R2=0.2697\n",
      "Validation Error: Avg loss: 2737.881592 \n",
      "\n",
      "2023-11-08 13:18:51.417359 Epoch 77, Training loss 3794.34326171875\n",
      "R2 values 0.5723, 0.0091, 0.1164; mean R2=0.2326\n",
      "Validation Error: Avg loss: 3417.580811 \n",
      "\n",
      "2023-11-08 13:18:51.896206 Epoch 78, Training loss 3184.082275390625\n",
      "R2 values 0.5185, 0.0035, 0.1050; mean R2=0.2090\n",
      "Validation Error: Avg loss: 3665.228027 \n",
      "\n",
      "2023-11-08 13:18:52.382116 Epoch 79, Training loss 3512.3583984375\n",
      "R2 values 0.6528, 0.1081, 0.0930; mean R2=0.2846\n",
      "Validation Error: Avg loss: 2831.958008 \n",
      "\n",
      "2023-11-08 13:18:52.870843 Epoch 80, Training loss 3324.054443359375\n",
      "R2 values 0.6511, 0.0004, 0.1902; mean R2=0.2806\n",
      "Validation Error: Avg loss: 2878.996338 \n",
      "\n",
      "2023-11-08 13:18:53.356871 Epoch 81, Training loss 3581.4384765625\n",
      "R2 values 0.5740, 0.0637, 0.1219; mean R2=0.2532\n",
      "Validation Error: Avg loss: 3349.401367 \n",
      "\n",
      "2023-11-08 13:18:53.840007 Epoch 82, Training loss 3445.6494140625\n",
      "R2 values 0.6573, 0.0061, 0.0892; mean R2=0.2509\n",
      "Validation Error: Avg loss: 2887.546631 \n",
      "\n",
      "2023-11-08 13:18:54.321812 Epoch 83, Training loss 3678.430908203125\n",
      "R2 values 0.6406, 0.0009, 0.0923; mean R2=0.2446\n",
      "Validation Error: Avg loss: 2945.658203 \n",
      "\n",
      "2023-11-08 13:18:54.815067 Epoch 84, Training loss 3407.55078125\n",
      "R2 values 0.7726, 0.0246, 0.1400; mean R2=0.3124\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2202.656006 \n",
      "\n",
      "2023-11-08 13:18:55.341821 Epoch 85, Training loss 3052.193359375\n",
      "R2 values 0.7143, 0.0078, 0.1401; mean R2=0.2874\n",
      "Validation Error: Avg loss: 2526.640137 \n",
      "\n",
      "2023-11-08 13:18:55.825332 Epoch 86, Training loss 3005.487548828125\n",
      "R2 values 0.6723, 0.0009, 0.1918; mean R2=0.2883\n",
      "Validation Error: Avg loss: 2702.225342 \n",
      "\n",
      "2023-11-08 13:18:56.349708 Epoch 87, Training loss 3102.186279296875\n",
      "R2 values 0.6563, 0.0009, 0.2465; mean R2=0.3012\n",
      "Validation Error: Avg loss: 2847.189209 \n",
      "\n",
      "2023-11-08 13:18:56.833129 Epoch 88, Training loss 3038.6923828125\n",
      "R2 values 0.7031, 0.0361, 0.1471; mean R2=0.2954\n",
      "Validation Error: Avg loss: 2602.569580 \n",
      "\n",
      "2023-11-08 13:18:57.312667 Epoch 89, Training loss 3132.821533203125\n",
      "R2 values 0.6965, 0.0020, 0.1747; mean R2=0.2911\n",
      "Validation Error: Avg loss: 2652.550293 \n",
      "\n",
      "2023-11-08 13:18:57.791475 Epoch 90, Training loss 3162.11572265625\n",
      "R2 values 0.7647, 0.0036, 0.1677; mean R2=0.3120\n",
      "Validation Error: Avg loss: 2271.081787 \n",
      "\n",
      "2023-11-08 13:18:58.280762 Epoch 91, Training loss 2930.86474609375\n",
      "R2 values 0.7826, 0.0000, 0.1500; mean R2=0.3109\n",
      "Validation Error: Avg loss: 2347.322266 \n",
      "\n",
      "2023-11-08 13:18:58.790606 Epoch 92, Training loss 3242.025146484375\n",
      "R2 values 0.6477, 0.0272, 0.2551; mean R2=0.3100\n",
      "Validation Error: Avg loss: 2875.192383 \n",
      "\n",
      "2023-11-08 13:18:59.297170 Epoch 93, Training loss 3149.3818359375\n",
      "R2 values 0.6559, 0.0005, 0.1600; mean R2=0.2722\n",
      "Validation Error: Avg loss: 2826.120361 \n",
      "\n",
      "2023-11-08 13:18:59.781848 Epoch 94, Training loss 3112.841064453125\n",
      "R2 values 0.6243, 0.0257, 0.1631; mean R2=0.2710\n",
      "Validation Error: Avg loss: 3034.164062 \n",
      "\n",
      "2023-11-08 13:19:00.266747 Epoch 95, Training loss 3210.639404296875\n",
      "R2 values 0.6723, 0.0000, 0.2470; mean R2=0.3065\n",
      "Validation Error: Avg loss: 2713.363281 \n",
      "\n",
      "2023-11-08 13:19:00.756192 Epoch 96, Training loss 3018.196533203125\n",
      "R2 values 0.7287, 0.0385, 0.2516; mean R2=0.3396\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2483.735107 \n",
      "\n",
      "2023-11-08 13:19:01.272402 Epoch 97, Training loss 2744.863525390625\n",
      "R2 values 0.7125, 0.0330, 0.1612; mean R2=0.3022\n",
      "Validation Error: Avg loss: 2570.764893 \n",
      "\n",
      "2023-11-08 13:19:01.758734 Epoch 98, Training loss 2810.9052734375\n",
      "R2 values 0.7284, 0.0000, 0.1123; mean R2=0.2802\n",
      "Validation Error: Avg loss: 2400.768311 \n",
      "\n",
      "2023-11-08 13:19:02.238049 Epoch 99, Training loss 2772.899658203125\n",
      "R2 values 0.6933, 0.0059, 0.1349; mean R2=0.2780\n",
      "Validation Error: Avg loss: 2558.226562 \n",
      "\n",
      "2023-11-08 13:19:02.719333 Epoch 100, Training loss 2977.718994140625\n",
      "R2 values 0.7645, 0.0011, 0.1902; mean R2=0.3186\n",
      "Validation Error: Avg loss: 2271.109863 \n",
      "\n",
      "2023-11-08 13:19:03.199092 Epoch 101, Training loss 3080.861328125\n",
      "R2 values 0.6641, 0.0874, 0.1066; mean R2=0.2860\n",
      "Validation Error: Avg loss: 2837.387939 \n",
      "\n",
      "2023-11-08 13:19:03.682134 Epoch 102, Training loss 3452.5048828125\n",
      "R2 values 0.6314, 0.1272, 0.2354; mean R2=0.3313\n",
      "Validation Error: Avg loss: 2902.783691 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:19:04.148401 Epoch 103, Training loss 2959.397705078125\n",
      "R2 values 0.6263, 0.0357, 0.2510; mean R2=0.3043\n",
      "Validation Error: Avg loss: 2872.160400 \n",
      "\n",
      "2023-11-08 13:19:04.625002 Epoch 104, Training loss 2735.114013671875\n",
      "R2 values 0.7571, 0.0000, 0.3128; mean R2=0.3566\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2056.461426 \n",
      "\n",
      "2023-11-08 13:19:05.137998 Epoch 105, Training loss 2938.509033203125\n",
      "R2 values 0.7291, 0.0278, 0.3061; mean R2=0.3543\n",
      "Validation Error: Avg loss: 2262.302979 \n",
      "\n",
      "2023-11-08 13:19:05.695714 Epoch 106, Training loss 3027.673828125\n",
      "R2 values 0.7295, 0.0001, 0.3506; mean R2=0.3601\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2320.205566 \n",
      "\n",
      "2023-11-08 13:19:06.208792 Epoch 107, Training loss 2862.809326171875\n",
      "R2 values 0.7453, 0.0118, 0.2900; mean R2=0.3490\n",
      "Validation Error: Avg loss: 2221.121582 \n",
      "\n",
      "2023-11-08 13:19:06.690993 Epoch 108, Training loss 2963.8740234375\n",
      "R2 values 0.7457, 0.0141, 0.2335; mean R2=0.3311\n",
      "Validation Error: Avg loss: 2263.822754 \n",
      "\n",
      "2023-11-08 13:19:07.179620 Epoch 109, Training loss 2623.819580078125\n",
      "R2 values 0.6737, 0.0028, 0.2007; mean R2=0.2924\n",
      "Validation Error: Avg loss: 2708.462158 \n",
      "\n",
      "2023-11-08 13:19:07.664055 Epoch 110, Training loss 2568.23828125\n",
      "R2 values 0.8479, 0.0016, 0.3296; mean R2=0.3930\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 1720.610352 \n",
      "\n",
      "2023-11-08 13:19:08.175132 Epoch 111, Training loss 2682.9853515625\n",
      "R2 values 0.7563, 0.0423, 0.2971; mean R2=0.3652\n",
      "Validation Error: Avg loss: 2184.403564 \n",
      "\n",
      "2023-11-08 13:19:08.714659 Epoch 112, Training loss 2698.20751953125\n",
      "R2 values 0.7868, 0.1641, 0.2555; mean R2=0.4021\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 1903.006958 \n",
      "\n",
      "2023-11-08 13:19:09.222766 Epoch 113, Training loss 3142.420166015625\n",
      "R2 values 0.7938, 0.2947, 0.2451; mean R2=0.4445\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 1860.247192 \n",
      "\n",
      "2023-11-08 13:19:09.735908 Epoch 114, Training loss 2590.11474609375\n",
      "R2 values 0.8147, 0.3251, 0.2136; mean R2=0.4511\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 1828.696533 \n",
      "\n",
      "2023-11-08 13:19:10.250528 Epoch 115, Training loss 2687.589599609375\n",
      "R2 values 0.7903, 0.0825, 0.3205; mean R2=0.3977\n",
      "Validation Error: Avg loss: 2036.156006 \n",
      "\n",
      "2023-11-08 13:19:10.745176 Epoch 116, Training loss 2451.718017578125\n",
      "R2 values 0.7226, 0.0320, 0.3443; mean R2=0.3663\n",
      "Validation Error: Avg loss: 2288.633545 \n",
      "\n",
      "2023-11-08 13:19:11.241268 Epoch 117, Training loss 2703.511474609375\n",
      "R2 values 0.7962, 0.0473, 0.3840; mean R2=0.4092\n",
      "Validation Error: Avg loss: 1816.724976 \n",
      "\n",
      "2023-11-08 13:19:11.723618 Epoch 118, Training loss 2387.078369140625\n",
      "R2 values 0.7920, 0.0705, 0.2573; mean R2=0.3733\n",
      "Validation Error: Avg loss: 1956.188354 \n",
      "\n",
      "2023-11-08 13:19:12.207545 Epoch 119, Training loss 2775.409912109375\n",
      "R2 values 0.8087, 0.1864, 0.3305; mean R2=0.4419\n",
      "Validation Error: Avg loss: 1829.160156 \n",
      "\n",
      "2023-11-08 13:19:12.703709 Epoch 120, Training loss 2711.498779296875\n",
      "R2 values 0.7737, 0.2287, 0.3292; mean R2=0.4439\n",
      "Validation Error: Avg loss: 2010.949707 \n",
      "\n",
      "2023-11-08 13:19:13.186701 Epoch 121, Training loss 2478.670654296875\n",
      "R2 values 0.8204, 0.2210, 0.4239; mean R2=0.4884\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 1645.039917 \n",
      "\n",
      "2023-11-08 13:19:13.703750 Epoch 122, Training loss 2434.08154296875\n",
      "R2 values 0.8010, 0.0921, 0.3955; mean R2=0.4295\n",
      "Validation Error: Avg loss: 1727.686279 \n",
      "\n",
      "2023-11-08 13:19:14.198912 Epoch 123, Training loss 2682.5283203125\n",
      "R2 values 0.7777, 0.2200, 0.3699; mean R2=0.4559\n",
      "Validation Error: Avg loss: 1913.694580 \n",
      "\n",
      "2023-11-08 13:19:14.684170 Epoch 124, Training loss 2561.904541015625\n",
      "R2 values 0.8528, 0.0537, 0.3841; mean R2=0.4302\n",
      "Validation Error: Avg loss: 1504.661011 \n",
      "\n",
      "2023-11-08 13:19:15.221748 Epoch 125, Training loss 2409.28662109375\n",
      "R2 values 0.8193, 0.0618, 0.3524; mean R2=0.4112\n",
      "Validation Error: Avg loss: 1749.871094 \n",
      "\n",
      "2023-11-08 13:19:15.698602 Epoch 126, Training loss 2124.055908203125\n",
      "R2 values 0.7897, 0.0217, 0.3373; mean R2=0.3829\n",
      "Validation Error: Avg loss: 1810.310181 \n",
      "\n",
      "2023-11-08 13:19:16.204393 Epoch 127, Training loss 2288.603759765625\n",
      "R2 values 0.7836, 0.0460, 0.4806; mean R2=0.4367\n",
      "Validation Error: Avg loss: 1847.041260 \n",
      "\n",
      "2023-11-08 13:19:16.694403 Epoch 128, Training loss 2512.580322265625\n",
      "R2 values 0.8038, 0.0897, 0.4008; mean R2=0.4314\n",
      "Validation Error: Avg loss: 1781.854004 \n",
      "\n",
      "2023-11-08 13:19:17.189056 Epoch 129, Training loss 2431.3759765625\n",
      "R2 values 0.8800, 0.1225, 0.4431; mean R2=0.4819\n",
      "Validation Error: Avg loss: 1399.414917 \n",
      "\n",
      "2023-11-08 13:19:17.676460 Epoch 130, Training loss 2001.681884765625\n",
      "R2 values 0.7598, 0.2058, 0.3046; mean R2=0.4234\n",
      "Validation Error: Avg loss: 2103.550049 \n",
      "\n",
      "2023-11-08 13:19:18.162848 Epoch 131, Training loss 2253.339599609375\n",
      "R2 values 0.8052, 0.1914, 0.3848; mean R2=0.4605\n",
      "Validation Error: Avg loss: 1662.062134 \n",
      "\n",
      "2023-11-08 13:19:18.637758 Epoch 132, Training loss 2014.649169921875\n",
      "R2 values 0.8269, 0.1315, 0.3750; mean R2=0.4445\n",
      "Validation Error: Avg loss: 1513.817139 \n",
      "\n",
      "2023-11-08 13:19:19.131841 Epoch 133, Training loss 2568.04833984375\n",
      "R2 values 0.8399, 0.1926, 0.3536; mean R2=0.4620\n",
      "Validation Error: Avg loss: 1585.117432 \n",
      "\n",
      "2023-11-08 13:19:19.602997 Epoch 134, Training loss 1961.62109375\n",
      "R2 values 0.7780, 0.1084, 0.3627; mean R2=0.4164\n",
      "Validation Error: Avg loss: 1850.601440 \n",
      "\n",
      "2023-11-08 13:19:20.077195 Epoch 135, Training loss 2360.032958984375\n",
      "R2 values 0.8966, 0.1946, 0.3791; mean R2=0.4901\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 1163.286865 \n",
      "\n",
      "2023-11-08 13:19:20.800127 Epoch 136, Training loss 1939.5634765625\n",
      "R2 values 0.8815, 0.0980, 0.4162; mean R2=0.4652\n",
      "Validation Error: Avg loss: 1243.796021 \n",
      "\n",
      "2023-11-08 13:19:21.341967 Epoch 137, Training loss 1873.2772216796875\n",
      "R2 values 0.9068, 0.3392, 0.4019; mean R2=0.5493\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 1089.424316 \n",
      "\n",
      "2023-11-08 13:19:21.838763 Epoch 138, Training loss 1994.2340087890625\n",
      "R2 values 0.8803, 0.1838, 0.3984; mean R2=0.4875\n",
      "Validation Error: Avg loss: 1295.871338 \n",
      "\n",
      "2023-11-08 13:19:22.291782 Epoch 139, Training loss 1884.4124755859375\n",
      "R2 values 0.8899, 0.1956, 0.4755; mean R2=0.5203\n",
      "Validation Error: Avg loss: 1116.145386 \n",
      "\n",
      "2023-11-08 13:19:22.766675 Epoch 140, Training loss 1763.41552734375\n",
      "R2 values 0.8472, 0.3992, 0.3904; mean R2=0.5456\n",
      "Validation Error: Avg loss: 1437.186279 \n",
      "\n",
      "2023-11-08 13:19:23.237745 Epoch 141, Training loss 1704.7425537109375\n",
      "R2 values 0.8774, 0.2008, 0.4004; mean R2=0.4929\n",
      "Validation Error: Avg loss: 1220.943970 \n",
      "\n",
      "2023-11-08 13:19:23.714385 Epoch 142, Training loss 1688.389892578125\n",
      "R2 values 0.8894, 0.1527, 0.4198; mean R2=0.4873\n",
      "Validation Error: Avg loss: 1221.654419 \n",
      "\n",
      "2023-11-08 13:19:24.185581 Epoch 143, Training loss 1866.1463623046875\n",
      "R2 values 0.8620, 0.1672, 0.4499; mean R2=0.4930\n",
      "Validation Error: Avg loss: 1278.678833 \n",
      "\n",
      "2023-11-08 13:19:24.690525 Epoch 144, Training loss 1645.3843994140625\n",
      "R2 values 0.8702, 0.1922, 0.4702; mean R2=0.5109\n",
      "Validation Error: Avg loss: 1270.891113 \n",
      "\n",
      "2023-11-08 13:19:25.179733 Epoch 145, Training loss 1724.094482421875\n",
      "R2 values 0.8742, 0.0793, 0.4144; mean R2=0.4559\n",
      "Validation Error: Avg loss: 1298.330444 \n",
      "\n",
      "2023-11-08 13:19:25.681240 Epoch 146, Training loss 1592.9105224609375\n",
      "R2 values 0.8919, 0.1344, 0.4849; mean R2=0.5037\n",
      "Validation Error: Avg loss: 1158.575928 \n",
      "\n",
      "2023-11-08 13:19:26.173689 Epoch 147, Training loss 1776.489990234375\n",
      "R2 values 0.8459, 0.1605, 0.4575; mean R2=0.4880\n",
      "Validation Error: Avg loss: 1360.384766 \n",
      "\n",
      "2023-11-08 13:19:26.657008 Epoch 148, Training loss 1671.9608154296875\n",
      "R2 values 0.9101, 0.1386, 0.4463; mean R2=0.4983\n",
      "Validation Error: Avg loss: 954.777832 \n",
      "\n",
      "2023-11-08 13:19:27.141642 Epoch 149, Training loss 1553.8623046875\n",
      "R2 values 0.8970, 0.1344, 0.4648; mean R2=0.4987\n",
      "Validation Error: Avg loss: 1038.410034 \n",
      "\n",
      "2023-11-08 13:19:27.624469 Epoch 150, Training loss 1524.336669921875\n",
      "R2 values 0.9147, 0.1685, 0.5229; mean R2=0.5354\n",
      "Validation Error: Avg loss: 890.725464 \n",
      "\n",
      "2023-11-08 13:19:28.117300 Epoch 151, Training loss 1559.58935546875\n",
      "R2 values 0.9025, 0.2385, 0.4693; mean R2=0.5368\n",
      "Validation Error: Avg loss: 1015.927063 \n",
      "\n",
      "2023-11-08 13:19:28.615164 Epoch 152, Training loss 1562.9925537109375\n",
      "R2 values 0.8849, 0.0463, 0.5343; mean R2=0.4885\n",
      "Validation Error: Avg loss: 1203.242676 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:19:29.092977 Epoch 153, Training loss 1643.4080810546875\n",
      "R2 values 0.9064, 0.1258, 0.4928; mean R2=0.5084\n",
      "Validation Error: Avg loss: 1033.708252 \n",
      "\n",
      "2023-11-08 13:19:29.576818 Epoch 154, Training loss 1410.905517578125\n",
      "R2 values 0.8850, 0.2186, 0.4884; mean R2=0.5307\n",
      "Validation Error: Avg loss: 1116.591431 \n",
      "\n",
      "2023-11-08 13:19:30.067200 Epoch 155, Training loss 1503.48974609375\n",
      "R2 values 0.7496, 0.1551, 0.4892; mean R2=0.4646\n",
      "Validation Error: Avg loss: 2039.151245 \n",
      "\n",
      "2023-11-08 13:19:30.569230 Epoch 156, Training loss 1830.3187255859375\n",
      "R2 values 0.8486, 0.2440, 0.4848; mean R2=0.5258\n",
      "Validation Error: Avg loss: 1341.381958 \n",
      "\n",
      "2023-11-08 13:19:31.039425 Epoch 157, Training loss 1523.293701171875\n",
      "R2 values 0.8250, 0.1768, 0.5085; mean R2=0.5035\n",
      "Validation Error: Avg loss: 1478.372437 \n",
      "\n",
      "2023-11-08 13:19:31.533705 Epoch 158, Training loss 1767.976318359375\n",
      "R2 values 0.8958, 0.0571, 0.5220; mean R2=0.4916\n",
      "Validation Error: Avg loss: 1070.254028 \n",
      "\n",
      "2023-11-08 13:19:31.994756 Epoch 159, Training loss 1362.72998046875\n",
      "R2 values 0.8491, 0.0157, 0.5842; mean R2=0.4830\n",
      "Validation Error: Avg loss: 1475.500488 \n",
      "\n",
      "2023-11-08 13:19:32.660960 Epoch 160, Training loss 1670.6534423828125\n",
      "R2 values 0.8913, 0.1075, 0.4568; mean R2=0.4852\n",
      "Validation Error: Avg loss: 1190.287231 \n",
      "\n",
      "2023-11-08 13:19:33.126489 Epoch 161, Training loss 1177.1448974609375\n",
      "R2 values 0.8881, 0.1848, 0.5317; mean R2=0.5349\n",
      "Validation Error: Avg loss: 1140.724731 \n",
      "\n",
      "2023-11-08 13:19:33.589914 Epoch 162, Training loss 1236.706298828125\n",
      "R2 values 0.8677, 0.1066, 0.5376; mean R2=0.5040\n",
      "Validation Error: Avg loss: 1200.788086 \n",
      "\n",
      "2023-11-08 13:19:34.042089 Epoch 163, Training loss 1274.556884765625\n",
      "R2 values 0.8114, 0.1270, 0.5760; mean R2=0.5048\n",
      "Validation Error: Avg loss: 1570.229004 \n",
      "\n",
      "2023-11-08 13:19:34.506677 Epoch 164, Training loss 1349.9986572265625\n",
      "R2 values 0.9461, 0.1118, 0.5943; mean R2=0.5507\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 710.122070 \n",
      "\n",
      "2023-11-08 13:19:35.001524 Epoch 165, Training loss 1282.1927490234375\n",
      "R2 values 0.9206, 0.1636, 0.5327; mean R2=0.5390\n",
      "Validation Error: Avg loss: 896.772278 \n",
      "\n",
      "2023-11-08 13:19:35.479054 Epoch 166, Training loss 1510.2894287109375\n",
      "R2 values 0.9042, 0.1698, 0.5205; mean R2=0.5315\n",
      "Validation Error: Avg loss: 1075.941650 \n",
      "\n",
      "2023-11-08 13:19:35.969071 Epoch 167, Training loss 1297.3408203125\n",
      "R2 values 0.9014, 0.1201, 0.5960; mean R2=0.5392\n",
      "Validation Error: Avg loss: 1034.443726 \n",
      "\n",
      "2023-11-08 13:19:36.452299 Epoch 168, Training loss 1274.451904296875\n",
      "R2 values 0.9148, 0.2666, 0.5031; mean R2=0.5615\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 924.729614 \n",
      "\n",
      "2023-11-08 13:19:36.952399 Epoch 169, Training loss 1243.620361328125\n",
      "R2 values 0.8683, 0.2877, 0.4326; mean R2=0.5296\n",
      "Validation Error: Avg loss: 1264.580933 \n",
      "\n",
      "2023-11-08 13:19:37.418595 Epoch 170, Training loss 1144.4180908203125\n",
      "R2 values 0.8952, 0.2650, 0.4308; mean R2=0.5303\n",
      "Validation Error: Avg loss: 1069.000244 \n",
      "\n",
      "2023-11-08 13:19:37.883259 Epoch 171, Training loss 1374.7225341796875\n",
      "R2 values 0.8486, 0.1691, 0.6036; mean R2=0.5404\n",
      "Validation Error: Avg loss: 1265.417236 \n",
      "\n",
      "2023-11-08 13:19:38.366882 Epoch 172, Training loss 1257.9542236328125\n",
      "R2 values 0.9124, 0.0881, 0.5343; mean R2=0.5116\n",
      "Validation Error: Avg loss: 912.249939 \n",
      "\n",
      "2023-11-08 13:19:38.844603 Epoch 173, Training loss 1194.06982421875\n",
      "R2 values 0.8906, 0.2433, 0.5838; mean R2=0.5726\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 992.776611 \n",
      "\n",
      "2023-11-08 13:19:39.334974 Epoch 174, Training loss 1500.39990234375\n",
      "R2 values 0.9058, 0.1360, 0.6501; mean R2=0.5640\n",
      "Validation Error: Avg loss: 930.088806 \n",
      "\n",
      "2023-11-08 13:19:39.794646 Epoch 175, Training loss 1177.0216064453125\n",
      "R2 values 0.9186, 0.0447, 0.6838; mean R2=0.5490\n",
      "Validation Error: Avg loss: 894.137329 \n",
      "\n",
      "2023-11-08 13:19:40.542747 Epoch 176, Training loss 1364.694580078125\n",
      "R2 values 0.9046, 0.1401, 0.5861; mean R2=0.5436\n",
      "Validation Error: Avg loss: 946.438354 \n",
      "\n",
      "2023-11-08 13:19:41.063872 Epoch 177, Training loss 1102.1944580078125\n",
      "R2 values 0.8840, 0.2118, 0.6035; mean R2=0.5665\n",
      "Validation Error: Avg loss: 1050.280762 \n",
      "\n",
      "2023-11-08 13:19:41.536327 Epoch 178, Training loss 1190.564208984375\n",
      "R2 values 0.9084, 0.0995, 0.6191; mean R2=0.5423\n",
      "Validation Error: Avg loss: 948.726807 \n",
      "\n",
      "2023-11-08 13:19:42.006746 Epoch 179, Training loss 1308.5831298828125\n",
      "R2 values 0.8845, 0.1576, 0.6584; mean R2=0.5668\n",
      "Validation Error: Avg loss: 1063.327026 \n",
      "\n",
      "2023-11-08 13:19:42.483608 Epoch 180, Training loss 1002.6195678710938\n",
      "R2 values 0.8633, 0.1743, 0.5702; mean R2=0.5360\n",
      "Validation Error: Avg loss: 1286.098145 \n",
      "\n",
      "2023-11-08 13:19:42.957390 Epoch 181, Training loss 1189.260986328125\n",
      "R2 values 0.9045, 0.3834, 0.5943; mean R2=0.6274\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 931.171631 \n",
      "\n",
      "2023-11-08 13:19:43.462932 Epoch 182, Training loss 1126.526123046875\n",
      "R2 values 0.8811, 0.2440, 0.5976; mean R2=0.5742\n",
      "Validation Error: Avg loss: 1113.274170 \n",
      "\n",
      "2023-11-08 13:19:43.969301 Epoch 183, Training loss 1065.357421875\n",
      "R2 values 0.8855, 0.1325, 0.5698; mean R2=0.5293\n",
      "Validation Error: Avg loss: 1118.111328 \n",
      "\n",
      "2023-11-08 13:19:44.443751 Epoch 184, Training loss 1141.26953125\n",
      "R2 values 0.9131, 0.1808, 0.6693; mean R2=0.5877\n",
      "Validation Error: Avg loss: 864.914246 \n",
      "\n",
      "2023-11-08 13:19:44.924479 Epoch 185, Training loss 1101.2464599609375\n",
      "R2 values 0.8571, 0.2009, 0.5983; mean R2=0.5521\n",
      "Validation Error: Avg loss: 1223.521118 \n",
      "\n",
      "2023-11-08 13:19:45.395926 Epoch 186, Training loss 1289.74755859375\n",
      "R2 values 0.8875, 0.2441, 0.6703; mean R2=0.6006\n",
      "Validation Error: Avg loss: 1049.491089 \n",
      "\n",
      "2023-11-08 13:19:45.875233 Epoch 187, Training loss 1098.8380126953125\n",
      "R2 values 0.8555, 0.0653, 0.6660; mean R2=0.5289\n",
      "Validation Error: Avg loss: 1269.750488 \n",
      "\n",
      "2023-11-08 13:19:46.349572 Epoch 188, Training loss 1380.0850830078125\n",
      "R2 values 0.8967, 0.1091, 0.5890; mean R2=0.5316\n",
      "Validation Error: Avg loss: 1017.243042 \n",
      "\n",
      "2023-11-08 13:19:46.823780 Epoch 189, Training loss 1291.11962890625\n",
      "R2 values 0.9195, 0.1706, 0.6648; mean R2=0.5850\n",
      "Validation Error: Avg loss: 797.517944 \n",
      "\n",
      "2023-11-08 13:19:47.292539 Epoch 190, Training loss 1244.96044921875\n",
      "R2 values 0.8947, 0.1410, 0.6882; mean R2=0.5746\n",
      "Validation Error: Avg loss: 962.779968 \n",
      "\n",
      "2023-11-08 13:19:47.751647 Epoch 191, Training loss 1084.8341064453125\n",
      "R2 values 0.8592, 0.0779, 0.7195; mean R2=0.5522\n",
      "Validation Error: Avg loss: 1350.949585 \n",
      "\n",
      "2023-11-08 13:19:48.218484 Epoch 192, Training loss 1103.2421875\n",
      "R2 values 0.9476, 0.0720, 0.5834; mean R2=0.5343\n",
      "Validation Error: Avg loss: 871.683777 \n",
      "\n",
      "2023-11-08 13:19:48.688922 Epoch 193, Training loss 932.4768676757812\n",
      "R2 values 0.9302, 0.1114, 0.6493; mean R2=0.5636\n",
      "Validation Error: Avg loss: 944.170959 \n",
      "\n",
      "2023-11-08 13:19:49.156681 Epoch 194, Training loss 1049.1622314453125\n",
      "R2 values 0.9005, 0.1865, 0.6670; mean R2=0.5847\n",
      "Validation Error: Avg loss: 911.557983 \n",
      "\n",
      "2023-11-08 13:19:49.634665 Epoch 195, Training loss 1102.828125\n",
      "R2 values 0.9273, 0.1712, 0.7043; mean R2=0.6010\n",
      "Validation Error: Avg loss: 918.914795 \n",
      "\n",
      "2023-11-08 13:19:50.107689 Epoch 196, Training loss 1045.95263671875\n",
      "R2 values 0.9344, 0.0788, 0.6847; mean R2=0.5660\n",
      "Validation Error: Avg loss: 769.671204 \n",
      "\n",
      "2023-11-08 13:19:50.654583 Epoch 197, Training loss 895.8095092773438\n",
      "R2 values 0.9120, 0.0582, 0.6364; mean R2=0.5355\n",
      "Validation Error: Avg loss: 921.321228 \n",
      "\n",
      "2023-11-08 13:19:51.128597 Epoch 198, Training loss 1077.244140625\n",
      "R2 values 0.8860, 0.0172, 0.6056; mean R2=0.5029\n",
      "Validation Error: Avg loss: 1215.258789 \n",
      "\n",
      "2023-11-08 13:19:51.597479 Epoch 199, Training loss 1052.247314453125\n",
      "R2 values 0.9274, 0.0321, 0.6946; mean R2=0.5513\n",
      "Validation Error: Avg loss: 817.551208 \n",
      "\n",
      "2023-11-08 13:19:52.066908 Epoch 200, Training loss 1055.2431640625\n",
      "R2 values 0.9555, 0.1101, 0.7270; mean R2=0.5975\n",
      "Validation Error: Avg loss: 605.100098 \n",
      "\n",
      "2023-11-08 13:19:52.542382 Epoch 201, Training loss 1007.9781494140625\n",
      "R2 values 0.9338, 0.2256, 0.6859; mean R2=0.6151\n",
      "Validation Error: Avg loss: 701.722778 \n",
      "\n",
      "2023-11-08 13:19:53.015309 Epoch 202, Training loss 949.34814453125\n",
      "R2 values 0.9225, 0.1253, 0.6736; mean R2=0.5738\n",
      "Validation Error: Avg loss: 870.750183 \n",
      "\n",
      "2023-11-08 13:19:53.497401 Epoch 203, Training loss 1100.2755126953125\n",
      "R2 values 0.9330, 0.1055, 0.7220; mean R2=0.5868\n",
      "Validation Error: Avg loss: 731.965210 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:19:54.117328 Epoch 204, Training loss 823.2910766601562\n",
      "R2 values 0.9456, 0.1758, 0.7460; mean R2=0.6225\n",
      "Validation Error: Avg loss: 743.404907 \n",
      "\n",
      "2023-11-08 13:19:54.573234 Epoch 205, Training loss 842.1994018554688\n",
      "R2 values 0.9656, 0.1121, 0.6961; mean R2=0.5913\n",
      "Validation Error: Avg loss: 508.312866 \n",
      "\n",
      "2023-11-08 13:19:55.035461 Epoch 206, Training loss 808.1808471679688\n",
      "R2 values 0.9386, 0.1835, 0.6890; mean R2=0.6037\n",
      "Validation Error: Avg loss: 725.160767 \n",
      "\n",
      "2023-11-08 13:19:55.497829 Epoch 207, Training loss 896.2237548828125\n",
      "R2 values 0.8876, 0.0956, 0.7052; mean R2=0.5628\n",
      "Validation Error: Avg loss: 999.763550 \n",
      "\n",
      "2023-11-08 13:19:55.985066 Epoch 208, Training loss 808.3256225585938\n",
      "R2 values 0.9430, 0.1514, 0.6819; mean R2=0.5921\n",
      "Validation Error: Avg loss: 701.146118 \n",
      "\n",
      "2023-11-08 13:19:56.470415 Epoch 209, Training loss 873.6314697265625\n",
      "R2 values 0.9285, 0.1564, 0.6270; mean R2=0.5706\n",
      "Validation Error: Avg loss: 784.489868 \n",
      "\n",
      "2023-11-08 13:19:57.003854 Epoch 210, Training loss 834.4083862304688\n",
      "R2 values 0.9399, 0.1116, 0.6585; mean R2=0.5700\n",
      "Validation Error: Avg loss: 690.424622 \n",
      "\n",
      "2023-11-08 13:19:57.486387 Epoch 211, Training loss 847.1312255859375\n",
      "R2 values 0.9097, 0.0894, 0.6487; mean R2=0.5493\n",
      "Validation Error: Avg loss: 1081.759277 \n",
      "\n",
      "2023-11-08 13:19:57.943402 Epoch 212, Training loss 864.5623779296875\n",
      "R2 values 0.9344, 0.1311, 0.6577; mean R2=0.5744\n",
      "Validation Error: Avg loss: 748.817505 \n",
      "\n",
      "2023-11-08 13:19:58.416789 Epoch 213, Training loss 859.454833984375\n",
      "R2 values 0.9347, 0.2774, 0.6509; mean R2=0.6210\n",
      "Validation Error: Avg loss: 706.498840 \n",
      "\n",
      "2023-11-08 13:19:58.885805 Epoch 214, Training loss 973.025146484375\n",
      "R2 values 0.9410, 0.2815, 0.6915; mean R2=0.6380\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 614.027100 \n",
      "\n",
      "2023-11-08 13:19:59.378762 Epoch 215, Training loss 758.9210815429688\n",
      "R2 values 0.9160, 0.3902, 0.6595; mean R2=0.6552\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 777.444763 \n",
      "\n",
      "2023-11-08 13:19:59.872464 Epoch 216, Training loss 759.2017211914062\n",
      "R2 values 0.9106, 0.4006, 0.6276; mean R2=0.6463\n",
      "Validation Error: Avg loss: 920.580933 \n",
      "\n",
      "2023-11-08 13:20:00.490980 Epoch 217, Training loss 697.9938354492188\n",
      "R2 values 0.9188, 0.3679, 0.7208; mean R2=0.6691\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 776.401733 \n",
      "\n",
      "2023-11-08 13:20:00.986477 Epoch 218, Training loss 815.7908325195312\n",
      "R2 values 0.9215, 0.2022, 0.6665; mean R2=0.5967\n",
      "Validation Error: Avg loss: 904.023926 \n",
      "\n",
      "2023-11-08 13:20:01.507900 Epoch 219, Training loss 774.2972412109375\n",
      "R2 values 0.9244, 0.3315, 0.7001; mean R2=0.6520\n",
      "Validation Error: Avg loss: 783.046387 \n",
      "\n",
      "2023-11-08 13:20:01.978398 Epoch 220, Training loss 793.0647583007812\n",
      "R2 values 0.9083, 0.3382, 0.6453; mean R2=0.6306\n",
      "Validation Error: Avg loss: 863.399536 \n",
      "\n",
      "2023-11-08 13:20:02.616241 Epoch 221, Training loss 836.3968505859375\n",
      "R2 values 0.9227, 0.3516, 0.7201; mean R2=0.6648\n",
      "Validation Error: Avg loss: 760.751343 \n",
      "\n",
      "2023-11-08 13:20:03.282104 Epoch 222, Training loss 959.9603881835938\n",
      "R2 values 0.9236, 0.3409, 0.7344; mean R2=0.6663\n",
      "Validation Error: Avg loss: 817.848206 \n",
      "\n",
      "2023-11-08 13:20:03.731984 Epoch 223, Training loss 844.6491088867188\n",
      "R2 values 0.9095, 0.2830, 0.6893; mean R2=0.6273\n",
      "Validation Error: Avg loss: 952.623169 \n",
      "\n",
      "2023-11-08 13:20:04.184812 Epoch 224, Training loss 798.1712646484375\n",
      "R2 values 0.8924, 0.2218, 0.6368; mean R2=0.5837\n",
      "Validation Error: Avg loss: 1021.488037 \n",
      "\n",
      "2023-11-08 13:20:04.624913 Epoch 225, Training loss 778.6103515625\n",
      "R2 values 0.9150, 0.2480, 0.6752; mean R2=0.6127\n",
      "Validation Error: Avg loss: 896.283630 \n",
      "\n",
      "2023-11-08 13:20:05.081688 Epoch 226, Training loss 1082.5709228515625\n",
      "R2 values 0.9077, 0.4297, 0.6924; mean R2=0.6766\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 803.515869 \n",
      "\n",
      "2023-11-08 13:20:05.571815 Epoch 227, Training loss 1127.35400390625\n",
      "R2 values 0.9269, 0.4700, 0.7624; mean R2=0.7197\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 695.462585 \n",
      "\n",
      "2023-11-08 13:20:06.038988 Epoch 228, Training loss 819.5731201171875\n",
      "R2 values 0.9124, 0.3416, 0.6244; mean R2=0.6261\n",
      "Validation Error: Avg loss: 837.953979 \n",
      "\n",
      "2023-11-08 13:20:06.560172 Epoch 229, Training loss 840.8573608398438\n",
      "R2 values 0.8852, 0.4887, 0.7537; mean R2=0.7092\n",
      "Validation Error: Avg loss: 1004.493896 \n",
      "\n",
      "2023-11-08 13:20:07.009375 Epoch 230, Training loss 835.0447387695312\n",
      "R2 values 0.9055, 0.5485, 0.7459; mean R2=0.7333\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 890.089905 \n",
      "\n",
      "2023-11-08 13:20:07.484304 Epoch 231, Training loss 882.6151123046875\n",
      "R2 values 0.9229, 0.4997, 0.6576; mean R2=0.6934\n",
      "Validation Error: Avg loss: 742.522156 \n",
      "\n",
      "2023-11-08 13:20:07.966606 Epoch 232, Training loss 627.6410522460938\n",
      "R2 values 0.9315, 0.5159, 0.7413; mean R2=0.7296\n",
      "Validation Error: Avg loss: 688.260742 \n",
      "\n",
      "2023-11-08 13:20:08.423629 Epoch 233, Training loss 967.0680541992188\n",
      "R2 values 0.9533, 0.4379, 0.7552; mean R2=0.7155\n",
      "Validation Error: Avg loss: 490.552032 \n",
      "\n",
      "2023-11-08 13:20:08.946393 Epoch 234, Training loss 817.87548828125\n",
      "R2 values 0.9350, 0.5045, 0.7690; mean R2=0.7362\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 615.550110 \n",
      "\n",
      "2023-11-08 13:20:09.418494 Epoch 235, Training loss 887.6451416015625\n",
      "R2 values 0.8810, 0.4208, 0.7172; mean R2=0.6730\n",
      "Validation Error: Avg loss: 1031.167358 \n",
      "\n",
      "2023-11-08 13:20:09.874834 Epoch 236, Training loss 678.6980590820312\n",
      "R2 values 0.9124, 0.2613, 0.7819; mean R2=0.6519\n",
      "Validation Error: Avg loss: 912.916748 \n",
      "\n",
      "2023-11-08 13:20:10.325798 Epoch 237, Training loss 706.5448608398438\n",
      "R2 values 0.8874, 0.2523, 0.7035; mean R2=0.6144\n",
      "Validation Error: Avg loss: 1050.023926 \n",
      "\n",
      "2023-11-08 13:20:10.782406 Epoch 238, Training loss 821.6312866210938\n",
      "R2 values 0.8998, 0.2853, 0.7321; mean R2=0.6391\n",
      "Validation Error: Avg loss: 886.136658 \n",
      "\n",
      "2023-11-08 13:20:11.234328 Epoch 239, Training loss 845.854736328125\n",
      "R2 values 0.9370, 0.4742, 0.7239; mean R2=0.7117\n",
      "Validation Error: Avg loss: 643.489563 \n",
      "\n",
      "2023-11-08 13:20:11.698161 Epoch 240, Training loss 675.904052734375\n",
      "R2 values 0.9511, 0.4888, 0.6484; mean R2=0.6961\n",
      "Validation Error: Avg loss: 591.351379 \n",
      "\n",
      "2023-11-08 13:20:12.269346 Epoch 241, Training loss 804.3662719726562\n",
      "R2 values 0.9618, 0.4021, 0.7262; mean R2=0.6967\n",
      "Validation Error: Avg loss: 520.938965 \n",
      "\n",
      "2023-11-08 13:20:12.725661 Epoch 242, Training loss 607.1467895507812\n",
      "R2 values 0.9058, 0.4155, 0.7021; mean R2=0.6745\n",
      "Validation Error: Avg loss: 907.418335 \n",
      "\n",
      "2023-11-08 13:20:13.174153 Epoch 243, Training loss 700.6941528320312\n",
      "R2 values 0.9120, 0.3105, 0.6545; mean R2=0.6257\n",
      "Validation Error: Avg loss: 929.953491 \n",
      "\n",
      "2023-11-08 13:20:13.633688 Epoch 244, Training loss 542.4268798828125\n",
      "R2 values 0.9259, 0.3446, 0.6793; mean R2=0.6499\n",
      "Validation Error: Avg loss: 770.316467 \n",
      "\n",
      "2023-11-08 13:20:14.085068 Epoch 245, Training loss 621.8414916992188\n",
      "R2 values 0.9198, 0.4423, 0.7249; mean R2=0.6957\n",
      "Validation Error: Avg loss: 746.121033 \n",
      "\n",
      "2023-11-08 13:20:14.538074 Epoch 246, Training loss 910.4561157226562\n",
      "R2 values 0.9267, 0.3772, 0.7043; mean R2=0.6694\n",
      "Validation Error: Avg loss: 684.733215 \n",
      "\n",
      "2023-11-08 13:20:15.243389 Epoch 247, Training loss 578.7819213867188\n",
      "R2 values 0.9156, 0.2833, 0.6663; mean R2=0.6218\n",
      "Validation Error: Avg loss: 794.581360 \n",
      "\n",
      "2023-11-08 13:20:15.700022 Epoch 248, Training loss 826.899658203125\n",
      "R2 values 0.9364, 0.3430, 0.7154; mean R2=0.6649\n",
      "Validation Error: Avg loss: 668.252808 \n",
      "\n",
      "2023-11-08 13:20:16.158610 Epoch 249, Training loss 707.4454345703125\n",
      "R2 values 0.9368, 0.4337, 0.7591; mean R2=0.7099\n",
      "Validation Error: Avg loss: 612.144470 \n",
      "\n",
      "2023-11-08 13:20:16.614053 Epoch 250, Training loss 565.2759399414062\n",
      "R2 values 0.9404, 0.4202, 0.7054; mean R2=0.6886\n",
      "Validation Error: Avg loss: 608.492493 \n",
      "\n",
      "2023-11-08 13:20:17.054958 Epoch 251, Training loss 542.6627807617188\n",
      "R2 values 0.8966, 0.5044, 0.7640; mean R2=0.7217\n",
      "Validation Error: Avg loss: 879.255920 \n",
      "\n",
      "2023-11-08 13:20:17.509072 Epoch 252, Training loss 706.97216796875\n",
      "R2 values 0.9545, 0.5143, 0.7413; mean R2=0.7367\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 534.252563 \n",
      "\n",
      "2023-11-08 13:20:17.991010 Epoch 253, Training loss 714.3636474609375\n",
      "R2 values 0.9330, 0.4664, 0.7820; mean R2=0.7272\n",
      "Validation Error: Avg loss: 656.414429 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:20:18.533743 Epoch 254, Training loss 697.173828125\n",
      "R2 values 0.9564, 0.5324, 0.7393; mean R2=0.7427\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 494.484009 \n",
      "\n",
      "2023-11-08 13:20:19.003434 Epoch 255, Training loss 615.9353637695312\n",
      "R2 values 0.9413, 0.4459, 0.7035; mean R2=0.6969\n",
      "Validation Error: Avg loss: 616.154114 \n",
      "\n",
      "2023-11-08 13:20:19.457087 Epoch 256, Training loss 650.417724609375\n",
      "R2 values 0.9347, 0.4947, 0.7548; mean R2=0.7281\n",
      "Validation Error: Avg loss: 755.187256 \n",
      "\n",
      "2023-11-08 13:20:19.972572 Epoch 257, Training loss 681.9623413085938\n",
      "R2 values 0.9231, 0.3759, 0.7264; mean R2=0.6751\n",
      "Validation Error: Avg loss: 743.187073 \n",
      "\n",
      "2023-11-08 13:20:20.424784 Epoch 258, Training loss 708.5933227539062\n",
      "R2 values 0.9140, 0.4484, 0.7389; mean R2=0.7004\n",
      "Validation Error: Avg loss: 763.635986 \n",
      "\n",
      "2023-11-08 13:20:20.879716 Epoch 259, Training loss 855.6239624023438\n",
      "R2 values 0.9234, 0.4194, 0.7638; mean R2=0.7022\n",
      "Validation Error: Avg loss: 672.463196 \n",
      "\n",
      "2023-11-08 13:20:21.330108 Epoch 260, Training loss 530.9406127929688\n",
      "R2 values 0.9412, 0.4941, 0.7685; mean R2=0.7346\n",
      "Validation Error: Avg loss: 778.057434 \n",
      "\n",
      "2023-11-08 13:20:21.792944 Epoch 261, Training loss 789.4483642578125\n",
      "R2 values 0.9021, 0.5812, 0.7907; mean R2=0.7580\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 835.116943 \n",
      "\n",
      "2023-11-08 13:20:22.379782 Epoch 262, Training loss 720.79296875\n",
      "R2 values 0.9157, 0.4918, 0.7374; mean R2=0.7150\n",
      "Validation Error: Avg loss: 851.072815 \n",
      "\n",
      "2023-11-08 13:20:22.829063 Epoch 263, Training loss 621.0672607421875\n",
      "R2 values 0.9388, 0.5496, 0.7552; mean R2=0.7479\n",
      "Validation Error: Avg loss: 759.897583 \n",
      "\n",
      "2023-11-08 13:20:23.344523 Epoch 264, Training loss 631.1716918945312\n",
      "R2 values 0.9361, 0.5838, 0.7189; mean R2=0.7463\n",
      "Validation Error: Avg loss: 617.424316 \n",
      "\n",
      "2023-11-08 13:20:23.788616 Epoch 265, Training loss 487.3558654785156\n",
      "R2 values 0.9466, 0.5285, 0.7453; mean R2=0.7401\n",
      "Validation Error: Avg loss: 526.184204 \n",
      "\n",
      "2023-11-08 13:20:24.241625 Epoch 266, Training loss 631.8726806640625\n",
      "R2 values 0.9507, 0.6183, 0.7478; mean R2=0.7723\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 515.544556 \n",
      "\n",
      "2023-11-08 13:20:24.721825 Epoch 267, Training loss 613.0921020507812\n",
      "R2 values 0.9402, 0.6085, 0.7826; mean R2=0.7771\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 552.221191 \n",
      "\n",
      "2023-11-08 13:20:25.190637 Epoch 268, Training loss 534.7066650390625\n",
      "R2 values 0.9137, 0.5950, 0.7453; mean R2=0.7513\n",
      "Validation Error: Avg loss: 779.002686 \n",
      "\n",
      "2023-11-08 13:20:25.648998 Epoch 269, Training loss 610.8362426757812\n",
      "R2 values 0.9424, 0.4092, 0.6852; mean R2=0.6789\n",
      "Validation Error: Avg loss: 734.810425 \n",
      "\n",
      "2023-11-08 13:20:26.123981 Epoch 270, Training loss 455.9032897949219\n",
      "R2 values 0.9256, 0.5368, 0.7357; mean R2=0.7327\n",
      "Validation Error: Avg loss: 735.543030 \n",
      "\n",
      "2023-11-08 13:20:26.590011 Epoch 271, Training loss 591.1282958984375\n",
      "R2 values 0.9115, 0.6019, 0.7258; mean R2=0.7464\n",
      "Validation Error: Avg loss: 752.509277 \n",
      "\n",
      "2023-11-08 13:20:27.040051 Epoch 272, Training loss 534.76220703125\n",
      "R2 values 0.9314, 0.5392, 0.7219; mean R2=0.7308\n",
      "Validation Error: Avg loss: 622.079773 \n",
      "\n",
      "2023-11-08 13:20:27.483971 Epoch 273, Training loss 547.616943359375\n",
      "R2 values 0.9344, 0.5976, 0.7486; mean R2=0.7602\n",
      "Validation Error: Avg loss: 590.910156 \n",
      "\n",
      "2023-11-08 13:20:28.107701 Epoch 274, Training loss 592.3573608398438\n",
      "R2 values 0.9434, 0.4724, 0.7785; mean R2=0.7314\n",
      "Validation Error: Avg loss: 585.602905 \n",
      "\n",
      "2023-11-08 13:20:28.634267 Epoch 275, Training loss 478.13421630859375\n",
      "R2 values 0.9495, 0.4527, 0.7661; mean R2=0.7228\n",
      "Validation Error: Avg loss: 550.688660 \n",
      "\n",
      "2023-11-08 13:20:29.183559 Epoch 276, Training loss 601.1015625\n",
      "R2 values 0.9544, 0.5569, 0.7660; mean R2=0.7591\n",
      "Validation Error: Avg loss: 552.238037 \n",
      "\n",
      "2023-11-08 13:20:29.644190 Epoch 277, Training loss 688.8141479492188\n",
      "R2 values 0.9416, 0.6562, 0.7769; mean R2=0.7915\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 585.619019 \n",
      "\n",
      "2023-11-08 13:20:30.107187 Epoch 278, Training loss 530.6690673828125\n",
      "R2 values 0.9264, 0.5502, 0.7758; mean R2=0.7508\n",
      "Validation Error: Avg loss: 642.067322 \n",
      "\n",
      "2023-11-08 13:20:30.555946 Epoch 279, Training loss 545.3477172851562\n",
      "R2 values 0.9528, 0.5186, 0.7892; mean R2=0.7535\n",
      "Validation Error: Avg loss: 524.033752 \n",
      "\n",
      "2023-11-08 13:20:31.009040 Epoch 280, Training loss 555.8375854492188\n",
      "R2 values 0.9185, 0.4921, 0.7525; mean R2=0.7210\n",
      "Validation Error: Avg loss: 758.100464 \n",
      "\n",
      "2023-11-08 13:20:31.469892 Epoch 281, Training loss 604.0582275390625\n",
      "R2 values 0.9197, 0.5567, 0.8146; mean R2=0.7636\n",
      "Validation Error: Avg loss: 727.908020 \n",
      "\n",
      "2023-11-08 13:20:31.950974 Epoch 282, Training loss 574.9313354492188\n",
      "R2 values 0.9173, 0.6306, 0.7800; mean R2=0.7760\n",
      "Validation Error: Avg loss: 735.562378 \n",
      "\n",
      "2023-11-08 13:20:32.400227 Epoch 283, Training loss 452.9939270019531\n",
      "R2 values 0.9472, 0.6555, 0.7715; mean R2=0.7914\n",
      "Validation Error: Avg loss: 626.460327 \n",
      "\n",
      "2023-11-08 13:20:32.851872 Epoch 284, Training loss 527.8046264648438\n",
      "R2 values 0.9373, 0.6084, 0.7840; mean R2=0.7766\n",
      "Validation Error: Avg loss: 567.615662 \n",
      "\n",
      "2023-11-08 13:20:33.292653 Epoch 285, Training loss 560.50048828125\n",
      "R2 values 0.9480, 0.5168, 0.7734; mean R2=0.7461\n",
      "Validation Error: Avg loss: 539.215942 \n",
      "\n",
      "2023-11-08 13:20:33.740682 Epoch 286, Training loss 558.2423095703125\n",
      "R2 values 0.9612, 0.6906, 0.7256; mean R2=0.7924\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 693.088623 \n",
      "\n",
      "2023-11-08 13:20:34.219502 Epoch 287, Training loss 633.4365234375\n",
      "R2 values 0.9233, 0.5248, 0.6873; mean R2=0.7118\n",
      "Validation Error: Avg loss: 739.010742 \n",
      "\n",
      "2023-11-08 13:20:34.674085 Epoch 288, Training loss 452.2205505371094\n",
      "R2 values 0.9343, 0.6417, 0.7259; mean R2=0.7673\n",
      "Validation Error: Avg loss: 659.785645 \n",
      "\n",
      "2023-11-08 13:20:35.116711 Epoch 289, Training loss 531.1749267578125\n",
      "R2 values 0.9272, 0.5951, 0.8125; mean R2=0.7783\n",
      "Validation Error: Avg loss: 793.672852 \n",
      "\n",
      "2023-11-08 13:20:35.561892 Epoch 290, Training loss 558.7832641601562\n",
      "R2 values 0.9358, 0.5132, 0.7360; mean R2=0.7283\n",
      "Validation Error: Avg loss: 652.512024 \n",
      "\n",
      "2023-11-08 13:20:36.028417 Epoch 291, Training loss 467.1944274902344\n",
      "R2 values 0.9455, 0.4563, 0.7277; mean R2=0.7098\n",
      "Validation Error: Avg loss: 671.226929 \n",
      "\n",
      "2023-11-08 13:20:36.478929 Epoch 292, Training loss 609.1212158203125\n",
      "R2 values 0.9400, 0.6135, 0.8087; mean R2=0.7874\n",
      "Validation Error: Avg loss: 542.613159 \n",
      "\n",
      "2023-11-08 13:20:36.940513 Epoch 293, Training loss 435.5054016113281\n",
      "R2 values 0.9501, 0.5739, 0.7750; mean R2=0.7663\n",
      "Validation Error: Avg loss: 689.763000 \n",
      "\n",
      "2023-11-08 13:20:37.711921 Epoch 294, Training loss 549.9407348632812\n",
      "R2 values 0.9447, 0.5809, 0.7634; mean R2=0.7630\n",
      "Validation Error: Avg loss: 590.128906 \n",
      "\n",
      "2023-11-08 13:20:38.167575 Epoch 295, Training loss 422.6488952636719\n",
      "R2 values 0.9555, 0.6109, 0.7519; mean R2=0.7728\n",
      "Validation Error: Avg loss: 515.846191 \n",
      "\n",
      "2023-11-08 13:20:38.611708 Epoch 296, Training loss 607.4298706054688\n",
      "R2 values 0.9358, 0.4854, 0.7412; mean R2=0.7208\n",
      "Validation Error: Avg loss: 643.315186 \n",
      "\n",
      "2023-11-08 13:20:39.055591 Epoch 297, Training loss 413.3529052734375\n",
      "R2 values 0.9259, 0.6489, 0.8426; mean R2=0.8058\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 633.396362 \n",
      "\n",
      "2023-11-08 13:20:39.539406 Epoch 298, Training loss 499.96697998046875\n",
      "R2 values 0.9245, 0.5753, 0.8007; mean R2=0.7668\n",
      "Validation Error: Avg loss: 734.860229 \n",
      "\n",
      "2023-11-08 13:20:39.984229 Epoch 299, Training loss 561.9329223632812\n",
      "R2 values 0.9263, 0.5427, 0.7490; mean R2=0.7393\n",
      "Validation Error: Avg loss: 659.057617 \n",
      "\n",
      "2023-11-08 13:20:40.491900 Epoch 300, Training loss 582.957763671875\n",
      "R2 values 0.9201, 0.5815, 0.7254; mean R2=0.7423\n",
      "Validation Error: Avg loss: 698.107056 \n",
      "\n",
      "2023-11-08 13:20:41.022329 Epoch 301, Training loss 468.92822265625\n",
      "R2 values 0.9444, 0.5394, 0.7707; mean R2=0.7515\n",
      "Validation Error: Avg loss: 571.517639 \n",
      "\n",
      "2023-11-08 13:20:41.545725 Epoch 302, Training loss 475.7342529296875\n",
      "R2 values 0.9134, 0.5816, 0.7682; mean R2=0.7544\n",
      "Validation Error: Avg loss: 846.989136 \n",
      "\n",
      "2023-11-08 13:20:42.010612 Epoch 303, Training loss 479.75115966796875\n",
      "R2 values 0.9528, 0.5085, 0.7769; mean R2=0.7461\n",
      "Validation Error: Avg loss: 604.235168 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:20:42.467447 Epoch 304, Training loss 438.1043701171875\n",
      "R2 values 0.9212, 0.6134, 0.7926; mean R2=0.7757\n",
      "Validation Error: Avg loss: 669.173096 \n",
      "\n",
      "2023-11-08 13:20:42.917887 Epoch 305, Training loss 487.51605224609375\n",
      "R2 values 0.9425, 0.5958, 0.7907; mean R2=0.7763\n",
      "Validation Error: Avg loss: 570.859924 \n",
      "\n",
      "2023-11-08 13:20:43.374515 Epoch 306, Training loss 541.390869140625\n",
      "R2 values 0.9175, 0.6469, 0.8080; mean R2=0.7908\n",
      "Validation Error: Avg loss: 901.312012 \n",
      "\n",
      "2023-11-08 13:20:43.820505 Epoch 307, Training loss 606.535400390625\n",
      "R2 values 0.8947, 0.5992, 0.7687; mean R2=0.7542\n",
      "Validation Error: Avg loss: 938.471069 \n",
      "\n",
      "2023-11-08 13:20:44.266069 Epoch 308, Training loss 575.5867919921875\n",
      "R2 values 0.9226, 0.5509, 0.7108; mean R2=0.7281\n",
      "Validation Error: Avg loss: 840.075500 \n",
      "\n",
      "2023-11-08 13:20:44.711872 Epoch 309, Training loss 518.2640991210938\n",
      "R2 values 0.9574, 0.5875, 0.7620; mean R2=0.7690\n",
      "Validation Error: Avg loss: 469.204407 \n",
      "\n",
      "2023-11-08 13:20:45.159011 Epoch 310, Training loss 504.7650451660156\n",
      "R2 values 0.9417, 0.6408, 0.7939; mean R2=0.7921\n",
      "Validation Error: Avg loss: 665.184509 \n",
      "\n",
      "2023-11-08 13:20:45.610763 Epoch 311, Training loss 547.3975219726562\n",
      "R2 values 0.9392, 0.7653, 0.7568; mean R2=0.8204\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 579.648010 \n",
      "\n",
      "2023-11-08 13:20:46.095620 Epoch 312, Training loss 507.1053161621094\n",
      "R2 values 0.9361, 0.6882, 0.8505; mean R2=0.8249\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 574.836792 \n",
      "\n",
      "2023-11-08 13:20:46.566782 Epoch 313, Training loss 578.22265625\n",
      "R2 values 0.9362, 0.6674, 0.8372; mean R2=0.8136\n",
      "Validation Error: Avg loss: 581.632080 \n",
      "\n",
      "2023-11-08 13:20:47.304112 Epoch 314, Training loss 437.02142333984375\n",
      "R2 values 0.9402, 0.6268, 0.7970; mean R2=0.7880\n",
      "Validation Error: Avg loss: 707.659241 \n",
      "\n",
      "2023-11-08 13:20:47.815271 Epoch 315, Training loss 600.0380249023438\n",
      "R2 values 0.9375, 0.5642, 0.8113; mean R2=0.7710\n",
      "Validation Error: Avg loss: 602.919128 \n",
      "\n",
      "2023-11-08 13:20:48.265768 Epoch 316, Training loss 566.5399780273438\n",
      "R2 values 0.9390, 0.6376, 0.8315; mean R2=0.8027\n",
      "Validation Error: Avg loss: 557.887634 \n",
      "\n",
      "2023-11-08 13:20:48.721302 Epoch 317, Training loss 445.2015380859375\n",
      "R2 values 0.9393, 0.5943, 0.7868; mean R2=0.7735\n",
      "Validation Error: Avg loss: 801.570129 \n",
      "\n",
      "2023-11-08 13:20:49.168119 Epoch 318, Training loss 614.5695190429688\n",
      "R2 values 0.9062, 0.6387, 0.7059; mean R2=0.7502\n",
      "Validation Error: Avg loss: 822.462219 \n",
      "\n",
      "2023-11-08 13:20:49.622691 Epoch 319, Training loss 555.3767700195312\n",
      "R2 values 0.9233, 0.7099, 0.8003; mean R2=0.8112\n",
      "Validation Error: Avg loss: 688.495544 \n",
      "\n",
      "2023-11-08 13:20:50.076378 Epoch 320, Training loss 498.78912353515625\n",
      "R2 values 0.9275, 0.5458, 0.7356; mean R2=0.7363\n",
      "Validation Error: Avg loss: 722.277893 \n",
      "\n",
      "2023-11-08 13:20:50.536588 Epoch 321, Training loss 437.66485595703125\n",
      "R2 values 0.9148, 0.6030, 0.7675; mean R2=0.7617\n",
      "Validation Error: Avg loss: 868.985107 \n",
      "\n",
      "2023-11-08 13:20:50.986998 Epoch 322, Training loss 650.1625366210938\n",
      "R2 values 0.9344, 0.7508, 0.7801; mean R2=0.8218\n",
      "Validation Error: Avg loss: 625.116211 \n",
      "\n",
      "2023-11-08 13:20:51.440261 Epoch 323, Training loss 535.5677490234375\n",
      "R2 values 0.9273, 0.7193, 0.7974; mean R2=0.8147\n",
      "Validation Error: Avg loss: 642.501526 \n",
      "\n",
      "2023-11-08 13:20:51.903042 Epoch 324, Training loss 455.53131103515625\n",
      "R2 values 0.9192, 0.6577, 0.8084; mean R2=0.7951\n",
      "Validation Error: Avg loss: 817.567444 \n",
      "\n",
      "2023-11-08 13:20:52.354360 Epoch 325, Training loss 515.711669921875\n",
      "R2 values 0.9627, 0.6421, 0.7549; mean R2=0.7866\n",
      "Validation Error: Avg loss: 492.956573 \n",
      "\n",
      "2023-11-08 13:20:52.815629 Epoch 326, Training loss 455.2657775878906\n",
      "R2 values 0.9506, 0.6592, 0.8010; mean R2=0.8036\n",
      "Validation Error: Avg loss: 501.588196 \n",
      "\n",
      "2023-11-08 13:20:53.487839 Epoch 327, Training loss 492.6969299316406\n",
      "R2 values 0.9337, 0.7458, 0.8115; mean R2=0.8304\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 574.943420 \n",
      "\n",
      "2023-11-08 13:20:54.026795 Epoch 328, Training loss 470.8064880371094\n",
      "R2 values 0.9440, 0.6308, 0.7893; mean R2=0.7880\n",
      "Validation Error: Avg loss: 569.271423 \n",
      "\n",
      "2023-11-08 13:20:54.482061 Epoch 329, Training loss 434.1963195800781\n",
      "R2 values 0.9532, 0.6684, 0.8110; mean R2=0.8108\n",
      "Validation Error: Avg loss: 478.007507 \n",
      "\n",
      "2023-11-08 13:20:54.937948 Epoch 330, Training loss 439.16802978515625\n",
      "R2 values 0.9399, 0.6413, 0.7633; mean R2=0.7815\n",
      "Validation Error: Avg loss: 564.171692 \n",
      "\n",
      "2023-11-08 13:20:55.393215 Epoch 331, Training loss 473.04266357421875\n",
      "R2 values 0.9427, 0.5121, 0.8081; mean R2=0.7543\n",
      "Validation Error: Avg loss: 552.120728 \n",
      "\n",
      "2023-11-08 13:20:55.864110 Epoch 332, Training loss 507.2867126464844\n",
      "R2 values 0.9019, 0.5434, 0.7620; mean R2=0.7358\n",
      "Validation Error: Avg loss: 846.016357 \n",
      "\n",
      "2023-11-08 13:20:56.320769 Epoch 333, Training loss 407.0530090332031\n",
      "R2 values 0.9403, 0.5149, 0.7739; mean R2=0.7430\n",
      "Validation Error: Avg loss: 686.457947 \n",
      "\n",
      "2023-11-08 13:20:56.800072 Epoch 334, Training loss 438.7535095214844\n",
      "R2 values 0.9014, 0.6436, 0.7917; mean R2=0.7789\n",
      "Validation Error: Avg loss: 770.121704 \n",
      "\n",
      "2023-11-08 13:20:57.261952 Epoch 335, Training loss 478.2678527832031\n",
      "R2 values 0.9386, 0.6533, 0.7918; mean R2=0.7946\n",
      "Validation Error: Avg loss: 550.700562 \n",
      "\n",
      "2023-11-08 13:20:57.724739 Epoch 336, Training loss 424.6218566894531\n",
      "R2 values 0.9512, 0.6962, 0.7744; mean R2=0.8073\n",
      "Validation Error: Avg loss: 599.686584 \n",
      "\n",
      "2023-11-08 13:20:58.199391 Epoch 337, Training loss 452.8879089355469\n",
      "R2 values 0.9353, 0.6646, 0.7948; mean R2=0.7982\n",
      "Validation Error: Avg loss: 824.319580 \n",
      "\n",
      "2023-11-08 13:20:58.650581 Epoch 338, Training loss 488.4193420410156\n",
      "R2 values 0.9467, 0.6910, 0.8061; mean R2=0.8146\n",
      "Validation Error: Avg loss: 603.980042 \n",
      "\n",
      "2023-11-08 13:20:59.124873 Epoch 339, Training loss 414.0849609375\n",
      "R2 values 0.9385, 0.6341, 0.8098; mean R2=0.7941\n",
      "Validation Error: Avg loss: 610.068970 \n",
      "\n",
      "2023-11-08 13:20:59.594948 Epoch 340, Training loss 506.8780822753906\n",
      "R2 values 0.9396, 0.7125, 0.8107; mean R2=0.8209\n",
      "Validation Error: Avg loss: 561.041931 \n",
      "\n",
      "2023-11-08 13:21:00.055618 Epoch 341, Training loss 563.0763549804688\n",
      "R2 values 0.9577, 0.6389, 0.7176; mean R2=0.7714\n",
      "Validation Error: Avg loss: 515.409790 \n",
      "\n",
      "2023-11-08 13:21:00.523486 Epoch 342, Training loss 453.9166564941406\n",
      "R2 values 0.9084, 0.6209, 0.7468; mean R2=0.7587\n",
      "Validation Error: Avg loss: 759.253784 \n",
      "\n",
      "2023-11-08 13:21:00.983439 Epoch 343, Training loss 535.755859375\n",
      "R2 values 0.9392, 0.6820, 0.7888; mean R2=0.8034\n",
      "Validation Error: Avg loss: 554.584473 \n",
      "\n",
      "2023-11-08 13:21:01.449322 Epoch 344, Training loss 584.7947387695312\n",
      "R2 values 0.9383, 0.6610, 0.8317; mean R2=0.8104\n",
      "Validation Error: Avg loss: 536.995972 \n",
      "\n",
      "2023-11-08 13:21:01.919553 Epoch 345, Training loss 472.1594543457031\n",
      "R2 values 0.9106, 0.7643, 0.7657; mean R2=0.8135\n",
      "Validation Error: Avg loss: 771.477722 \n",
      "\n",
      "2023-11-08 13:21:02.379379 Epoch 346, Training loss 599.6995849609375\n",
      "R2 values 0.9535, 0.7140, 0.8118; mean R2=0.8264\n",
      "Validation Error: Avg loss: 523.292542 \n",
      "\n",
      "2023-11-08 13:21:03.005055 Epoch 347, Training loss 398.3497619628906\n",
      "R2 values 0.9448, 0.6247, 0.7770; mean R2=0.7822\n",
      "Validation Error: Avg loss: 569.781921 \n",
      "\n",
      "2023-11-08 13:21:03.527594 Epoch 348, Training loss 397.26556396484375\n",
      "R2 values 0.9230, 0.6656, 0.7875; mean R2=0.7920\n",
      "Validation Error: Avg loss: 793.411438 \n",
      "\n",
      "2023-11-08 13:21:04.009382 Epoch 349, Training loss 539.9996337890625\n",
      "R2 values 0.9337, 0.5948, 0.8288; mean R2=0.7858\n",
      "Validation Error: Avg loss: 621.925110 \n",
      "\n",
      "2023-11-08 13:21:04.460267 Epoch 350, Training loss 552.5155029296875\n",
      "R2 values 0.9463, 0.6624, 0.7486; mean R2=0.7858\n",
      "Validation Error: Avg loss: 527.268982 \n",
      "\n",
      "2023-11-08 13:21:04.915914 Epoch 351, Training loss 515.5687866210938\n",
      "R2 values 0.9349, 0.6921, 0.7576; mean R2=0.7949\n",
      "Validation Error: Avg loss: 659.278137 \n",
      "\n",
      "2023-11-08 13:21:05.362081 Epoch 352, Training loss 460.8139953613281\n",
      "R2 values 0.9356, 0.6752, 0.8119; mean R2=0.8076\n",
      "Validation Error: Avg loss: 597.166992 \n",
      "\n",
      "2023-11-08 13:21:05.818048 Epoch 353, Training loss 460.74163818359375\n",
      "R2 values 0.9326, 0.5879, 0.7225; mean R2=0.7477\n",
      "Validation Error: Avg loss: 664.153503 \n",
      "\n",
      "2023-11-08 13:21:06.265345 Epoch 354, Training loss 421.63775634765625\n",
      "R2 values 0.9451, 0.6423, 0.8205; mean R2=0.8026\n",
      "Validation Error: Avg loss: 522.802429 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:21:06.717578 Epoch 355, Training loss 520.8202514648438\n",
      "R2 values 0.9342, 0.6564, 0.7672; mean R2=0.7859\n",
      "Validation Error: Avg loss: 646.003174 \n",
      "\n",
      "2023-11-08 13:21:07.171617 Epoch 356, Training loss 448.639404296875\n",
      "R2 values 0.9377, 0.6735, 0.7998; mean R2=0.8037\n",
      "Validation Error: Avg loss: 542.294006 \n",
      "\n",
      "2023-11-08 13:21:07.614454 Epoch 357, Training loss 382.83941650390625\n",
      "R2 values 0.9231, 0.7685, 0.8326; mean R2=0.8414\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 709.140381 \n",
      "\n",
      "2023-11-08 13:21:08.122749 Epoch 358, Training loss 423.1319580078125\n",
      "R2 values 0.9373, 0.7121, 0.8016; mean R2=0.8170\n",
      "Validation Error: Avg loss: 605.157288 \n",
      "\n",
      "2023-11-08 13:21:08.575426 Epoch 359, Training loss 399.0406188964844\n",
      "R2 values 0.9403, 0.6785, 0.8144; mean R2=0.8111\n",
      "Validation Error: Avg loss: 649.157471 \n",
      "\n",
      "2023-11-08 13:21:09.020273 Epoch 360, Training loss 394.0489501953125\n",
      "R2 values 0.9465, 0.7175, 0.7497; mean R2=0.8046\n",
      "Validation Error: Avg loss: 549.857910 \n",
      "\n",
      "2023-11-08 13:21:09.460664 Epoch 361, Training loss 449.5365295410156\n",
      "R2 values 0.9260, 0.7331, 0.7925; mean R2=0.8172\n",
      "Validation Error: Avg loss: 623.160217 \n",
      "\n",
      "2023-11-08 13:21:09.898065 Epoch 362, Training loss 385.478271484375\n",
      "R2 values 0.9515, 0.5842, 0.8112; mean R2=0.7823\n",
      "Validation Error: Avg loss: 744.890503 \n",
      "\n",
      "2023-11-08 13:21:10.343681 Epoch 363, Training loss 515.5292358398438\n",
      "R2 values 0.9238, 0.5934, 0.7546; mean R2=0.7573\n",
      "Validation Error: Avg loss: 723.623230 \n",
      "\n",
      "2023-11-08 13:21:10.791930 Epoch 364, Training loss 388.7980041503906\n",
      "R2 values 0.9180, 0.6492, 0.7789; mean R2=0.7820\n",
      "Validation Error: Avg loss: 742.284363 \n",
      "\n",
      "2023-11-08 13:21:11.237601 Epoch 365, Training loss 445.7513122558594\n",
      "R2 values 0.9569, 0.5449, 0.7785; mean R2=0.7601\n",
      "Validation Error: Avg loss: 608.539307 \n",
      "\n",
      "2023-11-08 13:21:11.688884 Epoch 366, Training loss 449.74871826171875\n",
      "R2 values 0.9386, 0.5029, 0.8205; mean R2=0.7540\n",
      "Validation Error: Avg loss: 711.297119 \n",
      "\n",
      "2023-11-08 13:21:12.296319 Epoch 367, Training loss 453.4509582519531\n",
      "R2 values 0.9548, 0.6979, 0.7764; mean R2=0.8097\n",
      "Validation Error: Avg loss: 451.955994 \n",
      "\n",
      "2023-11-08 13:21:12.848721 Epoch 368, Training loss 464.0116882324219\n",
      "R2 values 0.9458, 0.7202, 0.7957; mean R2=0.8206\n",
      "Validation Error: Avg loss: 589.611816 \n",
      "\n",
      "2023-11-08 13:21:13.290028 Epoch 369, Training loss 487.20379638671875\n",
      "R2 values 0.9450, 0.6799, 0.7979; mean R2=0.8076\n",
      "Validation Error: Avg loss: 561.757263 \n",
      "\n",
      "2023-11-08 13:21:13.790390 Epoch 370, Training loss 448.4850158691406\n",
      "R2 values 0.9331, 0.6617, 0.7822; mean R2=0.7923\n",
      "Validation Error: Avg loss: 776.297729 \n",
      "\n",
      "2023-11-08 13:21:14.234375 Epoch 371, Training loss 495.23883056640625\n",
      "R2 values 0.9383, 0.6093, 0.8196; mean R2=0.7891\n",
      "Validation Error: Avg loss: 590.307617 \n",
      "\n",
      "2023-11-08 13:21:14.674850 Epoch 372, Training loss 495.19818115234375\n",
      "R2 values 0.9578, 0.5448, 0.7920; mean R2=0.7649\n",
      "Validation Error: Avg loss: 505.617676 \n",
      "\n",
      "2023-11-08 13:21:15.136366 Epoch 373, Training loss 444.9385986328125\n",
      "R2 values 0.9457, 0.7110, 0.8712; mean R2=0.8426\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 483.413239 \n",
      "\n",
      "2023-11-08 13:21:15.620935 Epoch 374, Training loss 435.86962890625\n",
      "R2 values 0.9092, 0.7283, 0.8286; mean R2=0.8220\n",
      "Validation Error: Avg loss: 833.920227 \n",
      "\n",
      "2023-11-08 13:21:16.087180 Epoch 375, Training loss 517.6541748046875\n",
      "R2 values 0.9470, 0.6569, 0.8240; mean R2=0.8093\n",
      "Validation Error: Avg loss: 500.346558 \n",
      "\n",
      "2023-11-08 13:21:16.592461 Epoch 376, Training loss 435.907958984375\n",
      "R2 values 0.9545, 0.6384, 0.7942; mean R2=0.7957\n",
      "Validation Error: Avg loss: 543.510864 \n",
      "\n",
      "2023-11-08 13:21:17.050565 Epoch 377, Training loss 460.594482421875\n",
      "R2 values 0.9409, 0.7122, 0.8051; mean R2=0.8194\n",
      "Validation Error: Avg loss: 585.233948 \n",
      "\n",
      "2023-11-08 13:21:17.504260 Epoch 378, Training loss 459.94354248046875\n",
      "R2 values 0.9344, 0.6373, 0.7484; mean R2=0.7734\n",
      "Validation Error: Avg loss: 679.889832 \n",
      "\n",
      "2023-11-08 13:21:17.947197 Epoch 379, Training loss 477.0614929199219\n",
      "R2 values 0.9401, 0.7660, 0.7909; mean R2=0.8323\n",
      "Validation Error: Avg loss: 519.679504 \n",
      "\n",
      "2023-11-08 13:21:18.398338 Epoch 380, Training loss 405.3050842285156\n",
      "R2 values 0.9402, 0.6896, 0.7571; mean R2=0.7956\n",
      "Validation Error: Avg loss: 545.418884 \n",
      "\n",
      "2023-11-08 13:21:18.863812 Epoch 381, Training loss 527.9251098632812\n",
      "R2 values 0.9412, 0.7181, 0.7721; mean R2=0.8105\n",
      "Validation Error: Avg loss: 518.875488 \n",
      "\n",
      "2023-11-08 13:21:19.309267 Epoch 382, Training loss 359.8902893066406\n",
      "R2 values 0.9433, 0.7113, 0.8074; mean R2=0.8207\n",
      "Validation Error: Avg loss: 801.284668 \n",
      "\n",
      "2023-11-08 13:21:19.756811 Epoch 383, Training loss 447.2334289550781\n",
      "R2 values 0.9525, 0.6747, 0.7289; mean R2=0.7854\n",
      "Validation Error: Avg loss: 724.619019 \n",
      "\n",
      "2023-11-08 13:21:20.197777 Epoch 384, Training loss 454.3768615722656\n",
      "R2 values 0.9389, 0.6698, 0.8245; mean R2=0.8111\n",
      "Validation Error: Avg loss: 582.117065 \n",
      "\n",
      "2023-11-08 13:21:20.647801 Epoch 385, Training loss 424.1489562988281\n",
      "R2 values 0.9520, 0.6497, 0.7605; mean R2=0.7874\n",
      "Validation Error: Avg loss: 498.887787 \n",
      "\n",
      "2023-11-08 13:21:21.187621 Epoch 386, Training loss 339.17828369140625\n",
      "R2 values 0.9420, 0.6743, 0.8256; mean R2=0.8140\n",
      "Validation Error: Avg loss: 612.493225 \n",
      "\n",
      "2023-11-08 13:21:21.651686 Epoch 387, Training loss 371.5459289550781\n",
      "R2 values 0.9422, 0.7162, 0.8479; mean R2=0.8354\n",
      "Validation Error: Avg loss: 819.756531 \n",
      "\n",
      "2023-11-08 13:21:22.105302 Epoch 388, Training loss 424.48388671875\n",
      "R2 values 0.9468, 0.7232, 0.7716; mean R2=0.8139\n",
      "Validation Error: Avg loss: 506.789429 \n",
      "\n",
      "2023-11-08 13:21:22.549246 Epoch 389, Training loss 496.1803283691406\n",
      "R2 values 0.9371, 0.7183, 0.8169; mean R2=0.8241\n",
      "Validation Error: Avg loss: 588.375000 \n",
      "\n",
      "2023-11-08 13:21:22.992310 Epoch 390, Training loss 375.3885498046875\n",
      "R2 values 0.9530, 0.7005, 0.7102; mean R2=0.7879\n",
      "Validation Error: Avg loss: 731.231201 \n",
      "\n",
      "2023-11-08 13:21:23.553032 Epoch 391, Training loss 363.8828430175781\n",
      "R2 values 0.9318, 0.6620, 0.7818; mean R2=0.7919\n",
      "Validation Error: Avg loss: 741.232422 \n",
      "\n",
      "2023-11-08 13:21:24.002988 Epoch 392, Training loss 336.1945495605469\n",
      "R2 values 0.9501, 0.6707, 0.7484; mean R2=0.7897\n",
      "Validation Error: Avg loss: 543.957520 \n",
      "\n",
      "2023-11-08 13:21:24.447650 Epoch 393, Training loss 429.1260681152344\n",
      "R2 values 0.9413, 0.6637, 0.7533; mean R2=0.7861\n",
      "Validation Error: Avg loss: 539.303650 \n",
      "\n",
      "2023-11-08 13:21:24.911238 Epoch 394, Training loss 374.0361633300781\n",
      "R2 values 0.9385, 0.6803, 0.7988; mean R2=0.8059\n",
      "Validation Error: Avg loss: 618.737061 \n",
      "\n",
      "2023-11-08 13:21:25.355117 Epoch 395, Training loss 348.78533935546875\n",
      "R2 values 0.9478, 0.6866, 0.7576; mean R2=0.7973\n",
      "Validation Error: Avg loss: 530.526733 \n",
      "\n",
      "2023-11-08 13:21:25.834465 Epoch 396, Training loss 274.6534729003906\n",
      "R2 values 0.9383, 0.6226, 0.7648; mean R2=0.7753\n",
      "Validation Error: Avg loss: 577.597534 \n",
      "\n",
      "2023-11-08 13:21:26.295445 Epoch 397, Training loss 328.2519836425781\n",
      "R2 values 0.9593, 0.7244, 0.7650; mean R2=0.8162\n",
      "Validation Error: Avg loss: 491.971771 \n",
      "\n",
      "2023-11-08 13:21:26.745135 Epoch 398, Training loss 394.16839599609375\n",
      "R2 values 0.9466, 0.7120, 0.8115; mean R2=0.8234\n",
      "Validation Error: Avg loss: 511.226135 \n",
      "\n",
      "2023-11-08 13:21:27.198141 Epoch 399, Training loss 307.6346740722656\n",
      "R2 values 0.9401, 0.7460, 0.8288; mean R2=0.8383\n",
      "Validation Error: Avg loss: 634.164856 \n",
      "\n",
      "2023-11-08 13:21:27.650028 Epoch 400, Training loss 429.22869873046875\n",
      "R2 values 0.9325, 0.7169, 0.8311; mean R2=0.8268\n",
      "Validation Error: Avg loss: 576.911499 \n",
      "\n",
      "2023-11-08 13:21:28.101781 Epoch 401, Training loss 302.01165771484375\n",
      "R2 values 0.9505, 0.7658, 0.8093; mean R2=0.8419\n",
      "Validation Error: Avg loss: 498.180237 \n",
      "\n",
      "2023-11-08 13:21:28.554583 Epoch 402, Training loss 317.2376403808594\n",
      "R2 values 0.9464, 0.6796, 0.8070; mean R2=0.8110\n",
      "Validation Error: Avg loss: 611.141846 \n",
      "\n",
      "2023-11-08 13:21:28.998733 Epoch 403, Training loss 311.2141418457031\n",
      "R2 values 0.9321, 0.5524, 0.8219; mean R2=0.7688\n",
      "Validation Error: Avg loss: 780.826416 \n",
      "\n",
      "2023-11-08 13:21:29.435969 Epoch 404, Training loss 363.5740966796875\n",
      "R2 values 0.9423, 0.7084, 0.8095; mean R2=0.8201\n",
      "Validation Error: Avg loss: 554.744690 \n",
      "\n",
      "2023-11-08 13:21:29.880501 Epoch 405, Training loss 326.1399230957031\n",
      "R2 values 0.9538, 0.6917, 0.8393; mean R2=0.8282\n",
      "Validation Error: Avg loss: 448.992554 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:21:30.379407 Epoch 406, Training loss 323.9808654785156\n",
      "R2 values 0.9347, 0.7447, 0.8515; mean R2=0.8436\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 533.617920 \n",
      "\n",
      "2023-11-08 13:21:30.875345 Epoch 407, Training loss 448.90478515625\n",
      "R2 values 0.9421, 0.6934, 0.8139; mean R2=0.8165\n",
      "Validation Error: Avg loss: 622.344849 \n",
      "\n",
      "2023-11-08 13:21:31.356908 Epoch 408, Training loss 345.656982421875\n",
      "R2 values 0.9460, 0.7366, 0.8679; mean R2=0.8502\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 570.339844 \n",
      "\n",
      "2023-11-08 13:21:31.860736 Epoch 409, Training loss 291.4272766113281\n",
      "R2 values 0.9243, 0.7015, 0.7956; mean R2=0.8071\n",
      "Validation Error: Avg loss: 696.315918 \n",
      "\n",
      "2023-11-08 13:21:32.318807 Epoch 410, Training loss 336.3299255371094\n",
      "R2 values 0.9144, 0.6886, 0.8114; mean R2=0.8048\n",
      "Validation Error: Avg loss: 727.700867 \n",
      "\n",
      "2023-11-08 13:21:32.771030 Epoch 411, Training loss 457.1285095214844\n",
      "R2 values 0.9511, 0.7126, 0.8081; mean R2=0.8240\n",
      "Validation Error: Avg loss: 489.405426 \n",
      "\n",
      "2023-11-08 13:21:33.430665 Epoch 412, Training loss 334.3128356933594\n",
      "R2 values 0.9357, 0.7270, 0.8154; mean R2=0.8261\n",
      "Validation Error: Avg loss: 610.541504 \n",
      "\n",
      "2023-11-08 13:21:33.885170 Epoch 413, Training loss 293.2700500488281\n",
      "R2 values 0.9530, 0.7275, 0.7906; mean R2=0.8237\n",
      "Validation Error: Avg loss: 460.119171 \n",
      "\n",
      "2023-11-08 13:21:34.332729 Epoch 414, Training loss 322.09002685546875\n",
      "R2 values 0.9328, 0.7177, 0.7967; mean R2=0.8157\n",
      "Validation Error: Avg loss: 587.173401 \n",
      "\n",
      "2023-11-08 13:21:34.783907 Epoch 415, Training loss 336.7010192871094\n",
      "R2 values 0.9180, 0.7603, 0.8091; mean R2=0.8292\n",
      "Validation Error: Avg loss: 868.706787 \n",
      "\n",
      "2023-11-08 13:21:35.225631 Epoch 416, Training loss 373.4325256347656\n",
      "R2 values 0.9093, 0.7553, 0.8677; mean R2=0.8441\n",
      "Validation Error: Avg loss: 832.037842 \n",
      "\n",
      "2023-11-08 13:21:35.673974 Epoch 417, Training loss 341.3084716796875\n",
      "R2 values 0.9629, 0.7421, 0.7912; mean R2=0.8321\n",
      "Validation Error: Avg loss: 390.185394 \n",
      "\n",
      "2023-11-08 13:21:36.136719 Epoch 418, Training loss 403.7010498046875\n",
      "R2 values 0.9520, 0.7629, 0.7899; mean R2=0.8349\n",
      "Validation Error: Avg loss: 489.374420 \n",
      "\n",
      "2023-11-08 13:21:36.587859 Epoch 419, Training loss 393.05303955078125\n",
      "R2 values 0.9338, 0.7105, 0.8113; mean R2=0.8185\n",
      "Validation Error: Avg loss: 553.809631 \n",
      "\n",
      "2023-11-08 13:21:37.031267 Epoch 420, Training loss 346.0135192871094\n",
      "R2 values 0.9342, 0.7186, 0.8110; mean R2=0.8213\n",
      "Validation Error: Avg loss: 544.379700 \n",
      "\n",
      "2023-11-08 13:21:37.480394 Epoch 421, Training loss 348.1241149902344\n",
      "R2 values 0.9346, 0.6925, 0.7908; mean R2=0.8060\n",
      "Validation Error: Avg loss: 612.489685 \n",
      "\n",
      "2023-11-08 13:21:37.929913 Epoch 422, Training loss 366.7120666503906\n",
      "R2 values 0.9586, 0.6874, 0.7714; mean R2=0.8058\n",
      "Validation Error: Avg loss: 500.513214 \n",
      "\n",
      "2023-11-08 13:21:38.530905 Epoch 423, Training loss 331.3644104003906\n",
      "R2 values 0.9130, 0.7166, 0.7782; mean R2=0.8026\n",
      "Validation Error: Avg loss: 763.505066 \n",
      "\n",
      "2023-11-08 13:21:39.066060 Epoch 424, Training loss 366.80322265625\n",
      "R2 values 0.9468, 0.7210, 0.8195; mean R2=0.8291\n",
      "Validation Error: Avg loss: 483.968231 \n",
      "\n",
      "2023-11-08 13:21:39.516623 Epoch 425, Training loss 350.115234375\n",
      "R2 values 0.9461, 0.6875, 0.7956; mean R2=0.8097\n",
      "Validation Error: Avg loss: 666.604126 \n",
      "\n",
      "2023-11-08 13:21:39.968207 Epoch 426, Training loss 374.4189147949219\n",
      "R2 values 0.9375, 0.7295, 0.7940; mean R2=0.8204\n",
      "Validation Error: Avg loss: 666.828430 \n",
      "\n",
      "2023-11-08 13:21:40.410915 Epoch 427, Training loss 436.1598815917969\n",
      "R2 values 0.9586, 0.7119, 0.7999; mean R2=0.8235\n",
      "Validation Error: Avg loss: 433.153870 \n",
      "\n",
      "2023-11-08 13:21:40.859584 Epoch 428, Training loss 322.5411071777344\n",
      "R2 values 0.9494, 0.7553, 0.7898; mean R2=0.8315\n",
      "Validation Error: Avg loss: 506.654999 \n",
      "\n",
      "2023-11-08 13:21:41.303182 Epoch 429, Training loss 341.0564270019531\n",
      "R2 values 0.9391, 0.6439, 0.7773; mean R2=0.7868\n",
      "Validation Error: Avg loss: 723.132507 \n",
      "\n",
      "2023-11-08 13:21:41.755476 Epoch 430, Training loss 396.2323303222656\n",
      "R2 values 0.9410, 0.6883, 0.7908; mean R2=0.8067\n",
      "Validation Error: Avg loss: 584.174866 \n",
      "\n",
      "2023-11-08 13:21:42.215858 Epoch 431, Training loss 281.0503234863281\n",
      "R2 values 0.9412, 0.7861, 0.8156; mean R2=0.8476\n",
      "Validation Error: Avg loss: 551.132935 \n",
      "\n",
      "2023-11-08 13:21:42.669310 Epoch 432, Training loss 405.49835205078125\n",
      "R2 values 0.9217, 0.7731, 0.8125; mean R2=0.8358\n",
      "Validation Error: Avg loss: 649.732422 \n",
      "\n",
      "2023-11-08 13:21:43.134621 Epoch 433, Training loss 318.7652282714844\n",
      "R2 values 0.9494, 0.6893, 0.7638; mean R2=0.8009\n",
      "Validation Error: Avg loss: 506.485657 \n",
      "\n",
      "2023-11-08 13:21:43.585460 Epoch 434, Training loss 304.6036071777344\n",
      "R2 values 0.9396, 0.7590, 0.7715; mean R2=0.8234\n",
      "Validation Error: Avg loss: 650.476501 \n",
      "\n",
      "2023-11-08 13:21:44.028957 Epoch 435, Training loss 383.61871337890625\n",
      "R2 values 0.9507, 0.7254, 0.8227; mean R2=0.8329\n",
      "Validation Error: Avg loss: 463.818878 \n",
      "\n",
      "2023-11-08 13:21:44.472589 Epoch 436, Training loss 285.67462158203125\n",
      "R2 values 0.9490, 0.7042, 0.8446; mean R2=0.8326\n",
      "Validation Error: Avg loss: 469.004883 \n",
      "\n",
      "2023-11-08 13:21:44.911736 Epoch 437, Training loss 331.948486328125\n",
      "R2 values 0.9706, 0.7334, 0.7986; mean R2=0.8342\n",
      "Validation Error: Avg loss: 467.546631 \n",
      "\n",
      "2023-11-08 13:21:45.359875 Epoch 438, Training loss 349.3184509277344\n",
      "R2 values 0.9487, 0.7325, 0.7989; mean R2=0.8267\n",
      "Validation Error: Avg loss: 635.041443 \n",
      "\n",
      "2023-11-08 13:21:45.802963 Epoch 439, Training loss 352.363525390625\n",
      "R2 values 0.9512, 0.7704, 0.8254; mean R2=0.8490\n",
      "Validation Error: Avg loss: 526.344421 \n",
      "\n",
      "2023-11-08 13:21:46.242703 Epoch 440, Training loss 261.9879455566406\n",
      "R2 values 0.9496, 0.7401, 0.7745; mean R2=0.8214\n",
      "Validation Error: Avg loss: 511.952606 \n",
      "\n",
      "2023-11-08 13:21:46.705256 Epoch 441, Training loss 313.95306396484375\n",
      "R2 values 0.9597, 0.7651, 0.8123; mean R2=0.8457\n",
      "Validation Error: Avg loss: 442.790161 \n",
      "\n",
      "2023-11-08 13:21:47.146288 Epoch 442, Training loss 340.3349914550781\n",
      "R2 values 0.9171, 0.7509, 0.7935; mean R2=0.8205\n",
      "Validation Error: Avg loss: 909.489990 \n",
      "\n",
      "2023-11-08 13:21:47.594313 Epoch 443, Training loss 327.4130859375\n",
      "R2 values 0.9393, 0.7028, 0.8095; mean R2=0.8172\n",
      "Validation Error: Avg loss: 555.338928 \n",
      "\n",
      "2023-11-08 13:21:48.040204 Epoch 444, Training loss 299.7048645019531\n",
      "R2 values 0.9588, 0.7324, 0.8238; mean R2=0.8383\n",
      "Validation Error: Avg loss: 400.360138 \n",
      "\n",
      "2023-11-08 13:21:48.541638 Epoch 445, Training loss 259.5337829589844\n",
      "R2 values 0.9533, 0.6790, 0.8145; mean R2=0.8156\n",
      "Validation Error: Avg loss: 457.250275 \n",
      "\n",
      "2023-11-08 13:21:48.984079 Epoch 446, Training loss 360.2179260253906\n",
      "R2 values 0.9497, 0.7136, 0.8217; mean R2=0.8283\n",
      "Validation Error: Avg loss: 537.308350 \n",
      "\n",
      "2023-11-08 13:21:49.424363 Epoch 447, Training loss 319.8060302734375\n",
      "R2 values 0.9604, 0.7211, 0.8497; mean R2=0.8437\n",
      "Validation Error: Avg loss: 409.683990 \n",
      "\n",
      "2023-11-08 13:21:49.927442 Epoch 448, Training loss 299.28594970703125\n",
      "R2 values 0.9552, 0.7361, 0.8439; mean R2=0.8451\n",
      "Validation Error: Avg loss: 482.630035 \n",
      "\n",
      "2023-11-08 13:21:50.375390 Epoch 449, Training loss 338.39422607421875\n",
      "R2 values 0.9413, 0.7552, 0.7671; mean R2=0.8212\n",
      "Validation Error: Avg loss: 542.771057 \n",
      "\n",
      "2023-11-08 13:21:51.012967 Epoch 450, Training loss 353.0478210449219\n",
      "R2 values 0.9609, 0.6937, 0.8337; mean R2=0.8294\n",
      "Validation Error: Avg loss: 467.385071 \n",
      "\n",
      "2023-11-08 13:21:51.463839 Epoch 451, Training loss 300.70062255859375\n",
      "R2 values 0.9478, 0.7177, 0.8080; mean R2=0.8245\n",
      "Validation Error: Avg loss: 583.646851 \n",
      "\n",
      "2023-11-08 13:21:51.923413 Epoch 452, Training loss 278.802734375\n",
      "R2 values 0.9314, 0.7756, 0.8078; mean R2=0.8383\n",
      "Validation Error: Avg loss: 640.162842 \n",
      "\n",
      "2023-11-08 13:21:52.377770 Epoch 453, Training loss 320.1599426269531\n",
      "R2 values 0.9521, 0.7387, 0.8022; mean R2=0.8310\n",
      "Validation Error: Avg loss: 468.287720 \n",
      "\n",
      "2023-11-08 13:21:52.825483 Epoch 454, Training loss 430.2206115722656\n",
      "R2 values 0.9453, 0.6775, 0.8031; mean R2=0.8086\n",
      "Validation Error: Avg loss: 562.068298 \n",
      "\n",
      "2023-11-08 13:21:53.275534 Epoch 455, Training loss 313.3369445800781\n",
      "R2 values 0.9412, 0.7143, 0.8072; mean R2=0.8209\n",
      "Validation Error: Avg loss: 639.666260 \n",
      "\n",
      "2023-11-08 13:21:53.732090 Epoch 456, Training loss 318.3535461425781\n",
      "R2 values 0.9530, 0.6952, 0.8186; mean R2=0.8223\n",
      "Validation Error: Avg loss: 450.981659 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:21:54.176473 Epoch 457, Training loss 299.7511901855469\n",
      "R2 values 0.9305, 0.7466, 0.7971; mean R2=0.8247\n",
      "Validation Error: Avg loss: 614.399597 \n",
      "\n",
      "2023-11-08 13:21:54.618693 Epoch 458, Training loss 409.7590637207031\n",
      "R2 values 0.9261, 0.7509, 0.8328; mean R2=0.8366\n",
      "Validation Error: Avg loss: 719.107666 \n",
      "\n",
      "2023-11-08 13:21:55.071900 Epoch 459, Training loss 353.3584899902344\n",
      "R2 values 0.9557, 0.7574, 0.8133; mean R2=0.8422\n",
      "Validation Error: Avg loss: 596.258972 \n",
      "\n",
      "2023-11-08 13:21:55.521910 Epoch 460, Training loss 308.0521240234375\n",
      "R2 values 0.9351, 0.7555, 0.8132; mean R2=0.8346\n",
      "Validation Error: Avg loss: 574.307617 \n",
      "\n",
      "2023-11-08 13:21:55.959253 Epoch 461, Training loss 343.0601806640625\n",
      "R2 values 0.9508, 0.7209, 0.8206; mean R2=0.8308\n",
      "Validation Error: Avg loss: 480.973572 \n",
      "\n",
      "2023-11-08 13:21:56.401111 Epoch 462, Training loss 310.697021484375\n",
      "R2 values 0.9419, 0.7474, 0.8465; mean R2=0.8453\n",
      "Validation Error: Avg loss: 527.735779 \n",
      "\n",
      "2023-11-08 13:21:56.841634 Epoch 463, Training loss 299.34246826171875\n",
      "R2 values 0.9392, 0.7810, 0.8273; mean R2=0.8492\n",
      "Validation Error: Avg loss: 591.615540 \n",
      "\n",
      "2023-11-08 13:21:57.291119 Epoch 464, Training loss 267.8722839355469\n",
      "R2 values 0.9559, 0.8019, 0.8626; mean R2=0.8735\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 411.269684 \n",
      "\n",
      "2023-11-08 13:21:57.768241 Epoch 465, Training loss 255.00148010253906\n",
      "R2 values 0.9410, 0.7236, 0.8019; mean R2=0.8222\n",
      "Validation Error: Avg loss: 558.467468 \n",
      "\n",
      "2023-11-08 13:21:58.221196 Epoch 466, Training loss 309.9340515136719\n",
      "R2 values 0.9489, 0.7540, 0.8183; mean R2=0.8404\n",
      "Validation Error: Avg loss: 780.202637 \n",
      "\n",
      "2023-11-08 13:21:58.671462 Epoch 467, Training loss 393.2953186035156\n",
      "R2 values 0.9427, 0.6932, 0.7846; mean R2=0.8068\n",
      "Validation Error: Avg loss: 638.111023 \n",
      "\n",
      "2023-11-08 13:21:59.117605 Epoch 468, Training loss 236.2483673095703\n",
      "R2 values 0.9442, 0.6903, 0.8095; mean R2=0.8147\n",
      "Validation Error: Avg loss: 529.465393 \n",
      "\n",
      "2023-11-08 13:21:59.558750 Epoch 469, Training loss 252.3347625732422\n",
      "R2 values 0.9453, 0.7109, 0.7817; mean R2=0.8126\n",
      "Validation Error: Avg loss: 524.646484 \n",
      "\n",
      "2023-11-08 13:22:00.004267 Epoch 470, Training loss 297.5973815917969\n",
      "R2 values 0.9493, 0.6808, 0.7586; mean R2=0.7962\n",
      "Validation Error: Avg loss: 636.118713 \n",
      "\n",
      "2023-11-08 13:22:00.659159 Epoch 471, Training loss 240.63909912109375\n",
      "R2 values 0.9369, 0.7228, 0.8299; mean R2=0.8299\n",
      "Validation Error: Avg loss: 734.986694 \n",
      "\n",
      "2023-11-08 13:22:01.188753 Epoch 472, Training loss 382.9070129394531\n",
      "R2 values 0.9667, 0.7484, 0.8051; mean R2=0.8401\n",
      "Validation Error: Avg loss: 358.820709 \n",
      "\n",
      "2023-11-08 13:22:01.931247 Epoch 473, Training loss 251.51495361328125\n",
      "R2 values 0.9345, 0.7496, 0.8260; mean R2=0.8367\n",
      "Validation Error: Avg loss: 548.545898 \n",
      "\n",
      "2023-11-08 13:22:02.509215 Epoch 474, Training loss 311.3681335449219\n",
      "R2 values 0.9327, 0.7499, 0.7861; mean R2=0.8229\n",
      "Validation Error: Avg loss: 663.958252 \n",
      "\n",
      "2023-11-08 13:22:03.054585 Epoch 475, Training loss 252.02610778808594\n",
      "R2 values 0.9452, 0.7249, 0.7654; mean R2=0.8118\n",
      "Validation Error: Avg loss: 612.179932 \n",
      "\n",
      "2023-11-08 13:22:03.622939 Epoch 476, Training loss 245.02108764648438\n",
      "R2 values 0.9276, 0.6318, 0.7628; mean R2=0.7741\n",
      "Validation Error: Avg loss: 719.211792 \n",
      "\n",
      "2023-11-08 13:22:04.156542 Epoch 477, Training loss 220.36192321777344\n",
      "R2 values 0.9119, 0.7216, 0.8064; mean R2=0.8133\n",
      "Validation Error: Avg loss: 781.639893 \n",
      "\n",
      "2023-11-08 13:22:04.676254 Epoch 478, Training loss 330.5280456542969\n",
      "R2 values 0.9439, 0.7571, 0.8532; mean R2=0.8514\n",
      "Validation Error: Avg loss: 463.395752 \n",
      "\n",
      "2023-11-08 13:22:05.208832 Epoch 479, Training loss 238.68011474609375\n",
      "R2 values 0.9401, 0.7399, 0.8045; mean R2=0.8282\n",
      "Validation Error: Avg loss: 526.683533 \n",
      "\n",
      "2023-11-08 13:22:05.734260 Epoch 480, Training loss 362.0989990234375\n",
      "R2 values 0.9273, 0.7433, 0.7991; mean R2=0.8232\n",
      "Validation Error: Avg loss: 762.910522 \n",
      "\n",
      "2023-11-08 13:22:06.251372 Epoch 481, Training loss 326.41064453125\n",
      "R2 values 0.9321, 0.7156, 0.8108; mean R2=0.8195\n",
      "Validation Error: Avg loss: 598.184326 \n",
      "\n",
      "2023-11-08 13:22:06.778954 Epoch 482, Training loss 297.2882385253906\n",
      "R2 values 0.9249, 0.6922, 0.7853; mean R2=0.8008\n",
      "Validation Error: Avg loss: 664.692444 \n",
      "\n",
      "2023-11-08 13:22:07.330114 Epoch 483, Training loss 327.0623474121094\n",
      "R2 values 0.9593, 0.7084, 0.8179; mean R2=0.8285\n",
      "Validation Error: Avg loss: 404.342468 \n",
      "\n",
      "2023-11-08 13:22:07.851975 Epoch 484, Training loss 262.35546875\n",
      "R2 values 0.9526, 0.7403, 0.7622; mean R2=0.8184\n",
      "Validation Error: Avg loss: 636.319458 \n",
      "\n",
      "2023-11-08 13:22:08.344876 Epoch 485, Training loss 250.54942321777344\n",
      "R2 values 0.9454, 0.7801, 0.8180; mean R2=0.8478\n",
      "Validation Error: Avg loss: 557.480469 \n",
      "\n",
      "2023-11-08 13:22:08.828341 Epoch 486, Training loss 260.6396484375\n",
      "R2 values 0.9367, 0.7725, 0.8057; mean R2=0.8383\n",
      "Validation Error: Avg loss: 602.584412 \n",
      "\n",
      "2023-11-08 13:22:09.314106 Epoch 487, Training loss 261.430419921875\n",
      "R2 values 0.9264, 0.7301, 0.7814; mean R2=0.8126\n",
      "Validation Error: Avg loss: 702.149963 \n",
      "\n",
      "2023-11-08 13:22:09.791251 Epoch 488, Training loss 290.5431823730469\n",
      "R2 values 0.9570, 0.7571, 0.8333; mean R2=0.8491\n",
      "Validation Error: Avg loss: 415.655396 \n",
      "\n",
      "2023-11-08 13:22:10.279768 Epoch 489, Training loss 314.5221252441406\n",
      "R2 values 0.9504, 0.8064, 0.8555; mean R2=0.8708\n",
      "Validation Error: Avg loss: 491.251892 \n",
      "\n",
      "2023-11-08 13:22:10.767562 Epoch 490, Training loss 301.69403076171875\n",
      "R2 values 0.9284, 0.7632, 0.8460; mean R2=0.8459\n",
      "Validation Error: Avg loss: 667.868896 \n",
      "\n",
      "2023-11-08 13:22:11.261302 Epoch 491, Training loss 249.73733520507812\n",
      "R2 values 0.9418, 0.7636, 0.8089; mean R2=0.8381\n",
      "Validation Error: Avg loss: 534.873352 \n",
      "\n",
      "2023-11-08 13:22:11.865004 Epoch 492, Training loss 262.59027099609375\n",
      "R2 values 0.9480, 0.7255, 0.8542; mean R2=0.8426\n",
      "Validation Error: Avg loss: 489.674774 \n",
      "\n",
      "2023-11-08 13:22:12.408680 Epoch 493, Training loss 243.33151245117188\n",
      "R2 values 0.9564, 0.8078, 0.8206; mean R2=0.8616\n",
      "Validation Error: Avg loss: 502.164795 \n",
      "\n",
      "2023-11-08 13:22:12.907425 Epoch 494, Training loss 210.761474609375\n",
      "R2 values 0.9445, 0.7830, 0.8136; mean R2=0.8470\n",
      "Validation Error: Avg loss: 550.127319 \n",
      "\n",
      "2023-11-08 13:22:13.386858 Epoch 495, Training loss 220.89404296875\n",
      "R2 values 0.9620, 0.7898, 0.7604; mean R2=0.8374\n",
      "Validation Error: Avg loss: 423.669464 \n",
      "\n",
      "2023-11-08 13:22:13.864456 Epoch 496, Training loss 291.8052978515625\n",
      "R2 values 0.9493, 0.8001, 0.8301; mean R2=0.8598\n",
      "Validation Error: Avg loss: 458.064392 \n",
      "\n",
      "2023-11-08 13:22:14.351869 Epoch 497, Training loss 288.2001953125\n",
      "R2 values 0.9497, 0.7395, 0.8285; mean R2=0.8393\n",
      "Validation Error: Avg loss: 490.813019 \n",
      "\n",
      "2023-11-08 13:22:14.836644 Epoch 498, Training loss 248.66897583007812\n",
      "R2 values 0.9563, 0.6970, 0.8074; mean R2=0.8202\n",
      "Validation Error: Avg loss: 449.309509 \n",
      "\n",
      "2023-11-08 13:22:15.331288 Epoch 499, Training loss 241.69325256347656\n",
      "R2 values 0.9382, 0.7644, 0.8155; mean R2=0.8394\n",
      "Validation Error: Avg loss: 612.843445 \n",
      "\n",
      "2023-11-08 13:22:15.814410 Epoch 500, Training loss 271.16217041015625\n",
      "R2 values 0.9316, 0.7688, 0.8409; mean R2=0.8471\n",
      "Validation Error: Avg loss: 612.811523 \n",
      "\n",
      "2023-11-08 13:22:16.295914 Epoch 501, Training loss 302.5152282714844\n",
      "R2 values 0.9426, 0.7816, 0.8716; mean R2=0.8652\n",
      "Validation Error: Avg loss: 508.787292 \n",
      "\n",
      "2023-11-08 13:22:16.792636 Epoch 502, Training loss 313.5656433105469\n",
      "R2 values 0.9322, 0.7558, 0.8354; mean R2=0.8411\n",
      "Validation Error: Avg loss: 661.515686 \n",
      "\n",
      "2023-11-08 13:22:17.276846 Epoch 503, Training loss 254.2930908203125\n",
      "R2 values 0.9327, 0.7865, 0.8078; mean R2=0.8423\n",
      "Validation Error: Avg loss: 661.147339 \n",
      "\n",
      "2023-11-08 13:22:17.777138 Epoch 504, Training loss 284.8526916503906\n",
      "R2 values 0.9558, 0.7666, 0.8399; mean R2=0.8541\n",
      "Validation Error: Avg loss: 403.126831 \n",
      "\n",
      "2023-11-08 13:22:18.279535 Epoch 505, Training loss 233.48956298828125\n",
      "R2 values 0.9485, 0.7513, 0.8382; mean R2=0.8460\n",
      "Validation Error: Avg loss: 447.749725 \n",
      "\n",
      "2023-11-08 13:22:18.773429 Epoch 506, Training loss 271.91192626953125\n",
      "R2 values 0.9509, 0.7807, 0.8054; mean R2=0.8457\n",
      "Validation Error: Avg loss: 566.555847 \n",
      "\n",
      "2023-11-08 13:22:19.264777 Epoch 507, Training loss 301.66546630859375\n",
      "R2 values 0.9414, 0.7613, 0.7665; mean R2=0.8231\n",
      "Validation Error: Avg loss: 744.825195 \n",
      "\n",
      "2023-11-08 13:22:19.817881 Epoch 508, Training loss 199.76010131835938\n",
      "R2 values 0.9410, 0.7735, 0.8092; mean R2=0.8413\n",
      "Validation Error: Avg loss: 561.495605 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:22:20.295272 Epoch 509, Training loss 249.02383422851562\n",
      "R2 values 0.9289, 0.7556, 0.8467; mean R2=0.8437\n",
      "Validation Error: Avg loss: 583.053284 \n",
      "\n",
      "2023-11-08 13:22:20.801797 Epoch 510, Training loss 287.5744934082031\n",
      "R2 values 0.9488, 0.7812, 0.8327; mean R2=0.8542\n",
      "Validation Error: Avg loss: 508.727386 \n",
      "\n",
      "2023-11-08 13:22:21.289587 Epoch 511, Training loss 221.9014892578125\n",
      "R2 values 0.9486, 0.7888, 0.8249; mean R2=0.8541\n",
      "Validation Error: Avg loss: 555.678833 \n",
      "\n",
      "2023-11-08 13:22:21.777373 Epoch 512, Training loss 265.4109191894531\n",
      "R2 values 0.9639, 0.7738, 0.8600; mean R2=0.8659\n",
      "Validation Error: Avg loss: 357.418488 \n",
      "\n",
      "2023-11-08 13:22:22.304581 Epoch 513, Training loss 207.21046447753906\n",
      "R2 values 0.9528, 0.7698, 0.8496; mean R2=0.8574\n",
      "Validation Error: Avg loss: 431.556702 \n",
      "\n",
      "2023-11-08 13:22:22.798786 Epoch 514, Training loss 248.9742889404297\n",
      "R2 values 0.9489, 0.8018, 0.7941; mean R2=0.8482\n",
      "Validation Error: Avg loss: 530.089966 \n",
      "\n",
      "2023-11-08 13:22:23.288937 Epoch 515, Training loss 251.49432373046875\n",
      "R2 values 0.9455, 0.7480, 0.8396; mean R2=0.8443\n",
      "Validation Error: Avg loss: 675.589355 \n",
      "\n",
      "2023-11-08 13:22:23.783837 Epoch 516, Training loss 277.2290344238281\n",
      "R2 values 0.9452, 0.7792, 0.8673; mean R2=0.8639\n",
      "Validation Error: Avg loss: 494.438385 \n",
      "\n",
      "2023-11-08 13:22:24.277311 Epoch 517, Training loss 275.2920837402344\n",
      "R2 values 0.9270, 0.7534, 0.8088; mean R2=0.8297\n",
      "Validation Error: Avg loss: 650.362671 \n",
      "\n",
      "2023-11-08 13:22:24.763657 Epoch 518, Training loss 266.1759948730469\n",
      "R2 values 0.9490, 0.7747, 0.8100; mean R2=0.8446\n",
      "Validation Error: Avg loss: 565.791443 \n",
      "\n",
      "2023-11-08 13:22:25.252088 Epoch 519, Training loss 252.72503662109375\n",
      "R2 values 0.9341, 0.7294, 0.8100; mean R2=0.8245\n",
      "Validation Error: Avg loss: 715.944458 \n",
      "\n",
      "2023-11-08 13:22:25.742631 Epoch 520, Training loss 311.0539245605469\n",
      "R2 values 0.9489, 0.7724, 0.8289; mean R2=0.8501\n",
      "Validation Error: Avg loss: 439.502014 \n",
      "\n",
      "2023-11-08 13:22:26.231277 Epoch 521, Training loss 263.185791015625\n",
      "R2 values 0.9428, 0.7488, 0.8373; mean R2=0.8430\n",
      "Validation Error: Avg loss: 474.979004 \n",
      "\n",
      "2023-11-08 13:22:26.736888 Epoch 522, Training loss 300.9354553222656\n",
      "R2 values 0.9410, 0.7644, 0.8195; mean R2=0.8416\n",
      "Validation Error: Avg loss: 559.325317 \n",
      "\n",
      "2023-11-08 13:22:27.224734 Epoch 523, Training loss 265.550537109375\n",
      "R2 values 0.9500, 0.6642, 0.7929; mean R2=0.8024\n",
      "Validation Error: Avg loss: 624.084290 \n",
      "\n",
      "2023-11-08 13:22:27.719397 Epoch 524, Training loss 241.953857421875\n",
      "R2 values 0.9557, 0.7743, 0.8499; mean R2=0.8600\n",
      "Validation Error: Avg loss: 458.200104 \n",
      "\n",
      "2023-11-08 13:22:28.210697 Epoch 525, Training loss 263.1781005859375\n",
      "R2 values 0.9682, 0.7885, 0.8239; mean R2=0.8602\n",
      "Validation Error: Avg loss: 390.803314 \n",
      "\n",
      "2023-11-08 13:22:28.705649 Epoch 526, Training loss 312.23583984375\n",
      "R2 values 0.9426, 0.7923, 0.8564; mean R2=0.8638\n",
      "Validation Error: Avg loss: 717.200684 \n",
      "\n",
      "2023-11-08 13:22:29.193339 Epoch 527, Training loss 325.41204833984375\n",
      "R2 values 0.9429, 0.7938, 0.8103; mean R2=0.8490\n",
      "Validation Error: Avg loss: 632.693542 \n",
      "\n",
      "2023-11-08 13:22:29.682442 Epoch 528, Training loss 263.72833251953125\n",
      "R2 values 0.9500, 0.7308, 0.8087; mean R2=0.8298\n",
      "Validation Error: Avg loss: 473.911560 \n",
      "\n",
      "2023-11-08 13:22:30.227637 Epoch 529, Training loss 246.2894287109375\n",
      "R2 values 0.9505, 0.7757, 0.8217; mean R2=0.8493\n",
      "Validation Error: Avg loss: 461.744019 \n",
      "\n",
      "2023-11-08 13:22:30.898281 Epoch 530, Training loss 264.2473449707031\n",
      "R2 values 0.9449, 0.6883, 0.8617; mean R2=0.8317\n",
      "Validation Error: Avg loss: 520.283081 \n",
      "\n",
      "2023-11-08 13:22:31.380388 Epoch 531, Training loss 246.81430053710938\n",
      "R2 values 0.9379, 0.7663, 0.8266; mean R2=0.8436\n",
      "Validation Error: Avg loss: 566.732605 \n",
      "\n",
      "2023-11-08 13:22:31.881437 Epoch 532, Training loss 258.8858947753906\n",
      "R2 values 0.9528, 0.7330, 0.8346; mean R2=0.8401\n",
      "Validation Error: Avg loss: 445.440155 \n",
      "\n",
      "2023-11-08 13:22:32.364142 Epoch 533, Training loss 226.48553466796875\n",
      "R2 values 0.9579, 0.8049, 0.8435; mean R2=0.8688\n",
      "Validation Error: Avg loss: 434.919647 \n",
      "\n",
      "2023-11-08 13:22:32.844780 Epoch 534, Training loss 190.4528350830078\n",
      "R2 values 0.9576, 0.7389, 0.8495; mean R2=0.8487\n",
      "Validation Error: Avg loss: 405.546600 \n",
      "\n",
      "2023-11-08 13:22:33.322157 Epoch 535, Training loss 205.90675354003906\n",
      "R2 values 0.9426, 0.7838, 0.8320; mean R2=0.8528\n",
      "Validation Error: Avg loss: 484.426819 \n",
      "\n",
      "2023-11-08 13:22:33.809109 Epoch 536, Training loss 216.96849060058594\n",
      "R2 values 0.9433, 0.7739, 0.8317; mean R2=0.8497\n",
      "Validation Error: Avg loss: 498.287415 \n",
      "\n",
      "2023-11-08 13:22:34.296726 Epoch 537, Training loss 259.1654357910156\n",
      "R2 values 0.9451, 0.8057, 0.8207; mean R2=0.8572\n",
      "Validation Error: Avg loss: 628.412231 \n",
      "\n",
      "2023-11-08 13:22:34.782300 Epoch 538, Training loss 242.43673706054688\n",
      "R2 values 0.9369, 0.7641, 0.8182; mean R2=0.8397\n",
      "Validation Error: Avg loss: 716.264832 \n",
      "\n",
      "2023-11-08 13:22:35.271014 Epoch 539, Training loss 219.23648071289062\n",
      "R2 values 0.9430, 0.7716, 0.7792; mean R2=0.8312\n",
      "Validation Error: Avg loss: 535.642517 \n",
      "\n",
      "2023-11-08 13:22:35.753341 Epoch 540, Training loss 195.7947540283203\n",
      "R2 values 0.9382, 0.7643, 0.8798; mean R2=0.8608\n",
      "Validation Error: Avg loss: 521.245605 \n",
      "\n",
      "2023-11-08 13:22:36.236506 Epoch 541, Training loss 342.1797790527344\n",
      "R2 values 0.9582, 0.7191, 0.8185; mean R2=0.8319\n",
      "Validation Error: Avg loss: 456.441193 \n",
      "\n",
      "2023-11-08 13:22:36.734470 Epoch 542, Training loss 222.00286865234375\n",
      "R2 values 0.9592, 0.7755, 0.7949; mean R2=0.8432\n",
      "Validation Error: Avg loss: 599.205017 \n",
      "\n",
      "2023-11-08 13:22:37.221679 Epoch 543, Training loss 305.81671142578125\n",
      "R2 values 0.9629, 0.7449, 0.8310; mean R2=0.8463\n",
      "Validation Error: Avg loss: 373.973846 \n",
      "\n",
      "2023-11-08 13:22:37.787893 Epoch 544, Training loss 249.56478881835938\n",
      "R2 values 0.9502, 0.7185, 0.7765; mean R2=0.8150\n",
      "Validation Error: Avg loss: 515.689514 \n",
      "\n",
      "2023-11-08 13:22:38.287767 Epoch 545, Training loss 242.30418395996094\n",
      "R2 values 0.9352, 0.7829, 0.8248; mean R2=0.8476\n",
      "Validation Error: Avg loss: 579.078979 \n",
      "\n",
      "2023-11-08 13:22:38.775142 Epoch 546, Training loss 325.77398681640625\n",
      "R2 values 0.9537, 0.7336, 0.8429; mean R2=0.8434\n",
      "Validation Error: Avg loss: 493.622192 \n",
      "\n",
      "2023-11-08 13:22:39.291037 Epoch 547, Training loss 257.3802490234375\n",
      "R2 values 0.9444, 0.7704, 0.8528; mean R2=0.8559\n",
      "Validation Error: Avg loss: 604.338318 \n",
      "\n",
      "2023-11-08 13:22:39.781691 Epoch 548, Training loss 222.23387145996094\n",
      "R2 values 0.9438, 0.7943, 0.8850; mean R2=0.8744\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 493.121613 \n",
      "\n",
      "2023-11-08 13:22:40.295571 Epoch 549, Training loss 274.2485046386719\n",
      "R2 values 0.9487, 0.7754, 0.7518; mean R2=0.8253\n",
      "Validation Error: Avg loss: 507.400726 \n",
      "\n",
      "2023-11-08 13:22:40.790025 Epoch 550, Training loss 261.2020568847656\n",
      "R2 values 0.9337, 0.7373, 0.8426; mean R2=0.8379\n",
      "Validation Error: Avg loss: 607.625671 \n",
      "\n",
      "2023-11-08 13:22:41.284475 Epoch 551, Training loss 254.35098266601562\n",
      "R2 values 0.9497, 0.7952, 0.8050; mean R2=0.8500\n",
      "Validation Error: Avg loss: 557.583435 \n",
      "\n",
      "2023-11-08 13:22:41.773059 Epoch 552, Training loss 237.763671875\n",
      "R2 values 0.9501, 0.7453, 0.8700; mean R2=0.8551\n",
      "Validation Error: Avg loss: 544.215332 \n",
      "\n",
      "2023-11-08 13:22:42.263110 Epoch 553, Training loss 260.845703125\n",
      "R2 values 0.9462, 0.8070, 0.8461; mean R2=0.8664\n",
      "Validation Error: Avg loss: 475.745270 \n",
      "\n",
      "2023-11-08 13:22:42.747401 Epoch 554, Training loss 216.49986267089844\n",
      "R2 values 0.9366, 0.8045, 0.8482; mean R2=0.8631\n",
      "Validation Error: Avg loss: 581.343018 \n",
      "\n",
      "2023-11-08 13:22:43.229618 Epoch 555, Training loss 374.91119384765625\n",
      "R2 values 0.9541, 0.8368, 0.8550; mean R2=0.8819\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 495.104370 \n",
      "\n",
      "2023-11-08 13:22:43.915056 Epoch 556, Training loss 214.4544677734375\n",
      "R2 values 0.9390, 0.7870, 0.8215; mean R2=0.8492\n",
      "Validation Error: Avg loss: 759.658569 \n",
      "\n",
      "2023-11-08 13:22:44.564258 Epoch 557, Training loss 286.01983642578125\n",
      "R2 values 0.9374, 0.8197, 0.8472; mean R2=0.8681\n",
      "Validation Error: Avg loss: 513.507385 \n",
      "\n",
      "2023-11-08 13:22:45.056613 Epoch 558, Training loss 220.42391967773438\n",
      "R2 values 0.9524, 0.8214, 0.8414; mean R2=0.8717\n",
      "Validation Error: Avg loss: 474.319305 \n",
      "\n",
      "2023-11-08 13:22:45.548780 Epoch 559, Training loss 317.4182434082031\n",
      "R2 values 0.9567, 0.8359, 0.8873; mean R2=0.8933\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 399.552704 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:22:46.072515 Epoch 560, Training loss 218.7578887939453\n",
      "R2 values 0.9413, 0.7775, 0.8447; mean R2=0.8545\n",
      "Validation Error: Avg loss: 716.872620 \n",
      "\n",
      "2023-11-08 13:22:46.554933 Epoch 561, Training loss 311.8204345703125\n",
      "R2 values 0.9441, 0.8315, 0.8751; mean R2=0.8836\n",
      "Validation Error: Avg loss: 599.438416 \n",
      "\n",
      "2023-11-08 13:22:47.042761 Epoch 562, Training loss 267.34014892578125\n",
      "R2 values 0.9377, 0.8103, 0.8130; mean R2=0.8537\n",
      "Validation Error: Avg loss: 556.474976 \n",
      "\n",
      "2023-11-08 13:22:47.542193 Epoch 563, Training loss 287.53656005859375\n",
      "R2 values 0.9492, 0.7898, 0.8145; mean R2=0.8512\n",
      "Validation Error: Avg loss: 447.746185 \n",
      "\n",
      "2023-11-08 13:22:48.046541 Epoch 564, Training loss 282.2156066894531\n",
      "R2 values 0.9261, 0.7348, 0.8267; mean R2=0.8292\n",
      "Validation Error: Avg loss: 702.338989 \n",
      "\n",
      "2023-11-08 13:22:48.541997 Epoch 565, Training loss 289.0291748046875\n",
      "R2 values 0.9370, 0.7418, 0.8193; mean R2=0.8327\n",
      "Validation Error: Avg loss: 749.044128 \n",
      "\n",
      "2023-11-08 13:22:49.156576 Epoch 566, Training loss 306.9852600097656\n",
      "R2 values 0.9559, 0.8262, 0.8354; mean R2=0.8725\n",
      "Validation Error: Avg loss: 458.960632 \n",
      "\n",
      "2023-11-08 13:22:49.687705 Epoch 567, Training loss 355.3512878417969\n",
      "R2 values 0.9512, 0.7915, 0.8707; mean R2=0.8712\n",
      "Validation Error: Avg loss: 427.873962 \n",
      "\n",
      "2023-11-08 13:22:50.189635 Epoch 568, Training loss 305.9090576171875\n",
      "R2 values 0.9480, 0.7858, 0.8294; mean R2=0.8544\n",
      "Validation Error: Avg loss: 706.624084 \n",
      "\n",
      "2023-11-08 13:22:50.674459 Epoch 569, Training loss 292.7529602050781\n",
      "R2 values 0.9544, 0.8163, 0.8670; mean R2=0.8792\n",
      "Validation Error: Avg loss: 656.515442 \n",
      "\n",
      "2023-11-08 13:22:51.167810 Epoch 570, Training loss 314.4373474121094\n",
      "R2 values 0.9478, 0.7533, 0.8294; mean R2=0.8435\n",
      "Validation Error: Avg loss: 521.676819 \n",
      "\n",
      "2023-11-08 13:22:51.663733 Epoch 571, Training loss 205.07553100585938\n",
      "R2 values 0.9441, 0.7398, 0.7895; mean R2=0.8245\n",
      "Validation Error: Avg loss: 549.008972 \n",
      "\n",
      "2023-11-08 13:22:52.152008 Epoch 572, Training loss 469.5088806152344\n",
      "R2 values 0.9324, 0.7656, 0.8398; mean R2=0.8459\n",
      "Validation Error: Avg loss: 587.226807 \n",
      "\n",
      "2023-11-08 13:22:52.645760 Epoch 573, Training loss 220.47097778320312\n",
      "R2 values 0.9414, 0.7755, 0.8098; mean R2=0.8422\n",
      "Validation Error: Avg loss: 692.448364 \n",
      "\n",
      "2023-11-08 13:22:53.158529 Epoch 574, Training loss 286.5068054199219\n",
      "R2 values 0.9474, 0.8048, 0.8380; mean R2=0.8634\n",
      "Validation Error: Avg loss: 535.600952 \n",
      "\n",
      "2023-11-08 13:22:53.654998 Epoch 575, Training loss 248.1846923828125\n",
      "R2 values 0.9443, 0.7939, 0.8534; mean R2=0.8638\n",
      "Validation Error: Avg loss: 490.730164 \n",
      "\n",
      "2023-11-08 13:22:54.149099 Epoch 576, Training loss 216.47586059570312\n",
      "R2 values 0.9370, 0.8043, 0.8443; mean R2=0.8619\n",
      "Validation Error: Avg loss: 521.071899 \n",
      "\n",
      "2023-11-08 13:22:54.642272 Epoch 577, Training loss 262.1623229980469\n",
      "R2 values 0.9558, 0.7755, 0.8339; mean R2=0.8551\n",
      "Validation Error: Avg loss: 473.327484 \n",
      "\n",
      "2023-11-08 13:22:55.129900 Epoch 578, Training loss 204.7099151611328\n",
      "R2 values 0.9611, 0.7953, 0.8301; mean R2=0.8622\n",
      "Validation Error: Avg loss: 574.859131 \n",
      "\n",
      "2023-11-08 13:22:55.615473 Epoch 579, Training loss 256.7063903808594\n",
      "R2 values 0.9609, 0.8141, 0.8524; mean R2=0.8758\n",
      "Validation Error: Avg loss: 401.566528 \n",
      "\n",
      "2023-11-08 13:22:56.108906 Epoch 580, Training loss 212.6221160888672\n",
      "R2 values 0.9452, 0.8279, 0.8799; mean R2=0.8843\n",
      "Validation Error: Avg loss: 477.150116 \n",
      "\n",
      "2023-11-08 13:22:56.595005 Epoch 581, Training loss 301.28961181640625\n",
      "R2 values 0.9581, 0.7737, 0.8683; mean R2=0.8667\n",
      "Validation Error: Avg loss: 442.467163 \n",
      "\n",
      "2023-11-08 13:22:57.081794 Epoch 582, Training loss 193.48509216308594\n",
      "R2 values 0.9368, 0.8169, 0.8652; mean R2=0.8730\n",
      "Validation Error: Avg loss: 613.294556 \n",
      "\n",
      "2023-11-08 13:22:57.562407 Epoch 583, Training loss 251.47621154785156\n",
      "R2 values 0.9625, 0.7760, 0.8254; mean R2=0.8546\n",
      "Validation Error: Avg loss: 418.674072 \n",
      "\n",
      "2023-11-08 13:22:58.054796 Epoch 584, Training loss 180.05345153808594\n",
      "R2 values 0.9384, 0.7882, 0.8375; mean R2=0.8547\n",
      "Validation Error: Avg loss: 516.933533 \n",
      "\n",
      "2023-11-08 13:22:58.556074 Epoch 585, Training loss 198.318359375\n",
      "R2 values 0.9497, 0.7515, 0.8519; mean R2=0.8510\n",
      "Validation Error: Avg loss: 444.394440 \n",
      "\n",
      "2023-11-08 13:22:59.096309 Epoch 586, Training loss 247.7147216796875\n",
      "R2 values 0.9387, 0.7539, 0.8623; mean R2=0.8516\n",
      "Validation Error: Avg loss: 511.932220 \n",
      "\n",
      "2023-11-08 13:22:59.611052 Epoch 587, Training loss 223.62307739257812\n",
      "R2 values 0.9387, 0.7889, 0.7904; mean R2=0.8393\n",
      "Validation Error: Avg loss: 696.265320 \n",
      "\n",
      "2023-11-08 13:23:00.142475 Epoch 588, Training loss 283.6951904296875\n",
      "R2 values 0.9141, 0.7845, 0.8205; mean R2=0.8397\n",
      "Validation Error: Avg loss: 786.025574 \n",
      "\n",
      "2023-11-08 13:23:00.633543 Epoch 589, Training loss 240.9014892578125\n",
      "R2 values 0.9531, 0.7743, 0.8456; mean R2=0.8577\n",
      "Validation Error: Avg loss: 419.635651 \n",
      "\n",
      "2023-11-08 13:23:01.117188 Epoch 590, Training loss 191.17445373535156\n",
      "R2 values 0.9493, 0.8007, 0.8475; mean R2=0.8658\n",
      "Validation Error: Avg loss: 455.034271 \n",
      "\n",
      "2023-11-08 13:23:01.604142 Epoch 591, Training loss 228.27037048339844\n",
      "R2 values 0.9437, 0.8168, 0.8731; mean R2=0.8779\n",
      "Validation Error: Avg loss: 477.110229 \n",
      "\n",
      "2023-11-08 13:23:02.087363 Epoch 592, Training loss 216.5525360107422\n",
      "R2 values 0.9543, 0.8269, 0.8541; mean R2=0.8784\n",
      "Validation Error: Avg loss: 590.216370 \n",
      "\n",
      "2023-11-08 13:23:02.571133 Epoch 593, Training loss 333.1108703613281\n",
      "R2 values 0.9617, 0.7947, 0.8484; mean R2=0.8682\n",
      "Validation Error: Avg loss: 382.239990 \n",
      "\n",
      "2023-11-08 13:23:03.086765 Epoch 594, Training loss 210.8900146484375\n",
      "R2 values 0.9448, 0.8191, 0.7972; mean R2=0.8537\n",
      "Validation Error: Avg loss: 492.963806 \n",
      "\n",
      "2023-11-08 13:23:03.571962 Epoch 595, Training loss 294.5307922363281\n",
      "R2 values 0.9506, 0.7932, 0.7905; mean R2=0.8448\n",
      "Validation Error: Avg loss: 583.514832 \n",
      "\n",
      "2023-11-08 13:23:04.067761 Epoch 596, Training loss 207.41934204101562\n",
      "R2 values 0.9188, 0.7923, 0.8011; mean R2=0.8374\n",
      "Validation Error: Avg loss: 780.562561 \n",
      "\n",
      "2023-11-08 13:23:04.543274 Epoch 597, Training loss 259.59423828125\n",
      "R2 values 0.9472, 0.8714, 0.8735; mean R2=0.8974\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 505.301697 \n",
      "\n",
      "2023-11-08 13:23:05.069369 Epoch 598, Training loss 234.0659942626953\n",
      "R2 values 0.9228, 0.7544, 0.8526; mean R2=0.8433\n",
      "Validation Error: Avg loss: 624.044373 \n",
      "\n",
      "2023-11-08 13:23:05.554121 Epoch 599, Training loss 237.46533203125\n",
      "R2 values 0.9512, 0.6884, 0.8527; mean R2=0.8308\n",
      "Validation Error: Avg loss: 454.325073 \n",
      "\n",
      "2023-11-08 13:23:06.040305 Epoch 600, Training loss 293.5244445800781\n",
      "R2 values 0.9503, 0.7555, 0.8460; mean R2=0.8506\n",
      "Validation Error: Avg loss: 598.820740 \n",
      "\n",
      "2023-11-08 13:23:06.529898 Epoch 601, Training loss 278.0215148925781\n",
      "R2 values 0.9380, 0.8207, 0.8919; mean R2=0.8835\n",
      "Validation Error: Avg loss: 534.815979 \n",
      "\n",
      "2023-11-08 13:23:07.038122 Epoch 602, Training loss 243.72657775878906\n",
      "R2 values 0.9342, 0.8190, 0.8401; mean R2=0.8645\n",
      "Validation Error: Avg loss: 558.520691 \n",
      "\n",
      "2023-11-08 13:23:07.524153 Epoch 603, Training loss 206.6328125\n",
      "R2 values 0.9590, 0.7943, 0.8283; mean R2=0.8605\n",
      "Validation Error: Avg loss: 424.814117 \n",
      "\n",
      "2023-11-08 13:23:08.022992 Epoch 604, Training loss 246.27169799804688\n",
      "R2 values 0.9477, 0.7518, 0.8097; mean R2=0.8364\n",
      "Validation Error: Avg loss: 629.555969 \n",
      "\n",
      "2023-11-08 13:23:08.530277 Epoch 605, Training loss 275.651123046875\n",
      "R2 values 0.9498, 0.8169, 0.8600; mean R2=0.8756\n",
      "Validation Error: Avg loss: 532.225037 \n",
      "\n",
      "2023-11-08 13:23:09.165909 Epoch 606, Training loss 230.09645080566406\n",
      "R2 values 0.9363, 0.8331, 0.8645; mean R2=0.8780\n",
      "Validation Error: Avg loss: 575.182861 \n",
      "\n",
      "2023-11-08 13:23:09.757916 Epoch 607, Training loss 290.45147705078125\n",
      "R2 values 0.9537, 0.8087, 0.8352; mean R2=0.8659\n",
      "Validation Error: Avg loss: 412.515839 \n",
      "\n",
      "2023-11-08 13:23:10.241084 Epoch 608, Training loss 280.5355224609375\n",
      "R2 values 0.9527, 0.7399, 0.8307; mean R2=0.8411\n",
      "Validation Error: Avg loss: 614.464905 \n",
      "\n",
      "2023-11-08 13:23:10.727718 Epoch 609, Training loss 228.92335510253906\n",
      "R2 values 0.9436, 0.7712, 0.7936; mean R2=0.8362\n",
      "Validation Error: Avg loss: 664.572815 \n",
      "\n",
      "2023-11-08 13:23:11.214520 Epoch 610, Training loss 271.3478088378906\n",
      "R2 values 0.9271, 0.7183, 0.8245; mean R2=0.8233\n",
      "Validation Error: Avg loss: 635.758911 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:23:11.699802 Epoch 611, Training loss 256.7754821777344\n",
      "R2 values 0.9269, 0.7705, 0.8513; mean R2=0.8496\n",
      "Validation Error: Avg loss: 596.464417 \n",
      "\n",
      "2023-11-08 13:23:12.185604 Epoch 612, Training loss 321.5965881347656\n",
      "R2 values 0.9436, 0.7161, 0.8533; mean R2=0.8377\n",
      "Validation Error: Avg loss: 661.928833 \n",
      "\n",
      "2023-11-08 13:23:12.674137 Epoch 613, Training loss 284.8231506347656\n",
      "R2 values 0.9224, 0.7976, 0.8959; mean R2=0.8720\n",
      "Validation Error: Avg loss: 799.274048 \n",
      "\n",
      "2023-11-08 13:23:13.187428 Epoch 614, Training loss 374.4698486328125\n",
      "R2 values 0.9574, 0.7932, 0.8402; mean R2=0.8636\n",
      "Validation Error: Avg loss: 407.747437 \n",
      "\n",
      "2023-11-08 13:23:13.678566 Epoch 615, Training loss 240.62596130371094\n",
      "R2 values 0.9368, 0.7727, 0.8390; mean R2=0.8495\n",
      "Validation Error: Avg loss: 585.601501 \n",
      "\n",
      "2023-11-08 13:23:14.168546 Epoch 616, Training loss 407.873291015625\n",
      "R2 values 0.9548, 0.8114, 0.8665; mean R2=0.8776\n",
      "Validation Error: Avg loss: 572.428284 \n",
      "\n",
      "2023-11-08 13:23:14.669442 Epoch 617, Training loss 268.55767822265625\n",
      "R2 values 0.9415, 0.8225, 0.8516; mean R2=0.8719\n",
      "Validation Error: Avg loss: 574.018616 \n",
      "\n",
      "2023-11-08 13:23:15.164522 Epoch 618, Training loss 271.4292907714844\n",
      "R2 values 0.9333, 0.8380, 0.8957; mean R2=0.8890\n",
      "Validation Error: Avg loss: 535.369812 \n",
      "\n",
      "2023-11-08 13:23:15.657041 Epoch 619, Training loss 258.6831970214844\n",
      "R2 values 0.9508, 0.7842, 0.7887; mean R2=0.8412\n",
      "Validation Error: Avg loss: 479.492706 \n",
      "\n",
      "2023-11-08 13:23:16.154462 Epoch 620, Training loss 248.0623321533203\n",
      "R2 values 0.9176, 0.7498, 0.8251; mean R2=0.8308\n",
      "Validation Error: Avg loss: 673.123169 \n",
      "\n",
      "2023-11-08 13:23:16.648312 Epoch 621, Training loss 258.638427734375\n",
      "R2 values 0.9444, 0.7707, 0.8587; mean R2=0.8579\n",
      "Validation Error: Avg loss: 481.813721 \n",
      "\n",
      "2023-11-08 13:23:17.171633 Epoch 622, Training loss 238.37374877929688\n",
      "R2 values 0.9510, 0.7850, 0.8261; mean R2=0.8540\n",
      "Validation Error: Avg loss: 465.880737 \n",
      "\n",
      "2023-11-08 13:23:17.665723 Epoch 623, Training loss 160.62820434570312\n",
      "R2 values 0.9441, 0.7926, 0.8414; mean R2=0.8594\n",
      "Validation Error: Avg loss: 518.723267 \n",
      "\n",
      "2023-11-08 13:23:18.162582 Epoch 624, Training loss 214.0001220703125\n",
      "R2 values 0.9542, 0.7686, 0.7876; mean R2=0.8368\n",
      "Validation Error: Avg loss: 484.115021 \n",
      "\n",
      "2023-11-08 13:23:18.675148 Epoch 625, Training loss 216.4980010986328\n",
      "R2 values 0.9578, 0.7591, 0.8206; mean R2=0.8459\n",
      "Validation Error: Avg loss: 512.648193 \n",
      "\n",
      "2023-11-08 13:23:19.169320 Epoch 626, Training loss 265.7538757324219\n",
      "R2 values 0.9498, 0.7906, 0.8280; mean R2=0.8562\n",
      "Validation Error: Avg loss: 644.186035 \n",
      "\n",
      "2023-11-08 13:23:19.651043 Epoch 627, Training loss 221.8706512451172\n",
      "R2 values 0.9506, 0.8176, 0.8277; mean R2=0.8653\n",
      "Validation Error: Avg loss: 447.060425 \n",
      "\n",
      "2023-11-08 13:23:20.143675 Epoch 628, Training loss 175.56182861328125\n",
      "R2 values 0.9584, 0.8044, 0.8451; mean R2=0.8693\n",
      "Validation Error: Avg loss: 374.897400 \n",
      "\n",
      "2023-11-08 13:23:20.634547 Epoch 629, Training loss 277.3896484375\n",
      "R2 values 0.9664, 0.7808, 0.8736; mean R2=0.8736\n",
      "Validation Error: Avg loss: 338.317596 \n",
      "\n",
      "2023-11-08 13:23:21.228737 Epoch 630, Training loss 197.93466186523438\n",
      "R2 values 0.9543, 0.8137, 0.8549; mean R2=0.8743\n",
      "Validation Error: Avg loss: 469.532196 \n",
      "\n",
      "2023-11-08 13:23:21.742820 Epoch 631, Training loss 192.27340698242188\n",
      "R2 values 0.9335, 0.7995, 0.8093; mean R2=0.8474\n",
      "Validation Error: Avg loss: 687.978027 \n",
      "\n",
      "2023-11-08 13:23:22.223318 Epoch 632, Training loss 168.0768280029297\n",
      "R2 values 0.9521, 0.8263, 0.8769; mean R2=0.8851\n",
      "Validation Error: Avg loss: 463.872833 \n",
      "\n",
      "2023-11-08 13:23:22.706910 Epoch 633, Training loss 161.9694366455078\n",
      "R2 values 0.9384, 0.8198, 0.8630; mean R2=0.8737\n",
      "Validation Error: Avg loss: 529.462036 \n",
      "\n",
      "2023-11-08 13:23:23.200434 Epoch 634, Training loss 203.8415069580078\n",
      "R2 values 0.9412, 0.8265, 0.8534; mean R2=0.8737\n",
      "Validation Error: Avg loss: 481.281250 \n",
      "\n",
      "2023-11-08 13:23:23.691126 Epoch 635, Training loss 207.3336639404297\n",
      "R2 values 0.9529, 0.8235, 0.8683; mean R2=0.8816\n",
      "Validation Error: Avg loss: 409.358337 \n",
      "\n",
      "2023-11-08 13:23:24.173187 Epoch 636, Training loss 226.1455078125\n",
      "R2 values 0.9457, 0.8267, 0.8824; mean R2=0.8849\n",
      "Validation Error: Avg loss: 460.927582 \n",
      "\n",
      "2023-11-08 13:23:24.658897 Epoch 637, Training loss 195.1156005859375\n",
      "R2 values 0.9440, 0.8353, 0.8786; mean R2=0.8860\n",
      "Validation Error: Avg loss: 464.205414 \n",
      "\n",
      "2023-11-08 13:23:25.152933 Epoch 638, Training loss 225.0097198486328\n",
      "R2 values 0.9433, 0.8078, 0.8684; mean R2=0.8732\n",
      "Validation Error: Avg loss: 500.333954 \n",
      "\n",
      "2023-11-08 13:23:25.641863 Epoch 639, Training loss 180.555419921875\n",
      "R2 values 0.9495, 0.7549, 0.8607; mean R2=0.8550\n",
      "Validation Error: Avg loss: 481.004761 \n",
      "\n",
      "2023-11-08 13:23:26.144118 Epoch 640, Training loss 192.78785705566406\n",
      "R2 values 0.9343, 0.8495, 0.8463; mean R2=0.8767\n",
      "Validation Error: Avg loss: 553.147461 \n",
      "\n",
      "2023-11-08 13:23:26.628590 Epoch 641, Training loss 181.00588989257812\n",
      "R2 values 0.9534, 0.8158, 0.9016; mean R2=0.8903\n",
      "Validation Error: Avg loss: 380.237610 \n",
      "\n",
      "2023-11-08 13:23:27.134123 Epoch 642, Training loss 171.43844604492188\n",
      "R2 values 0.9460, 0.8060, 0.8294; mean R2=0.8605\n",
      "Validation Error: Avg loss: 471.455994 \n",
      "\n",
      "2023-11-08 13:23:27.634018 Epoch 643, Training loss 184.804931640625\n",
      "R2 values 0.9568, 0.7360, 0.8432; mean R2=0.8453\n",
      "Validation Error: Avg loss: 468.271729 \n",
      "\n",
      "2023-11-08 13:23:28.153212 Epoch 644, Training loss 242.69529724121094\n",
      "R2 values 0.9513, 0.7705, 0.8373; mean R2=0.8530\n",
      "Validation Error: Avg loss: 614.094360 \n",
      "\n",
      "2023-11-08 13:23:28.660946 Epoch 645, Training loss 201.53977966308594\n",
      "R2 values 0.9552, 0.7930, 0.8208; mean R2=0.8563\n",
      "Validation Error: Avg loss: 419.279663 \n",
      "\n",
      "2023-11-08 13:23:29.154409 Epoch 646, Training loss 236.2834930419922\n",
      "R2 values 0.9315, 0.6812, 0.8082; mean R2=0.8069\n",
      "Validation Error: Avg loss: 649.047180 \n",
      "\n",
      "2023-11-08 13:23:29.646928 Epoch 647, Training loss 230.48358154296875\n",
      "R2 values 0.9483, 0.6938, 0.8019; mean R2=0.8147\n",
      "Validation Error: Avg loss: 524.181396 \n",
      "\n",
      "2023-11-08 13:23:30.134812 Epoch 648, Training loss 178.85589599609375\n",
      "R2 values 0.9317, 0.7633, 0.8372; mean R2=0.8440\n",
      "Validation Error: Avg loss: 605.009521 \n",
      "\n",
      "2023-11-08 13:23:30.633603 Epoch 649, Training loss 199.1632080078125\n",
      "R2 values 0.9364, 0.8032, 0.8701; mean R2=0.8699\n",
      "Validation Error: Avg loss: 602.116943 \n",
      "\n",
      "2023-11-08 13:23:31.130770 Epoch 650, Training loss 213.77549743652344\n",
      "R2 values 0.9458, 0.8302, 0.8482; mean R2=0.8747\n",
      "Validation Error: Avg loss: 555.539551 \n",
      "\n",
      "2023-11-08 13:23:31.631561 Epoch 651, Training loss 218.06573486328125\n",
      "R2 values 0.9572, 0.8315, 0.8700; mean R2=0.8863\n",
      "Validation Error: Avg loss: 410.775330 \n",
      "\n",
      "2023-11-08 13:23:32.144709 Epoch 652, Training loss 184.8773956298828\n",
      "R2 values 0.9639, 0.8385, 0.8856; mean R2=0.8960\n",
      "Validation Error: Avg loss: 379.946259 \n",
      "\n",
      "2023-11-08 13:23:32.650115 Epoch 653, Training loss 162.04217529296875\n",
      "R2 values 0.9440, 0.8304, 0.8513; mean R2=0.8752\n",
      "Validation Error: Avg loss: 547.388733 \n",
      "\n",
      "2023-11-08 13:23:33.340505 Epoch 654, Training loss 171.9040069580078\n",
      "R2 values 0.9361, 0.8376, 0.8483; mean R2=0.8740\n",
      "Validation Error: Avg loss: 583.308655 \n",
      "\n",
      "2023-11-08 13:23:33.891886 Epoch 655, Training loss 168.69076538085938\n",
      "R2 values 0.9538, 0.8023, 0.8578; mean R2=0.8713\n",
      "Validation Error: Avg loss: 415.299164 \n",
      "\n",
      "2023-11-08 13:23:34.376005 Epoch 656, Training loss 189.0997314453125\n",
      "R2 values 0.9681, 0.8000, 0.8507; mean R2=0.8729\n",
      "Validation Error: Avg loss: 383.836670 \n",
      "\n",
      "2023-11-08 13:23:34.851789 Epoch 657, Training loss 280.6529541015625\n",
      "R2 values 0.9566, 0.7961, 0.7892; mean R2=0.8473\n",
      "Validation Error: Avg loss: 463.278809 \n",
      "\n",
      "2023-11-08 13:23:35.332748 Epoch 658, Training loss 190.64849853515625\n",
      "R2 values 0.9415, 0.8283, 0.8190; mean R2=0.8629\n",
      "Validation Error: Avg loss: 501.272339 \n",
      "\n",
      "2023-11-08 13:23:35.823807 Epoch 659, Training loss 176.4319305419922\n",
      "R2 values 0.9435, 0.8122, 0.8295; mean R2=0.8617\n",
      "Validation Error: Avg loss: 551.952942 \n",
      "\n",
      "2023-11-08 13:23:36.314500 Epoch 660, Training loss 205.3219757080078\n",
      "R2 values 0.9520, 0.8500, 0.8417; mean R2=0.8812\n",
      "Validation Error: Avg loss: 418.721619 \n",
      "\n",
      "2023-11-08 13:23:36.855716 Epoch 661, Training loss 171.72756958007812\n",
      "R2 values 0.9626, 0.8309, 0.8356; mean R2=0.8764\n",
      "Validation Error: Avg loss: 363.596649 \n",
      "\n",
      "2023-11-08 13:23:37.371115 Epoch 662, Training loss 269.2489013671875\n",
      "R2 values 0.9564, 0.8089, 0.8312; mean R2=0.8655\n",
      "Validation Error: Avg loss: 490.188660 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:23:37.885572 Epoch 663, Training loss 227.16665649414062\n",
      "R2 values 0.9481, 0.7904, 0.8869; mean R2=0.8751\n",
      "Validation Error: Avg loss: 566.007202 \n",
      "\n",
      "2023-11-08 13:23:38.401993 Epoch 664, Training loss 185.0224609375\n",
      "R2 values 0.9496, 0.7911, 0.8750; mean R2=0.8719\n",
      "Validation Error: Avg loss: 493.431915 \n",
      "\n",
      "2023-11-08 13:23:38.897330 Epoch 665, Training loss 173.14329528808594\n",
      "R2 values 0.9655, 0.7898, 0.8342; mean R2=0.8632\n",
      "Validation Error: Avg loss: 411.327484 \n",
      "\n",
      "2023-11-08 13:23:39.389219 Epoch 666, Training loss 200.55250549316406\n",
      "R2 values 0.9659, 0.8059, 0.8303; mean R2=0.8674\n",
      "Validation Error: Avg loss: 497.805450 \n",
      "\n",
      "2023-11-08 13:23:39.890335 Epoch 667, Training loss 167.89813232421875\n",
      "R2 values 0.9554, 0.7737, 0.8818; mean R2=0.8703\n",
      "Validation Error: Avg loss: 443.355347 \n",
      "\n",
      "2023-11-08 13:23:40.390476 Epoch 668, Training loss 198.60633850097656\n",
      "R2 values 0.9594, 0.7490, 0.8087; mean R2=0.8390\n",
      "Validation Error: Avg loss: 436.263733 \n",
      "\n",
      "2023-11-08 13:23:40.866905 Epoch 669, Training loss 240.15965270996094\n",
      "R2 values 0.9660, 0.7796, 0.8534; mean R2=0.8663\n",
      "Validation Error: Avg loss: 330.170410 \n",
      "\n",
      "2023-11-08 13:23:41.357046 Epoch 670, Training loss 171.8739776611328\n",
      "R2 values 0.9516, 0.8398, 0.8529; mean R2=0.8814\n",
      "Validation Error: Avg loss: 677.788269 \n",
      "\n",
      "2023-11-08 13:23:41.838783 Epoch 671, Training loss 185.53607177734375\n",
      "R2 values 0.9479, 0.8289, 0.8634; mean R2=0.8801\n",
      "Validation Error: Avg loss: 668.985962 \n",
      "\n",
      "2023-11-08 13:23:42.312907 Epoch 672, Training loss 294.79290771484375\n",
      "R2 values 0.9443, 0.8420, 0.8719; mean R2=0.8860\n",
      "Validation Error: Avg loss: 492.497498 \n",
      "\n",
      "2023-11-08 13:23:42.793810 Epoch 673, Training loss 178.5846710205078\n",
      "R2 values 0.9501, 0.7971, 0.8740; mean R2=0.8738\n",
      "Validation Error: Avg loss: 458.809174 \n",
      "\n",
      "2023-11-08 13:23:43.287432 Epoch 674, Training loss 222.06781005859375\n",
      "R2 values 0.9386, 0.7867, 0.8313; mean R2=0.8522\n",
      "Validation Error: Avg loss: 566.881287 \n",
      "\n",
      "2023-11-08 13:23:43.772555 Epoch 675, Training loss 283.9788818359375\n",
      "R2 values 0.9316, 0.7561, 0.8278; mean R2=0.8385\n",
      "Validation Error: Avg loss: 707.977661 \n",
      "\n",
      "2023-11-08 13:23:44.263035 Epoch 676, Training loss 265.5841979980469\n",
      "R2 values 0.9512, 0.8226, 0.8720; mean R2=0.8820\n",
      "Validation Error: Avg loss: 438.238556 \n",
      "\n",
      "2023-11-08 13:23:44.772753 Epoch 677, Training loss 180.80470275878906\n",
      "R2 values 0.9388, 0.7750, 0.8708; mean R2=0.8615\n",
      "Validation Error: Avg loss: 549.991699 \n",
      "\n",
      "2023-11-08 13:23:45.252277 Epoch 678, Training loss 305.9623107910156\n",
      "R2 values 0.9607, 0.7832, 0.8445; mean R2=0.8628\n",
      "Validation Error: Avg loss: 450.235199 \n",
      "\n",
      "2023-11-08 13:23:45.742706 Epoch 679, Training loss 193.1224365234375\n",
      "R2 values 0.9573, 0.8039, 0.8364; mean R2=0.8658\n",
      "Validation Error: Avg loss: 549.455811 \n",
      "\n",
      "2023-11-08 13:23:46.227990 Epoch 680, Training loss 318.4624938964844\n",
      "R2 values 0.9542, 0.8060, 0.8675; mean R2=0.8759\n",
      "Validation Error: Avg loss: 403.824799 \n",
      "\n",
      "2023-11-08 13:23:46.711778 Epoch 681, Training loss 150.58399963378906\n",
      "R2 values 0.9650, 0.8171, 0.8508; mean R2=0.8777\n",
      "Validation Error: Avg loss: 369.401459 \n",
      "\n",
      "2023-11-08 13:23:47.221657 Epoch 682, Training loss 242.42662048339844\n",
      "R2 values 0.9623, 0.8206, 0.8661; mean R2=0.8830\n",
      "Validation Error: Avg loss: 371.981598 \n",
      "\n",
      "2023-11-08 13:23:47.703366 Epoch 683, Training loss 237.20510864257812\n",
      "R2 values 0.9604, 0.8162, 0.8484; mean R2=0.8750\n",
      "Validation Error: Avg loss: 565.681213 \n",
      "\n",
      "2023-11-08 13:23:48.203448 Epoch 684, Training loss 204.10165405273438\n",
      "R2 values 0.9495, 0.7929, 0.8803; mean R2=0.8742\n",
      "Validation Error: Avg loss: 519.768005 \n",
      "\n",
      "2023-11-08 13:23:48.690800 Epoch 685, Training loss 160.34588623046875\n",
      "R2 values 0.9369, 0.8056, 0.8598; mean R2=0.8674\n",
      "Validation Error: Avg loss: 602.237671 \n",
      "\n",
      "2023-11-08 13:23:49.182110 Epoch 686, Training loss 195.35836791992188\n",
      "R2 values 0.9541, 0.8415, 0.8490; mean R2=0.8815\n",
      "Validation Error: Avg loss: 414.901611 \n",
      "\n",
      "2023-11-08 13:23:49.675017 Epoch 687, Training loss 172.284423828125\n",
      "R2 values 0.9604, 0.7756, 0.8437; mean R2=0.8599\n",
      "Validation Error: Avg loss: 364.606262 \n",
      "\n",
      "2023-11-08 13:23:50.161007 Epoch 688, Training loss 159.7237091064453\n",
      "R2 values 0.9379, 0.7448, 0.8205; mean R2=0.8344\n",
      "Validation Error: Avg loss: 542.067932 \n",
      "\n",
      "2023-11-08 13:23:50.650315 Epoch 689, Training loss 167.91839599609375\n",
      "R2 values 0.9602, 0.7517, 0.8448; mean R2=0.8522\n",
      "Validation Error: Avg loss: 389.485809 \n",
      "\n",
      "2023-11-08 13:23:51.138864 Epoch 690, Training loss 189.01168823242188\n",
      "R2 values 0.9611, 0.7962, 0.8573; mean R2=0.8715\n",
      "Validation Error: Avg loss: 384.821289 \n",
      "\n",
      "2023-11-08 13:23:51.621493 Epoch 691, Training loss 161.2107391357422\n",
      "R2 values 0.9326, 0.7773, 0.8186; mean R2=0.8429\n",
      "Validation Error: Avg loss: 607.488831 \n",
      "\n",
      "2023-11-08 13:23:52.102592 Epoch 692, Training loss 207.636962890625\n",
      "R2 values 0.9558, 0.7833, 0.8654; mean R2=0.8682\n",
      "Validation Error: Avg loss: 463.656799 \n",
      "\n",
      "2023-11-08 13:23:52.661442 Epoch 693, Training loss 180.41873168945312\n",
      "R2 values 0.9552, 0.8024, 0.8433; mean R2=0.8670\n",
      "Validation Error: Avg loss: 444.048676 \n",
      "\n",
      "2023-11-08 13:23:53.148932 Epoch 694, Training loss 174.7562713623047\n",
      "R2 values 0.9607, 0.8050, 0.8200; mean R2=0.8619\n",
      "Validation Error: Avg loss: 390.544983 \n",
      "\n",
      "2023-11-08 13:23:53.653566 Epoch 695, Training loss 152.41738891601562\n",
      "R2 values 0.9632, 0.8069, 0.8764; mean R2=0.8822\n",
      "Validation Error: Avg loss: 324.891113 \n",
      "\n",
      "2023-11-08 13:23:54.198405 Epoch 696, Training loss 197.2428436279297\n",
      "R2 values 0.9590, 0.8212, 0.8799; mean R2=0.8867\n",
      "Validation Error: Avg loss: 417.945404 \n",
      "\n",
      "2023-11-08 13:23:54.738840 Epoch 697, Training loss 171.436279296875\n",
      "R2 values 0.9266, 0.8021, 0.8314; mean R2=0.8534\n",
      "Validation Error: Avg loss: 809.264221 \n",
      "\n",
      "2023-11-08 13:23:55.236539 Epoch 698, Training loss 205.66110229492188\n",
      "R2 values 0.9453, 0.7937, 0.8295; mean R2=0.8562\n",
      "Validation Error: Avg loss: 541.099976 \n",
      "\n",
      "2023-11-08 13:23:55.728353 Epoch 699, Training loss 225.87176513671875\n",
      "R2 values 0.9452, 0.7514, 0.8338; mean R2=0.8435\n",
      "Validation Error: Avg loss: 564.255493 \n",
      "\n",
      "2023-11-08 13:23:56.220384 Epoch 700, Training loss 256.277587890625\n",
      "R2 values 0.9248, 0.7631, 0.8594; mean R2=0.8491\n",
      "Validation Error: Avg loss: 609.987854 \n",
      "\n",
      "2023-11-08 13:23:56.709157 Epoch 701, Training loss 218.56028747558594\n",
      "R2 values 0.9486, 0.7791, 0.8334; mean R2=0.8537\n",
      "Validation Error: Avg loss: 583.621948 \n",
      "\n",
      "2023-11-08 13:23:57.221631 Epoch 702, Training loss 186.31016540527344\n",
      "R2 values 0.9347, 0.7944, 0.7975; mean R2=0.8422\n",
      "Validation Error: Avg loss: 568.148010 \n",
      "\n",
      "2023-11-08 13:23:57.717859 Epoch 703, Training loss 172.79891967773438\n",
      "R2 values 0.9492, 0.8101, 0.8296; mean R2=0.8630\n",
      "Validation Error: Avg loss: 437.614014 \n",
      "\n",
      "2023-11-08 13:23:58.214082 Epoch 704, Training loss 255.86399841308594\n",
      "R2 values 0.9406, 0.8108, 0.8454; mean R2=0.8656\n",
      "Validation Error: Avg loss: 503.867950 \n",
      "\n",
      "2023-11-08 13:23:58.728028 Epoch 705, Training loss 174.72286987304688\n",
      "R2 values 0.9416, 0.8054, 0.8086; mean R2=0.8519\n",
      "Validation Error: Avg loss: 619.914551 \n",
      "\n",
      "2023-11-08 13:23:59.224497 Epoch 706, Training loss 187.6674346923828\n",
      "R2 values 0.9394, 0.8018, 0.8826; mean R2=0.8746\n",
      "Validation Error: Avg loss: 617.381165 \n",
      "\n",
      "2023-11-08 13:23:59.721419 Epoch 707, Training loss 217.5560302734375\n",
      "R2 values 0.9500, 0.8118, 0.8766; mean R2=0.8794\n",
      "Validation Error: Avg loss: 443.670288 \n",
      "\n",
      "2023-11-08 13:24:00.207729 Epoch 708, Training loss 149.4110870361328\n",
      "R2 values 0.9557, 0.8008, 0.8637; mean R2=0.8734\n",
      "Validation Error: Avg loss: 407.956116 \n",
      "\n",
      "2023-11-08 13:24:00.690801 Epoch 709, Training loss 147.0592803955078\n",
      "R2 values 0.9539, 0.8152, 0.8661; mean R2=0.8784\n",
      "Validation Error: Avg loss: 410.838623 \n",
      "\n",
      "2023-11-08 13:24:01.176910 Epoch 710, Training loss 155.0889434814453\n",
      "R2 values 0.9288, 0.8305, 0.8490; mean R2=0.8695\n",
      "Validation Error: Avg loss: 618.847229 \n",
      "\n",
      "2023-11-08 13:24:01.666554 Epoch 711, Training loss 169.76229858398438\n",
      "R2 values 0.9377, 0.7828, 0.8484; mean R2=0.8563\n",
      "Validation Error: Avg loss: 631.156921 \n",
      "\n",
      "2023-11-08 13:24:02.207550 Epoch 712, Training loss 185.56031799316406\n",
      "R2 values 0.9518, 0.8322, 0.8472; mean R2=0.8771\n",
      "Validation Error: Avg loss: 468.532318 \n",
      "\n",
      "2023-11-08 13:24:02.686840 Epoch 713, Training loss 192.90203857421875\n",
      "R2 values 0.9582, 0.8528, 0.8513; mean R2=0.8874\n",
      "Validation Error: Avg loss: 383.640564 \n",
      "\n",
      "2023-11-08 13:24:03.170574 Epoch 714, Training loss 149.8486328125\n",
      "R2 values 0.9638, 0.8450, 0.8528; mean R2=0.8872\n",
      "Validation Error: Avg loss: 333.454285 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:24:03.670433 Epoch 715, Training loss 177.7269744873047\n",
      "R2 values 0.9552, 0.8244, 0.8445; mean R2=0.8747\n",
      "Validation Error: Avg loss: 388.152496 \n",
      "\n",
      "2023-11-08 13:24:04.152076 Epoch 716, Training loss 193.0048828125\n",
      "R2 values 0.9524, 0.7336, 0.8737; mean R2=0.8532\n",
      "Validation Error: Avg loss: 438.783752 \n",
      "\n",
      "2023-11-08 13:24:04.718009 Epoch 717, Training loss 132.11032104492188\n",
      "R2 values 0.9496, 0.8202, 0.7823; mean R2=0.8507\n",
      "Validation Error: Avg loss: 564.516479 \n",
      "\n",
      "2023-11-08 13:24:05.205459 Epoch 718, Training loss 139.7473602294922\n",
      "R2 values 0.9437, 0.7354, 0.8529; mean R2=0.8440\n",
      "Validation Error: Avg loss: 674.562927 \n",
      "\n",
      "2023-11-08 13:24:05.700668 Epoch 719, Training loss 231.91587829589844\n",
      "R2 values 0.9359, 0.7879, 0.8431; mean R2=0.8556\n",
      "Validation Error: Avg loss: 606.064575 \n",
      "\n",
      "2023-11-08 13:24:06.209317 Epoch 720, Training loss 181.22789001464844\n",
      "R2 values 0.9506, 0.7756, 0.8303; mean R2=0.8522\n",
      "Validation Error: Avg loss: 449.926544 \n",
      "\n",
      "2023-11-08 13:24:06.696446 Epoch 721, Training loss 167.59536743164062\n",
      "R2 values 0.9391, 0.7912, 0.8781; mean R2=0.8695\n",
      "Validation Error: Avg loss: 514.802856 \n",
      "\n",
      "2023-11-08 13:24:07.195754 Epoch 722, Training loss 152.8387451171875\n",
      "R2 values 0.9574, 0.7948, 0.8557; mean R2=0.8693\n",
      "Validation Error: Avg loss: 602.721069 \n",
      "\n",
      "2023-11-08 13:24:07.733049 Epoch 723, Training loss 221.74142456054688\n",
      "R2 values 0.9527, 0.7839, 0.8395; mean R2=0.8587\n",
      "Validation Error: Avg loss: 502.166504 \n",
      "\n",
      "2023-11-08 13:24:08.228881 Epoch 724, Training loss 162.20135498046875\n",
      "R2 values 0.9653, 0.8243, 0.8488; mean R2=0.8795\n",
      "Validation Error: Avg loss: 430.965088 \n",
      "\n",
      "2023-11-08 13:24:08.741519 Epoch 725, Training loss 256.0442199707031\n",
      "R2 values 0.9623, 0.7856, 0.8642; mean R2=0.8707\n",
      "Validation Error: Avg loss: 390.292694 \n",
      "\n",
      "2023-11-08 13:24:09.240422 Epoch 726, Training loss 178.8037109375\n",
      "R2 values 0.9435, 0.7220, 0.8160; mean R2=0.8272\n",
      "Validation Error: Avg loss: 801.629395 \n",
      "\n",
      "2023-11-08 13:24:09.723224 Epoch 727, Training loss 363.2071838378906\n",
      "R2 values 0.9494, 0.7900, 0.8449; mean R2=0.8614\n",
      "Validation Error: Avg loss: 519.301880 \n",
      "\n",
      "2023-11-08 13:24:10.221354 Epoch 728, Training loss 154.42079162597656\n",
      "R2 values 0.9515, 0.8202, 0.8660; mean R2=0.8792\n",
      "Validation Error: Avg loss: 425.306122 \n",
      "\n",
      "2023-11-08 13:24:10.718223 Epoch 729, Training loss 204.58819580078125\n",
      "R2 values 0.9467, 0.8342, 0.8548; mean R2=0.8786\n",
      "Validation Error: Avg loss: 447.306213 \n",
      "\n",
      "2023-11-08 13:24:11.457012 Epoch 730, Training loss 193.8140106201172\n",
      "R2 values 0.9439, 0.7831, 0.8899; mean R2=0.8723\n",
      "Validation Error: Avg loss: 741.664856 \n",
      "\n",
      "2023-11-08 13:24:11.973199 Epoch 731, Training loss 267.59942626953125\n",
      "R2 values 0.9516, 0.7848, 0.8673; mean R2=0.8679\n",
      "Validation Error: Avg loss: 432.687775 \n",
      "\n",
      "2023-11-08 13:24:12.466045 Epoch 732, Training loss 113.60847473144531\n",
      "R2 values 0.9485, 0.7823, 0.8930; mean R2=0.8746\n",
      "Validation Error: Avg loss: 490.460083 \n",
      "\n",
      "2023-11-08 13:24:12.994755 Epoch 733, Training loss 300.0476379394531\n",
      "R2 values 0.9549, 0.8129, 0.8780; mean R2=0.8819\n",
      "Validation Error: Avg loss: 398.220459 \n",
      "\n",
      "2023-11-08 13:24:13.483450 Epoch 734, Training loss 176.65054321289062\n",
      "R2 values 0.9633, 0.8140, 0.8861; mean R2=0.8878\n",
      "Validation Error: Avg loss: 670.556458 \n",
      "\n",
      "2023-11-08 13:24:13.983978 Epoch 735, Training loss 281.6168518066406\n",
      "R2 values 0.9602, 0.8055, 0.8742; mean R2=0.8800\n",
      "Validation Error: Avg loss: 376.093903 \n",
      "\n",
      "2023-11-08 13:24:14.478631 Epoch 736, Training loss 145.2216796875\n",
      "R2 values 0.9434, 0.8228, 0.8198; mean R2=0.8620\n",
      "Validation Error: Avg loss: 578.827515 \n",
      "\n",
      "2023-11-08 13:24:14.994274 Epoch 737, Training loss 267.58160400390625\n",
      "R2 values 0.9360, 0.7957, 0.8152; mean R2=0.8490\n",
      "Validation Error: Avg loss: 602.584290 \n",
      "\n",
      "2023-11-08 13:24:15.492692 Epoch 738, Training loss 217.41128540039062\n",
      "R2 values 0.9275, 0.7404, 0.8379; mean R2=0.8353\n",
      "Validation Error: Avg loss: 672.202637 \n",
      "\n",
      "2023-11-08 13:24:16.000421 Epoch 739, Training loss 179.44981384277344\n",
      "R2 values 0.9354, 0.7603, 0.8461; mean R2=0.8473\n",
      "Validation Error: Avg loss: 568.539795 \n",
      "\n",
      "2023-11-08 13:24:16.497513 Epoch 740, Training loss 155.8087158203125\n",
      "R2 values 0.9406, 0.8021, 0.8810; mean R2=0.8746\n",
      "Validation Error: Avg loss: 513.472046 \n",
      "\n",
      "2023-11-08 13:24:16.993278 Epoch 741, Training loss 143.16275024414062\n",
      "R2 values 0.9599, 0.8167, 0.8811; mean R2=0.8859\n",
      "Validation Error: Avg loss: 426.864349 \n",
      "\n",
      "2023-11-08 13:24:17.512158 Epoch 742, Training loss 207.61155700683594\n",
      "R2 values 0.9659, 0.8273, 0.8856; mean R2=0.8929\n",
      "Validation Error: Avg loss: 321.215881 \n",
      "\n",
      "2023-11-08 13:24:18.004084 Epoch 743, Training loss 186.19696044921875\n",
      "R2 values 0.9691, 0.8393, 0.8627; mean R2=0.8903\n",
      "Validation Error: Avg loss: 355.180969 \n",
      "\n",
      "2023-11-08 13:24:18.499139 Epoch 744, Training loss 187.2491912841797\n",
      "R2 values 0.9458, 0.8034, 0.8685; mean R2=0.8725\n",
      "Validation Error: Avg loss: 547.855652 \n",
      "\n",
      "2023-11-08 13:24:18.991960 Epoch 745, Training loss 150.2134246826172\n",
      "R2 values 0.9545, 0.7882, 0.8472; mean R2=0.8633\n",
      "Validation Error: Avg loss: 482.135406 \n",
      "\n",
      "2023-11-08 13:24:19.532875 Epoch 746, Training loss 138.32318115234375\n",
      "R2 values 0.9308, 0.7956, 0.8902; mean R2=0.8722\n",
      "Validation Error: Avg loss: 579.151489 \n",
      "\n",
      "2023-11-08 13:24:20.023293 Epoch 747, Training loss 183.78663635253906\n",
      "R2 values 0.9417, 0.8028, 0.8840; mean R2=0.8762\n",
      "Validation Error: Avg loss: 486.722015 \n",
      "\n",
      "2023-11-08 13:24:20.517855 Epoch 748, Training loss 156.50204467773438\n",
      "R2 values 0.9559, 0.8423, 0.8190; mean R2=0.8724\n",
      "Validation Error: Avg loss: 414.004150 \n",
      "\n",
      "2023-11-08 13:24:21.074174 Epoch 749, Training loss 195.67877197265625\n",
      "R2 values 0.9535, 0.7818, 0.8533; mean R2=0.8629\n",
      "Validation Error: Avg loss: 416.548828 \n",
      "\n",
      "2023-11-08 13:24:21.571531 Epoch 750, Training loss 229.89759826660156\n",
      "R2 values 0.9505, 0.7495, 0.8202; mean R2=0.8401\n",
      "Validation Error: Avg loss: 525.204895 \n",
      "\n",
      "2023-11-08 13:24:22.071009 Epoch 751, Training loss 170.8203125\n",
      "R2 values 0.9500, 0.7959, 0.7997; mean R2=0.8486\n",
      "Validation Error: Avg loss: 506.226624 \n",
      "\n",
      "2023-11-08 13:24:22.584113 Epoch 752, Training loss 160.03619384765625\n",
      "R2 values 0.9148, 0.7816, 0.8408; mean R2=0.8457\n",
      "Validation Error: Avg loss: 669.484192 \n",
      "\n",
      "2023-11-08 13:24:23.093629 Epoch 753, Training loss 192.7671661376953\n",
      "R2 values 0.9551, 0.8309, 0.8375; mean R2=0.8745\n",
      "Validation Error: Avg loss: 431.679840 \n",
      "\n",
      "2023-11-08 13:24:23.609071 Epoch 754, Training loss 197.8075408935547\n",
      "R2 values 0.9516, 0.8338, 0.8267; mean R2=0.8707\n",
      "Validation Error: Avg loss: 520.538391 \n",
      "\n",
      "2023-11-08 13:24:24.110902 Epoch 755, Training loss 162.465087890625\n",
      "R2 values 0.9402, 0.8561, 0.8432; mean R2=0.8798\n",
      "Validation Error: Avg loss: 611.874512 \n",
      "\n",
      "2023-11-08 13:24:24.612247 Epoch 756, Training loss 235.77134704589844\n",
      "R2 values 0.9394, 0.8117, 0.8388; mean R2=0.8633\n",
      "Validation Error: Avg loss: 533.798218 \n",
      "\n",
      "2023-11-08 13:24:25.113376 Epoch 757, Training loss 152.11563110351562\n",
      "R2 values 0.9653, 0.8175, 0.8619; mean R2=0.8816\n",
      "Validation Error: Avg loss: 385.016632 \n",
      "\n",
      "2023-11-08 13:24:25.614969 Epoch 758, Training loss 218.72433471679688\n",
      "R2 values 0.9646, 0.7960, 0.8847; mean R2=0.8818\n",
      "Validation Error: Avg loss: 382.561707 \n",
      "\n",
      "2023-11-08 13:24:26.115523 Epoch 759, Training loss 176.99017333984375\n",
      "R2 values 0.9527, 0.7839, 0.8965; mean R2=0.8777\n",
      "Validation Error: Avg loss: 455.928802 \n",
      "\n",
      "2023-11-08 13:24:26.615969 Epoch 760, Training loss 211.5596923828125\n",
      "R2 values 0.9545, 0.8179, 0.8765; mean R2=0.8830\n",
      "Validation Error: Avg loss: 380.458679 \n",
      "\n",
      "2023-11-08 13:24:27.119139 Epoch 761, Training loss 178.6764373779297\n",
      "R2 values 0.9585, 0.8130, 0.8462; mean R2=0.8726\n",
      "Validation Error: Avg loss: 405.043121 \n",
      "\n",
      "2023-11-08 13:24:27.640101 Epoch 762, Training loss 208.7499542236328\n",
      "R2 values 0.9462, 0.8220, 0.8829; mean R2=0.8837\n",
      "Validation Error: Avg loss: 557.462524 \n",
      "\n",
      "2023-11-08 13:24:28.146647 Epoch 763, Training loss 150.81336975097656\n",
      "R2 values 0.9466, 0.7926, 0.8501; mean R2=0.8631\n",
      "Validation Error: Avg loss: 667.456116 \n",
      "\n",
      "2023-11-08 13:24:28.650509 Epoch 764, Training loss 229.4185791015625\n",
      "R2 values 0.9442, 0.7721, 0.8571; mean R2=0.8578\n",
      "Validation Error: Avg loss: 520.159912 \n",
      "\n",
      "2023-11-08 13:24:29.199810 Epoch 765, Training loss 157.67727661132812\n",
      "R2 values 0.9579, 0.8098, 0.8306; mean R2=0.8661\n",
      "Validation Error: Avg loss: 398.316803 \n",
      "\n",
      "2023-11-08 13:24:29.703613 Epoch 766, Training loss 181.16470336914062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 values 0.9620, 0.8110, 0.8500; mean R2=0.8743\n",
      "Validation Error: Avg loss: 381.750610 \n",
      "\n",
      "2023-11-08 13:24:30.286660 Epoch 767, Training loss 213.13116455078125\n",
      "R2 values 0.9570, 0.8598, 0.8674; mean R2=0.8947\n",
      "Validation Error: Avg loss: 524.111938 \n",
      "\n",
      "2023-11-08 13:24:30.789381 Epoch 768, Training loss 254.18682861328125\n",
      "R2 values 0.9443, 0.8019, 0.8719; mean R2=0.8727\n",
      "Validation Error: Avg loss: 575.331604 \n",
      "\n",
      "2023-11-08 13:24:31.289462 Epoch 769, Training loss 170.21360778808594\n",
      "R2 values 0.9612, 0.7970, 0.8655; mean R2=0.8746\n",
      "Validation Error: Avg loss: 412.833588 \n",
      "\n",
      "2023-11-08 13:24:31.798689 Epoch 770, Training loss 241.92762756347656\n",
      "R2 values 0.9501, 0.8234, 0.8681; mean R2=0.8806\n",
      "Validation Error: Avg loss: 480.177307 \n",
      "\n",
      "2023-11-08 13:24:32.316447 Epoch 771, Training loss 186.89010620117188\n",
      "R2 values 0.9331, 0.7972, 0.8806; mean R2=0.8703\n",
      "Validation Error: Avg loss: 667.578186 \n",
      "\n",
      "2023-11-08 13:24:32.855115 Epoch 772, Training loss 209.77645874023438\n",
      "R2 values 0.9572, 0.7760, 0.8644; mean R2=0.8659\n",
      "Validation Error: Avg loss: 542.421875 \n",
      "\n",
      "2023-11-08 13:24:33.360930 Epoch 773, Training loss 214.6824493408203\n",
      "R2 values 0.9612, 0.7991, 0.8660; mean R2=0.8754\n",
      "Validation Error: Avg loss: 354.278717 \n",
      "\n",
      "2023-11-08 13:24:33.890424 Epoch 774, Training loss 132.7388153076172\n",
      "R2 values 0.9528, 0.8081, 0.8593; mean R2=0.8734\n",
      "Validation Error: Avg loss: 416.211548 \n",
      "\n",
      "2023-11-08 13:24:34.387861 Epoch 775, Training loss 138.63510131835938\n",
      "R2 values 0.9599, 0.7757, 0.8258; mean R2=0.8538\n",
      "Validation Error: Avg loss: 413.885773 \n",
      "\n",
      "2023-11-08 13:24:34.882095 Epoch 776, Training loss 247.64508056640625\n",
      "R2 values 0.9479, 0.7881, 0.8482; mean R2=0.8614\n",
      "Validation Error: Avg loss: 681.179626 \n",
      "\n",
      "2023-11-08 13:24:35.380376 Epoch 777, Training loss 176.61505126953125\n",
      "R2 values 0.9452, 0.7626, 0.8552; mean R2=0.8544\n",
      "Validation Error: Avg loss: 716.641846 \n",
      "\n",
      "2023-11-08 13:24:35.874108 Epoch 778, Training loss 228.34690856933594\n",
      "R2 values 0.9572, 0.8359, 0.8317; mean R2=0.8750\n",
      "Validation Error: Avg loss: 404.371307 \n",
      "\n",
      "2023-11-08 13:24:36.371715 Epoch 779, Training loss 130.90231323242188\n",
      "R2 values 0.9537, 0.8396, 0.8675; mean R2=0.8870\n",
      "Validation Error: Avg loss: 415.356354 \n",
      "\n",
      "2023-11-08 13:24:36.869725 Epoch 780, Training loss 208.49386596679688\n",
      "R2 values 0.9559, 0.8219, 0.9012; mean R2=0.8930\n",
      "Validation Error: Avg loss: 383.734039 \n",
      "\n",
      "2023-11-08 13:24:37.358094 Epoch 781, Training loss 177.48902893066406\n",
      "R2 values 0.9476, 0.8062, 0.9048; mean R2=0.8862\n",
      "Validation Error: Avg loss: 597.307861 \n",
      "\n",
      "2023-11-08 13:24:37.849962 Epoch 782, Training loss 264.5511474609375\n",
      "R2 values 0.9440, 0.8478, 0.8762; mean R2=0.8893\n",
      "Validation Error: Avg loss: 487.331818 \n",
      "\n",
      "2023-11-08 13:24:38.355718 Epoch 783, Training loss 146.04934692382812\n",
      "R2 values 0.9612, 0.7766, 0.8731; mean R2=0.8703\n",
      "Validation Error: Avg loss: 369.324280 \n",
      "\n",
      "2023-11-08 13:24:38.924595 Epoch 784, Training loss 141.1353302001953\n",
      "R2 values 0.9616, 0.8215, 0.8852; mean R2=0.8894\n",
      "Validation Error: Avg loss: 354.356964 \n",
      "\n",
      "2023-11-08 13:24:39.430622 Epoch 785, Training loss 214.8897705078125\n",
      "R2 values 0.9519, 0.8419, 0.8779; mean R2=0.8906\n",
      "Validation Error: Avg loss: 483.957367 \n",
      "\n",
      "2023-11-08 13:24:39.930279 Epoch 786, Training loss 157.49000549316406\n",
      "R2 values 0.9456, 0.8288, 0.8992; mean R2=0.8912\n",
      "Validation Error: Avg loss: 661.482361 \n",
      "\n",
      "2023-11-08 13:24:40.435198 Epoch 787, Training loss 239.65916442871094\n",
      "R2 values 0.9581, 0.8195, 0.8718; mean R2=0.8831\n",
      "Validation Error: Avg loss: 411.203888 \n",
      "\n",
      "2023-11-08 13:24:40.928100 Epoch 788, Training loss 172.5765838623047\n",
      "R2 values 0.9593, 0.7995, 0.8668; mean R2=0.8752\n",
      "Validation Error: Avg loss: 400.124908 \n",
      "\n",
      "2023-11-08 13:24:41.432094 Epoch 789, Training loss 205.13014221191406\n",
      "R2 values 0.9525, 0.8207, 0.8533; mean R2=0.8755\n",
      "Validation Error: Avg loss: 434.167084 \n",
      "\n",
      "2023-11-08 13:24:41.947410 Epoch 790, Training loss 194.20460510253906\n",
      "R2 values 0.9429, 0.8224, 0.8793; mean R2=0.8816\n",
      "Validation Error: Avg loss: 686.429016 \n",
      "\n",
      "2023-11-08 13:24:42.460552 Epoch 791, Training loss 188.35438537597656\n",
      "R2 values 0.9478, 0.7834, 0.8655; mean R2=0.8655\n",
      "Validation Error: Avg loss: 680.212769 \n",
      "\n",
      "2023-11-08 13:24:42.979386 Epoch 792, Training loss 235.29905700683594\n",
      "R2 values 0.9515, 0.8168, 0.8372; mean R2=0.8685\n",
      "Validation Error: Avg loss: 442.653473 \n",
      "\n",
      "2023-11-08 13:24:43.479908 Epoch 793, Training loss 156.21632385253906\n",
      "R2 values 0.9601, 0.7805, 0.8317; mean R2=0.8574\n",
      "Validation Error: Avg loss: 434.248230 \n",
      "\n",
      "2023-11-08 13:24:43.979758 Epoch 794, Training loss 297.40716552734375\n",
      "R2 values 0.9620, 0.8319, 0.8628; mean R2=0.8856\n",
      "Validation Error: Avg loss: 352.964539 \n",
      "\n",
      "2023-11-08 13:24:44.464688 Epoch 795, Training loss 169.1239471435547\n",
      "R2 values 0.9427, 0.8345, 0.8774; mean R2=0.8849\n",
      "Validation Error: Avg loss: 689.008667 \n",
      "\n",
      "2023-11-08 13:24:44.953710 Epoch 796, Training loss 197.1334686279297\n",
      "R2 values 0.9434, 0.8307, 0.8739; mean R2=0.8827\n",
      "Validation Error: Avg loss: 710.502563 \n",
      "\n",
      "2023-11-08 13:24:45.442714 Epoch 797, Training loss 276.0642395019531\n",
      "R2 values 0.9551, 0.8011, 0.8763; mean R2=0.8775\n",
      "Validation Error: Avg loss: 409.344727 \n",
      "\n",
      "2023-11-08 13:24:45.931918 Epoch 798, Training loss 136.7386932373047\n",
      "R2 values 0.9578, 0.8302, 0.8354; mean R2=0.8745\n",
      "Validation Error: Avg loss: 401.511353 \n",
      "\n",
      "2023-11-08 13:24:46.419301 Epoch 799, Training loss 238.64520263671875\n",
      "R2 values 0.9564, 0.8426, 0.8519; mean R2=0.8836\n",
      "Validation Error: Avg loss: 402.293213 \n",
      "\n",
      "2023-11-08 13:24:46.909672 Epoch 800, Training loss 186.46331787109375\n",
      "R2 values 0.9477, 0.8128, 0.8674; mean R2=0.8760\n",
      "Validation Error: Avg loss: 767.611633 \n",
      "\n",
      "2023-11-08 13:24:47.399029 Epoch 801, Training loss 220.00067138671875\n",
      "R2 values 0.9524, 0.8074, 0.8428; mean R2=0.8675\n",
      "Validation Error: Avg loss: 651.168701 \n",
      "\n",
      "2023-11-08 13:24:47.884446 Epoch 802, Training loss 233.18727111816406\n",
      "R2 values 0.9570, 0.8380, 0.8593; mean R2=0.8848\n",
      "Validation Error: Avg loss: 376.108765 \n",
      "\n",
      "2023-11-08 13:24:48.439798 Epoch 803, Training loss 161.70315551757812\n",
      "R2 values 0.9552, 0.8236, 0.8657; mean R2=0.8815\n",
      "Validation Error: Avg loss: 448.897827 \n",
      "\n",
      "2023-11-08 13:24:48.998437 Epoch 804, Training loss 306.22247314453125\n",
      "R2 values 0.9489, 0.7720, 0.8814; mean R2=0.8674\n",
      "Validation Error: Avg loss: 425.617950 \n",
      "\n",
      "2023-11-08 13:24:49.482924 Epoch 805, Training loss 192.804931640625\n",
      "R2 values 0.9535, 0.7905, 0.9006; mean R2=0.8815\n",
      "Validation Error: Avg loss: 528.322021 \n",
      "\n",
      "2023-11-08 13:24:49.966940 Epoch 806, Training loss 211.7847442626953\n",
      "R2 values 0.9443, 0.7964, 0.9147; mean R2=0.8851\n",
      "Validation Error: Avg loss: 569.615234 \n",
      "\n",
      "2023-11-08 13:24:50.463478 Epoch 807, Training loss 179.912109375\n",
      "R2 values 0.9410, 0.8269, 0.8611; mean R2=0.8763\n",
      "Validation Error: Avg loss: 543.741516 \n",
      "\n",
      "2023-11-08 13:24:50.977733 Epoch 808, Training loss 181.93040466308594\n",
      "R2 values 0.9334, 0.7799, 0.8908; mean R2=0.8680\n",
      "Validation Error: Avg loss: 538.016968 \n",
      "\n",
      "2023-11-08 13:24:51.470674 Epoch 809, Training loss 202.97340393066406\n",
      "R2 values 0.9446, 0.8034, 0.8562; mean R2=0.8681\n",
      "Validation Error: Avg loss: 470.790497 \n",
      "\n",
      "2023-11-08 13:24:51.971916 Epoch 810, Training loss 188.9888153076172\n",
      "R2 values 0.9586, 0.8055, 0.8727; mean R2=0.8790\n",
      "Validation Error: Avg loss: 519.421692 \n",
      "\n",
      "2023-11-08 13:24:52.451762 Epoch 811, Training loss 158.2317352294922\n",
      "R2 values 0.9598, 0.7988, 0.8717; mean R2=0.8768\n",
      "Validation Error: Avg loss: 519.585754 \n",
      "\n",
      "2023-11-08 13:24:52.947916 Epoch 812, Training loss 186.781494140625\n",
      "R2 values 0.9523, 0.8033, 0.8470; mean R2=0.8676\n",
      "Validation Error: Avg loss: 572.466248 \n",
      "\n",
      "2023-11-08 13:24:53.433507 Epoch 813, Training loss 167.1940155029297\n",
      "R2 values 0.9472, 0.7933, 0.8597; mean R2=0.8668\n",
      "Validation Error: Avg loss: 457.406769 \n",
      "\n",
      "2023-11-08 13:24:53.927576 Epoch 814, Training loss 180.7842254638672\n",
      "R2 values 0.9445, 0.8504, 0.8693; mean R2=0.8881\n",
      "Validation Error: Avg loss: 525.693176 \n",
      "\n",
      "2023-11-08 13:24:54.421677 Epoch 815, Training loss 168.59951782226562\n",
      "R2 values 0.9422, 0.8476, 0.8581; mean R2=0.8826\n",
      "Validation Error: Avg loss: 560.168640 \n",
      "\n",
      "2023-11-08 13:24:54.908588 Epoch 816, Training loss 192.88624572753906\n",
      "R2 values 0.9381, 0.8350, 0.8765; mean R2=0.8832\n",
      "Validation Error: Avg loss: 667.719727 \n",
      "\n",
      "2023-11-08 13:24:55.390757 Epoch 817, Training loss 205.90814208984375\n",
      "R2 values 0.9473, 0.8317, 0.8584; mean R2=0.8791\n",
      "Validation Error: Avg loss: 547.697327 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:24:55.877470 Epoch 818, Training loss 150.59812927246094\n",
      "R2 values 0.9396, 0.8500, 0.8753; mean R2=0.8883\n",
      "Validation Error: Avg loss: 515.924133 \n",
      "\n",
      "2023-11-08 13:24:56.371397 Epoch 819, Training loss 220.4471893310547\n",
      "R2 values 0.9607, 0.8562, 0.8548; mean R2=0.8906\n",
      "Validation Error: Avg loss: 402.804443 \n",
      "\n",
      "2023-11-08 13:24:56.866001 Epoch 820, Training loss 190.31741333007812\n",
      "R2 values 0.9572, 0.8210, 0.8525; mean R2=0.8769\n",
      "Validation Error: Avg loss: 568.545227 \n",
      "\n",
      "2023-11-08 13:24:57.416065 Epoch 821, Training loss 227.3144073486328\n",
      "R2 values 0.9393, 0.8499, 0.8387; mean R2=0.8760\n",
      "Validation Error: Avg loss: 680.186462 \n",
      "\n",
      "2023-11-08 13:24:57.972587 Epoch 822, Training loss 222.0948944091797\n",
      "R2 values 0.9468, 0.8807, 0.8196; mean R2=0.8824\n",
      "Validation Error: Avg loss: 476.521149 \n",
      "\n",
      "2023-11-08 13:24:58.466652 Epoch 823, Training loss 173.16830444335938\n",
      "R2 values 0.9449, 0.8354, 0.8305; mean R2=0.8703\n",
      "Validation Error: Avg loss: 516.355469 \n",
      "\n",
      "2023-11-08 13:24:58.953334 Epoch 824, Training loss 186.46218872070312\n",
      "R2 values 0.9348, 0.8624, 0.8759; mean R2=0.8910\n",
      "Validation Error: Avg loss: 615.836182 \n",
      "\n",
      "2023-11-08 13:24:59.447890 Epoch 825, Training loss 159.4365234375\n",
      "R2 values 0.9494, 0.8182, 0.8683; mean R2=0.8787\n",
      "Validation Error: Avg loss: 649.689270 \n",
      "\n",
      "2023-11-08 13:24:59.936826 Epoch 826, Training loss 227.81832885742188\n",
      "R2 values 0.9453, 0.8380, 0.9058; mean R2=0.8964\n",
      "Validation Error: Avg loss: 518.834473 \n",
      "\n",
      "2023-11-08 13:25:00.656722 Epoch 827, Training loss 165.89634704589844\n",
      "R2 values 0.9493, 0.8521, 0.9022; mean R2=0.9012\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 445.698303 \n",
      "\n",
      "2023-11-08 13:25:01.180586 Epoch 828, Training loss 147.7992401123047\n",
      "R2 values 0.9552, 0.8248, 0.8548; mean R2=0.8783\n",
      "Validation Error: Avg loss: 457.213470 \n",
      "\n",
      "2023-11-08 13:25:01.675745 Epoch 829, Training loss 161.25038146972656\n",
      "R2 values 0.9660, 0.7839, 0.8765; mean R2=0.8755\n",
      "Validation Error: Avg loss: 449.959381 \n",
      "\n",
      "2023-11-08 13:25:02.177926 Epoch 830, Training loss 206.3807373046875\n",
      "R2 values 0.9421, 0.8195, 0.8548; mean R2=0.8721\n",
      "Validation Error: Avg loss: 660.245361 \n",
      "\n",
      "2023-11-08 13:25:02.669686 Epoch 831, Training loss 159.7222900390625\n",
      "R2 values 0.9420, 0.8225, 0.8476; mean R2=0.8707\n",
      "Validation Error: Avg loss: 667.920776 \n",
      "\n",
      "2023-11-08 13:25:03.158866 Epoch 832, Training loss 242.66128540039062\n",
      "R2 values 0.9652, 0.8630, 0.8866; mean R2=0.9049\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 311.420563 \n",
      "\n",
      "2023-11-08 13:25:03.700822 Epoch 833, Training loss 194.455078125\n",
      "R2 values 0.9589, 0.7796, 0.8572; mean R2=0.8652\n",
      "Validation Error: Avg loss: 401.527954 \n",
      "\n",
      "2023-11-08 13:25:04.225496 Epoch 834, Training loss 193.59234619140625\n",
      "R2 values 0.9606, 0.8285, 0.8929; mean R2=0.8940\n",
      "Validation Error: Avg loss: 389.263672 \n",
      "\n",
      "2023-11-08 13:25:04.732939 Epoch 835, Training loss 135.820556640625\n",
      "R2 values 0.9483, 0.8078, 0.9053; mean R2=0.8871\n",
      "Validation Error: Avg loss: 488.441193 \n",
      "\n",
      "2023-11-08 13:25:05.223434 Epoch 836, Training loss 162.6365966796875\n",
      "R2 values 0.9477, 0.7695, 0.8673; mean R2=0.8615\n",
      "Validation Error: Avg loss: 596.021118 \n",
      "\n",
      "2023-11-08 13:25:05.720184 Epoch 837, Training loss 203.36050415039062\n",
      "R2 values 0.9611, 0.8269, 0.8779; mean R2=0.8886\n",
      "Validation Error: Avg loss: 422.850769 \n",
      "\n",
      "2023-11-08 13:25:06.217205 Epoch 838, Training loss 143.95579528808594\n",
      "R2 values 0.9515, 0.8082, 0.8450; mean R2=0.8682\n",
      "Validation Error: Avg loss: 423.345245 \n",
      "\n",
      "2023-11-08 13:25:06.967471 Epoch 839, Training loss 213.64004516601562\n",
      "R2 values 0.9552, 0.7746, 0.8730; mean R2=0.8676\n",
      "Validation Error: Avg loss: 399.078247 \n",
      "\n",
      "2023-11-08 13:25:07.488087 Epoch 840, Training loss 173.7933807373047\n",
      "R2 values 0.9542, 0.7837, 0.8151; mean R2=0.8510\n",
      "Validation Error: Avg loss: 444.144867 \n",
      "\n",
      "2023-11-08 13:25:07.996809 Epoch 841, Training loss 186.5395965576172\n",
      "R2 values 0.9499, 0.7815, 0.8089; mean R2=0.8468\n",
      "Validation Error: Avg loss: 584.949951 \n",
      "\n",
      "2023-11-08 13:25:08.487928 Epoch 842, Training loss 235.6355438232422\n",
      "R2 values 0.9307, 0.7904, 0.8205; mean R2=0.8472\n",
      "Validation Error: Avg loss: 670.895081 \n",
      "\n",
      "2023-11-08 13:25:08.973018 Epoch 843, Training loss 138.63832092285156\n",
      "R2 values 0.9470, 0.7951, 0.8564; mean R2=0.8662\n",
      "Validation Error: Avg loss: 449.000702 \n",
      "\n",
      "2023-11-08 13:25:09.462893 Epoch 844, Training loss 175.4327850341797\n",
      "R2 values 0.9591, 0.8353, 0.8607; mean R2=0.8851\n",
      "Validation Error: Avg loss: 365.324280 \n",
      "\n",
      "2023-11-08 13:25:09.949093 Epoch 845, Training loss 211.73196411132812\n",
      "R2 values 0.9480, 0.7859, 0.8768; mean R2=0.8702\n",
      "Validation Error: Avg loss: 636.357361 \n",
      "\n",
      "2023-11-08 13:25:10.429255 Epoch 846, Training loss 176.22122192382812\n",
      "R2 values 0.9369, 0.7905, 0.8523; mean R2=0.8599\n",
      "Validation Error: Avg loss: 650.043030 \n",
      "\n",
      "2023-11-08 13:25:10.924678 Epoch 847, Training loss 168.47512817382812\n",
      "R2 values 0.9514, 0.8312, 0.8843; mean R2=0.8890\n",
      "Validation Error: Avg loss: 430.058014 \n",
      "\n",
      "2023-11-08 13:25:11.413917 Epoch 848, Training loss 183.84390258789062\n",
      "R2 values 0.9674, 0.7908, 0.8830; mean R2=0.8804\n",
      "Validation Error: Avg loss: 351.202606 \n",
      "\n",
      "2023-11-08 13:25:11.899816 Epoch 849, Training loss 140.02142333984375\n",
      "R2 values 0.9683, 0.8268, 0.8943; mean R2=0.8965\n",
      "Validation Error: Avg loss: 307.262115 \n",
      "\n",
      "2023-11-08 13:25:12.379722 Epoch 850, Training loss 155.05136108398438\n",
      "R2 values 0.9591, 0.8244, 0.8820; mean R2=0.8885\n",
      "Validation Error: Avg loss: 603.777527 \n",
      "\n",
      "2023-11-08 13:25:12.862608 Epoch 851, Training loss 193.71395874023438\n",
      "R2 values 0.9455, 0.8118, 0.8935; mean R2=0.8836\n",
      "Validation Error: Avg loss: 448.123810 \n",
      "\n",
      "2023-11-08 13:25:13.409504 Epoch 852, Training loss 179.02716064453125\n",
      "R2 values 0.9466, 0.8540, 0.8285; mean R2=0.8764\n",
      "Validation Error: Avg loss: 492.036438 \n",
      "\n",
      "2023-11-08 13:25:13.891964 Epoch 853, Training loss 195.0753173828125\n",
      "R2 values 0.9658, 0.8301, 0.8711; mean R2=0.8890\n",
      "Validation Error: Avg loss: 380.349213 \n",
      "\n",
      "2023-11-08 13:25:14.378353 Epoch 854, Training loss 157.07200622558594\n",
      "R2 values 0.9445, 0.7793, 0.8462; mean R2=0.8567\n",
      "Validation Error: Avg loss: 646.473450 \n",
      "\n",
      "2023-11-08 13:25:14.862130 Epoch 855, Training loss 163.9012908935547\n",
      "R2 values 0.9532, 0.8026, 0.8738; mean R2=0.8765\n",
      "Validation Error: Avg loss: 438.487335 \n",
      "\n",
      "2023-11-08 13:25:15.338286 Epoch 856, Training loss 149.56019592285156\n",
      "R2 values 0.9515, 0.8642, 0.8747; mean R2=0.8968\n",
      "Validation Error: Avg loss: 415.684296 \n",
      "\n",
      "2023-11-08 13:25:15.916909 Epoch 857, Training loss 153.4080047607422\n",
      "R2 values 0.9412, 0.8272, 0.8570; mean R2=0.8752\n",
      "Validation Error: Avg loss: 501.003510 \n",
      "\n",
      "2023-11-08 13:25:16.402168 Epoch 858, Training loss 187.3964080810547\n",
      "R2 values 0.9325, 0.8173, 0.8890; mean R2=0.8796\n",
      "Validation Error: Avg loss: 630.323242 \n",
      "\n",
      "2023-11-08 13:25:16.897159 Epoch 859, Training loss 163.3920440673828\n",
      "R2 values 0.9375, 0.8147, 0.8676; mean R2=0.8733\n",
      "Validation Error: Avg loss: 565.758423 \n",
      "\n",
      "2023-11-08 13:25:17.372554 Epoch 860, Training loss 130.85902404785156\n",
      "R2 values 0.9485, 0.8078, 0.8682; mean R2=0.8748\n",
      "Validation Error: Avg loss: 470.299774 \n",
      "\n",
      "2023-11-08 13:25:17.893746 Epoch 861, Training loss 149.90821838378906\n",
      "R2 values 0.9540, 0.8440, 0.8675; mean R2=0.8885\n",
      "Validation Error: Avg loss: 477.520752 \n",
      "\n",
      "2023-11-08 13:25:18.384698 Epoch 862, Training loss 150.75755310058594\n",
      "R2 values 0.9483, 0.8236, 0.8939; mean R2=0.8886\n",
      "Validation Error: Avg loss: 419.716248 \n",
      "\n",
      "2023-11-08 13:25:18.872061 Epoch 863, Training loss 123.33687591552734\n",
      "R2 values 0.9604, 0.7993, 0.8409; mean R2=0.8669\n",
      "Validation Error: Avg loss: 384.326996 \n",
      "\n",
      "2023-11-08 13:25:19.360735 Epoch 864, Training loss 144.13992309570312\n",
      "R2 values 0.9499, 0.8176, 0.8747; mean R2=0.8808\n",
      "Validation Error: Avg loss: 446.461700 \n",
      "\n",
      "2023-11-08 13:25:19.842498 Epoch 865, Training loss 159.47117614746094\n",
      "R2 values 0.9504, 0.8456, 0.8565; mean R2=0.8842\n",
      "Validation Error: Avg loss: 422.565735 \n",
      "\n",
      "2023-11-08 13:25:20.440762 Epoch 866, Training loss 154.18145751953125\n",
      "R2 values 0.9494, 0.8212, 0.8567; mean R2=0.8758\n",
      "Validation Error: Avg loss: 444.950348 \n",
      "\n",
      "2023-11-08 13:25:20.942572 Epoch 867, Training loss 131.4340362548828\n",
      "R2 values 0.9418, 0.8577, 0.8442; mean R2=0.8812\n",
      "Validation Error: Avg loss: 529.059143 \n",
      "\n",
      "2023-11-08 13:25:21.459091 Epoch 868, Training loss 129.97463989257812\n",
      "R2 values 0.9438, 0.8130, 0.8559; mean R2=0.8709\n",
      "Validation Error: Avg loss: 543.361816 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:25:21.951657 Epoch 869, Training loss 188.72012329101562\n",
      "R2 values 0.9416, 0.8287, 0.8576; mean R2=0.8759\n",
      "Validation Error: Avg loss: 529.614136 \n",
      "\n",
      "2023-11-08 13:25:22.434745 Epoch 870, Training loss 163.4537811279297\n",
      "R2 values 0.9612, 0.8274, 0.8793; mean R2=0.8893\n",
      "Validation Error: Avg loss: 384.174438 \n",
      "\n",
      "2023-11-08 13:25:22.915321 Epoch 871, Training loss 141.29039001464844\n",
      "R2 values 0.9639, 0.8391, 0.8892; mean R2=0.8974\n",
      "Validation Error: Avg loss: 365.006439 \n",
      "\n",
      "2023-11-08 13:25:23.386853 Epoch 872, Training loss 144.04872131347656\n",
      "R2 values 0.9598, 0.8085, 0.8258; mean R2=0.8647\n",
      "Validation Error: Avg loss: 675.646362 \n",
      "\n",
      "2023-11-08 13:25:23.866391 Epoch 873, Training loss 242.5682373046875\n",
      "R2 values 0.9549, 0.8369, 0.8814; mean R2=0.8911\n",
      "Validation Error: Avg loss: 555.255676 \n",
      "\n",
      "2023-11-08 13:25:24.355475 Epoch 874, Training loss 166.44720458984375\n",
      "R2 values 0.9466, 0.7735, 0.9014; mean R2=0.8738\n",
      "Validation Error: Avg loss: 456.421570 \n",
      "\n",
      "2023-11-08 13:25:24.843448 Epoch 875, Training loss 157.6070556640625\n",
      "R2 values 0.9509, 0.7986, 0.8761; mean R2=0.8752\n",
      "Validation Error: Avg loss: 447.954559 \n",
      "\n",
      "2023-11-08 13:25:25.329722 Epoch 876, Training loss 172.79969787597656\n",
      "R2 values 0.9579, 0.8300, 0.8520; mean R2=0.8799\n",
      "Validation Error: Avg loss: 413.308716 \n",
      "\n",
      "2023-11-08 13:25:25.815592 Epoch 877, Training loss 173.32855224609375\n",
      "R2 values 0.9567, 0.8003, 0.8691; mean R2=0.8754\n",
      "Validation Error: Avg loss: 509.908936 \n",
      "\n",
      "2023-11-08 13:25:26.294399 Epoch 878, Training loss 217.14503479003906\n",
      "R2 values 0.9509, 0.8225, 0.8886; mean R2=0.8873\n",
      "Validation Error: Avg loss: 420.544159 \n",
      "\n",
      "2023-11-08 13:25:26.867145 Epoch 879, Training loss 142.34609985351562\n",
      "R2 values 0.9583, 0.7661, 0.8439; mean R2=0.8561\n",
      "Validation Error: Avg loss: 447.519196 \n",
      "\n",
      "2023-11-08 13:25:27.349461 Epoch 880, Training loss 204.3877410888672\n",
      "R2 values 0.9554, 0.7969, 0.8831; mean R2=0.8785\n",
      "Validation Error: Avg loss: 397.342712 \n",
      "\n",
      "2023-11-08 13:25:27.850050 Epoch 881, Training loss 146.4035186767578\n",
      "R2 values 0.9495, 0.8010, 0.8415; mean R2=0.8640\n",
      "Validation Error: Avg loss: 500.377502 \n",
      "\n",
      "2023-11-08 13:25:28.341148 Epoch 882, Training loss 165.37783813476562\n",
      "R2 values 0.9644, 0.8460, 0.9015; mean R2=0.9040\n",
      "Validation Error: Avg loss: 360.454376 \n",
      "\n",
      "2023-11-08 13:25:29.075765 Epoch 883, Training loss 130.7421875\n",
      "R2 values 0.9325, 0.8253, 0.8545; mean R2=0.8708\n",
      "Validation Error: Avg loss: 560.768005 \n",
      "\n",
      "2023-11-08 13:25:29.604163 Epoch 884, Training loss 154.38018798828125\n",
      "R2 values 0.9284, 0.8243, 0.8729; mean R2=0.8752\n",
      "Validation Error: Avg loss: 584.740967 \n",
      "\n",
      "2023-11-08 13:25:30.084118 Epoch 885, Training loss 171.69496154785156\n",
      "R2 values 0.9454, 0.8140, 0.8843; mean R2=0.8812\n",
      "Validation Error: Avg loss: 470.993866 \n",
      "\n",
      "2023-11-08 13:25:30.569265 Epoch 886, Training loss 171.2895050048828\n",
      "R2 values 0.9341, 0.8104, 0.8680; mean R2=0.8708\n",
      "Validation Error: Avg loss: 581.677673 \n",
      "\n",
      "2023-11-08 13:25:31.051342 Epoch 887, Training loss 177.87648010253906\n",
      "R2 values 0.9524, 0.8454, 0.8345; mean R2=0.8774\n",
      "Validation Error: Avg loss: 428.376312 \n",
      "\n",
      "2023-11-08 13:25:31.560285 Epoch 888, Training loss 178.48020935058594\n",
      "R2 values 0.9535, 0.8507, 0.8797; mean R2=0.8947\n",
      "Validation Error: Avg loss: 441.958160 \n",
      "\n",
      "2023-11-08 13:25:32.052336 Epoch 889, Training loss 146.5949249267578\n",
      "R2 values 0.9524, 0.8100, 0.8303; mean R2=0.8642\n",
      "Validation Error: Avg loss: 588.719666 \n",
      "\n",
      "2023-11-08 13:25:32.539637 Epoch 890, Training loss 165.0222625732422\n",
      "R2 values 0.9555, 0.8063, 0.8444; mean R2=0.8688\n",
      "Validation Error: Avg loss: 415.523346 \n",
      "\n",
      "2023-11-08 13:25:33.017672 Epoch 891, Training loss 202.01214599609375\n",
      "R2 values 0.9362, 0.8156, 0.8688; mean R2=0.8735\n",
      "Validation Error: Avg loss: 520.764038 \n",
      "\n",
      "2023-11-08 13:25:33.498854 Epoch 892, Training loss 167.6956787109375\n",
      "R2 values 0.9511, 0.8532, 0.8652; mean R2=0.8899\n",
      "Validation Error: Avg loss: 475.152802 \n",
      "\n",
      "2023-11-08 13:25:33.983629 Epoch 893, Training loss 146.76426696777344\n",
      "R2 values 0.9211, 0.8498, 0.8593; mean R2=0.8768\n",
      "Validation Error: Avg loss: 809.916687 \n",
      "\n",
      "2023-11-08 13:25:34.473475 Epoch 894, Training loss 171.66481018066406\n",
      "R2 values 0.9424, 0.8104, 0.8978; mean R2=0.8835\n",
      "Validation Error: Avg loss: 503.314941 \n",
      "\n",
      "2023-11-08 13:25:34.959119 Epoch 895, Training loss 180.97352600097656\n",
      "R2 values 0.9564, 0.8220, 0.8920; mean R2=0.8902\n",
      "Validation Error: Avg loss: 419.270599 \n",
      "\n",
      "2023-11-08 13:25:35.443888 Epoch 896, Training loss 130.27239990234375\n",
      "R2 values 0.9388, 0.7992, 0.8702; mean R2=0.8694\n",
      "Validation Error: Avg loss: 563.767578 \n",
      "\n",
      "2023-11-08 13:25:35.928127 Epoch 897, Training loss 159.79966735839844\n",
      "R2 values 0.9459, 0.8430, 0.8829; mean R2=0.8906\n",
      "Validation Error: Avg loss: 587.109924 \n",
      "\n",
      "2023-11-08 13:25:36.412121 Epoch 898, Training loss 167.90151977539062\n",
      "R2 values 0.9489, 0.8118, 0.9138; mean R2=0.8915\n",
      "Validation Error: Avg loss: 632.866943 \n",
      "\n",
      "2023-11-08 13:25:36.911928 Epoch 899, Training loss 196.0531768798828\n",
      "R2 values 0.9377, 0.8501, 0.8673; mean R2=0.8850\n",
      "Validation Error: Avg loss: 502.247009 \n",
      "\n",
      "2023-11-08 13:25:37.389771 Epoch 900, Training loss 176.9672088623047\n",
      "R2 values 0.9468, 0.8650, 0.8973; mean R2=0.9030\n",
      "Validation Error: Avg loss: 426.627625 \n",
      "\n",
      "2023-11-08 13:25:37.875596 Epoch 901, Training loss 173.95556640625\n",
      "R2 values 0.9474, 0.8374, 0.8694; mean R2=0.8847\n",
      "Validation Error: Avg loss: 521.794067 \n",
      "\n",
      "2023-11-08 13:25:38.412091 Epoch 902, Training loss 116.28949737548828\n",
      "R2 values 0.9618, 0.8390, 0.8491; mean R2=0.8833\n",
      "Validation Error: Avg loss: 533.113342 \n",
      "\n",
      "2023-11-08 13:25:38.905960 Epoch 903, Training loss 160.78021240234375\n",
      "R2 values 0.9533, 0.8068, 0.8667; mean R2=0.8756\n",
      "Validation Error: Avg loss: 508.488007 \n",
      "\n",
      "2023-11-08 13:25:39.391300 Epoch 904, Training loss 160.3793487548828\n",
      "R2 values 0.9523, 0.8766, 0.8704; mean R2=0.8998\n",
      "Validation Error: Avg loss: 395.193390 \n",
      "\n",
      "2023-11-08 13:25:39.871495 Epoch 905, Training loss 142.12538146972656\n",
      "R2 values 0.9429, 0.8364, 0.8701; mean R2=0.8831\n",
      "Validation Error: Avg loss: 469.116364 \n",
      "\n",
      "2023-11-08 13:25:40.357433 Epoch 906, Training loss 197.2897186279297\n",
      "R2 values 0.9310, 0.8306, 0.8705; mean R2=0.8774\n",
      "Validation Error: Avg loss: 550.681641 \n",
      "\n",
      "2023-11-08 13:25:40.832174 Epoch 907, Training loss 114.21693420410156\n",
      "R2 values 0.9515, 0.7977, 0.8256; mean R2=0.8582\n",
      "Validation Error: Avg loss: 741.186584 \n",
      "\n",
      "2023-11-08 13:25:41.320813 Epoch 908, Training loss 163.3890838623047\n",
      "R2 values 0.9292, 0.7552, 0.8612; mean R2=0.8485\n",
      "Validation Error: Avg loss: 624.163208 \n",
      "\n",
      "2023-11-08 13:25:41.805185 Epoch 909, Training loss 181.6697235107422\n",
      "R2 values 0.9431, 0.7877, 0.8706; mean R2=0.8671\n",
      "Validation Error: Avg loss: 494.133179 \n",
      "\n",
      "2023-11-08 13:25:42.329629 Epoch 910, Training loss 190.81552124023438\n",
      "R2 values 0.9506, 0.8379, 0.8985; mean R2=0.8957\n",
      "Validation Error: Avg loss: 397.506836 \n",
      "\n",
      "2023-11-08 13:25:42.810579 Epoch 911, Training loss 137.14291381835938\n",
      "R2 values 0.9341, 0.8609, 0.8850; mean R2=0.8933\n",
      "Validation Error: Avg loss: 558.129761 \n",
      "\n",
      "2023-11-08 13:25:43.290491 Epoch 912, Training loss 176.84976196289062\n",
      "R2 values 0.9471, 0.8865, 0.8764; mean R2=0.9034\n",
      "Validation Error: Avg loss: 464.966614 \n",
      "\n",
      "2023-11-08 13:25:43.773207 Epoch 913, Training loss 117.41456604003906\n",
      "R2 values 0.9463, 0.8452, 0.8996; mean R2=0.8970\n",
      "Validation Error: Avg loss: 483.745911 \n",
      "\n",
      "2023-11-08 13:25:44.256107 Epoch 914, Training loss 116.60584259033203\n",
      "R2 values 0.9503, 0.8389, 0.8614; mean R2=0.8835\n",
      "Validation Error: Avg loss: 454.390442 \n",
      "\n",
      "2023-11-08 13:25:44.788156 Epoch 915, Training loss 168.09121704101562\n",
      "R2 values 0.9596, 0.8146, 0.8777; mean R2=0.8840\n",
      "Validation Error: Avg loss: 363.228790 \n",
      "\n",
      "2023-11-08 13:25:45.270941 Epoch 916, Training loss 159.8012237548828\n",
      "R2 values 0.9489, 0.8303, 0.8534; mean R2=0.8775\n",
      "Validation Error: Avg loss: 604.132629 \n",
      "\n",
      "2023-11-08 13:25:45.749824 Epoch 917, Training loss 128.9331817626953\n",
      "R2 values 0.9378, 0.8279, 0.8307; mean R2=0.8654\n",
      "Validation Error: Avg loss: 704.401184 \n",
      "\n",
      "2023-11-08 13:25:46.230870 Epoch 918, Training loss 207.88027954101562\n",
      "R2 values 0.9544, 0.8088, 0.8455; mean R2=0.8696\n",
      "Validation Error: Avg loss: 422.569824 \n",
      "\n",
      "2023-11-08 13:25:46.716497 Epoch 919, Training loss 119.72191619873047\n",
      "R2 values 0.9459, 0.7899, 0.8842; mean R2=0.8733\n",
      "Validation Error: Avg loss: 449.985657 \n",
      "\n",
      "2023-11-08 13:25:47.315874 Epoch 920, Training loss 205.6055145263672\n",
      "R2 values 0.9366, 0.7821, 0.8915; mean R2=0.8701\n",
      "Validation Error: Avg loss: 579.597229 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:25:47.804908 Epoch 921, Training loss 223.11106872558594\n",
      "R2 values 0.9155, 0.7193, 0.8575; mean R2=0.8307\n",
      "Validation Error: Avg loss: 797.070679 \n",
      "\n",
      "2023-11-08 13:25:48.290637 Epoch 922, Training loss 223.70974731445312\n",
      "R2 values 0.9590, 0.8308, 0.8472; mean R2=0.8790\n",
      "Validation Error: Avg loss: 444.645782 \n",
      "\n",
      "2023-11-08 13:25:48.779995 Epoch 923, Training loss 154.1364288330078\n",
      "R2 values 0.9552, 0.8403, 0.8490; mean R2=0.8815\n",
      "Validation Error: Avg loss: 441.339203 \n",
      "\n",
      "2023-11-08 13:25:49.261444 Epoch 924, Training loss 264.6053771972656\n",
      "R2 values 0.9506, 0.8173, 0.8774; mean R2=0.8818\n",
      "Validation Error: Avg loss: 426.365173 \n",
      "\n",
      "2023-11-08 13:25:49.767278 Epoch 925, Training loss 167.9646453857422\n",
      "R2 values 0.9591, 0.8610, 0.8751; mean R2=0.8984\n",
      "Validation Error: Avg loss: 367.439178 \n",
      "\n",
      "2023-11-08 13:25:50.259214 Epoch 926, Training loss 138.730712890625\n",
      "R2 values 0.9552, 0.8026, 0.8656; mean R2=0.8745\n",
      "Validation Error: Avg loss: 594.744507 \n",
      "\n",
      "2023-11-08 13:25:50.784004 Epoch 927, Training loss 187.01797485351562\n",
      "R2 values 0.9596, 0.8363, 0.8885; mean R2=0.8948\n",
      "Validation Error: Avg loss: 484.209930 \n",
      "\n",
      "2023-11-08 13:25:51.267654 Epoch 928, Training loss 173.01910400390625\n",
      "R2 values 0.9510, 0.8391, 0.9057; mean R2=0.8986\n",
      "Validation Error: Avg loss: 420.422943 \n",
      "\n",
      "2023-11-08 13:25:51.745556 Epoch 929, Training loss 171.24107360839844\n",
      "R2 values 0.9453, 0.8530, 0.8900; mean R2=0.8961\n",
      "Validation Error: Avg loss: 471.789886 \n",
      "\n",
      "2023-11-08 13:25:52.225630 Epoch 930, Training loss 157.60716247558594\n",
      "R2 values 0.9548, 0.8296, 0.8660; mean R2=0.8835\n",
      "Validation Error: Avg loss: 464.487274 \n",
      "\n",
      "2023-11-08 13:25:52.705769 Epoch 931, Training loss 150.83425903320312\n",
      "R2 values 0.9462, 0.7876, 0.8570; mean R2=0.8636\n",
      "Validation Error: Avg loss: 548.346741 \n",
      "\n",
      "2023-11-08 13:25:53.191532 Epoch 932, Training loss 163.84475708007812\n",
      "R2 values 0.9435, 0.7865, 0.8324; mean R2=0.8541\n",
      "Validation Error: Avg loss: 509.772583 \n",
      "\n",
      "2023-11-08 13:25:53.670772 Epoch 933, Training loss 238.22686767578125\n",
      "R2 values 0.9454, 0.8353, 0.8887; mean R2=0.8898\n",
      "Validation Error: Avg loss: 426.209808 \n",
      "\n",
      "2023-11-08 13:25:54.149769 Epoch 934, Training loss 151.59005737304688\n",
      "R2 values 0.9451, 0.8458, 0.8609; mean R2=0.8839\n",
      "Validation Error: Avg loss: 522.448792 \n",
      "\n",
      "2023-11-08 13:25:54.642123 Epoch 935, Training loss 158.01959228515625\n",
      "R2 values 0.9332, 0.8355, 0.8624; mean R2=0.8770\n",
      "Validation Error: Avg loss: 710.359131 \n",
      "\n",
      "2023-11-08 13:25:55.126413 Epoch 936, Training loss 181.71282958984375\n",
      "R2 values 0.9358, 0.8302, 0.8787; mean R2=0.8816\n",
      "Validation Error: Avg loss: 698.702820 \n",
      "\n",
      "2023-11-08 13:25:55.619322 Epoch 937, Training loss 183.44114685058594\n",
      "R2 values 0.9422, 0.7678, 0.8877; mean R2=0.8659\n",
      "Validation Error: Avg loss: 522.508972 \n",
      "\n",
      "2023-11-08 13:25:56.094618 Epoch 938, Training loss 146.7498321533203\n",
      "R2 values 0.9494, 0.8336, 0.8816; mean R2=0.8882\n",
      "Validation Error: Avg loss: 424.114685 \n",
      "\n",
      "2023-11-08 13:25:56.855246 Epoch 939, Training loss 153.6873779296875\n",
      "R2 values 0.9464, 0.8369, 0.8715; mean R2=0.8849\n",
      "Validation Error: Avg loss: 501.373413 \n",
      "\n",
      "2023-11-08 13:25:57.351223 Epoch 940, Training loss 181.81094360351562\n",
      "R2 values 0.9524, 0.8291, 0.8813; mean R2=0.8876\n",
      "Validation Error: Avg loss: 455.244080 \n",
      "\n",
      "2023-11-08 13:25:57.827544 Epoch 941, Training loss 151.01611328125\n",
      "R2 values 0.9495, 0.8575, 0.8551; mean R2=0.8874\n",
      "Validation Error: Avg loss: 527.651733 \n",
      "\n",
      "2023-11-08 13:25:58.323477 Epoch 942, Training loss 112.43464660644531\n",
      "R2 values 0.9559, 0.8371, 0.8672; mean R2=0.8867\n",
      "Validation Error: Avg loss: 470.706421 \n",
      "\n",
      "2023-11-08 13:25:58.814283 Epoch 943, Training loss 202.34469604492188\n",
      "R2 values 0.9551, 0.8376, 0.8811; mean R2=0.8913\n",
      "Validation Error: Avg loss: 445.765106 \n",
      "\n",
      "2023-11-08 13:25:59.296442 Epoch 944, Training loss 155.43380737304688\n",
      "R2 values 0.9578, 0.8156, 0.8933; mean R2=0.8889\n",
      "Validation Error: Avg loss: 421.639343 \n",
      "\n",
      "2023-11-08 13:25:59.788240 Epoch 945, Training loss 184.9849853515625\n",
      "R2 values 0.9440, 0.7877, 0.8689; mean R2=0.8669\n",
      "Validation Error: Avg loss: 613.189880 \n",
      "\n",
      "2023-11-08 13:26:00.274132 Epoch 946, Training loss 171.4955291748047\n",
      "R2 values 0.9577, 0.8111, 0.8867; mean R2=0.8851\n",
      "Validation Error: Avg loss: 365.949585 \n",
      "\n",
      "2023-11-08 13:26:00.757111 Epoch 947, Training loss 138.59573364257812\n",
      "R2 values 0.9489, 0.8105, 0.8532; mean R2=0.8709\n",
      "Validation Error: Avg loss: 481.745972 \n",
      "\n",
      "2023-11-08 13:26:01.242283 Epoch 948, Training loss 142.0594940185547\n",
      "R2 values 0.9446, 0.7926, 0.8578; mean R2=0.8650\n",
      "Validation Error: Avg loss: 518.104065 \n",
      "\n",
      "2023-11-08 13:26:01.723273 Epoch 949, Training loss 105.98796081542969\n",
      "R2 values 0.9302, 0.8093, 0.8494; mean R2=0.8630\n",
      "Validation Error: Avg loss: 772.070862 \n",
      "\n",
      "2023-11-08 13:26:02.207337 Epoch 950, Training loss 208.7501220703125\n",
      "R2 values 0.9513, 0.7686, 0.8264; mean R2=0.8488\n",
      "Validation Error: Avg loss: 528.415833 \n",
      "\n",
      "2023-11-08 13:26:02.690162 Epoch 951, Training loss 104.01407623291016\n",
      "R2 values 0.9551, 0.8387, 0.8598; mean R2=0.8845\n",
      "Validation Error: Avg loss: 385.788940 \n",
      "\n",
      "2023-11-08 13:26:03.365451 Epoch 952, Training loss 171.623291015625\n",
      "R2 values 0.9451, 0.8124, 0.8535; mean R2=0.8703\n",
      "Validation Error: Avg loss: 469.229309 \n",
      "\n",
      "2023-11-08 13:26:03.961373 Epoch 953, Training loss 143.7432861328125\n",
      "R2 values 0.9554, 0.8041, 0.8926; mean R2=0.8840\n",
      "Validation Error: Avg loss: 462.933838 \n",
      "\n",
      "2023-11-08 13:26:04.440989 Epoch 954, Training loss 121.66991424560547\n",
      "R2 values 0.9590, 0.8126, 0.8725; mean R2=0.8813\n",
      "Validation Error: Avg loss: 489.925873 \n",
      "\n",
      "2023-11-08 13:26:04.926514 Epoch 955, Training loss 121.11448669433594\n",
      "R2 values 0.9524, 0.8219, 0.8727; mean R2=0.8823\n",
      "Validation Error: Avg loss: 438.561707 \n",
      "\n",
      "2023-11-08 13:26:05.407585 Epoch 956, Training loss 111.63758087158203\n",
      "R2 values 0.9593, 0.8352, 0.8955; mean R2=0.8967\n",
      "Validation Error: Avg loss: 370.995209 \n",
      "\n",
      "2023-11-08 13:26:05.883706 Epoch 957, Training loss 130.0813446044922\n",
      "R2 values 0.9560, 0.8540, 0.8844; mean R2=0.8981\n",
      "Validation Error: Avg loss: 472.326813 \n",
      "\n",
      "2023-11-08 13:26:06.363324 Epoch 958, Training loss 152.5030517578125\n",
      "R2 values 0.9601, 0.8352, 0.8827; mean R2=0.8927\n",
      "Validation Error: Avg loss: 490.352112 \n",
      "\n",
      "2023-11-08 13:26:06.844460 Epoch 959, Training loss 123.25018310546875\n",
      "R2 values 0.9495, 0.8084, 0.8637; mean R2=0.8739\n",
      "Validation Error: Avg loss: 556.453003 \n",
      "\n",
      "2023-11-08 13:26:07.322887 Epoch 960, Training loss 108.4720687866211\n",
      "R2 values 0.9551, 0.7905, 0.8666; mean R2=0.8707\n",
      "Validation Error: Avg loss: 452.789429 \n",
      "\n",
      "2023-11-08 13:26:07.804981 Epoch 961, Training loss 153.9387969970703\n",
      "R2 values 0.9466, 0.8152, 0.8572; mean R2=0.8730\n",
      "Validation Error: Avg loss: 501.553162 \n",
      "\n",
      "2023-11-08 13:26:08.300870 Epoch 962, Training loss 126.4431381225586\n",
      "R2 values 0.9519, 0.8434, 0.8612; mean R2=0.8855\n",
      "Validation Error: Avg loss: 508.427368 \n",
      "\n",
      "2023-11-08 13:26:08.785801 Epoch 963, Training loss 120.02913665771484\n",
      "R2 values 0.9471, 0.8432, 0.8634; mean R2=0.8846\n",
      "Validation Error: Avg loss: 512.897644 \n",
      "\n",
      "2023-11-08 13:26:09.268006 Epoch 964, Training loss 141.05865478515625\n",
      "R2 values 0.9429, 0.8253, 0.8794; mean R2=0.8825\n",
      "Validation Error: Avg loss: 515.200928 \n",
      "\n",
      "2023-11-08 13:26:09.757035 Epoch 965, Training loss 138.11453247070312\n",
      "R2 values 0.9551, 0.8328, 0.8624; mean R2=0.8835\n",
      "Validation Error: Avg loss: 424.773987 \n",
      "\n",
      "2023-11-08 13:26:10.241106 Epoch 966, Training loss 116.58265686035156\n",
      "R2 values 0.9538, 0.8186, 0.9048; mean R2=0.8924\n",
      "Validation Error: Avg loss: 430.987457 \n",
      "\n",
      "2023-11-08 13:26:10.720587 Epoch 967, Training loss 130.45664978027344\n",
      "R2 values 0.9551, 0.8287, 0.8761; mean R2=0.8866\n",
      "Validation Error: Avg loss: 563.711609 \n",
      "\n",
      "2023-11-08 13:26:11.200075 Epoch 968, Training loss 167.4208221435547\n",
      "R2 values 0.9526, 0.8386, 0.8856; mean R2=0.8923\n",
      "Validation Error: Avg loss: 430.617279 \n",
      "\n",
      "2023-11-08 13:26:11.675549 Epoch 969, Training loss 122.74803161621094\n",
      "R2 values 0.9482, 0.8095, 0.8860; mean R2=0.8812\n",
      "Validation Error: Avg loss: 444.119110 \n",
      "\n",
      "2023-11-08 13:26:12.153878 Epoch 970, Training loss 144.56536865234375\n",
      "R2 values 0.9593, 0.8230, 0.8640; mean R2=0.8821\n",
      "Validation Error: Avg loss: 396.101044 \n",
      "\n",
      "2023-11-08 13:26:12.646555 Epoch 971, Training loss 167.6612548828125\n",
      "R2 values 0.9474, 0.7733, 0.8619; mean R2=0.8609\n",
      "Validation Error: Avg loss: 595.825989 \n",
      "\n",
      "2023-11-08 13:26:13.378513 Epoch 972, Training loss 112.19615173339844\n",
      "R2 values 0.9343, 0.7428, 0.8768; mean R2=0.8513\n",
      "Validation Error: Avg loss: 846.027832 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:26:13.864179 Epoch 973, Training loss 173.63485717773438\n",
      "R2 values 0.9391, 0.7601, 0.8863; mean R2=0.8619\n",
      "Validation Error: Avg loss: 544.406494 \n",
      "\n",
      "2023-11-08 13:26:14.349936 Epoch 974, Training loss 127.87671661376953\n",
      "R2 values 0.9438, 0.8374, 0.8646; mean R2=0.8819\n",
      "Validation Error: Avg loss: 459.895721 \n",
      "\n",
      "2023-11-08 13:26:14.836862 Epoch 975, Training loss 159.9779815673828\n",
      "R2 values 0.9580, 0.7880, 0.8520; mean R2=0.8660\n",
      "Validation Error: Avg loss: 416.646179 \n",
      "\n",
      "2023-11-08 13:26:15.314850 Epoch 976, Training loss 161.32550048828125\n",
      "R2 values 0.9553, 0.8353, 0.8621; mean R2=0.8843\n",
      "Validation Error: Avg loss: 492.603333 \n",
      "\n",
      "2023-11-08 13:26:15.795807 Epoch 977, Training loss 108.08200073242188\n",
      "R2 values 0.9454, 0.8277, 0.8689; mean R2=0.8806\n",
      "Validation Error: Avg loss: 520.798279 \n",
      "\n",
      "2023-11-08 13:26:16.270629 Epoch 978, Training loss 103.10154724121094\n",
      "R2 values 0.9410, 0.8441, 0.8649; mean R2=0.8834\n",
      "Validation Error: Avg loss: 568.390137 \n",
      "\n",
      "2023-11-08 13:26:16.892732 Epoch 979, Training loss 118.8502426147461\n",
      "R2 values 0.9623, 0.8098, 0.8846; mean R2=0.8856\n",
      "Validation Error: Avg loss: 368.859375 \n",
      "\n",
      "2023-11-08 13:26:17.368606 Epoch 980, Training loss 131.26441955566406\n",
      "R2 values 0.9607, 0.8207, 0.8605; mean R2=0.8806\n",
      "Validation Error: Avg loss: 425.524170 \n",
      "\n",
      "2023-11-08 13:26:17.831783 Epoch 981, Training loss 129.82168579101562\n",
      "R2 values 0.9540, 0.8638, 0.8785; mean R2=0.8988\n",
      "Validation Error: Avg loss: 428.951263 \n",
      "\n",
      "2023-11-08 13:26:18.316191 Epoch 982, Training loss 134.24441528320312\n",
      "R2 values 0.9572, 0.8471, 0.8794; mean R2=0.8946\n",
      "Validation Error: Avg loss: 418.411011 \n",
      "\n",
      "2023-11-08 13:26:18.823327 Epoch 983, Training loss 110.5009536743164\n",
      "R2 values 0.9436, 0.8497, 0.8655; mean R2=0.8863\n",
      "Validation Error: Avg loss: 537.514038 \n",
      "\n",
      "2023-11-08 13:26:19.356681 Epoch 984, Training loss 145.69691467285156\n",
      "R2 values 0.9596, 0.8192, 0.8695; mean R2=0.8827\n",
      "Validation Error: Avg loss: 421.288879 \n",
      "\n",
      "2023-11-08 13:26:19.836897 Epoch 985, Training loss 129.57424926757812\n",
      "R2 values 0.9571, 0.8585, 0.8561; mean R2=0.8906\n",
      "Validation Error: Avg loss: 396.032410 \n",
      "\n",
      "2023-11-08 13:26:20.305231 Epoch 986, Training loss 111.92040252685547\n",
      "R2 values 0.9369, 0.8373, 0.8871; mean R2=0.8871\n",
      "Validation Error: Avg loss: 513.556458 \n",
      "\n",
      "2023-11-08 13:26:20.790469 Epoch 987, Training loss 147.29627990722656\n",
      "R2 values 0.9586, 0.8478, 0.8654; mean R2=0.8906\n",
      "Validation Error: Avg loss: 375.564484 \n",
      "\n",
      "2023-11-08 13:26:21.265546 Epoch 988, Training loss 135.13038635253906\n",
      "R2 values 0.9580, 0.8004, 0.8421; mean R2=0.8668\n",
      "Validation Error: Avg loss: 460.319122 \n",
      "\n",
      "2023-11-08 13:26:21.737532 Epoch 989, Training loss 123.06150817871094\n",
      "R2 values 0.9544, 0.8289, 0.8715; mean R2=0.8849\n",
      "Validation Error: Avg loss: 507.983795 \n",
      "\n",
      "2023-11-08 13:26:22.218990 Epoch 990, Training loss 197.4993438720703\n",
      "R2 values 0.9622, 0.8233, 0.8617; mean R2=0.8824\n",
      "Validation Error: Avg loss: 353.981201 \n",
      "\n",
      "2023-11-08 13:26:22.695834 Epoch 991, Training loss 115.14408111572266\n",
      "R2 values 0.9510, 0.8441, 0.8864; mean R2=0.8938\n",
      "Validation Error: Avg loss: 463.406494 \n",
      "\n",
      "2023-11-08 13:26:23.193221 Epoch 992, Training loss 117.97734832763672\n",
      "R2 values 0.9481, 0.7896, 0.8903; mean R2=0.8760\n",
      "Validation Error: Avg loss: 471.928528 \n",
      "\n",
      "2023-11-08 13:26:23.671609 Epoch 993, Training loss 122.12496185302734\n",
      "R2 values 0.9446, 0.8009, 0.8778; mean R2=0.8744\n",
      "Validation Error: Avg loss: 499.668030 \n",
      "\n",
      "2023-11-08 13:26:24.148154 Epoch 994, Training loss 121.92208099365234\n",
      "R2 values 0.9426, 0.8119, 0.8513; mean R2=0.8686\n",
      "Validation Error: Avg loss: 567.780090 \n",
      "\n",
      "2023-11-08 13:26:24.628572 Epoch 995, Training loss 126.51171112060547\n",
      "R2 values 0.9391, 0.8099, 0.8853; mean R2=0.8781\n",
      "Validation Error: Avg loss: 513.838196 \n",
      "\n",
      "2023-11-08 13:26:25.112152 Epoch 996, Training loss 118.37352752685547\n",
      "R2 values 0.9432, 0.8391, 0.8584; mean R2=0.8803\n",
      "Validation Error: Avg loss: 467.032715 \n",
      "\n",
      "2023-11-08 13:26:25.653436 Epoch 997, Training loss 112.3960952758789\n",
      "R2 values 0.9516, 0.8276, 0.8964; mean R2=0.8919\n",
      "Validation Error: Avg loss: 422.759033 \n",
      "\n",
      "2023-11-08 13:26:26.131768 Epoch 998, Training loss 113.63064575195312\n",
      "R2 values 0.9628, 0.8372, 0.8771; mean R2=0.8924\n",
      "Validation Error: Avg loss: 406.064056 \n",
      "\n",
      "2023-11-08 13:26:26.607833 Epoch 999, Training loss 167.2762451171875\n",
      "R2 values 0.9528, 0.8179, 0.8796; mean R2=0.8834\n",
      "Validation Error: Avg loss: 479.068787 \n",
      "\n",
      "2023-11-08 13:26:27.083126 Epoch 1000, Training loss 116.82320404052734\n",
      "R2 values 0.9550, 0.8264, 0.8749; mean R2=0.8854\n",
      "Validation Error: Avg loss: 384.475586 \n",
      "\n",
      "2023-11-08 13:26:27.563261 Epoch 1001, Training loss 130.06768798828125\n",
      "R2 values 0.9466, 0.8290, 0.8845; mean R2=0.8867\n",
      "Validation Error: Avg loss: 440.494293 \n",
      "\n",
      "2023-11-08 13:26:28.032742 Epoch 1002, Training loss 172.00303649902344\n",
      "R2 values 0.9394, 0.8284, 0.8811; mean R2=0.8829\n",
      "Validation Error: Avg loss: 530.526978 \n",
      "\n",
      "2023-11-08 13:26:28.662003 Epoch 1003, Training loss 138.67457580566406\n",
      "R2 values 0.9425, 0.8010, 0.8858; mean R2=0.8764\n",
      "Validation Error: Avg loss: 538.269836 \n",
      "\n",
      "2023-11-08 13:26:29.156511 Epoch 1004, Training loss 132.50680541992188\n",
      "R2 values 0.9429, 0.8600, 0.8874; mean R2=0.8968\n",
      "Validation Error: Avg loss: 503.893463 \n",
      "\n",
      "2023-11-08 13:26:29.637522 Epoch 1005, Training loss 131.7144012451172\n",
      "R2 values 0.9559, 0.8468, 0.8782; mean R2=0.8936\n",
      "Validation Error: Avg loss: 379.379150 \n",
      "\n",
      "2023-11-08 13:26:30.131098 Epoch 1006, Training loss 150.43289184570312\n",
      "R2 values 0.9391, 0.8611, 0.8729; mean R2=0.8911\n",
      "Validation Error: Avg loss: 621.909241 \n",
      "\n",
      "2023-11-08 13:26:30.630769 Epoch 1007, Training loss 160.72679138183594\n",
      "R2 values 0.9506, 0.8242, 0.8773; mean R2=0.8840\n",
      "Validation Error: Avg loss: 493.789490 \n",
      "\n",
      "2023-11-08 13:26:31.109866 Epoch 1008, Training loss 117.98371887207031\n",
      "R2 values 0.9537, 0.7856, 0.8715; mean R2=0.8702\n",
      "Validation Error: Avg loss: 426.965118 \n",
      "\n",
      "2023-11-08 13:26:31.651087 Epoch 1009, Training loss 123.88240051269531\n",
      "R2 values 0.9592, 0.8301, 0.8718; mean R2=0.8870\n",
      "Validation Error: Avg loss: 391.668671 \n",
      "\n",
      "2023-11-08 13:26:32.143342 Epoch 1010, Training loss 140.83157348632812\n",
      "R2 values 0.9476, 0.8105, 0.8488; mean R2=0.8689\n",
      "Validation Error: Avg loss: 528.215637 \n",
      "\n",
      "2023-11-08 13:26:32.632664 Epoch 1011, Training loss 112.40251159667969\n",
      "R2 values 0.9571, 0.8128, 0.8676; mean R2=0.8792\n",
      "Validation Error: Avg loss: 573.387085 \n",
      "\n",
      "2023-11-08 13:26:33.114820 Epoch 1012, Training loss 184.21815490722656\n",
      "R2 values 0.9485, 0.8714, 0.8422; mean R2=0.8874\n",
      "Validation Error: Avg loss: 453.745636 \n",
      "\n",
      "2023-11-08 13:26:33.600270 Epoch 1013, Training loss 108.31414794921875\n",
      "R2 values 0.9551, 0.8506, 0.8696; mean R2=0.8918\n",
      "Validation Error: Avg loss: 427.487671 \n",
      "\n",
      "2023-11-08 13:26:34.089244 Epoch 1014, Training loss 178.68809509277344\n",
      "R2 values 0.9561, 0.7882, 0.8732; mean R2=0.8725\n",
      "Validation Error: Avg loss: 410.420502 \n",
      "\n",
      "2023-11-08 13:26:34.579766 Epoch 1015, Training loss 163.0103759765625\n",
      "R2 values 0.9521, 0.8168, 0.8607; mean R2=0.8765\n",
      "Validation Error: Avg loss: 552.425415 \n",
      "\n",
      "2023-11-08 13:26:35.077757 Epoch 1016, Training loss 122.53559112548828\n",
      "R2 values 0.9526, 0.8490, 0.8979; mean R2=0.8998\n",
      "Validation Error: Avg loss: 661.569458 \n",
      "\n",
      "2023-11-08 13:26:35.564119 Epoch 1017, Training loss 165.43409729003906\n",
      "R2 values 0.9556, 0.9033, 0.8828; mean R2=0.9139\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 415.949646 \n",
      "\n",
      "2023-11-08 13:26:36.128927 Epoch 1018, Training loss 113.8690414428711\n",
      "R2 values 0.9483, 0.8501, 0.8819; mean R2=0.8934\n",
      "Validation Error: Avg loss: 415.916168 \n",
      "\n",
      "2023-11-08 13:26:36.607300 Epoch 1019, Training loss 162.15847778320312\n",
      "R2 values 0.9544, 0.8482, 0.8578; mean R2=0.8868\n",
      "Validation Error: Avg loss: 402.510651 \n",
      "\n",
      "2023-11-08 13:26:37.086611 Epoch 1020, Training loss 165.17514038085938\n",
      "R2 values 0.9590, 0.8300, 0.8956; mean R2=0.8949\n",
      "Validation Error: Avg loss: 550.897278 \n",
      "\n",
      "2023-11-08 13:26:37.575112 Epoch 1021, Training loss 132.84796142578125\n",
      "R2 values 0.9449, 0.8427, 0.9038; mean R2=0.8971\n",
      "Validation Error: Avg loss: 568.423889 \n",
      "\n",
      "2023-11-08 13:26:38.058717 Epoch 1022, Training loss 169.4022674560547\n",
      "R2 values 0.9506, 0.8077, 0.8735; mean R2=0.8773\n",
      "Validation Error: Avg loss: 514.869568 \n",
      "\n",
      "2023-11-08 13:26:38.573238 Epoch 1023, Training loss 111.16585540771484\n",
      "R2 values 0.9415, 0.8155, 0.8753; mean R2=0.8774\n",
      "Validation Error: Avg loss: 476.388519 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:26:39.060031 Epoch 1024, Training loss 162.95960998535156\n",
      "R2 values 0.9499, 0.8481, 0.8821; mean R2=0.8934\n",
      "Validation Error: Avg loss: 424.609711 \n",
      "\n",
      "2023-11-08 13:26:39.550485 Epoch 1025, Training loss 150.80162048339844\n",
      "R2 values 0.9394, 0.8347, 0.8876; mean R2=0.8872\n",
      "Validation Error: Avg loss: 536.442383 \n",
      "\n",
      "2023-11-08 13:26:40.063996 Epoch 1026, Training loss 138.49461364746094\n",
      "R2 values 0.9409, 0.8280, 0.8756; mean R2=0.8815\n",
      "Validation Error: Avg loss: 569.286682 \n",
      "\n",
      "2023-11-08 13:26:40.555546 Epoch 1027, Training loss 168.10675048828125\n",
      "R2 values 0.9557, 0.8495, 0.8625; mean R2=0.8893\n",
      "Validation Error: Avg loss: 447.543304 \n",
      "\n",
      "2023-11-08 13:26:41.050307 Epoch 1028, Training loss 124.56648254394531\n",
      "R2 values 0.9413, 0.8119, 0.8799; mean R2=0.8777\n",
      "Validation Error: Avg loss: 493.308563 \n",
      "\n",
      "2023-11-08 13:26:41.540303 Epoch 1029, Training loss 114.18621826171875\n",
      "R2 values 0.9584, 0.8180, 0.8527; mean R2=0.8764\n",
      "Validation Error: Avg loss: 388.205444 \n",
      "\n",
      "2023-11-08 13:26:42.025033 Epoch 1030, Training loss 151.9346923828125\n",
      "R2 values 0.9443, 0.8454, 0.8745; mean R2=0.8881\n",
      "Validation Error: Avg loss: 565.882629 \n",
      "\n",
      "2023-11-08 13:26:42.509486 Epoch 1031, Training loss 157.13836669921875\n",
      "R2 values 0.9460, 0.8441, 0.8369; mean R2=0.8757\n",
      "Validation Error: Avg loss: 594.516296 \n",
      "\n",
      "2023-11-08 13:26:42.995623 Epoch 1032, Training loss 241.0273895263672\n",
      "R2 values 0.9474, 0.8077, 0.8758; mean R2=0.8770\n",
      "Validation Error: Avg loss: 460.235413 \n",
      "\n",
      "2023-11-08 13:26:43.489347 Epoch 1033, Training loss 190.66217041015625\n",
      "R2 values 0.9500, 0.8262, 0.8786; mean R2=0.8850\n",
      "Validation Error: Avg loss: 487.216522 \n",
      "\n",
      "2023-11-08 13:26:44.184592 Epoch 1034, Training loss 215.13316345214844\n",
      "R2 values 0.9407, 0.8374, 0.8922; mean R2=0.8901\n",
      "Validation Error: Avg loss: 672.144104 \n",
      "\n",
      "2023-11-08 13:26:44.730030 Epoch 1035, Training loss 156.27432250976562\n",
      "R2 values 0.9387, 0.8054, 0.8898; mean R2=0.8780\n",
      "Validation Error: Avg loss: 652.049072 \n",
      "\n",
      "2023-11-08 13:26:45.221683 Epoch 1036, Training loss 255.4639892578125\n",
      "R2 values 0.9499, 0.8246, 0.9086; mean R2=0.8944\n",
      "Validation Error: Avg loss: 403.851257 \n",
      "\n",
      "2023-11-08 13:26:45.696649 Epoch 1037, Training loss 146.2141876220703\n",
      "R2 values 0.9506, 0.8247, 0.8985; mean R2=0.8913\n",
      "Validation Error: Avg loss: 449.318207 \n",
      "\n",
      "2023-11-08 13:26:46.175525 Epoch 1038, Training loss 172.13356018066406\n",
      "R2 values 0.9462, 0.7875, 0.8781; mean R2=0.8706\n",
      "Validation Error: Avg loss: 481.487305 \n",
      "\n",
      "2023-11-08 13:26:46.646885 Epoch 1039, Training loss 148.97274780273438\n",
      "R2 values 0.9645, 0.8665, 0.8796; mean R2=0.9035\n",
      "Validation Error: Avg loss: 487.159058 \n",
      "\n",
      "2023-11-08 13:26:47.119024 Epoch 1040, Training loss 168.30335998535156\n",
      "R2 values 0.9532, 0.8391, 0.8728; mean R2=0.8883\n",
      "Validation Error: Avg loss: 582.937134 \n",
      "\n",
      "2023-11-08 13:26:47.607783 Epoch 1041, Training loss 122.1296615600586\n",
      "R2 values 0.9441, 0.7554, 0.8579; mean R2=0.8525\n",
      "Validation Error: Avg loss: 511.824402 \n",
      "\n",
      "2023-11-08 13:26:48.094125 Epoch 1042, Training loss 132.2576446533203\n",
      "R2 values 0.9453, 0.8395, 0.8580; mean R2=0.8809\n",
      "Validation Error: Avg loss: 471.073669 \n",
      "\n",
      "2023-11-08 13:26:48.593688 Epoch 1043, Training loss 131.67822265625\n",
      "R2 values 0.9391, 0.8473, 0.8995; mean R2=0.8953\n",
      "Validation Error: Avg loss: 460.398438 \n",
      "\n",
      "2023-11-08 13:26:49.071545 Epoch 1044, Training loss 108.87349700927734\n",
      "R2 values 0.9517, 0.8337, 0.8605; mean R2=0.8819\n",
      "Validation Error: Avg loss: 505.431091 \n",
      "\n",
      "2023-11-08 13:26:49.559083 Epoch 1045, Training loss 144.02357482910156\n",
      "R2 values 0.9473, 0.8068, 0.8577; mean R2=0.8706\n",
      "Validation Error: Avg loss: 580.644470 \n",
      "\n",
      "2023-11-08 13:26:50.038941 Epoch 1046, Training loss 137.88731384277344\n",
      "R2 values 0.9481, 0.7649, 0.8559; mean R2=0.8563\n",
      "Validation Error: Avg loss: 516.115662 \n",
      "\n",
      "2023-11-08 13:26:50.513853 Epoch 1047, Training loss 126.43522644042969\n",
      "R2 values 0.9663, 0.8056, 0.8575; mean R2=0.8765\n",
      "Validation Error: Avg loss: 367.989136 \n",
      "\n",
      "2023-11-08 13:26:51.049102 Epoch 1048, Training loss 126.66730499267578\n",
      "R2 values 0.9606, 0.8312, 0.8789; mean R2=0.8902\n",
      "Validation Error: Avg loss: 381.281158 \n",
      "\n",
      "2023-11-08 13:26:51.524002 Epoch 1049, Training loss 94.10704040527344\n",
      "R2 values 0.9459, 0.8631, 0.8626; mean R2=0.8905\n",
      "Validation Error: Avg loss: 538.665588 \n",
      "\n",
      "2023-11-08 13:26:52.003471 Epoch 1050, Training loss 122.83092498779297\n",
      "R2 values 0.9588, 0.8322, 0.8900; mean R2=0.8937\n",
      "Validation Error: Avg loss: 363.108612 \n",
      "\n",
      "2023-11-08 13:26:52.481770 Epoch 1051, Training loss 107.11644744873047\n",
      "R2 values 0.9672, 0.8453, 0.9008; mean R2=0.9044\n",
      "Validation Error: Avg loss: 302.517883 \n",
      "\n",
      "2023-11-08 13:26:52.961876 Epoch 1052, Training loss 139.60647583007812\n",
      "R2 values 0.9651, 0.8284, 0.8888; mean R2=0.8941\n",
      "Validation Error: Avg loss: 365.236359 \n",
      "\n",
      "2023-11-08 13:26:53.455641 Epoch 1053, Training loss 119.55230712890625\n",
      "R2 values 0.9575, 0.8147, 0.8816; mean R2=0.8846\n",
      "Validation Error: Avg loss: 476.948639 \n",
      "\n",
      "2023-11-08 13:26:53.963901 Epoch 1054, Training loss 118.40325164794922\n",
      "R2 values 0.9509, 0.8485, 0.8847; mean R2=0.8947\n",
      "Validation Error: Avg loss: 503.280518 \n",
      "\n",
      "2023-11-08 13:26:54.445267 Epoch 1055, Training loss 130.33164978027344\n",
      "R2 values 0.9429, 0.8404, 0.8997; mean R2=0.8943\n",
      "Validation Error: Avg loss: 495.921356 \n",
      "\n",
      "2023-11-08 13:26:54.929241 Epoch 1056, Training loss 136.3291015625\n",
      "R2 values 0.9564, 0.8374, 0.8774; mean R2=0.8904\n",
      "Validation Error: Avg loss: 404.946136 \n",
      "\n",
      "2023-11-08 13:26:55.415397 Epoch 1057, Training loss 102.4473876953125\n",
      "R2 values 0.9431, 0.8447, 0.8675; mean R2=0.8851\n",
      "Validation Error: Avg loss: 466.896790 \n",
      "\n",
      "2023-11-08 13:26:55.892424 Epoch 1058, Training loss 141.84609985351562\n",
      "R2 values 0.9517, 0.8396, 0.9193; mean R2=0.9035\n",
      "Validation Error: Avg loss: 483.652008 \n",
      "\n",
      "2023-11-08 13:26:56.371147 Epoch 1059, Training loss 112.88885498046875\n",
      "R2 values 0.9453, 0.8208, 0.8670; mean R2=0.8777\n",
      "Validation Error: Avg loss: 575.891663 \n",
      "\n",
      "2023-11-08 13:26:56.852951 Epoch 1060, Training loss 128.8531036376953\n",
      "R2 values 0.9508, 0.8193, 0.8782; mean R2=0.8827\n",
      "Validation Error: Avg loss: 442.604401 \n",
      "\n",
      "2023-11-08 13:26:57.330407 Epoch 1061, Training loss 120.02944946289062\n",
      "R2 values 0.9335, 0.8155, 0.8947; mean R2=0.8812\n",
      "Validation Error: Avg loss: 545.857849 \n",
      "\n",
      "2023-11-08 13:26:57.813368 Epoch 1062, Training loss 136.34523010253906\n",
      "R2 values 0.9510, 0.8211, 0.8773; mean R2=0.8831\n",
      "Validation Error: Avg loss: 407.399750 \n",
      "\n",
      "2023-11-08 13:26:58.297485 Epoch 1063, Training loss 123.92328643798828\n",
      "R2 values 0.9454, 0.8337, 0.8871; mean R2=0.8887\n",
      "Validation Error: Avg loss: 555.968323 \n",
      "\n",
      "2023-11-08 13:26:58.784924 Epoch 1064, Training loss 108.28819274902344\n",
      "R2 values 0.9405, 0.8157, 0.8444; mean R2=0.8669\n",
      "Validation Error: Avg loss: 713.302246 \n",
      "\n",
      "2023-11-08 13:26:59.261599 Epoch 1065, Training loss 162.63807678222656\n",
      "R2 values 0.9529, 0.8223, 0.8136; mean R2=0.8629\n",
      "Validation Error: Avg loss: 510.408813 \n",
      "\n",
      "2023-11-08 13:26:59.731835 Epoch 1066, Training loss 117.10087585449219\n",
      "R2 values 0.9560, 0.8204, 0.8371; mean R2=0.8712\n",
      "Validation Error: Avg loss: 421.623413 \n",
      "\n",
      "2023-11-08 13:27:00.280321 Epoch 1067, Training loss 165.85183715820312\n",
      "R2 values 0.9587, 0.8506, 0.8815; mean R2=0.8969\n",
      "Validation Error: Avg loss: 363.102234 \n",
      "\n",
      "2023-11-08 13:27:00.761822 Epoch 1068, Training loss 134.6357421875\n",
      "R2 values 0.9541, 0.8653, 0.8702; mean R2=0.8965\n",
      "Validation Error: Avg loss: 487.917755 \n",
      "\n",
      "2023-11-08 13:27:01.246128 Epoch 1069, Training loss 125.9388656616211\n",
      "R2 values 0.9409, 0.8437, 0.8218; mean R2=0.8688\n",
      "Validation Error: Avg loss: 545.299500 \n",
      "\n",
      "2023-11-08 13:27:01.731729 Epoch 1070, Training loss 137.7290802001953\n",
      "R2 values 0.9543, 0.7946, 0.8609; mean R2=0.8699\n",
      "Validation Error: Avg loss: 435.193451 \n",
      "\n",
      "2023-11-08 13:27:02.212112 Epoch 1071, Training loss 143.42868041992188\n",
      "R2 values 0.9475, 0.7943, 0.8797; mean R2=0.8739\n",
      "Validation Error: Avg loss: 493.205078 \n",
      "\n",
      "2023-11-08 13:27:02.694549 Epoch 1072, Training loss 137.52005004882812\n",
      "R2 values 0.9523, 0.7778, 0.8549; mean R2=0.8617\n",
      "Validation Error: Avg loss: 499.542755 \n",
      "\n",
      "2023-11-08 13:27:03.318336 Epoch 1073, Training loss 138.3695068359375\n",
      "R2 values 0.9607, 0.8203, 0.8655; mean R2=0.8821\n",
      "Validation Error: Avg loss: 458.339020 \n",
      "\n",
      "2023-11-08 13:27:03.808197 Epoch 1074, Training loss 131.89935302734375\n",
      "R2 values 0.9445, 0.7943, 0.8807; mean R2=0.8732\n",
      "Validation Error: Avg loss: 525.288391 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:27:04.276096 Epoch 1075, Training loss 109.17113494873047\n",
      "R2 values 0.9682, 0.8448, 0.8433; mean R2=0.8854\n",
      "Validation Error: Avg loss: 348.105316 \n",
      "\n",
      "2023-11-08 13:27:04.763082 Epoch 1076, Training loss 117.84748077392578\n",
      "R2 values 0.9484, 0.8590, 0.8683; mean R2=0.8919\n",
      "Validation Error: Avg loss: 500.447754 \n",
      "\n",
      "2023-11-08 13:27:05.254073 Epoch 1077, Training loss 110.21426391601562\n",
      "R2 values 0.9523, 0.7976, 0.8495; mean R2=0.8665\n",
      "Validation Error: Avg loss: 481.720734 \n",
      "\n",
      "2023-11-08 13:27:05.727160 Epoch 1078, Training loss 124.97804260253906\n",
      "R2 values 0.9528, 0.8126, 0.8557; mean R2=0.8737\n",
      "Validation Error: Avg loss: 450.750214 \n",
      "\n",
      "2023-11-08 13:27:06.253776 Epoch 1079, Training loss 110.2879867553711\n",
      "R2 values 0.9606, 0.8023, 0.8620; mean R2=0.8750\n",
      "Validation Error: Avg loss: 388.479858 \n",
      "\n",
      "2023-11-08 13:27:06.730976 Epoch 1080, Training loss 114.32565307617188\n",
      "R2 values 0.9520, 0.8181, 0.8781; mean R2=0.8827\n",
      "Validation Error: Avg loss: 412.434723 \n",
      "\n",
      "2023-11-08 13:27:07.223451 Epoch 1081, Training loss 103.22139739990234\n",
      "R2 values 0.9474, 0.8346, 0.8838; mean R2=0.8886\n",
      "Validation Error: Avg loss: 426.125244 \n",
      "\n",
      "2023-11-08 13:27:07.705982 Epoch 1082, Training loss 154.50064086914062\n",
      "R2 values 0.9459, 0.8572, 0.8790; mean R2=0.8940\n",
      "Validation Error: Avg loss: 497.261841 \n",
      "\n",
      "2023-11-08 13:27:08.184661 Epoch 1083, Training loss 118.15392303466797\n",
      "R2 values 0.9471, 0.8158, 0.8799; mean R2=0.8809\n",
      "Validation Error: Avg loss: 615.877625 \n",
      "\n",
      "2023-11-08 13:27:08.677289 Epoch 1084, Training loss 170.10525512695312\n",
      "R2 values 0.9544, 0.8325, 0.8664; mean R2=0.8845\n",
      "Validation Error: Avg loss: 503.687958 \n",
      "\n",
      "2023-11-08 13:27:09.174049 Epoch 1085, Training loss 115.21549224853516\n",
      "R2 values 0.9546, 0.8453, 0.8697; mean R2=0.8899\n",
      "Validation Error: Avg loss: 414.809601 \n",
      "\n",
      "2023-11-08 13:27:09.644206 Epoch 1086, Training loss 103.75616455078125\n",
      "R2 values 0.9608, 0.8304, 0.8643; mean R2=0.8852\n",
      "Validation Error: Avg loss: 379.921173 \n",
      "\n",
      "2023-11-08 13:27:10.136171 Epoch 1087, Training loss 158.120849609375\n",
      "R2 values 0.9526, 0.8372, 0.8799; mean R2=0.8899\n",
      "Validation Error: Avg loss: 430.682343 \n",
      "\n",
      "2023-11-08 13:27:10.620262 Epoch 1088, Training loss 138.43284606933594\n",
      "R2 values 0.9365, 0.8299, 0.8743; mean R2=0.8802\n",
      "Validation Error: Avg loss: 693.293884 \n",
      "\n",
      "2023-11-08 13:27:11.101647 Epoch 1089, Training loss 154.12698364257812\n",
      "R2 values 0.9470, 0.8581, 0.8834; mean R2=0.8962\n",
      "Validation Error: Avg loss: 702.263916 \n",
      "\n",
      "2023-11-08 13:27:11.587377 Epoch 1090, Training loss 170.21340942382812\n",
      "R2 values 0.9403, 0.8171, 0.8882; mean R2=0.8819\n",
      "Validation Error: Avg loss: 491.111816 \n",
      "\n",
      "2023-11-08 13:27:12.061040 Epoch 1091, Training loss 134.1195068359375\n",
      "R2 values 0.9541, 0.8263, 0.8827; mean R2=0.8877\n",
      "Validation Error: Avg loss: 447.409546 \n",
      "\n",
      "2023-11-08 13:27:12.535369 Epoch 1092, Training loss 179.876953125\n",
      "R2 values 0.9484, 0.8335, 0.8637; mean R2=0.8819\n",
      "Validation Error: Avg loss: 424.569824 \n",
      "\n",
      "2023-11-08 13:27:13.036770 Epoch 1093, Training loss 106.27790832519531\n",
      "R2 values 0.9506, 0.8324, 0.8593; mean R2=0.8808\n",
      "Validation Error: Avg loss: 516.147583 \n",
      "\n",
      "2023-11-08 13:27:13.515956 Epoch 1094, Training loss 164.21200561523438\n",
      "R2 values 0.9572, 0.8465, 0.8898; mean R2=0.8978\n",
      "Validation Error: Avg loss: 454.725525 \n",
      "\n",
      "2023-11-08 13:27:13.989250 Epoch 1095, Training loss 149.51907348632812\n",
      "R2 values 0.9591, 0.8176, 0.8347; mean R2=0.8705\n",
      "Validation Error: Avg loss: 422.537872 \n",
      "\n",
      "2023-11-08 13:27:14.468796 Epoch 1096, Training loss 160.0675811767578\n",
      "R2 values 0.9570, 0.8453, 0.8415; mean R2=0.8813\n",
      "Validation Error: Avg loss: 445.527161 \n",
      "\n",
      "2023-11-08 13:27:14.955253 Epoch 1097, Training loss 121.57244873046875\n",
      "R2 values 0.9606, 0.7926, 0.8322; mean R2=0.8618\n",
      "Validation Error: Avg loss: 447.695068 \n",
      "\n",
      "2023-11-08 13:27:15.443849 Epoch 1098, Training loss 131.14117431640625\n",
      "R2 values 0.9409, 0.8115, 0.8830; mean R2=0.8785\n",
      "Validation Error: Avg loss: 527.159119 \n",
      "\n",
      "2023-11-08 13:27:15.925289 Epoch 1099, Training loss 102.57479095458984\n",
      "R2 values 0.9401, 0.8173, 0.8758; mean R2=0.8777\n",
      "Validation Error: Avg loss: 475.398651 \n",
      "\n",
      "2023-11-08 13:27:16.406615 Epoch 1100, Training loss 136.39881896972656\n",
      "R2 values 0.9412, 0.8102, 0.8720; mean R2=0.8745\n",
      "Validation Error: Avg loss: 486.783875 \n",
      "\n",
      "2023-11-08 13:27:16.903207 Epoch 1101, Training loss 117.79613494873047\n",
      "R2 values 0.9426, 0.8092, 0.8646; mean R2=0.8721\n",
      "Validation Error: Avg loss: 538.011597 \n",
      "\n",
      "2023-11-08 13:27:17.382282 Epoch 1102, Training loss 170.1785430908203\n",
      "R2 values 0.9472, 0.8525, 0.9069; mean R2=0.9022\n",
      "Validation Error: Avg loss: 624.950500 \n",
      "\n",
      "2023-11-08 13:27:17.854363 Epoch 1103, Training loss 167.8920135498047\n",
      "R2 values 0.9466, 0.8284, 0.8912; mean R2=0.8888\n",
      "Validation Error: Avg loss: 552.390564 \n",
      "\n",
      "2023-11-08 13:27:18.341968 Epoch 1104, Training loss 123.74219512939453\n",
      "R2 values 0.9489, 0.8308, 0.9172; mean R2=0.8990\n",
      "Validation Error: Avg loss: 435.892395 \n",
      "\n",
      "2023-11-08 13:27:18.847155 Epoch 1105, Training loss 125.17382049560547\n",
      "R2 values 0.9682, 0.8681, 0.9037; mean R2=0.9133\n",
      "Validation Error: Avg loss: 275.507111 \n",
      "\n",
      "2023-11-08 13:27:19.321584 Epoch 1106, Training loss 126.40385437011719\n",
      "R2 values 0.9485, 0.8266, 0.8761; mean R2=0.8837\n",
      "Validation Error: Avg loss: 478.019958 \n",
      "\n",
      "2023-11-08 13:27:19.795053 Epoch 1107, Training loss 138.59747314453125\n",
      "R2 values 0.9554, 0.8099, 0.8515; mean R2=0.8723\n",
      "Validation Error: Avg loss: 561.460632 \n",
      "\n",
      "2023-11-08 13:27:20.292533 Epoch 1108, Training loss 127.21505737304688\n",
      "R2 values 0.9522, 0.7857, 0.8976; mean R2=0.8785\n",
      "Validation Error: Avg loss: 571.960205 \n",
      "\n",
      "2023-11-08 13:27:20.774030 Epoch 1109, Training loss 148.2727813720703\n",
      "R2 values 0.9659, 0.8524, 0.8894; mean R2=0.9026\n",
      "Validation Error: Avg loss: 366.085541 \n",
      "\n",
      "2023-11-08 13:27:21.240938 Epoch 1110, Training loss 129.19786071777344\n",
      "R2 values 0.9524, 0.8472, 0.8825; mean R2=0.8940\n",
      "Validation Error: Avg loss: 435.560974 \n",
      "\n",
      "2023-11-08 13:27:21.720671 Epoch 1111, Training loss 167.15065002441406\n",
      "R2 values 0.9488, 0.8701, 0.9038; mean R2=0.9075\n",
      "Validation Error: Avg loss: 462.321991 \n",
      "\n",
      "2023-11-08 13:27:22.197929 Epoch 1112, Training loss 134.25115966796875\n",
      "R2 values 0.9513, 0.8398, 0.8791; mean R2=0.8900\n",
      "Validation Error: Avg loss: 544.550964 \n",
      "\n",
      "2023-11-08 13:27:22.821715 Epoch 1113, Training loss 133.01524353027344\n",
      "R2 values 0.9401, 0.8304, 0.8861; mean R2=0.8855\n",
      "Validation Error: Avg loss: 537.987366 \n",
      "\n",
      "2023-11-08 13:27:23.389313 Epoch 1114, Training loss 114.02940368652344\n",
      "R2 values 0.9598, 0.8268, 0.8469; mean R2=0.8779\n",
      "Validation Error: Avg loss: 376.256683 \n",
      "\n",
      "2023-11-08 13:27:23.868517 Epoch 1115, Training loss 104.53287506103516\n",
      "R2 values 0.9411, 0.8240, 0.8638; mean R2=0.8763\n",
      "Validation Error: Avg loss: 557.353333 \n",
      "\n",
      "2023-11-08 13:27:24.352204 Epoch 1116, Training loss 178.48162841796875\n",
      "R2 values 0.9584, 0.7951, 0.8527; mean R2=0.8687\n",
      "Validation Error: Avg loss: 453.447266 \n",
      "\n",
      "2023-11-08 13:27:24.841279 Epoch 1117, Training loss 112.83612060546875\n",
      "R2 values 0.9326, 0.8648, 0.8997; mean R2=0.8990\n",
      "Validation Error: Avg loss: 700.220459 \n",
      "\n",
      "2023-11-08 13:27:25.330835 Epoch 1118, Training loss 191.06658935546875\n",
      "R2 values 0.9601, 0.8333, 0.8818; mean R2=0.8917\n",
      "Validation Error: Avg loss: 413.295593 \n",
      "\n",
      "2023-11-08 13:27:25.860061 Epoch 1119, Training loss 113.84764862060547\n",
      "R2 values 0.9494, 0.8199, 0.8970; mean R2=0.8888\n",
      "Validation Error: Avg loss: 420.167725 \n",
      "\n",
      "2023-11-08 13:27:26.335196 Epoch 1120, Training loss 152.02651977539062\n",
      "R2 values 0.9608, 0.8303, 0.8657; mean R2=0.8856\n",
      "Validation Error: Avg loss: 348.003876 \n",
      "\n",
      "2023-11-08 13:27:26.817013 Epoch 1121, Training loss 143.0742950439453\n",
      "R2 values 0.9490, 0.8077, 0.9002; mean R2=0.8856\n",
      "Validation Error: Avg loss: 526.566833 \n",
      "\n",
      "2023-11-08 13:27:27.292824 Epoch 1122, Training loss 176.04981994628906\n",
      "R2 values 0.9473, 0.8096, 0.9185; mean R2=0.8918\n",
      "Validation Error: Avg loss: 525.260315 \n",
      "\n",
      "2023-11-08 13:27:27.777897 Epoch 1123, Training loss 121.3544692993164\n",
      "R2 values 0.9533, 0.8142, 0.8858; mean R2=0.8844\n",
      "Validation Error: Avg loss: 441.436615 \n",
      "\n",
      "2023-11-08 13:27:28.262647 Epoch 1124, Training loss 113.71298217773438\n",
      "R2 values 0.9577, 0.8408, 0.8867; mean R2=0.8951\n",
      "Validation Error: Avg loss: 410.719299 \n",
      "\n",
      "2023-11-08 13:27:28.763780 Epoch 1125, Training loss 197.15245056152344\n",
      "R2 values 0.9494, 0.8492, 0.8773; mean R2=0.8920\n",
      "Validation Error: Avg loss: 430.795380 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:27:29.237267 Epoch 1126, Training loss 108.95696258544922\n",
      "R2 values 0.9623, 0.8242, 0.8695; mean R2=0.8854\n",
      "Validation Error: Avg loss: 456.902863 \n",
      "\n",
      "2023-11-08 13:27:29.794020 Epoch 1127, Training loss 153.53733825683594\n",
      "R2 values 0.9502, 0.8324, 0.8806; mean R2=0.8877\n",
      "Validation Error: Avg loss: 463.466003 \n",
      "\n",
      "2023-11-08 13:27:30.272512 Epoch 1128, Training loss 117.21179962158203\n",
      "R2 values 0.9578, 0.8230, 0.8566; mean R2=0.8792\n",
      "Validation Error: Avg loss: 405.698547 \n",
      "\n",
      "2023-11-08 13:27:30.745859 Epoch 1129, Training loss 129.1129608154297\n",
      "R2 values 0.9506, 0.8517, 0.8477; mean R2=0.8833\n",
      "Validation Error: Avg loss: 446.260742 \n",
      "\n",
      "2023-11-08 13:27:31.299228 Epoch 1130, Training loss 101.85875701904297\n",
      "R2 values 0.9570, 0.8477, 0.8808; mean R2=0.8952\n",
      "Validation Error: Avg loss: 378.066315 \n",
      "\n",
      "2023-11-08 13:27:31.845257 Epoch 1131, Training loss 94.82542419433594\n",
      "R2 values 0.9563, 0.8153, 0.8721; mean R2=0.8812\n",
      "Validation Error: Avg loss: 507.389313 \n",
      "\n",
      "2023-11-08 13:27:32.319067 Epoch 1132, Training loss 136.03021240234375\n",
      "R2 values 0.9608, 0.8151, 0.9079; mean R2=0.8946\n",
      "Validation Error: Avg loss: 432.694946 \n",
      "\n",
      "2023-11-08 13:27:32.800708 Epoch 1133, Training loss 89.75582885742188\n",
      "R2 values 0.9553, 0.8150, 0.8657; mean R2=0.8787\n",
      "Validation Error: Avg loss: 416.882904 \n",
      "\n",
      "2023-11-08 13:27:33.278849 Epoch 1134, Training loss 140.03981018066406\n",
      "R2 values 0.9594, 0.8145, 0.8762; mean R2=0.8834\n",
      "Validation Error: Avg loss: 374.093170 \n",
      "\n",
      "2023-11-08 13:27:33.765812 Epoch 1135, Training loss 92.19800567626953\n",
      "R2 values 0.9534, 0.8375, 0.8889; mean R2=0.8933\n",
      "Validation Error: Avg loss: 453.828918 \n",
      "\n",
      "2023-11-08 13:27:34.262456 Epoch 1136, Training loss 115.73666381835938\n",
      "R2 values 0.9515, 0.8139, 0.8817; mean R2=0.8824\n",
      "Validation Error: Avg loss: 518.864258 \n",
      "\n",
      "2023-11-08 13:27:34.760178 Epoch 1137, Training loss 102.27783203125\n",
      "R2 values 0.9527, 0.8082, 0.8523; mean R2=0.8711\n",
      "Validation Error: Avg loss: 510.306915 \n",
      "\n",
      "2023-11-08 13:27:35.246579 Epoch 1138, Training loss 85.03250885009766\n",
      "R2 values 0.9580, 0.8383, 0.8729; mean R2=0.8898\n",
      "Validation Error: Avg loss: 429.104065 \n",
      "\n",
      "2023-11-08 13:27:35.740220 Epoch 1139, Training loss 118.41732788085938\n",
      "R2 values 0.9468, 0.8500, 0.8766; mean R2=0.8912\n",
      "Validation Error: Avg loss: 483.300171 \n",
      "\n",
      "2023-11-08 13:27:36.225640 Epoch 1140, Training loss 145.50119018554688\n",
      "R2 values 0.9518, 0.8148, 0.8785; mean R2=0.8817\n",
      "Validation Error: Avg loss: 514.377258 \n",
      "\n",
      "2023-11-08 13:27:36.723763 Epoch 1141, Training loss 101.77652740478516\n",
      "R2 values 0.9525, 0.8088, 0.9010; mean R2=0.8874\n",
      "Validation Error: Avg loss: 428.243683 \n",
      "\n",
      "2023-11-08 13:27:37.212204 Epoch 1142, Training loss 103.37970733642578\n",
      "R2 values 0.9534, 0.7910, 0.8783; mean R2=0.8743\n",
      "Validation Error: Avg loss: 443.926971 \n",
      "\n",
      "2023-11-08 13:27:37.843909 Epoch 1143, Training loss 128.72265625\n",
      "R2 values 0.9493, 0.8372, 0.8959; mean R2=0.8941\n",
      "Validation Error: Avg loss: 416.183594 \n",
      "\n",
      "2023-11-08 13:27:38.323086 Epoch 1144, Training loss 125.42306518554688\n",
      "R2 values 0.9559, 0.8065, 0.8966; mean R2=0.8863\n",
      "Validation Error: Avg loss: 400.503693 \n",
      "\n",
      "2023-11-08 13:27:38.826260 Epoch 1145, Training loss 96.72769165039062\n",
      "R2 values 0.9539, 0.7671, 0.8651; mean R2=0.8620\n",
      "Validation Error: Avg loss: 441.729126 \n",
      "\n",
      "2023-11-08 13:27:39.329213 Epoch 1146, Training loss 125.95272827148438\n",
      "R2 values 0.9537, 0.8162, 0.8930; mean R2=0.8876\n",
      "Validation Error: Avg loss: 438.290009 \n",
      "\n",
      "2023-11-08 13:27:39.842859 Epoch 1147, Training loss 114.73352813720703\n",
      "R2 values 0.9683, 0.8286, 0.8974; mean R2=0.8981\n",
      "Validation Error: Avg loss: 333.886230 \n",
      "\n",
      "2023-11-08 13:27:40.323674 Epoch 1148, Training loss 88.32795715332031\n",
      "R2 values 0.9589, 0.8322, 0.8994; mean R2=0.8969\n",
      "Validation Error: Avg loss: 360.550476 \n",
      "\n",
      "2023-11-08 13:27:40.801153 Epoch 1149, Training loss 104.67961883544922\n",
      "R2 values 0.9529, 0.8333, 0.8657; mean R2=0.8839\n",
      "Validation Error: Avg loss: 424.717224 \n",
      "\n",
      "2023-11-08 13:27:41.283003 Epoch 1150, Training loss 91.18736267089844\n",
      "R2 values 0.9475, 0.8511, 0.8809; mean R2=0.8932\n",
      "Validation Error: Avg loss: 436.201019 \n",
      "\n",
      "2023-11-08 13:27:41.767229 Epoch 1151, Training loss 118.12957763671875\n",
      "R2 values 0.9394, 0.8229, 0.8744; mean R2=0.8789\n",
      "Validation Error: Avg loss: 494.174774 \n",
      "\n",
      "2023-11-08 13:27:42.284367 Epoch 1152, Training loss 142.59532165527344\n",
      "R2 values 0.9471, 0.8506, 0.8863; mean R2=0.8947\n",
      "Validation Error: Avg loss: 514.041260 \n",
      "\n",
      "2023-11-08 13:27:42.762133 Epoch 1153, Training loss 91.69377136230469\n",
      "R2 values 0.9466, 0.8645, 0.8800; mean R2=0.8970\n",
      "Validation Error: Avg loss: 507.170532 \n",
      "\n",
      "2023-11-08 13:27:43.229738 Epoch 1154, Training loss 101.01455688476562\n",
      "R2 values 0.9598, 0.8115, 0.9149; mean R2=0.8954\n",
      "Validation Error: Avg loss: 401.405060 \n",
      "\n",
      "2023-11-08 13:27:43.716107 Epoch 1155, Training loss 97.44992065429688\n",
      "R2 values 0.9681, 0.8525, 0.8984; mean R2=0.9063\n",
      "Validation Error: Avg loss: 300.698822 \n",
      "\n",
      "2023-11-08 13:27:44.217129 Epoch 1156, Training loss 116.4122085571289\n",
      "R2 values 0.9570, 0.8496, 0.8999; mean R2=0.9022\n",
      "Validation Error: Avg loss: 447.655792 \n",
      "\n",
      "2023-11-08 13:27:44.703380 Epoch 1157, Training loss 110.56778717041016\n",
      "R2 values 0.9604, 0.8070, 0.9030; mean R2=0.8901\n",
      "Validation Error: Avg loss: 392.801636 \n",
      "\n",
      "2023-11-08 13:27:45.188050 Epoch 1158, Training loss 99.54939270019531\n",
      "R2 values 0.9462, 0.8419, 0.8662; mean R2=0.8848\n",
      "Validation Error: Avg loss: 485.369812 \n",
      "\n",
      "2023-11-08 13:27:45.681225 Epoch 1159, Training loss 123.3222427368164\n",
      "R2 values 0.9467, 0.8279, 0.9027; mean R2=0.8924\n",
      "Validation Error: Avg loss: 456.581024 \n",
      "\n",
      "2023-11-08 13:27:46.221683 Epoch 1160, Training loss 102.33647918701172\n",
      "R2 values 0.9386, 0.8330, 0.8956; mean R2=0.8891\n",
      "Validation Error: Avg loss: 486.061310 \n",
      "\n",
      "2023-11-08 13:27:46.710268 Epoch 1161, Training loss 135.5727081298828\n",
      "R2 values 0.9505, 0.8471, 0.8620; mean R2=0.8866\n",
      "Validation Error: Avg loss: 432.759369 \n",
      "\n",
      "2023-11-08 13:27:47.188401 Epoch 1162, Training loss 105.51383972167969\n",
      "R2 values 0.9456, 0.8425, 0.9092; mean R2=0.8991\n",
      "Validation Error: Avg loss: 515.896851 \n",
      "\n",
      "2023-11-08 13:27:47.662456 Epoch 1163, Training loss 83.52437591552734\n",
      "R2 values 0.9615, 0.7682, 0.8726; mean R2=0.8674\n",
      "Validation Error: Avg loss: 571.360046 \n",
      "\n",
      "2023-11-08 13:27:48.148778 Epoch 1164, Training loss 165.9053955078125\n",
      "R2 values 0.9567, 0.8354, 0.8805; mean R2=0.8909\n",
      "Validation Error: Avg loss: 490.407410 \n",
      "\n",
      "2023-11-08 13:27:48.656809 Epoch 1165, Training loss 110.24868774414062\n",
      "R2 values 0.9561, 0.8127, 0.8894; mean R2=0.8861\n",
      "Validation Error: Avg loss: 375.304504 \n",
      "\n",
      "2023-11-08 13:27:49.174966 Epoch 1166, Training loss 175.19439697265625\n",
      "R2 values 0.9638, 0.8480, 0.8908; mean R2=0.9009\n",
      "Validation Error: Avg loss: 311.860260 \n",
      "\n",
      "2023-11-08 13:27:49.679687 Epoch 1167, Training loss 96.64362335205078\n",
      "R2 values 0.9638, 0.8151, 0.8935; mean R2=0.8908\n",
      "Validation Error: Avg loss: 339.987701 \n",
      "\n",
      "2023-11-08 13:27:50.178555 Epoch 1168, Training loss 90.5673828125\n",
      "R2 values 0.9458, 0.8512, 0.8820; mean R2=0.8930\n",
      "Validation Error: Avg loss: 560.607788 \n",
      "\n",
      "2023-11-08 13:27:50.666363 Epoch 1169, Training loss 102.81808471679688\n",
      "R2 values 0.9551, 0.8555, 0.8850; mean R2=0.8985\n",
      "Validation Error: Avg loss: 434.957947 \n",
      "\n",
      "2023-11-08 13:27:51.148891 Epoch 1170, Training loss 98.71484375\n",
      "R2 values 0.9515, 0.8410, 0.8471; mean R2=0.8799\n",
      "Validation Error: Avg loss: 453.035309 \n",
      "\n",
      "2023-11-08 13:27:51.635304 Epoch 1171, Training loss 104.77616119384766\n",
      "R2 values 0.9429, 0.8460, 0.8972; mean R2=0.8954\n",
      "Validation Error: Avg loss: 433.364136 \n",
      "\n",
      "2023-11-08 13:27:52.120160 Epoch 1172, Training loss 111.84053039550781\n",
      "R2 values 0.9555, 0.8479, 0.8923; mean R2=0.8986\n",
      "Validation Error: Avg loss: 401.958496 \n",
      "\n",
      "2023-11-08 13:27:52.601623 Epoch 1173, Training loss 99.70197296142578\n",
      "R2 values 0.9464, 0.8310, 0.8803; mean R2=0.8859\n",
      "Validation Error: Avg loss: 598.265503 \n",
      "\n",
      "2023-11-08 13:27:53.074651 Epoch 1174, Training loss 105.01016998291016\n",
      "R2 values 0.9551, 0.8485, 0.8739; mean R2=0.8925\n",
      "Validation Error: Avg loss: 440.129242 \n",
      "\n",
      "2023-11-08 13:27:53.563838 Epoch 1175, Training loss 126.08238983154297\n",
      "R2 values 0.9469, 0.8079, 0.8472; mean R2=0.8673\n",
      "Validation Error: Avg loss: 525.687317 \n",
      "\n",
      "2023-11-08 13:27:54.045279 Epoch 1176, Training loss 133.17764282226562\n",
      "R2 values 0.9507, 0.8469, 0.8853; mean R2=0.8943\n",
      "Validation Error: Avg loss: 439.873413 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:27:54.526886 Epoch 1177, Training loss 141.90713500976562\n",
      "R2 values 0.9524, 0.8413, 0.8560; mean R2=0.8832\n",
      "Validation Error: Avg loss: 417.053558 \n",
      "\n",
      "2023-11-08 13:27:55.178215 Epoch 1178, Training loss 109.77486419677734\n",
      "R2 values 0.9514, 0.8454, 0.9005; mean R2=0.8991\n",
      "Validation Error: Avg loss: 555.744995 \n",
      "\n",
      "2023-11-08 13:27:55.765003 Epoch 1179, Training loss 172.70909118652344\n",
      "R2 values 0.9586, 0.8424, 0.8797; mean R2=0.8936\n",
      "Validation Error: Avg loss: 383.608429 \n",
      "\n",
      "2023-11-08 13:27:56.247330 Epoch 1180, Training loss 112.43806457519531\n",
      "R2 values 0.9452, 0.8325, 0.8877; mean R2=0.8884\n",
      "Validation Error: Avg loss: 498.555969 \n",
      "\n",
      "2023-11-08 13:27:56.728807 Epoch 1181, Training loss 171.07150268554688\n",
      "R2 values 0.9508, 0.8289, 0.8804; mean R2=0.8867\n",
      "Validation Error: Avg loss: 467.115723 \n",
      "\n",
      "2023-11-08 13:27:57.199363 Epoch 1182, Training loss 145.19590759277344\n",
      "R2 values 0.9548, 0.8610, 0.8640; mean R2=0.8933\n",
      "Validation Error: Avg loss: 559.586304 \n",
      "\n",
      "2023-11-08 13:27:57.681913 Epoch 1183, Training loss 120.6634521484375\n",
      "R2 values 0.9430, 0.8897, 0.8959; mean R2=0.9095\n",
      "Validation Error: Avg loss: 767.026550 \n",
      "\n",
      "2023-11-08 13:27:58.178933 Epoch 1184, Training loss 245.84320068359375\n",
      "R2 values 0.9544, 0.8214, 0.8802; mean R2=0.8853\n",
      "Validation Error: Avg loss: 428.207642 \n",
      "\n",
      "2023-11-08 13:27:58.670764 Epoch 1185, Training loss 96.32562255859375\n",
      "R2 values 0.9569, 0.8230, 0.8776; mean R2=0.8858\n",
      "Validation Error: Avg loss: 427.878296 \n",
      "\n",
      "2023-11-08 13:27:59.173051 Epoch 1186, Training loss 247.21197509765625\n",
      "R2 values 0.9340, 0.8326, 0.9130; mean R2=0.8932\n",
      "Validation Error: Avg loss: 521.706177 \n",
      "\n",
      "2023-11-08 13:27:59.686501 Epoch 1187, Training loss 93.73819732666016\n",
      "R2 values 0.9468, 0.8030, 0.8773; mean R2=0.8757\n",
      "Validation Error: Avg loss: 709.492371 \n",
      "\n",
      "2023-11-08 13:28:00.164025 Epoch 1188, Training loss 116.90516662597656\n",
      "R2 values 0.9518, 0.8226, 0.8825; mean R2=0.8856\n",
      "Validation Error: Avg loss: 702.623413 \n",
      "\n",
      "2023-11-08 13:28:00.647180 Epoch 1189, Training loss 252.43203735351562\n",
      "R2 values 0.9559, 0.8411, 0.8374; mean R2=0.8782\n",
      "Validation Error: Avg loss: 393.342041 \n",
      "\n",
      "2023-11-08 13:28:01.132086 Epoch 1190, Training loss 143.35633850097656\n",
      "R2 values 0.9476, 0.8290, 0.8713; mean R2=0.8826\n",
      "Validation Error: Avg loss: 443.460815 \n",
      "\n",
      "2023-11-08 13:28:01.620337 Epoch 1191, Training loss 197.3041229248047\n",
      "R2 values 0.9497, 0.8250, 0.8726; mean R2=0.8824\n",
      "Validation Error: Avg loss: 434.992920 \n",
      "\n",
      "2023-11-08 13:28:02.167915 Epoch 1192, Training loss 130.32421875\n",
      "R2 values 0.9602, 0.7870, 0.8989; mean R2=0.8820\n",
      "Validation Error: Avg loss: 572.146606 \n",
      "\n",
      "2023-11-08 13:28:02.650446 Epoch 1193, Training loss 132.6812286376953\n",
      "R2 values 0.9531, 0.8036, 0.8739; mean R2=0.8769\n",
      "Validation Error: Avg loss: 604.046265 \n",
      "\n",
      "2023-11-08 13:28:03.122785 Epoch 1194, Training loss 179.64569091796875\n",
      "R2 values 0.9597, 0.8284, 0.8823; mean R2=0.8902\n",
      "Validation Error: Avg loss: 401.164795 \n",
      "\n",
      "2023-11-08 13:28:03.604777 Epoch 1195, Training loss 138.4585723876953\n",
      "R2 values 0.9625, 0.8152, 0.8823; mean R2=0.8867\n",
      "Validation Error: Avg loss: 360.146851 \n",
      "\n",
      "2023-11-08 13:28:04.089348 Epoch 1196, Training loss 147.66258239746094\n",
      "R2 values 0.9473, 0.8422, 0.8837; mean R2=0.8910\n",
      "Validation Error: Avg loss: 470.694733 \n",
      "\n",
      "2023-11-08 13:28:04.634390 Epoch 1197, Training loss 114.68854522705078\n",
      "R2 values 0.9442, 0.8237, 0.8923; mean R2=0.8868\n",
      "Validation Error: Avg loss: 521.856323 \n",
      "\n",
      "2023-11-08 13:28:05.159521 Epoch 1198, Training loss 125.5853500366211\n",
      "R2 values 0.9528, 0.8355, 0.8669; mean R2=0.8851\n",
      "Validation Error: Avg loss: 473.829346 \n",
      "\n",
      "2023-11-08 13:28:05.641486 Epoch 1199, Training loss 136.47564697265625\n",
      "R2 values 0.9577, 0.8468, 0.8519; mean R2=0.8854\n",
      "Validation Error: Avg loss: 404.826691 \n",
      "\n",
      "2023-11-08 13:28:06.145647 Epoch 1200, Training loss 90.1840591430664\n",
      "R2 values 0.9512, 0.8429, 0.8857; mean R2=0.8933\n",
      "Validation Error: Avg loss: 442.015167 \n",
      "\n",
      "2023-11-08 13:28:06.632882 Epoch 1201, Training loss 166.67897033691406\n",
      "R2 values 0.9518, 0.8562, 0.8914; mean R2=0.8998\n",
      "Validation Error: Avg loss: 457.006073 \n",
      "\n",
      "2023-11-08 13:28:07.112229 Epoch 1202, Training loss 107.66992950439453\n",
      "R2 values 0.9529, 0.8756, 0.8727; mean R2=0.9004\n",
      "Validation Error: Avg loss: 662.473206 \n",
      "\n",
      "2023-11-08 13:28:07.598459 Epoch 1203, Training loss 131.8482666015625\n",
      "R2 values 0.9545, 0.8537, 0.8716; mean R2=0.8932\n",
      "Validation Error: Avg loss: 494.706787 \n",
      "\n",
      "2023-11-08 13:28:08.089334 Epoch 1204, Training loss 129.72872924804688\n",
      "R2 values 0.9441, 0.8557, 0.8807; mean R2=0.8935\n",
      "Validation Error: Avg loss: 470.693787 \n",
      "\n",
      "2023-11-08 13:28:08.579274 Epoch 1205, Training loss 159.15284729003906\n",
      "R2 values 0.9539, 0.8373, 0.8847; mean R2=0.8920\n",
      "Validation Error: Avg loss: 390.216827 \n",
      "\n",
      "2023-11-08 13:28:09.079144 Epoch 1206, Training loss 163.0240020751953\n",
      "R2 values 0.9536, 0.8342, 0.8982; mean R2=0.8953\n",
      "Validation Error: Avg loss: 385.035278 \n",
      "\n",
      "2023-11-08 13:28:09.565619 Epoch 1207, Training loss 126.94981384277344\n",
      "R2 values 0.9445, 0.8552, 0.9164; mean R2=0.9054\n",
      "Validation Error: Avg loss: 514.648804 \n",
      "\n",
      "2023-11-08 13:28:10.053574 Epoch 1208, Training loss 140.44000244140625\n",
      "R2 values 0.9433, 0.8149, 0.8813; mean R2=0.8798\n",
      "Validation Error: Avg loss: 472.039093 \n",
      "\n",
      "2023-11-08 13:28:10.523471 Epoch 1209, Training loss 113.15652465820312\n",
      "R2 values 0.9334, 0.8484, 0.8839; mean R2=0.8886\n",
      "Validation Error: Avg loss: 560.755188 \n",
      "\n",
      "2023-11-08 13:28:11.015990 Epoch 1210, Training loss 135.13372802734375\n",
      "R2 values 0.9470, 0.8328, 0.8948; mean R2=0.8916\n",
      "Validation Error: Avg loss: 431.004089 \n",
      "\n",
      "2023-11-08 13:28:11.506843 Epoch 1211, Training loss 167.19398498535156\n",
      "R2 values 0.9396, 0.7878, 0.9113; mean R2=0.8796\n",
      "Validation Error: Avg loss: 525.423889 \n",
      "\n",
      "2023-11-08 13:28:11.982571 Epoch 1212, Training loss 125.68508911132812\n",
      "R2 values 0.9448, 0.8614, 0.8940; mean R2=0.9001\n",
      "Validation Error: Avg loss: 620.751648 \n",
      "\n",
      "2023-11-08 13:28:12.458746 Epoch 1213, Training loss 93.93083190917969\n",
      "R2 values 0.9433, 0.8322, 0.8457; mean R2=0.8737\n",
      "Validation Error: Avg loss: 640.901733 \n",
      "\n",
      "2023-11-08 13:28:12.942132 Epoch 1214, Training loss 115.8620376586914\n",
      "R2 values 0.9556, 0.8056, 0.8860; mean R2=0.8824\n",
      "Validation Error: Avg loss: 431.294586 \n",
      "\n",
      "2023-11-08 13:28:13.471960 Epoch 1215, Training loss 111.83589172363281\n",
      "R2 values 0.9459, 0.7998, 0.8469; mean R2=0.8642\n",
      "Validation Error: Avg loss: 473.081085 \n",
      "\n",
      "2023-11-08 13:28:13.965905 Epoch 1216, Training loss 146.57562255859375\n",
      "R2 values 0.9442, 0.8357, 0.8937; mean R2=0.8912\n",
      "Validation Error: Avg loss: 451.446136 \n",
      "\n",
      "2023-11-08 13:28:14.445647 Epoch 1217, Training loss 130.99209594726562\n",
      "R2 values 0.9487, 0.8400, 0.8928; mean R2=0.8939\n",
      "Validation Error: Avg loss: 553.263794 \n",
      "\n",
      "2023-11-08 13:28:14.946695 Epoch 1218, Training loss 132.2174835205078\n",
      "R2 values 0.9514, 0.8382, 0.9031; mean R2=0.8976\n",
      "Validation Error: Avg loss: 508.513306 \n",
      "\n",
      "2023-11-08 13:28:15.425819 Epoch 1219, Training loss 114.68891143798828\n",
      "R2 values 0.9533, 0.7928, 0.8912; mean R2=0.8791\n",
      "Validation Error: Avg loss: 416.882904 \n",
      "\n",
      "2023-11-08 13:28:15.916384 Epoch 1220, Training loss 122.69892120361328\n",
      "R2 values 0.9466, 0.8677, 0.8947; mean R2=0.9030\n",
      "Validation Error: Avg loss: 433.953339 \n",
      "\n",
      "2023-11-08 13:28:16.415780 Epoch 1221, Training loss 129.23670959472656\n",
      "R2 values 0.9517, 0.8232, 0.8916; mean R2=0.8888\n",
      "Validation Error: Avg loss: 454.758545 \n",
      "\n",
      "2023-11-08 13:28:16.908637 Epoch 1222, Training loss 113.38705444335938\n",
      "R2 values 0.9583, 0.8431, 0.8564; mean R2=0.8859\n",
      "Validation Error: Avg loss: 475.444427 \n",
      "\n",
      "2023-11-08 13:28:17.390524 Epoch 1223, Training loss 87.16459655761719\n",
      "R2 values 0.9579, 0.8525, 0.8771; mean R2=0.8958\n",
      "Validation Error: Avg loss: 389.853943 \n",
      "\n",
      "2023-11-08 13:28:17.865552 Epoch 1224, Training loss 100.89312744140625\n",
      "R2 values 0.9431, 0.8067, 0.8762; mean R2=0.8753\n",
      "Validation Error: Avg loss: 463.022583 \n",
      "\n",
      "2023-11-08 13:28:18.359234 Epoch 1225, Training loss 92.69845581054688\n",
      "R2 values 0.9625, 0.8083, 0.8571; mean R2=0.8760\n",
      "Validation Error: Avg loss: 374.969330 \n",
      "\n",
      "2023-11-08 13:28:18.843929 Epoch 1226, Training loss 95.89156341552734\n",
      "R2 values 0.9568, 0.8048, 0.8852; mean R2=0.8823\n",
      "Validation Error: Avg loss: 396.334930 \n",
      "\n",
      "2023-11-08 13:28:19.333668 Epoch 1227, Training loss 103.96003723144531\n",
      "R2 values 0.9418, 0.8184, 0.8502; mean R2=0.8702\n",
      "Validation Error: Avg loss: 511.242523 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:28:19.816398 Epoch 1228, Training loss 117.64961242675781\n",
      "R2 values 0.9560, 0.8280, 0.8654; mean R2=0.8831\n",
      "Validation Error: Avg loss: 389.025848 \n",
      "\n",
      "2023-11-08 13:28:20.509960 Epoch 1229, Training loss 91.77079772949219\n",
      "R2 values 0.9429, 0.8265, 0.8907; mean R2=0.8867\n",
      "Validation Error: Avg loss: 482.412140 \n",
      "\n",
      "2023-11-08 13:28:21.058365 Epoch 1230, Training loss 155.82530212402344\n",
      "R2 values 0.9506, 0.8234, 0.8914; mean R2=0.8884\n",
      "Validation Error: Avg loss: 411.839905 \n",
      "\n",
      "2023-11-08 13:28:21.539196 Epoch 1231, Training loss 76.07129669189453\n",
      "R2 values 0.9359, 0.8045, 0.8893; mean R2=0.8766\n",
      "Validation Error: Avg loss: 559.807739 \n",
      "\n",
      "2023-11-08 13:28:22.019861 Epoch 1232, Training loss 129.48423767089844\n",
      "R2 values 0.9411, 0.8547, 0.8753; mean R2=0.8904\n",
      "Validation Error: Avg loss: 510.201385 \n",
      "\n",
      "2023-11-08 13:28:22.494097 Epoch 1233, Training loss 131.24276733398438\n",
      "R2 values 0.9419, 0.8249, 0.8867; mean R2=0.8845\n",
      "Validation Error: Avg loss: 597.735046 \n",
      "\n",
      "2023-11-08 13:28:22.972122 Epoch 1234, Training loss 102.72544860839844\n",
      "R2 values 0.9427, 0.8461, 0.9045; mean R2=0.8978\n",
      "Validation Error: Avg loss: 621.012634 \n",
      "\n",
      "2023-11-08 13:28:23.443303 Epoch 1235, Training loss 152.53994750976562\n",
      "R2 values 0.9372, 0.8501, 0.9040; mean R2=0.8971\n",
      "Validation Error: Avg loss: 534.097168 \n",
      "\n",
      "2023-11-08 13:28:23.942785 Epoch 1236, Training loss 134.53616333007812\n",
      "R2 values 0.9526, 0.8364, 0.8776; mean R2=0.8889\n",
      "Validation Error: Avg loss: 417.885345 \n",
      "\n",
      "2023-11-08 13:28:24.421290 Epoch 1237, Training loss 156.3021697998047\n",
      "R2 values 0.9541, 0.8456, 0.8671; mean R2=0.8889\n",
      "Validation Error: Avg loss: 399.202484 \n",
      "\n",
      "2023-11-08 13:28:24.906388 Epoch 1238, Training loss 127.54937744140625\n",
      "R2 values 0.9441, 0.8275, 0.8895; mean R2=0.8870\n",
      "Validation Error: Avg loss: 483.855194 \n",
      "\n",
      "2023-11-08 13:28:25.386381 Epoch 1239, Training loss 142.64547729492188\n",
      "R2 values 0.9475, 0.8362, 0.8626; mean R2=0.8821\n",
      "Validation Error: Avg loss: 513.708679 \n",
      "\n",
      "2023-11-08 13:28:25.861997 Epoch 1240, Training loss 113.13470458984375\n",
      "R2 values 0.9453, 0.8468, 0.8876; mean R2=0.8932\n",
      "Validation Error: Avg loss: 507.886322 \n",
      "\n",
      "2023-11-08 13:28:26.332079 Epoch 1241, Training loss 132.8957977294922\n",
      "R2 values 0.9460, 0.8277, 0.9166; mean R2=0.8968\n",
      "Validation Error: Avg loss: 431.334961 \n",
      "\n",
      "2023-11-08 13:28:26.802979 Epoch 1242, Training loss 171.99668884277344\n",
      "R2 values 0.9455, 0.8369, 0.9108; mean R2=0.8977\n",
      "Validation Error: Avg loss: 521.095459 \n",
      "\n",
      "2023-11-08 13:28:27.309827 Epoch 1243, Training loss 116.46733093261719\n",
      "R2 values 0.9555, 0.8095, 0.8761; mean R2=0.8804\n",
      "Validation Error: Avg loss: 429.256958 \n",
      "\n",
      "2023-11-08 13:28:27.787244 Epoch 1244, Training loss 164.59815979003906\n",
      "R2 values 0.9526, 0.8718, 0.8833; mean R2=0.9026\n",
      "Validation Error: Avg loss: 428.252045 \n",
      "\n",
      "2023-11-08 13:28:28.266180 Epoch 1245, Training loss 148.59251403808594\n",
      "R2 values 0.9572, 0.8132, 0.8825; mean R2=0.8843\n",
      "Validation Error: Avg loss: 365.348907 \n",
      "\n",
      "2023-11-08 13:28:28.740725 Epoch 1246, Training loss 121.37445831298828\n",
      "R2 values 0.9316, 0.8371, 0.8717; mean R2=0.8801\n",
      "Validation Error: Avg loss: 529.892944 \n",
      "\n",
      "2023-11-08 13:28:29.233735 Epoch 1247, Training loss 152.3196563720703\n",
      "R2 values 0.9365, 0.8542, 0.8989; mean R2=0.8965\n",
      "Validation Error: Avg loss: 525.604553 \n",
      "\n",
      "2023-11-08 13:28:29.944956 Epoch 1248, Training loss 141.7057342529297\n",
      "R2 values 0.9591, 0.8101, 0.9029; mean R2=0.8907\n",
      "Validation Error: Avg loss: 551.738892 \n",
      "\n",
      "2023-11-08 13:28:30.447514 Epoch 1249, Training loss 141.93699645996094\n",
      "R2 values 0.9553, 0.8061, 0.8939; mean R2=0.8851\n",
      "Validation Error: Avg loss: 537.823486 \n",
      "\n",
      "2023-11-08 13:28:30.938248 Epoch 1250, Training loss 156.96266174316406\n",
      "R2 values 0.9354, 0.8292, 0.8771; mean R2=0.8806\n",
      "Validation Error: Avg loss: 502.804016 \n",
      "\n",
      "2023-11-08 13:28:31.407326 Epoch 1251, Training loss 128.5400390625\n",
      "R2 values 0.9523, 0.8542, 0.8762; mean R2=0.8942\n",
      "Validation Error: Avg loss: 390.367249 \n",
      "\n",
      "2023-11-08 13:28:31.884966 Epoch 1252, Training loss 132.40557861328125\n",
      "R2 values 0.9394, 0.8463, 0.8734; mean R2=0.8864\n",
      "Validation Error: Avg loss: 499.623413 \n",
      "\n",
      "2023-11-08 13:28:32.355170 Epoch 1253, Training loss 139.29676818847656\n",
      "R2 values 0.9357, 0.8377, 0.8578; mean R2=0.8771\n",
      "Validation Error: Avg loss: 679.114990 \n",
      "\n",
      "2023-11-08 13:28:32.869967 Epoch 1254, Training loss 124.9306411743164\n",
      "R2 values 0.9501, 0.8359, 0.8612; mean R2=0.8824\n",
      "Validation Error: Avg loss: 541.638428 \n",
      "\n",
      "2023-11-08 13:28:33.333111 Epoch 1255, Training loss 97.35791015625\n",
      "R2 values 0.9465, 0.8301, 0.8771; mean R2=0.8846\n",
      "Validation Error: Avg loss: 489.870270 \n",
      "\n",
      "2023-11-08 13:28:33.810935 Epoch 1256, Training loss 93.27311706542969\n",
      "R2 values 0.9531, 0.8148, 0.8953; mean R2=0.8877\n",
      "Validation Error: Avg loss: 443.137054 \n",
      "\n",
      "2023-11-08 13:28:34.312876 Epoch 1257, Training loss 137.2237548828125\n",
      "R2 values 0.9451, 0.8467, 0.8917; mean R2=0.8945\n",
      "Validation Error: Avg loss: 507.390350 \n",
      "\n",
      "2023-11-08 13:28:34.789565 Epoch 1258, Training loss 100.08834075927734\n",
      "R2 values 0.9420, 0.8547, 0.8900; mean R2=0.8956\n",
      "Validation Error: Avg loss: 614.173523 \n",
      "\n",
      "2023-11-08 13:28:35.262406 Epoch 1259, Training loss 112.29656219482422\n",
      "R2 values 0.9491, 0.8373, 0.8746; mean R2=0.8870\n",
      "Validation Error: Avg loss: 473.369690 \n",
      "\n",
      "2023-11-08 13:28:35.743753 Epoch 1260, Training loss 101.2151870727539\n",
      "R2 values 0.9391, 0.8183, 0.8762; mean R2=0.8779\n",
      "Validation Error: Avg loss: 500.206116 \n",
      "\n",
      "2023-11-08 13:28:36.229565 Epoch 1261, Training loss 135.34873962402344\n",
      "R2 values 0.9550, 0.8338, 0.9073; mean R2=0.8987\n",
      "Validation Error: Avg loss: 382.804962 \n",
      "\n",
      "2023-11-08 13:28:36.710587 Epoch 1262, Training loss 94.68158721923828\n",
      "R2 values 0.9532, 0.8049, 0.8753; mean R2=0.8778\n",
      "Validation Error: Avg loss: 426.333557 \n",
      "\n",
      "2023-11-08 13:28:37.186170 Epoch 1263, Training loss 112.51646423339844\n",
      "R2 values 0.9498, 0.8287, 0.9186; mean R2=0.8990\n",
      "Validation Error: Avg loss: 437.360626 \n",
      "\n",
      "2023-11-08 13:28:37.660886 Epoch 1264, Training loss 112.05268096923828\n",
      "R2 values 0.9671, 0.8389, 0.8791; mean R2=0.8950\n",
      "Validation Error: Avg loss: 433.573151 \n",
      "\n",
      "2023-11-08 13:28:38.148273 Epoch 1265, Training loss 82.16338348388672\n",
      "R2 values 0.9572, 0.8004, 0.8704; mean R2=0.8760\n",
      "Validation Error: Avg loss: 423.353455 \n",
      "\n",
      "2023-11-08 13:28:38.632508 Epoch 1266, Training loss 120.86487579345703\n",
      "R2 values 0.9514, 0.8345, 0.8419; mean R2=0.8759\n",
      "Validation Error: Avg loss: 486.932373 \n",
      "\n",
      "2023-11-08 13:28:39.122879 Epoch 1267, Training loss 92.9268798828125\n",
      "R2 values 0.9471, 0.8210, 0.9044; mean R2=0.8908\n",
      "Validation Error: Avg loss: 425.022003 \n",
      "\n",
      "2023-11-08 13:28:39.598035 Epoch 1268, Training loss 81.92576599121094\n",
      "R2 values 0.9529, 0.7805, 0.9007; mean R2=0.8780\n",
      "Validation Error: Avg loss: 437.493164 \n",
      "\n",
      "2023-11-08 13:28:40.077874 Epoch 1269, Training loss 83.19973754882812\n",
      "R2 values 0.9622, 0.8271, 0.9091; mean R2=0.8995\n",
      "Validation Error: Avg loss: 378.547974 \n",
      "\n",
      "2023-11-08 13:28:40.548632 Epoch 1270, Training loss 122.148681640625\n",
      "R2 values 0.9564, 0.7989, 0.8769; mean R2=0.8774\n",
      "Validation Error: Avg loss: 430.592682 \n",
      "\n",
      "2023-11-08 13:28:41.016935 Epoch 1271, Training loss 111.25336456298828\n",
      "R2 values 0.9511, 0.8208, 0.8544; mean R2=0.8754\n",
      "Validation Error: Avg loss: 480.159241 \n",
      "\n",
      "2023-11-08 13:28:41.492721 Epoch 1272, Training loss 88.0172119140625\n",
      "R2 values 0.9466, 0.8240, 0.8850; mean R2=0.8852\n",
      "Validation Error: Avg loss: 441.105316 \n",
      "\n",
      "2023-11-08 13:28:41.990665 Epoch 1273, Training loss 79.8284683227539\n",
      "R2 values 0.9571, 0.8216, 0.8766; mean R2=0.8851\n",
      "Validation Error: Avg loss: 437.796844 \n",
      "\n",
      "2023-11-08 13:28:42.461888 Epoch 1274, Training loss 128.9310302734375\n",
      "R2 values 0.9520, 0.8368, 0.8941; mean R2=0.8943\n",
      "Validation Error: Avg loss: 387.543152 \n",
      "\n",
      "2023-11-08 13:28:42.946411 Epoch 1275, Training loss 108.19204711914062\n",
      "R2 values 0.9472, 0.8393, 0.8719; mean R2=0.8861\n",
      "Validation Error: Avg loss: 434.259766 \n",
      "\n",
      "2023-11-08 13:28:43.564225 Epoch 1276, Training loss 108.6129150390625\n",
      "R2 values 0.9593, 0.8505, 0.8787; mean R2=0.8962\n",
      "Validation Error: Avg loss: 433.261200 \n",
      "\n",
      "2023-11-08 13:28:44.054816 Epoch 1277, Training loss 96.73605346679688\n",
      "R2 values 0.9462, 0.8463, 0.8961; mean R2=0.8962\n",
      "Validation Error: Avg loss: 533.902161 \n",
      "\n",
      "2023-11-08 13:28:44.563919 Epoch 1278, Training loss 83.20816040039062\n",
      "R2 values 0.9581, 0.8377, 0.8591; mean R2=0.8849\n",
      "Validation Error: Avg loss: 462.709930 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:28:45.098661 Epoch 1279, Training loss 126.75349426269531\n",
      "R2 values 0.9522, 0.8287, 0.8734; mean R2=0.8847\n",
      "Validation Error: Avg loss: 548.769714 \n",
      "\n",
      "2023-11-08 13:28:45.618077 Epoch 1280, Training loss 108.39622497558594\n",
      "R2 values 0.9587, 0.8548, 0.8983; mean R2=0.9039\n",
      "Validation Error: Avg loss: 430.153809 \n",
      "\n",
      "2023-11-08 13:28:46.100212 Epoch 1281, Training loss 97.77877807617188\n",
      "R2 values 0.9448, 0.8445, 0.8762; mean R2=0.8885\n",
      "Validation Error: Avg loss: 452.026642 \n",
      "\n",
      "2023-11-08 13:28:46.561456 Epoch 1282, Training loss 120.34252166748047\n",
      "R2 values 0.9496, 0.8524, 0.8860; mean R2=0.8960\n",
      "Validation Error: Avg loss: 441.128998 \n",
      "\n",
      "2023-11-08 13:28:47.033179 Epoch 1283, Training loss 138.47483825683594\n",
      "R2 values 0.9540, 0.8367, 0.8979; mean R2=0.8962\n",
      "Validation Error: Avg loss: 476.964111 \n",
      "\n",
      "2023-11-08 13:28:47.511070 Epoch 1284, Training loss 100.67267608642578\n",
      "R2 values 0.9444, 0.8095, 0.9055; mean R2=0.8865\n",
      "Validation Error: Avg loss: 580.970398 \n",
      "\n",
      "2023-11-08 13:28:48.006642 Epoch 1285, Training loss 123.6197509765625\n",
      "R2 values 0.9571, 0.8481, 0.9036; mean R2=0.9029\n",
      "Validation Error: Avg loss: 375.943665 \n",
      "\n",
      "2023-11-08 13:28:48.498796 Epoch 1286, Training loss 99.2962875366211\n",
      "R2 values 0.9556, 0.8504, 0.9002; mean R2=0.9021\n",
      "Validation Error: Avg loss: 361.085754 \n",
      "\n",
      "2023-11-08 13:28:48.992835 Epoch 1287, Training loss 143.59971618652344\n",
      "R2 values 0.9662, 0.8323, 0.9141; mean R2=0.9042\n",
      "Validation Error: Avg loss: 318.349670 \n",
      "\n",
      "2023-11-08 13:28:49.482899 Epoch 1288, Training loss 94.93547821044922\n",
      "R2 values 0.9545, 0.8233, 0.8821; mean R2=0.8866\n",
      "Validation Error: Avg loss: 584.370422 \n",
      "\n",
      "2023-11-08 13:28:49.950430 Epoch 1289, Training loss 163.58334350585938\n",
      "R2 values 0.9431, 0.8101, 0.8700; mean R2=0.8744\n",
      "Validation Error: Avg loss: 571.182190 \n",
      "\n",
      "2023-11-08 13:28:50.558731 Epoch 1290, Training loss 108.9590072631836\n",
      "R2 values 0.9546, 0.8448, 0.8741; mean R2=0.8912\n",
      "Validation Error: Avg loss: 400.325714 \n",
      "\n",
      "2023-11-08 13:28:51.037424 Epoch 1291, Training loss 102.87879180908203\n",
      "R2 values 0.9450, 0.8602, 0.8945; mean R2=0.8999\n",
      "Validation Error: Avg loss: 459.224182 \n",
      "\n",
      "2023-11-08 13:28:51.508430 Epoch 1292, Training loss 124.21027374267578\n",
      "R2 values 0.9484, 0.8236, 0.8762; mean R2=0.8827\n",
      "Validation Error: Avg loss: 531.134583 \n",
      "\n",
      "2023-11-08 13:28:51.984118 Epoch 1293, Training loss 96.49993133544922\n",
      "R2 values 0.9544, 0.8602, 0.8594; mean R2=0.8913\n",
      "Validation Error: Avg loss: 459.424194 \n",
      "\n",
      "2023-11-08 13:28:52.462643 Epoch 1294, Training loss 93.07180786132812\n",
      "R2 values 0.9583, 0.8499, 0.8882; mean R2=0.8988\n",
      "Validation Error: Avg loss: 376.971252 \n",
      "\n",
      "2023-11-08 13:28:52.953898 Epoch 1295, Training loss 78.17753601074219\n",
      "R2 values 0.9519, 0.8526, 0.8989; mean R2=0.9011\n",
      "Validation Error: Avg loss: 413.281952 \n",
      "\n",
      "2023-11-08 13:28:53.424513 Epoch 1296, Training loss 108.10902404785156\n",
      "R2 values 0.9665, 0.8332, 0.8648; mean R2=0.8882\n",
      "Validation Error: Avg loss: 371.004791 \n",
      "\n",
      "2023-11-08 13:28:53.946436 Epoch 1297, Training loss 92.29493713378906\n",
      "R2 values 0.9573, 0.8196, 0.8808; mean R2=0.8859\n",
      "Validation Error: Avg loss: 492.893097 \n",
      "\n",
      "2023-11-08 13:28:54.419439 Epoch 1298, Training loss 120.18106079101562\n",
      "R2 values 0.9494, 0.8145, 0.8693; mean R2=0.8777\n",
      "Validation Error: Avg loss: 467.303040 \n",
      "\n",
      "2023-11-08 13:28:54.891380 Epoch 1299, Training loss 93.6080322265625\n",
      "R2 values 0.9461, 0.8258, 0.8802; mean R2=0.8840\n",
      "Validation Error: Avg loss: 440.741364 \n",
      "\n",
      "2023-11-08 13:28:55.365801 Epoch 1300, Training loss 101.88654327392578\n",
      "R2 values 0.9437, 0.8244, 0.8701; mean R2=0.8794\n",
      "Validation Error: Avg loss: 469.783203 \n",
      "\n",
      "2023-11-08 13:28:55.839812 Epoch 1301, Training loss 84.88816833496094\n",
      "R2 values 0.9304, 0.8686, 0.8788; mean R2=0.8926\n",
      "Validation Error: Avg loss: 575.214478 \n",
      "\n",
      "2023-11-08 13:28:56.321217 Epoch 1302, Training loss 82.86820983886719\n",
      "R2 values 0.9480, 0.7986, 0.8965; mean R2=0.8811\n",
      "Validation Error: Avg loss: 468.175049 \n",
      "\n",
      "2023-11-08 13:28:56.793967 Epoch 1303, Training loss 122.88748931884766\n",
      "R2 values 0.9474, 0.8732, 0.8956; mean R2=0.9054\n",
      "Validation Error: Avg loss: 504.594971 \n",
      "\n",
      "2023-11-08 13:28:57.279078 Epoch 1304, Training loss 108.34738159179688\n",
      "R2 values 0.9452, 0.8487, 0.8846; mean R2=0.8929\n",
      "Validation Error: Avg loss: 473.076294 \n",
      "\n",
      "2023-11-08 13:28:57.754425 Epoch 1305, Training loss 98.83966827392578\n",
      "R2 values 0.9571, 0.8128, 0.8937; mean R2=0.8879\n",
      "Validation Error: Avg loss: 369.359802 \n",
      "\n",
      "2023-11-08 13:28:58.474366 Epoch 1306, Training loss 110.3211669921875\n",
      "R2 values 0.9482, 0.7939, 0.8949; mean R2=0.8790\n",
      "Validation Error: Avg loss: 480.843567 \n",
      "\n",
      "2023-11-08 13:28:59.020138 Epoch 1307, Training loss 98.11642456054688\n",
      "R2 values 0.9533, 0.8236, 0.8527; mean R2=0.8765\n",
      "Validation Error: Avg loss: 552.230713 \n",
      "\n",
      "2023-11-08 13:28:59.506509 Epoch 1308, Training loss 161.9555206298828\n",
      "R2 values 0.9492, 0.8387, 0.8869; mean R2=0.8916\n",
      "Validation Error: Avg loss: 449.123810 \n",
      "\n",
      "2023-11-08 13:28:59.974344 Epoch 1309, Training loss 91.47702026367188\n",
      "R2 values 0.9524, 0.8356, 0.8726; mean R2=0.8869\n",
      "Validation Error: Avg loss: 424.088562 \n",
      "\n",
      "2023-11-08 13:29:00.451173 Epoch 1310, Training loss 125.35366821289062\n",
      "R2 values 0.9473, 0.8179, 0.9113; mean R2=0.8922\n",
      "Validation Error: Avg loss: 434.208801 \n",
      "\n",
      "2023-11-08 13:29:00.931852 Epoch 1311, Training loss 99.74102020263672\n",
      "R2 values 0.9437, 0.8356, 0.8882; mean R2=0.8892\n",
      "Validation Error: Avg loss: 673.134888 \n",
      "\n",
      "2023-11-08 13:29:01.419007 Epoch 1312, Training loss 134.51455688476562\n",
      "R2 values 0.9389, 0.8570, 0.8867; mean R2=0.8942\n",
      "Validation Error: Avg loss: 528.594299 \n",
      "\n",
      "2023-11-08 13:29:01.918392 Epoch 1313, Training loss 116.24466705322266\n",
      "R2 values 0.9512, 0.7995, 0.8757; mean R2=0.8755\n",
      "Validation Error: Avg loss: 458.359375 \n",
      "\n",
      "2023-11-08 13:29:02.392297 Epoch 1314, Training loss 100.7271499633789\n",
      "R2 values 0.9513, 0.7971, 0.8781; mean R2=0.8755\n",
      "Validation Error: Avg loss: 455.064972 \n",
      "\n",
      "2023-11-08 13:29:02.862036 Epoch 1315, Training loss 164.6542205810547\n",
      "R2 values 0.9545, 0.8251, 0.8645; mean R2=0.8813\n",
      "Validation Error: Avg loss: 394.696045 \n",
      "\n",
      "2023-11-08 13:29:03.335530 Epoch 1316, Training loss 125.12444305419922\n",
      "R2 values 0.9514, 0.8227, 0.8940; mean R2=0.8894\n",
      "Validation Error: Avg loss: 465.899841 \n",
      "\n",
      "2023-11-08 13:29:03.815715 Epoch 1317, Training loss 105.2403564453125\n",
      "R2 values 0.9563, 0.8308, 0.8951; mean R2=0.8941\n",
      "Validation Error: Avg loss: 419.364471 \n",
      "\n",
      "2023-11-08 13:29:04.291139 Epoch 1318, Training loss 102.22120666503906\n",
      "R2 values 0.9609, 0.8325, 0.8844; mean R2=0.8926\n",
      "Validation Error: Avg loss: 369.003448 \n",
      "\n",
      "2023-11-08 13:29:04.871273 Epoch 1319, Training loss 135.09620666503906\n",
      "R2 values 0.9539, 0.8097, 0.8452; mean R2=0.8696\n",
      "Validation Error: Avg loss: 437.571838 \n",
      "\n",
      "2023-11-08 13:29:05.347218 Epoch 1320, Training loss 102.93781280517578\n",
      "R2 values 0.9578, 0.8361, 0.9011; mean R2=0.8983\n",
      "Validation Error: Avg loss: 379.232819 \n",
      "\n",
      "2023-11-08 13:29:05.821351 Epoch 1321, Training loss 79.13819885253906\n",
      "R2 values 0.9478, 0.8211, 0.8935; mean R2=0.8875\n",
      "Validation Error: Avg loss: 553.241821 \n",
      "\n",
      "2023-11-08 13:29:06.363610 Epoch 1322, Training loss 145.0988006591797\n",
      "R2 values 0.9606, 0.8240, 0.8856; mean R2=0.8901\n",
      "Validation Error: Avg loss: 351.644928 \n",
      "\n",
      "2023-11-08 13:29:06.843844 Epoch 1323, Training loss 113.14282989501953\n",
      "R2 values 0.9459, 0.8424, 0.9065; mean R2=0.8982\n",
      "Validation Error: Avg loss: 418.583282 \n",
      "\n",
      "2023-11-08 13:29:07.313190 Epoch 1324, Training loss 108.20026397705078\n",
      "R2 values 0.9572, 0.7923, 0.8676; mean R2=0.8724\n",
      "Validation Error: Avg loss: 396.803253 \n",
      "\n",
      "2023-11-08 13:29:07.782364 Epoch 1325, Training loss 93.20988464355469\n",
      "R2 values 0.9572, 0.7787, 0.8719; mean R2=0.8693\n",
      "Validation Error: Avg loss: 409.878387 \n",
      "\n",
      "2023-11-08 13:29:08.253018 Epoch 1326, Training loss 100.07002258300781\n",
      "R2 values 0.9559, 0.7984, 0.8883; mean R2=0.8809\n",
      "Validation Error: Avg loss: 465.106842 \n",
      "\n",
      "2023-11-08 13:29:08.725656 Epoch 1327, Training loss 95.94676208496094\n",
      "R2 values 0.9528, 0.8299, 0.9221; mean R2=0.9016\n",
      "Validation Error: Avg loss: 462.897888 \n",
      "\n",
      "2023-11-08 13:29:09.204829 Epoch 1328, Training loss 117.03803253173828\n",
      "R2 values 0.9553, 0.8573, 0.8950; mean R2=0.9025\n",
      "Validation Error: Avg loss: 397.357422 \n",
      "\n",
      "2023-11-08 13:29:09.695081 Epoch 1329, Training loss 102.42253112792969\n",
      "R2 values 0.9530, 0.8322, 0.9062; mean R2=0.8971\n",
      "Validation Error: Avg loss: 458.621460 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:29:10.181590 Epoch 1330, Training loss 87.12275695800781\n",
      "R2 values 0.9580, 0.8491, 0.9054; mean R2=0.9042\n",
      "Validation Error: Avg loss: 363.549774 \n",
      "\n",
      "2023-11-08 13:29:10.661962 Epoch 1331, Training loss 119.39346313476562\n",
      "R2 values 0.9353, 0.8089, 0.8826; mean R2=0.8756\n",
      "Validation Error: Avg loss: 527.816162 \n",
      "\n",
      "2023-11-08 13:29:11.138017 Epoch 1332, Training loss 96.91350555419922\n",
      "R2 values 0.9356, 0.8669, 0.8709; mean R2=0.8911\n",
      "Validation Error: Avg loss: 545.054443 \n",
      "\n",
      "2023-11-08 13:29:11.622095 Epoch 1333, Training loss 90.42914581298828\n",
      "R2 values 0.9272, 0.8131, 0.8587; mean R2=0.8664\n",
      "Validation Error: Avg loss: 670.858704 \n",
      "\n",
      "2023-11-08 13:29:12.185203 Epoch 1334, Training loss 96.9597396850586\n",
      "R2 values 0.9580, 0.8412, 0.8459; mean R2=0.8817\n",
      "Validation Error: Avg loss: 548.878845 \n",
      "\n",
      "2023-11-08 13:29:12.666508 Epoch 1335, Training loss 96.660888671875\n",
      "R2 values 0.9582, 0.8009, 0.8624; mean R2=0.8738\n",
      "Validation Error: Avg loss: 379.008667 \n",
      "\n",
      "2023-11-08 13:29:13.326633 Epoch 1336, Training loss 84.93173217773438\n",
      "R2 values 0.9557, 0.8190, 0.8366; mean R2=0.8705\n",
      "Validation Error: Avg loss: 389.234497 \n",
      "\n",
      "2023-11-08 13:29:13.812745 Epoch 1337, Training loss 112.23419189453125\n",
      "R2 values 0.9498, 0.8059, 0.8481; mean R2=0.8680\n",
      "Validation Error: Avg loss: 471.018860 \n",
      "\n",
      "2023-11-08 13:29:14.289035 Epoch 1338, Training loss 69.34733581542969\n",
      "R2 values 0.9520, 0.8647, 0.8832; mean R2=0.8999\n",
      "Validation Error: Avg loss: 559.080566 \n",
      "\n",
      "2023-11-08 13:29:14.812666 Epoch 1339, Training loss 93.11898040771484\n",
      "R2 values 0.9539, 0.8153, 0.8960; mean R2=0.8884\n",
      "Validation Error: Avg loss: 532.448059 \n",
      "\n",
      "2023-11-08 13:29:15.284143 Epoch 1340, Training loss 99.25366973876953\n",
      "R2 values 0.9418, 0.8355, 0.9214; mean R2=0.8995\n",
      "Validation Error: Avg loss: 479.147186 \n",
      "\n",
      "2023-11-08 13:29:15.760051 Epoch 1341, Training loss 89.0204086303711\n",
      "R2 values 0.9535, 0.8626, 0.8817; mean R2=0.8993\n",
      "Validation Error: Avg loss: 390.231934 \n",
      "\n",
      "2023-11-08 13:29:16.239655 Epoch 1342, Training loss 145.16427612304688\n",
      "R2 values 0.9515, 0.8211, 0.8984; mean R2=0.8904\n",
      "Validation Error: Avg loss: 416.812653 \n",
      "\n",
      "2023-11-08 13:29:16.713818 Epoch 1343, Training loss 87.29531860351562\n",
      "R2 values 0.9424, 0.8489, 0.9001; mean R2=0.8971\n",
      "Validation Error: Avg loss: 513.360107 \n",
      "\n",
      "2023-11-08 13:29:17.193733 Epoch 1344, Training loss 100.34659576416016\n",
      "R2 values 0.9474, 0.8531, 0.8975; mean R2=0.8993\n",
      "Validation Error: Avg loss: 515.872009 \n",
      "\n",
      "2023-11-08 13:29:17.724714 Epoch 1345, Training loss 79.97654724121094\n",
      "R2 values 0.9528, 0.8162, 0.8981; mean R2=0.8891\n",
      "Validation Error: Avg loss: 478.333710 \n",
      "\n",
      "2023-11-08 13:29:18.205016 Epoch 1346, Training loss 99.94337463378906\n",
      "R2 values 0.9615, 0.8254, 0.8738; mean R2=0.8869\n",
      "Validation Error: Avg loss: 354.444214 \n",
      "\n",
      "2023-11-08 13:29:18.725360 Epoch 1347, Training loss 128.0257110595703\n",
      "R2 values 0.9604, 0.8213, 0.8874; mean R2=0.8897\n",
      "Validation Error: Avg loss: 419.467621 \n",
      "\n",
      "2023-11-08 13:29:19.216113 Epoch 1348, Training loss 91.47999572753906\n",
      "R2 values 0.9569, 0.8179, 0.8857; mean R2=0.8868\n",
      "Validation Error: Avg loss: 542.816711 \n",
      "\n",
      "2023-11-08 13:29:19.710476 Epoch 1349, Training loss 103.53997039794922\n",
      "R2 values 0.9511, 0.8406, 0.8788; mean R2=0.8902\n",
      "Validation Error: Avg loss: 560.919128 \n",
      "\n",
      "2023-11-08 13:29:20.184335 Epoch 1350, Training loss 91.05062103271484\n",
      "R2 values 0.9498, 0.8465, 0.8750; mean R2=0.8904\n",
      "Validation Error: Avg loss: 483.224304 \n",
      "\n",
      "2023-11-08 13:29:20.659709 Epoch 1351, Training loss 91.03946685791016\n",
      "R2 values 0.9565, 0.8377, 0.8687; mean R2=0.8876\n",
      "Validation Error: Avg loss: 400.165405 \n",
      "\n",
      "2023-11-08 13:29:21.135215 Epoch 1352, Training loss 92.89717102050781\n",
      "R2 values 0.9584, 0.8327, 0.8512; mean R2=0.8808\n",
      "Validation Error: Avg loss: 519.291687 \n",
      "\n",
      "2023-11-08 13:29:21.625386 Epoch 1353, Training loss 84.06130981445312\n",
      "R2 values 0.9538, 0.8087, 0.8879; mean R2=0.8835\n",
      "Validation Error: Avg loss: 548.998413 \n",
      "\n",
      "2023-11-08 13:29:22.107550 Epoch 1354, Training loss 116.3024673461914\n",
      "R2 values 0.9389, 0.8613, 0.8914; mean R2=0.8972\n",
      "Validation Error: Avg loss: 548.750854 \n",
      "\n",
      "2023-11-08 13:29:22.592973 Epoch 1355, Training loss 121.00255584716797\n",
      "R2 values 0.9502, 0.8934, 0.8743; mean R2=0.9060\n",
      "Validation Error: Avg loss: 422.372986 \n",
      "\n",
      "2023-11-08 13:29:23.086163 Epoch 1356, Training loss 111.46533203125\n",
      "R2 values 0.9520, 0.8737, 0.8902; mean R2=0.9053\n",
      "Validation Error: Avg loss: 438.510864 \n",
      "\n",
      "2023-11-08 13:29:23.557967 Epoch 1357, Training loss 132.30677795410156\n",
      "R2 values 0.9463, 0.8434, 0.9050; mean R2=0.8982\n",
      "Validation Error: Avg loss: 591.623718 \n",
      "\n",
      "2023-11-08 13:29:24.028043 Epoch 1358, Training loss 87.36095428466797\n",
      "R2 values 0.9508, 0.8409, 0.8890; mean R2=0.8936\n",
      "Validation Error: Avg loss: 555.898254 \n",
      "\n",
      "2023-11-08 13:29:24.514641 Epoch 1359, Training loss 133.04910278320312\n",
      "R2 values 0.9507, 0.8557, 0.8931; mean R2=0.8998\n",
      "Validation Error: Avg loss: 420.891083 \n",
      "\n",
      "2023-11-08 13:29:24.989447 Epoch 1360, Training loss 111.6719741821289\n",
      "R2 values 0.9531, 0.8675, 0.9080; mean R2=0.9095\n",
      "Validation Error: Avg loss: 378.343628 \n",
      "\n",
      "2023-11-08 13:29:25.461051 Epoch 1361, Training loss 138.2183380126953\n",
      "R2 values 0.9563, 0.8581, 0.9034; mean R2=0.9060\n",
      "Validation Error: Avg loss: 429.295959 \n",
      "\n",
      "2023-11-08 13:29:25.941967 Epoch 1362, Training loss 88.21845245361328\n",
      "R2 values 0.9486, 0.8341, 0.8944; mean R2=0.8924\n",
      "Validation Error: Avg loss: 576.369019 \n",
      "\n",
      "2023-11-08 13:29:26.414389 Epoch 1363, Training loss 193.92466735839844\n",
      "R2 values 0.9572, 0.8436, 0.8811; mean R2=0.8940\n",
      "Validation Error: Avg loss: 443.298981 \n",
      "\n",
      "2023-11-08 13:29:26.925723 Epoch 1364, Training loss 103.15168762207031\n",
      "R2 values 0.9515, 0.7893, 0.8858; mean R2=0.8755\n",
      "Validation Error: Avg loss: 469.875763 \n",
      "\n",
      "2023-11-08 13:29:27.393283 Epoch 1365, Training loss 193.07147216796875\n",
      "R2 values 0.9481, 0.8092, 0.8724; mean R2=0.8766\n",
      "Validation Error: Avg loss: 448.131836 \n",
      "\n",
      "2023-11-08 13:29:27.870297 Epoch 1366, Training loss 149.25257873535156\n",
      "R2 values 0.9411, 0.8295, 0.8783; mean R2=0.8829\n",
      "Validation Error: Avg loss: 575.832825 \n",
      "\n",
      "2023-11-08 13:29:28.350531 Epoch 1367, Training loss 107.8139419555664\n",
      "R2 values 0.9445, 0.8677, 0.9026; mean R2=0.9049\n",
      "Validation Error: Avg loss: 488.922974 \n",
      "\n",
      "2023-11-08 13:29:28.901113 Epoch 1368, Training loss 118.88827514648438\n",
      "R2 values 0.9419, 0.8500, 0.8990; mean R2=0.8970\n",
      "Validation Error: Avg loss: 477.016052 \n",
      "\n",
      "2023-11-08 13:29:29.384338 Epoch 1369, Training loss 145.97119140625\n",
      "R2 values 0.9563, 0.8537, 0.8865; mean R2=0.8988\n",
      "Validation Error: Avg loss: 390.019196 \n",
      "\n",
      "2023-11-08 13:29:29.871477 Epoch 1370, Training loss 80.92180633544922\n",
      "R2 values 0.9557, 0.8048, 0.8867; mean R2=0.8824\n",
      "Validation Error: Avg loss: 449.113525 \n",
      "\n",
      "2023-11-08 13:29:30.350674 Epoch 1371, Training loss 142.05072021484375\n",
      "R2 values 0.9445, 0.8282, 0.8793; mean R2=0.8840\n",
      "Validation Error: Avg loss: 597.753906 \n",
      "\n",
      "2023-11-08 13:29:30.833086 Epoch 1372, Training loss 118.2357406616211\n",
      "R2 values 0.9480, 0.8611, 0.8763; mean R2=0.8951\n",
      "Validation Error: Avg loss: 491.791229 \n",
      "\n",
      "2023-11-08 13:29:31.316986 Epoch 1373, Training loss 120.579345703125\n",
      "R2 values 0.9387, 0.7912, 0.8668; mean R2=0.8656\n",
      "Validation Error: Avg loss: 507.374634 \n",
      "\n",
      "2023-11-08 13:29:31.802186 Epoch 1374, Training loss 146.2516632080078\n",
      "R2 values 0.9421, 0.8618, 0.9109; mean R2=0.9049\n",
      "Validation Error: Avg loss: 462.869293 \n",
      "\n",
      "2023-11-08 13:29:32.272248 Epoch 1375, Training loss 154.57907104492188\n",
      "R2 values 0.9450, 0.8005, 0.8717; mean R2=0.8724\n",
      "Validation Error: Avg loss: 539.451721 \n",
      "\n",
      "2023-11-08 13:29:32.748291 Epoch 1376, Training loss 104.0741958618164\n",
      "R2 values 0.9531, 0.8587, 0.9056; mean R2=0.9058\n",
      "Validation Error: Avg loss: 449.535828 \n",
      "\n",
      "2023-11-08 13:29:33.225128 Epoch 1377, Training loss 128.4827880859375\n",
      "R2 values 0.9463, 0.8438, 0.8947; mean R2=0.8949\n",
      "Validation Error: Avg loss: 524.405212 \n",
      "\n",
      "2023-11-08 13:29:33.724379 Epoch 1378, Training loss 102.456787109375\n",
      "R2 values 0.9462, 0.8438, 0.9239; mean R2=0.9046\n",
      "Validation Error: Avg loss: 423.838104 \n",
      "\n",
      "2023-11-08 13:29:34.192790 Epoch 1379, Training loss 132.15293884277344\n",
      "R2 values 0.9499, 0.8349, 0.8865; mean R2=0.8905\n",
      "Validation Error: Avg loss: 447.666748 \n",
      "\n",
      "2023-11-08 13:29:34.668700 Epoch 1380, Training loss 111.97635650634766\n",
      "R2 values 0.9496, 0.8327, 0.9105; mean R2=0.8976\n",
      "Validation Error: Avg loss: 551.538147 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:29:35.146389 Epoch 1381, Training loss 163.17031860351562\n",
      "R2 values 0.9393, 0.7998, 0.9097; mean R2=0.8829\n",
      "Validation Error: Avg loss: 613.546082 \n",
      "\n",
      "2023-11-08 13:29:35.627217 Epoch 1382, Training loss 119.7951431274414\n",
      "R2 values 0.9573, 0.8389, 0.8743; mean R2=0.8902\n",
      "Validation Error: Avg loss: 389.363983 \n",
      "\n",
      "2023-11-08 13:29:36.104944 Epoch 1383, Training loss 106.54961395263672\n",
      "R2 values 0.9367, 0.8361, 0.8689; mean R2=0.8806\n",
      "Validation Error: Avg loss: 531.823547 \n",
      "\n",
      "2023-11-08 13:29:36.618584 Epoch 1384, Training loss 102.08402252197266\n",
      "R2 values 0.9433, 0.8520, 0.8719; mean R2=0.8891\n",
      "Validation Error: Avg loss: 492.810059 \n",
      "\n",
      "2023-11-08 13:29:37.106797 Epoch 1385, Training loss 89.15301513671875\n",
      "R2 values 0.9525, 0.8420, 0.9056; mean R2=0.9000\n",
      "Validation Error: Avg loss: 441.489960 \n",
      "\n",
      "2023-11-08 13:29:37.708560 Epoch 1386, Training loss 135.68154907226562\n",
      "R2 values 0.9512, 0.8489, 0.8910; mean R2=0.8970\n",
      "Validation Error: Avg loss: 454.214294 \n",
      "\n",
      "2023-11-08 13:29:38.188686 Epoch 1387, Training loss 128.70208740234375\n",
      "R2 values 0.9387, 0.8117, 0.8823; mean R2=0.8776\n",
      "Validation Error: Avg loss: 529.596558 \n",
      "\n",
      "2023-11-08 13:29:38.667777 Epoch 1388, Training loss 107.82091522216797\n",
      "R2 values 0.9498, 0.8556, 0.8399; mean R2=0.8818\n",
      "Validation Error: Avg loss: 554.151672 \n",
      "\n",
      "2023-11-08 13:29:39.154576 Epoch 1389, Training loss 94.9917984008789\n",
      "R2 values 0.9557, 0.8114, 0.8669; mean R2=0.8780\n",
      "Validation Error: Avg loss: 526.401123 \n",
      "\n",
      "2023-11-08 13:29:39.649478 Epoch 1390, Training loss 120.665283203125\n",
      "R2 values 0.9536, 0.8104, 0.8574; mean R2=0.8738\n",
      "Validation Error: Avg loss: 438.938263 \n",
      "\n",
      "2023-11-08 13:29:40.122411 Epoch 1391, Training loss 105.42205810546875\n",
      "R2 values 0.9548, 0.8435, 0.8735; mean R2=0.8906\n",
      "Validation Error: Avg loss: 393.891876 \n",
      "\n",
      "2023-11-08 13:29:40.598303 Epoch 1392, Training loss 88.34002685546875\n",
      "R2 values 0.9633, 0.8438, 0.8867; mean R2=0.8979\n",
      "Validation Error: Avg loss: 359.092896 \n",
      "\n",
      "2023-11-08 13:29:41.075947 Epoch 1393, Training loss 77.74971008300781\n",
      "R2 values 0.9558, 0.8423, 0.8672; mean R2=0.8884\n",
      "Validation Error: Avg loss: 455.128662 \n",
      "\n",
      "2023-11-08 13:29:41.551661 Epoch 1394, Training loss 68.80681610107422\n",
      "R2 values 0.9580, 0.8334, 0.9114; mean R2=0.9009\n",
      "Validation Error: Avg loss: 401.268585 \n",
      "\n",
      "2023-11-08 13:29:42.008914 Epoch 1395, Training loss 75.63761138916016\n",
      "R2 values 0.9612, 0.8135, 0.9160; mean R2=0.8969\n",
      "Validation Error: Avg loss: 404.663422 \n",
      "\n",
      "2023-11-08 13:29:42.485707 Epoch 1396, Training loss 106.53123474121094\n",
      "R2 values 0.9457, 0.8292, 0.9010; mean R2=0.8920\n",
      "Validation Error: Avg loss: 475.024689 \n",
      "\n",
      "2023-11-08 13:29:42.961353 Epoch 1397, Training loss 85.55638885498047\n",
      "R2 values 0.9509, 0.8299, 0.8555; mean R2=0.8788\n",
      "Validation Error: Avg loss: 474.997406 \n",
      "\n",
      "2023-11-08 13:29:43.438495 Epoch 1398, Training loss 71.71405792236328\n",
      "R2 values 0.9444, 0.8233, 0.8861; mean R2=0.8846\n",
      "Validation Error: Avg loss: 547.551758 \n",
      "\n",
      "2023-11-08 13:29:43.919619 Epoch 1399, Training loss 84.2384033203125\n",
      "R2 values 0.9524, 0.8303, 0.8856; mean R2=0.8894\n",
      "Validation Error: Avg loss: 458.052643 \n",
      "\n",
      "2023-11-08 13:29:44.396993 Epoch 1400, Training loss 88.90008544921875\n",
      "R2 values 0.9406, 0.8212, 0.9144; mean R2=0.8921\n",
      "Validation Error: Avg loss: 510.914276 \n",
      "\n",
      "2023-11-08 13:29:44.872512 Epoch 1401, Training loss 91.51656341552734\n",
      "R2 values 0.9448, 0.8397, 0.8695; mean R2=0.8847\n",
      "Validation Error: Avg loss: 513.794189 \n",
      "\n",
      "2023-11-08 13:29:45.351215 Epoch 1402, Training loss 88.54005432128906\n",
      "R2 values 0.9604, 0.8531, 0.8959; mean R2=0.9031\n",
      "Validation Error: Avg loss: 460.713440 \n",
      "\n",
      "2023-11-08 13:29:45.827456 Epoch 1403, Training loss 76.55532836914062\n",
      "R2 values 0.9594, 0.8511, 0.8899; mean R2=0.9001\n",
      "Validation Error: Avg loss: 420.006287 \n",
      "\n",
      "2023-11-08 13:29:46.299150 Epoch 1404, Training loss 104.4789047241211\n",
      "R2 values 0.9434, 0.8389, 0.9039; mean R2=0.8954\n",
      "Validation Error: Avg loss: 478.080414 \n",
      "\n",
      "2023-11-08 13:29:46.786726 Epoch 1405, Training loss 94.15335083007812\n",
      "R2 values 0.9606, 0.8595, 0.8954; mean R2=0.9052\n",
      "Validation Error: Avg loss: 332.519104 \n",
      "\n",
      "2023-11-08 13:29:47.272596 Epoch 1406, Training loss 98.45259857177734\n",
      "R2 values 0.9526, 0.8413, 0.8775; mean R2=0.8905\n",
      "Validation Error: Avg loss: 407.938782 \n",
      "\n",
      "2023-11-08 13:29:47.752515 Epoch 1407, Training loss 84.82355499267578\n",
      "R2 values 0.9447, 0.8082, 0.8967; mean R2=0.8832\n",
      "Validation Error: Avg loss: 484.238861 \n",
      "\n",
      "2023-11-08 13:29:48.225861 Epoch 1408, Training loss 97.7756118774414\n",
      "R2 values 0.9468, 0.8434, 0.8686; mean R2=0.8863\n",
      "Validation Error: Avg loss: 593.278503 \n",
      "\n",
      "2023-11-08 13:29:48.718956 Epoch 1409, Training loss 94.9201431274414\n",
      "R2 values 0.9524, 0.8350, 0.9009; mean R2=0.8961\n",
      "Validation Error: Avg loss: 554.659546 \n",
      "\n",
      "2023-11-08 13:29:49.188113 Epoch 1410, Training loss 79.44923400878906\n",
      "R2 values 0.9516, 0.8041, 0.9000; mean R2=0.8852\n",
      "Validation Error: Avg loss: 414.364624 \n",
      "\n",
      "2023-11-08 13:29:49.676378 Epoch 1411, Training loss 84.1506576538086\n",
      "R2 values 0.9553, 0.8413, 0.8809; mean R2=0.8925\n",
      "Validation Error: Avg loss: 397.311615 \n",
      "\n",
      "2023-11-08 13:29:50.162467 Epoch 1412, Training loss 103.58283233642578\n",
      "R2 values 0.9513, 0.8383, 0.8720; mean R2=0.8872\n",
      "Validation Error: Avg loss: 459.910492 \n",
      "\n",
      "2023-11-08 13:29:50.640424 Epoch 1413, Training loss 76.83927917480469\n",
      "R2 values 0.9600, 0.8519, 0.8763; mean R2=0.8961\n",
      "Validation Error: Avg loss: 402.802185 \n",
      "\n",
      "2023-11-08 13:29:51.120760 Epoch 1414, Training loss 85.56644439697266\n",
      "R2 values 0.9476, 0.8206, 0.8827; mean R2=0.8836\n",
      "Validation Error: Avg loss: 538.370911 \n",
      "\n",
      "2023-11-08 13:29:51.590763 Epoch 1415, Training loss 83.82777404785156\n",
      "R2 values 0.9532, 0.8262, 0.8715; mean R2=0.8836\n",
      "Validation Error: Avg loss: 427.271790 \n",
      "\n",
      "2023-11-08 13:29:52.077311 Epoch 1416, Training loss 87.20571899414062\n",
      "R2 values 0.9535, 0.8409, 0.8976; mean R2=0.8973\n",
      "Validation Error: Avg loss: 395.024139 \n",
      "\n",
      "2023-11-08 13:29:52.553368 Epoch 1417, Training loss 119.23175048828125\n",
      "R2 values 0.9589, 0.8211, 0.8962; mean R2=0.8921\n",
      "Validation Error: Avg loss: 433.337921 \n",
      "\n",
      "2023-11-08 13:29:53.030528 Epoch 1418, Training loss 67.81216430664062\n",
      "R2 values 0.9494, 0.8791, 0.9181; mean R2=0.9155\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 566.577148 \n",
      "\n",
      "2023-11-08 13:29:53.647346 Epoch 1419, Training loss 119.9222640991211\n",
      "R2 values 0.9565, 0.8807, 0.9005; mean R2=0.9125\n",
      "Validation Error: Avg loss: 451.377167 \n",
      "\n",
      "2023-11-08 13:29:54.127640 Epoch 1420, Training loss 82.22093200683594\n",
      "R2 values 0.9559, 0.8649, 0.8949; mean R2=0.9053\n",
      "Validation Error: Avg loss: 387.368744 \n",
      "\n",
      "2023-11-08 13:29:54.608974 Epoch 1421, Training loss 70.75025177001953\n",
      "R2 values 0.9562, 0.8500, 0.8879; mean R2=0.8980\n",
      "Validation Error: Avg loss: 381.830017 \n",
      "\n",
      "2023-11-08 13:29:55.092448 Epoch 1422, Training loss 116.48407745361328\n",
      "R2 values 0.9451, 0.8562, 0.9087; mean R2=0.9033\n",
      "Validation Error: Avg loss: 531.625000 \n",
      "\n",
      "2023-11-08 13:29:55.571563 Epoch 1423, Training loss 104.93124389648438\n",
      "R2 values 0.9477, 0.8220, 0.8924; mean R2=0.8873\n",
      "Validation Error: Avg loss: 652.905457 \n",
      "\n",
      "2023-11-08 13:29:56.045649 Epoch 1424, Training loss 102.77225494384766\n",
      "R2 values 0.9512, 0.8757, 0.8696; mean R2=0.8988\n",
      "Validation Error: Avg loss: 479.814789 \n",
      "\n",
      "2023-11-08 13:29:56.527969 Epoch 1425, Training loss 67.09281921386719\n",
      "R2 values 0.9469, 0.8403, 0.8993; mean R2=0.8955\n",
      "Validation Error: Avg loss: 453.120605 \n",
      "\n",
      "2023-11-08 13:29:57.011842 Epoch 1426, Training loss 113.28607940673828\n",
      "R2 values 0.9540, 0.8306, 0.8874; mean R2=0.8907\n",
      "Validation Error: Avg loss: 438.582611 \n",
      "\n",
      "2023-11-08 13:29:57.492490 Epoch 1427, Training loss 99.00115966796875\n",
      "R2 values 0.9395, 0.8183, 0.8818; mean R2=0.8799\n",
      "Validation Error: Avg loss: 743.098206 \n",
      "\n",
      "2023-11-08 13:29:57.973476 Epoch 1428, Training loss 92.71648406982422\n",
      "R2 values 0.9500, 0.8695, 0.8976; mean R2=0.9057\n",
      "Validation Error: Avg loss: 520.995789 \n",
      "\n",
      "2023-11-08 13:29:58.456182 Epoch 1429, Training loss 133.50485229492188\n",
      "R2 values 0.9472, 0.8533, 0.8940; mean R2=0.8982\n",
      "Validation Error: Avg loss: 432.807495 \n",
      "\n",
      "2023-11-08 13:29:58.940908 Epoch 1430, Training loss 110.7704086303711\n",
      "R2 values 0.9517, 0.8715, 0.8678; mean R2=0.8970\n",
      "Validation Error: Avg loss: 413.996643 \n",
      "\n",
      "2023-11-08 13:29:59.416471 Epoch 1431, Training loss 130.05453491210938\n",
      "R2 values 0.9459, 0.8541, 0.8715; mean R2=0.8905\n",
      "Validation Error: Avg loss: 489.633301 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:29:59.911229 Epoch 1432, Training loss 89.23136901855469\n",
      "R2 values 0.9494, 0.8053, 0.8885; mean R2=0.8811\n",
      "Validation Error: Avg loss: 596.621155 \n",
      "\n",
      "2023-11-08 13:30:00.486856 Epoch 1433, Training loss 104.93513488769531\n",
      "R2 values 0.9536, 0.8267, 0.8453; mean R2=0.8752\n",
      "Validation Error: Avg loss: 581.284729 \n",
      "\n",
      "2023-11-08 13:30:01.181502 Epoch 1434, Training loss 93.58096313476562\n",
      "R2 values 0.9528, 0.8412, 0.8977; mean R2=0.8972\n",
      "Validation Error: Avg loss: 426.989410 \n",
      "\n",
      "2023-11-08 13:30:01.650030 Epoch 1435, Training loss 86.31340026855469\n",
      "R2 values 0.9532, 0.8029, 0.8819; mean R2=0.8794\n",
      "Validation Error: Avg loss: 397.657257 \n",
      "\n",
      "2023-11-08 13:30:02.135977 Epoch 1436, Training loss 119.20178985595703\n",
      "R2 values 0.9534, 0.8597, 0.8467; mean R2=0.8866\n",
      "Validation Error: Avg loss: 436.940155 \n",
      "\n",
      "2023-11-08 13:30:02.737180 Epoch 1437, Training loss 73.09069061279297\n",
      "R2 values 0.9625, 0.8413, 0.8721; mean R2=0.8920\n",
      "Validation Error: Avg loss: 410.409698 \n",
      "\n",
      "2023-11-08 13:30:03.197872 Epoch 1438, Training loss 114.2421875\n",
      "R2 values 0.9417, 0.8157, 0.8550; mean R2=0.8708\n",
      "Validation Error: Avg loss: 572.098206 \n",
      "\n",
      "2023-11-08 13:30:03.664574 Epoch 1439, Training loss 79.98194885253906\n",
      "R2 values 0.9518, 0.8366, 0.8742; mean R2=0.8875\n",
      "Validation Error: Avg loss: 461.016571 \n",
      "\n",
      "2023-11-08 13:30:04.134781 Epoch 1440, Training loss 120.32697296142578\n",
      "R2 values 0.9496, 0.8181, 0.8778; mean R2=0.8818\n",
      "Validation Error: Avg loss: 466.594513 \n",
      "\n",
      "2023-11-08 13:30:04.602822 Epoch 1441, Training loss 109.03755950927734\n",
      "R2 values 0.9499, 0.8396, 0.8879; mean R2=0.8925\n",
      "Validation Error: Avg loss: 541.678772 \n",
      "\n",
      "2023-11-08 13:30:05.091097 Epoch 1442, Training loss 158.2602996826172\n",
      "R2 values 0.9392, 0.8301, 0.8870; mean R2=0.8854\n",
      "Validation Error: Avg loss: 612.192322 \n",
      "\n",
      "2023-11-08 13:30:05.565062 Epoch 1443, Training loss 129.43186950683594\n",
      "R2 values 0.9378, 0.8731, 0.8910; mean R2=0.9006\n",
      "Validation Error: Avg loss: 547.820435 \n",
      "\n",
      "2023-11-08 13:30:06.041718 Epoch 1444, Training loss 144.43841552734375\n",
      "R2 values 0.9448, 0.8803, 0.8939; mean R2=0.9063\n",
      "Validation Error: Avg loss: 431.214691 \n",
      "\n",
      "2023-11-08 13:30:06.510326 Epoch 1445, Training loss 92.39873504638672\n",
      "R2 values 0.9485, 0.8298, 0.8795; mean R2=0.8859\n",
      "Validation Error: Avg loss: 472.809998 \n",
      "\n",
      "2023-11-08 13:30:06.994759 Epoch 1446, Training loss 106.97835540771484\n",
      "R2 values 0.9278, 0.8203, 0.8779; mean R2=0.8753\n",
      "Validation Error: Avg loss: 727.034302 \n",
      "\n",
      "2023-11-08 13:30:07.470257 Epoch 1447, Training loss 120.2945785522461\n",
      "R2 values 0.9400, 0.8088, 0.8624; mean R2=0.8704\n",
      "Validation Error: Avg loss: 570.335815 \n",
      "\n",
      "2023-11-08 13:30:07.954543 Epoch 1448, Training loss 121.79348754882812\n",
      "R2 values 0.9533, 0.8260, 0.8815; mean R2=0.8869\n",
      "Validation Error: Avg loss: 416.717316 \n",
      "\n",
      "2023-11-08 13:30:08.433609 Epoch 1449, Training loss 94.17726135253906\n",
      "R2 values 0.9584, 0.8321, 0.8980; mean R2=0.8961\n",
      "Validation Error: Avg loss: 418.015442 \n",
      "\n",
      "2023-11-08 13:30:08.920238 Epoch 1450, Training loss 92.22128295898438\n",
      "R2 values 0.9428, 0.8328, 0.8836; mean R2=0.8864\n",
      "Validation Error: Avg loss: 525.588379 \n",
      "\n",
      "2023-11-08 13:30:09.388873 Epoch 1451, Training loss 117.0394515991211\n",
      "R2 values 0.9490, 0.8372, 0.8944; mean R2=0.8935\n",
      "Validation Error: Avg loss: 492.328278 \n",
      "\n",
      "2023-11-08 13:30:09.861100 Epoch 1452, Training loss 106.25757598876953\n",
      "R2 values 0.9571, 0.8438, 0.8950; mean R2=0.8986\n",
      "Validation Error: Avg loss: 397.246521 \n",
      "\n",
      "2023-11-08 13:30:10.362731 Epoch 1453, Training loss 108.7161636352539\n",
      "R2 values 0.9345, 0.8252, 0.8672; mean R2=0.8756\n",
      "Validation Error: Avg loss: 537.886658 \n",
      "\n",
      "2023-11-08 13:30:10.860102 Epoch 1454, Training loss 104.77428436279297\n",
      "R2 values 0.9340, 0.8364, 0.9029; mean R2=0.8911\n",
      "Validation Error: Avg loss: 583.514038 \n",
      "\n",
      "2023-11-08 13:30:11.373803 Epoch 1455, Training loss 82.05914306640625\n",
      "R2 values 0.9459, 0.8468, 0.8811; mean R2=0.8913\n",
      "Validation Error: Avg loss: 548.594482 \n",
      "\n",
      "2023-11-08 13:30:11.852056 Epoch 1456, Training loss 136.00515747070312\n",
      "R2 values 0.9460, 0.8304, 0.8778; mean R2=0.8847\n",
      "Validation Error: Avg loss: 516.288086 \n",
      "\n",
      "2023-11-08 13:30:12.319518 Epoch 1457, Training loss 89.53193664550781\n",
      "R2 values 0.9455, 0.8057, 0.8635; mean R2=0.8716\n",
      "Validation Error: Avg loss: 524.785950 \n",
      "\n",
      "2023-11-08 13:30:12.790128 Epoch 1458, Training loss 101.83101654052734\n",
      "R2 values 0.9575, 0.8435, 0.8930; mean R2=0.8980\n",
      "Validation Error: Avg loss: 437.607849 \n",
      "\n",
      "2023-11-08 13:30:13.260152 Epoch 1459, Training loss 109.46365356445312\n",
      "R2 values 0.9458, 0.8777, 0.8696; mean R2=0.8977\n",
      "Validation Error: Avg loss: 501.148407 \n",
      "\n",
      "2023-11-08 13:30:13.754869 Epoch 1460, Training loss 99.7784423828125\n",
      "R2 values 0.9562, 0.8592, 0.8594; mean R2=0.8916\n",
      "Validation Error: Avg loss: 451.984497 \n",
      "\n",
      "2023-11-08 13:30:14.221185 Epoch 1461, Training loss 112.68009185791016\n",
      "R2 values 0.9473, 0.8604, 0.8542; mean R2=0.8873\n",
      "Validation Error: Avg loss: 494.961548 \n",
      "\n",
      "2023-11-08 13:30:14.693680 Epoch 1462, Training loss 81.31526947021484\n",
      "R2 values 0.9493, 0.8685, 0.8865; mean R2=0.9015\n",
      "Validation Error: Avg loss: 442.021088 \n",
      "\n",
      "2023-11-08 13:30:15.172726 Epoch 1463, Training loss 89.86740112304688\n",
      "R2 values 0.9434, 0.7989, 0.8872; mean R2=0.8765\n",
      "Validation Error: Avg loss: 514.359497 \n",
      "\n",
      "2023-11-08 13:30:15.649864 Epoch 1464, Training loss 94.03327178955078\n",
      "R2 values 0.9427, 0.8307, 0.8707; mean R2=0.8814\n",
      "Validation Error: Avg loss: 568.546082 \n",
      "\n",
      "2023-11-08 13:30:16.119183 Epoch 1465, Training loss 100.02747344970703\n",
      "R2 values 0.9412, 0.8433, 0.9097; mean R2=0.8981\n",
      "Validation Error: Avg loss: 493.353180 \n",
      "\n",
      "2023-11-08 13:30:16.588303 Epoch 1466, Training loss 75.86833190917969\n",
      "R2 values 0.9515, 0.8525, 0.8889; mean R2=0.8976\n",
      "Validation Error: Avg loss: 420.943298 \n",
      "\n",
      "2023-11-08 13:30:17.108620 Epoch 1467, Training loss 100.85059356689453\n",
      "R2 values 0.9381, 0.8356, 0.8894; mean R2=0.8877\n",
      "Validation Error: Avg loss: 532.214111 \n",
      "\n",
      "2023-11-08 13:30:17.633318 Epoch 1468, Training loss 69.37772369384766\n",
      "R2 values 0.9489, 0.8391, 0.9178; mean R2=0.9020\n",
      "Validation Error: Avg loss: 479.888245 \n",
      "\n",
      "2023-11-08 13:30:18.104158 Epoch 1469, Training loss 88.4295425415039\n",
      "R2 values 0.9424, 0.8407, 0.8985; mean R2=0.8939\n",
      "Validation Error: Avg loss: 594.602051 \n",
      "\n",
      "2023-11-08 13:30:18.588895 Epoch 1470, Training loss 92.37789154052734\n",
      "R2 values 0.9515, 0.8539, 0.8903; mean R2=0.8986\n",
      "Validation Error: Avg loss: 512.712830 \n",
      "\n",
      "2023-11-08 13:30:19.064077 Epoch 1471, Training loss 87.89277648925781\n",
      "R2 values 0.9488, 0.8406, 0.8778; mean R2=0.8891\n",
      "Validation Error: Avg loss: 442.018585 \n",
      "\n",
      "2023-11-08 13:30:19.534804 Epoch 1472, Training loss 91.04474639892578\n",
      "R2 values 0.9488, 0.8633, 0.9015; mean R2=0.9046\n",
      "Validation Error: Avg loss: 431.807648 \n",
      "\n",
      "2023-11-08 13:30:20.029340 Epoch 1473, Training loss 93.13468933105469\n",
      "R2 values 0.9403, 0.8479, 0.8951; mean R2=0.8944\n",
      "Validation Error: Avg loss: 509.786804 \n",
      "\n",
      "2023-11-08 13:30:20.567235 Epoch 1474, Training loss 97.49339294433594\n",
      "R2 values 0.9421, 0.7982, 0.8643; mean R2=0.8682\n",
      "Validation Error: Avg loss: 559.198853 \n",
      "\n",
      "2023-11-08 13:30:21.056859 Epoch 1475, Training loss 82.4348373413086\n",
      "R2 values 0.9492, 0.8626, 0.8925; mean R2=0.9014\n",
      "Validation Error: Avg loss: 424.337494 \n",
      "\n",
      "2023-11-08 13:30:21.531167 Epoch 1476, Training loss 74.34468078613281\n",
      "R2 values 0.9524, 0.8489, 0.8576; mean R2=0.8863\n",
      "Validation Error: Avg loss: 410.965424 \n",
      "\n",
      "2023-11-08 13:30:22.017114 Epoch 1477, Training loss 72.44989776611328\n",
      "R2 values 0.9534, 0.8578, 0.8630; mean R2=0.8914\n",
      "Validation Error: Avg loss: 409.510559 \n",
      "\n",
      "2023-11-08 13:30:22.490988 Epoch 1478, Training loss 124.30439758300781\n",
      "R2 values 0.9523, 0.8452, 0.8864; mean R2=0.8946\n",
      "Validation Error: Avg loss: 477.595337 \n",
      "\n",
      "2023-11-08 13:30:22.970703 Epoch 1479, Training loss 79.48393249511719\n",
      "R2 values 0.9576, 0.8470, 0.9071; mean R2=0.9039\n",
      "Validation Error: Avg loss: 468.967834 \n",
      "\n",
      "2023-11-08 13:30:23.438993 Epoch 1480, Training loss 80.53189086914062\n",
      "R2 values 0.9339, 0.8065, 0.8881; mean R2=0.8762\n",
      "Validation Error: Avg loss: 637.844055 \n",
      "\n",
      "2023-11-08 13:30:23.918898 Epoch 1481, Training loss 128.08551025390625\n",
      "R2 values 0.9568, 0.8323, 0.8623; mean R2=0.8838\n",
      "Validation Error: Avg loss: 413.628021 \n",
      "\n",
      "2023-11-08 13:30:24.390939 Epoch 1482, Training loss 122.55191802978516\n",
      "R2 values 0.9466, 0.8414, 0.8892; mean R2=0.8924\n",
      "Validation Error: Avg loss: 443.887299 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:30:24.864444 Epoch 1483, Training loss 93.3354263305664\n",
      "R2 values 0.9459, 0.8414, 0.8559; mean R2=0.8811\n",
      "Validation Error: Avg loss: 558.972534 \n",
      "\n",
      "2023-11-08 13:30:25.341524 Epoch 1484, Training loss 117.32493591308594\n",
      "R2 values 0.9368, 0.8062, 0.9027; mean R2=0.8819\n",
      "Validation Error: Avg loss: 627.440491 \n",
      "\n",
      "2023-11-08 13:30:25.812749 Epoch 1485, Training loss 151.4522705078125\n",
      "R2 values 0.9501, 0.8218, 0.8764; mean R2=0.8827\n",
      "Validation Error: Avg loss: 460.846344 \n",
      "\n",
      "2023-11-08 13:30:26.342498 Epoch 1486, Training loss 151.482666015625\n",
      "R2 values 0.9653, 0.8727, 0.8919; mean R2=0.9100\n",
      "Validation Error: Avg loss: 350.367950 \n",
      "\n",
      "2023-11-08 13:30:26.814733 Epoch 1487, Training loss 139.92559814453125\n",
      "R2 values 0.9432, 0.8262, 0.9130; mean R2=0.8941\n",
      "Validation Error: Avg loss: 562.636780 \n",
      "\n",
      "2023-11-08 13:30:27.304522 Epoch 1488, Training loss 91.60679626464844\n",
      "R2 values 0.9514, 0.8307, 0.8993; mean R2=0.8938\n",
      "Validation Error: Avg loss: 547.398743 \n",
      "\n",
      "2023-11-08 13:30:27.785046 Epoch 1489, Training loss 189.51426696777344\n",
      "R2 values 0.9496, 0.7947, 0.8984; mean R2=0.8809\n",
      "Validation Error: Avg loss: 443.073151 \n",
      "\n",
      "2023-11-08 13:30:28.263724 Epoch 1490, Training loss 114.80313873291016\n",
      "R2 values 0.9400, 0.8666, 0.9211; mean R2=0.9093\n",
      "Validation Error: Avg loss: 473.894928 \n",
      "\n",
      "2023-11-08 13:30:28.789022 Epoch 1491, Training loss 122.36746215820312\n",
      "R2 values 0.9523, 0.7933, 0.8683; mean R2=0.8713\n",
      "Validation Error: Avg loss: 477.496185 \n",
      "\n",
      "2023-11-08 13:30:29.259053 Epoch 1492, Training loss 98.42398834228516\n",
      "R2 values 0.9401, 0.7933, 0.8861; mean R2=0.8732\n",
      "Validation Error: Avg loss: 561.125122 \n",
      "\n",
      "2023-11-08 13:30:29.833750 Epoch 1493, Training loss 95.49344635009766\n",
      "R2 values 0.9518, 0.8285, 0.8796; mean R2=0.8866\n",
      "Validation Error: Avg loss: 540.625549 \n",
      "\n",
      "2023-11-08 13:30:30.321541 Epoch 1494, Training loss 87.49127960205078\n",
      "R2 values 0.9552, 0.8285, 0.8677; mean R2=0.8838\n",
      "Validation Error: Avg loss: 421.818604 \n",
      "\n",
      "2023-11-08 13:30:30.801262 Epoch 1495, Training loss 90.5124282836914\n",
      "R2 values 0.9541, 0.8502, 0.8967; mean R2=0.9003\n",
      "Validation Error: Avg loss: 402.414490 \n",
      "\n",
      "2023-11-08 13:30:31.278916 Epoch 1496, Training loss 143.44476318359375\n",
      "R2 values 0.9525, 0.8514, 0.8926; mean R2=0.8988\n",
      "Validation Error: Avg loss: 430.278259 \n",
      "\n",
      "2023-11-08 13:30:31.753263 Epoch 1497, Training loss 84.33280181884766\n",
      "R2 values 0.9585, 0.8703, 0.8831; mean R2=0.9040\n",
      "Validation Error: Avg loss: 518.363220 \n",
      "\n",
      "2023-11-08 13:30:32.235956 Epoch 1498, Training loss 123.8544692993164\n",
      "R2 values 0.9504, 0.8170, 0.8841; mean R2=0.8839\n",
      "Validation Error: Avg loss: 475.540161 \n",
      "\n",
      "2023-11-08 13:30:32.706394 Epoch 1499, Training loss 111.4404525756836\n",
      "R2 values 0.9409, 0.8562, 0.8879; mean R2=0.8950\n",
      "Validation Error: Avg loss: 471.097260 \n",
      "\n",
      "2023-11-08 13:30:33.179365 Epoch 1500, Training loss 121.63691711425781\n",
      "R2 values 0.9507, 0.8513, 0.8714; mean R2=0.8911\n",
      "Validation Error: Avg loss: 424.170563 \n",
      "\n",
      "2023-11-08 13:30:33.653565 Epoch 1501, Training loss 93.05780792236328\n",
      "R2 values 0.9503, 0.8348, 0.8550; mean R2=0.8800\n",
      "Validation Error: Avg loss: 495.111084 \n",
      "\n",
      "2023-11-08 13:30:34.138800 Epoch 1502, Training loss 74.7525863647461\n",
      "R2 values 0.9513, 0.8567, 0.8772; mean R2=0.8950\n",
      "Validation Error: Avg loss: 501.577393 \n",
      "\n",
      "2023-11-08 13:30:34.613426 Epoch 1503, Training loss 97.57275390625\n",
      "R2 values 0.9454, 0.8257, 0.8481; mean R2=0.8730\n",
      "Validation Error: Avg loss: 498.511139 \n",
      "\n",
      "2023-11-08 13:30:35.235805 Epoch 1504, Training loss 105.30169677734375\n",
      "R2 values 0.9437, 0.8374, 0.9155; mean R2=0.8988\n",
      "Validation Error: Avg loss: 438.679047 \n",
      "\n",
      "2023-11-08 13:30:35.770293 Epoch 1505, Training loss 105.97470092773438\n",
      "R2 values 0.9531, 0.8459, 0.8904; mean R2=0.8964\n",
      "Validation Error: Avg loss: 403.751495 \n",
      "\n",
      "2023-11-08 13:30:36.257465 Epoch 1506, Training loss 77.40444946289062\n",
      "R2 values 0.9453, 0.8432, 0.9014; mean R2=0.8966\n",
      "Validation Error: Avg loss: 452.535828 \n",
      "\n",
      "2023-11-08 13:30:36.725960 Epoch 1507, Training loss 115.16763305664062\n",
      "R2 values 0.9478, 0.8584, 0.8903; mean R2=0.8988\n",
      "Validation Error: Avg loss: 434.856049 \n",
      "\n",
      "2023-11-08 13:30:37.216624 Epoch 1508, Training loss 86.85018920898438\n",
      "R2 values 0.9572, 0.8718, 0.8948; mean R2=0.9079\n",
      "Validation Error: Avg loss: 410.493866 \n",
      "\n",
      "2023-11-08 13:30:37.690096 Epoch 1509, Training loss 66.24954223632812\n",
      "R2 values 0.9490, 0.8392, 0.8788; mean R2=0.8890\n",
      "Validation Error: Avg loss: 528.036804 \n",
      "\n",
      "2023-11-08 13:30:38.167654 Epoch 1510, Training loss 67.19680786132812\n",
      "R2 values 0.9468, 0.8587, 0.9137; mean R2=0.9064\n",
      "Validation Error: Avg loss: 467.013672 \n",
      "\n",
      "2023-11-08 13:30:38.660026 Epoch 1511, Training loss 86.36181640625\n",
      "R2 values 0.9712, 0.8363, 0.8869; mean R2=0.8982\n",
      "Validation Error: Avg loss: 308.918823 \n",
      "\n",
      "2023-11-08 13:30:39.154676 Epoch 1512, Training loss 103.35970306396484\n",
      "R2 values 0.9601, 0.7996, 0.8832; mean R2=0.8810\n",
      "Validation Error: Avg loss: 364.816864 \n",
      "\n",
      "2023-11-08 13:30:39.632181 Epoch 1513, Training loss 80.43598175048828\n",
      "R2 values 0.9529, 0.8363, 0.8875; mean R2=0.8923\n",
      "Validation Error: Avg loss: 405.208008 \n",
      "\n",
      "2023-11-08 13:30:40.119774 Epoch 1514, Training loss 93.2882080078125\n",
      "R2 values 0.9540, 0.8699, 0.8503; mean R2=0.8914\n",
      "Validation Error: Avg loss: 422.371948 \n",
      "\n",
      "2023-11-08 13:30:40.601274 Epoch 1515, Training loss 80.59964752197266\n",
      "R2 values 0.9543, 0.8285, 0.8494; mean R2=0.8774\n",
      "Validation Error: Avg loss: 456.817810 \n",
      "\n",
      "2023-11-08 13:30:41.075048 Epoch 1516, Training loss 63.27374267578125\n",
      "R2 values 0.9522, 0.8167, 0.8665; mean R2=0.8785\n",
      "Validation Error: Avg loss: 439.717926 \n",
      "\n",
      "2023-11-08 13:30:41.543909 Epoch 1517, Training loss 98.93647003173828\n",
      "R2 values 0.9443, 0.8478, 0.8786; mean R2=0.8902\n",
      "Validation Error: Avg loss: 521.990234 \n",
      "\n",
      "2023-11-08 13:30:42.023083 Epoch 1518, Training loss 77.51412963867188\n",
      "R2 values 0.9495, 0.8601, 0.8894; mean R2=0.8997\n",
      "Validation Error: Avg loss: 488.225037 \n",
      "\n",
      "2023-11-08 13:30:42.647241 Epoch 1519, Training loss 72.99047088623047\n",
      "R2 values 0.9511, 0.8180, 0.8829; mean R2=0.8840\n",
      "Validation Error: Avg loss: 431.642181 \n",
      "\n",
      "2023-11-08 13:30:43.207956 Epoch 1520, Training loss 82.86199951171875\n",
      "R2 values 0.9528, 0.8346, 0.8941; mean R2=0.8938\n",
      "Validation Error: Avg loss: 418.127930 \n",
      "\n",
      "2023-11-08 13:30:43.677748 Epoch 1521, Training loss 89.46273040771484\n",
      "R2 values 0.9466, 0.8237, 0.9039; mean R2=0.8914\n",
      "Validation Error: Avg loss: 569.086853 \n",
      "\n",
      "2023-11-08 13:30:44.149849 Epoch 1522, Training loss 88.03948974609375\n",
      "R2 values 0.9388, 0.8557, 0.8836; mean R2=0.8927\n",
      "Validation Error: Avg loss: 556.461670 \n",
      "\n",
      "2023-11-08 13:30:44.620444 Epoch 1523, Training loss 105.53844451904297\n",
      "R2 values 0.9466, 0.8325, 0.8877; mean R2=0.8889\n",
      "Validation Error: Avg loss: 435.727600 \n",
      "\n",
      "2023-11-08 13:30:45.084793 Epoch 1524, Training loss 86.05835723876953\n",
      "R2 values 0.9535, 0.8236, 0.9147; mean R2=0.8973\n",
      "Validation Error: Avg loss: 407.867676 \n",
      "\n",
      "2023-11-08 13:30:45.556223 Epoch 1525, Training loss 93.32853698730469\n",
      "R2 values 0.9551, 0.8335, 0.8827; mean R2=0.8904\n",
      "Validation Error: Avg loss: 470.938324 \n",
      "\n",
      "2023-11-08 13:30:46.052293 Epoch 1526, Training loss 77.07447052001953\n",
      "R2 values 0.9378, 0.8328, 0.8797; mean R2=0.8834\n",
      "Validation Error: Avg loss: 557.839478 \n",
      "\n",
      "2023-11-08 13:30:46.513941 Epoch 1527, Training loss 114.35640716552734\n",
      "R2 values 0.9504, 0.8386, 0.8833; mean R2=0.8908\n",
      "Validation Error: Avg loss: 494.768646 \n",
      "\n",
      "2023-11-08 13:30:46.989277 Epoch 1528, Training loss 94.52428436279297\n",
      "R2 values 0.9429, 0.8588, 0.9113; mean R2=0.9043\n",
      "Validation Error: Avg loss: 451.791809 \n",
      "\n",
      "2023-11-08 13:30:47.479341 Epoch 1529, Training loss 70.8436050415039\n",
      "R2 values 0.9489, 0.8341, 0.8757; mean R2=0.8862\n",
      "Validation Error: Avg loss: 426.872620 \n",
      "\n",
      "2023-11-08 13:30:47.946490 Epoch 1530, Training loss 101.49824523925781\n",
      "R2 values 0.9554, 0.8729, 0.8884; mean R2=0.9055\n",
      "Validation Error: Avg loss: 448.234100 \n",
      "\n",
      "2023-11-08 13:30:48.424617 Epoch 1531, Training loss 72.83409118652344\n",
      "R2 values 0.9370, 0.8469, 0.9008; mean R2=0.8949\n",
      "Validation Error: Avg loss: 630.900879 \n",
      "\n",
      "2023-11-08 13:30:48.905024 Epoch 1532, Training loss 107.76365661621094\n",
      "R2 values 0.9649, 0.8490, 0.8943; mean R2=0.9027\n",
      "Validation Error: Avg loss: 362.912048 \n",
      "\n",
      "2023-11-08 13:30:49.379257 Epoch 1533, Training loss 90.99168395996094\n",
      "R2 values 0.9570, 0.8268, 0.8919; mean R2=0.8919\n",
      "Validation Error: Avg loss: 391.778931 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:30:49.854774 Epoch 1534, Training loss 139.00009155273438\n",
      "R2 values 0.9520, 0.8509, 0.8942; mean R2=0.8990\n",
      "Validation Error: Avg loss: 417.356476 \n",
      "\n",
      "2023-11-08 13:30:50.346477 Epoch 1535, Training loss 91.73101043701172\n",
      "R2 values 0.9436, 0.8458, 0.9180; mean R2=0.9025\n",
      "Validation Error: Avg loss: 519.251099 \n",
      "\n",
      "2023-11-08 13:30:50.825890 Epoch 1536, Training loss 84.65602111816406\n",
      "R2 values 0.9577, 0.8267, 0.9094; mean R2=0.8979\n",
      "Validation Error: Avg loss: 609.783447 \n",
      "\n",
      "2023-11-08 13:30:51.302024 Epoch 1537, Training loss 152.60450744628906\n",
      "R2 values 0.9537, 0.8535, 0.8855; mean R2=0.8975\n",
      "Validation Error: Avg loss: 411.720703 \n",
      "\n",
      "2023-11-08 13:30:51.986332 Epoch 1538, Training loss 86.70379638671875\n",
      "R2 values 0.9494, 0.7771, 0.8444; mean R2=0.8570\n",
      "Validation Error: Avg loss: 461.951935 \n",
      "\n",
      "2023-11-08 13:30:52.491326 Epoch 1539, Training loss 151.90773010253906\n",
      "R2 values 0.9415, 0.8232, 0.8959; mean R2=0.8869\n",
      "Validation Error: Avg loss: 465.621063 \n",
      "\n",
      "2023-11-08 13:30:52.974813 Epoch 1540, Training loss 101.74202728271484\n",
      "R2 values 0.9531, 0.8385, 0.8979; mean R2=0.8965\n",
      "Validation Error: Avg loss: 654.687561 \n",
      "\n",
      "2023-11-08 13:30:53.450690 Epoch 1541, Training loss 166.28794860839844\n",
      "R2 values 0.9511, 0.8294, 0.8978; mean R2=0.8928\n",
      "Validation Error: Avg loss: 495.081177 \n",
      "\n",
      "2023-11-08 13:30:53.925536 Epoch 1542, Training loss 97.87998962402344\n",
      "R2 values 0.9505, 0.8603, 0.8824; mean R2=0.8977\n",
      "Validation Error: Avg loss: 458.093567 \n",
      "\n",
      "2023-11-08 13:30:54.402768 Epoch 1543, Training loss 106.57661437988281\n",
      "R2 values 0.9573, 0.8489, 0.8784; mean R2=0.8949\n",
      "Validation Error: Avg loss: 411.318695 \n",
      "\n",
      "2023-11-08 13:30:54.886781 Epoch 1544, Training loss 135.6121368408203\n",
      "R2 values 0.9503, 0.8099, 0.8983; mean R2=0.8862\n",
      "Validation Error: Avg loss: 459.336304 \n",
      "\n",
      "2023-11-08 13:30:55.355104 Epoch 1545, Training loss 79.93711853027344\n",
      "R2 values 0.9463, 0.8500, 0.9008; mean R2=0.8990\n",
      "Validation Error: Avg loss: 583.338379 \n",
      "\n",
      "2023-11-08 13:30:55.827354 Epoch 1546, Training loss 151.5441131591797\n",
      "R2 values 0.9414, 0.8007, 0.8832; mean R2=0.8751\n",
      "Validation Error: Avg loss: 721.462524 \n",
      "\n",
      "2023-11-08 13:30:56.303665 Epoch 1547, Training loss 112.47418212890625\n",
      "R2 values 0.9467, 0.8462, 0.8840; mean R2=0.8923\n",
      "Validation Error: Avg loss: 477.803253 \n",
      "\n",
      "2023-11-08 13:30:56.779866 Epoch 1548, Training loss 88.33126831054688\n",
      "R2 values 0.9544, 0.8432, 0.8727; mean R2=0.8901\n",
      "Validation Error: Avg loss: 417.600861 \n",
      "\n",
      "2023-11-08 13:30:57.263391 Epoch 1549, Training loss 100.28514862060547\n",
      "R2 values 0.9540, 0.8249, 0.8900; mean R2=0.8896\n",
      "Validation Error: Avg loss: 435.952637 \n",
      "\n",
      "2023-11-08 13:30:57.745911 Epoch 1550, Training loss 68.67401885986328\n",
      "R2 values 0.9492, 0.8111, 0.8926; mean R2=0.8843\n",
      "Validation Error: Avg loss: 445.392731 \n",
      "\n",
      "2023-11-08 13:30:58.215988 Epoch 1551, Training loss 81.97834014892578\n",
      "R2 values 0.9509, 0.8379, 0.9163; mean R2=0.9017\n",
      "Validation Error: Avg loss: 423.779449 \n",
      "\n",
      "2023-11-08 13:30:58.701787 Epoch 1552, Training loss 93.5634765625\n",
      "R2 values 0.9467, 0.8544, 0.8984; mean R2=0.8998\n",
      "Validation Error: Avg loss: 443.772034 \n",
      "\n",
      "2023-11-08 13:30:59.190661 Epoch 1553, Training loss 72.30689239501953\n",
      "R2 values 0.9477, 0.8326, 0.8778; mean R2=0.8860\n",
      "Validation Error: Avg loss: 465.957764 \n",
      "\n",
      "2023-11-08 13:30:59.679698 Epoch 1554, Training loss 62.68537139892578\n",
      "R2 values 0.9488, 0.8641, 0.9035; mean R2=0.9055\n",
      "Validation Error: Avg loss: 436.263763 \n",
      "\n",
      "2023-11-08 13:31:00.164415 Epoch 1555, Training loss 78.81134796142578\n",
      "R2 values 0.9450, 0.8161, 0.8836; mean R2=0.8816\n",
      "Validation Error: Avg loss: 495.170898 \n",
      "\n",
      "2023-11-08 13:31:00.645819 Epoch 1556, Training loss 70.93487548828125\n",
      "R2 values 0.9643, 0.8394, 0.8983; mean R2=0.9007\n",
      "Validation Error: Avg loss: 381.397186 \n",
      "\n",
      "2023-11-08 13:31:01.133251 Epoch 1557, Training loss 92.22380065917969\n",
      "R2 values 0.9479, 0.8388, 0.8904; mean R2=0.8924\n",
      "Validation Error: Avg loss: 490.748627 \n",
      "\n",
      "2023-11-08 13:31:01.621812 Epoch 1558, Training loss 87.37227630615234\n",
      "R2 values 0.9528, 0.8417, 0.8992; mean R2=0.8979\n",
      "Validation Error: Avg loss: 427.323059 \n",
      "\n",
      "2023-11-08 13:31:02.137682 Epoch 1559, Training loss 86.7083969116211\n",
      "R2 values 0.9445, 0.8049, 0.9085; mean R2=0.8860\n",
      "Validation Error: Avg loss: 429.690399 \n",
      "\n",
      "2023-11-08 13:31:02.624608 Epoch 1560, Training loss 104.80718231201172\n",
      "R2 values 0.9428, 0.8209, 0.9024; mean R2=0.8887\n",
      "Validation Error: Avg loss: 495.203308 \n",
      "\n",
      "2023-11-08 13:31:03.092078 Epoch 1561, Training loss 91.10714721679688\n",
      "R2 values 0.9360, 0.8230, 0.9111; mean R2=0.8900\n",
      "Validation Error: Avg loss: 590.400757 \n",
      "\n",
      "2023-11-08 13:31:03.577792 Epoch 1562, Training loss 78.21920013427734\n",
      "R2 values 0.9560, 0.8306, 0.9033; mean R2=0.8966\n",
      "Validation Error: Avg loss: 453.419373 \n",
      "\n",
      "2023-11-08 13:31:04.070654 Epoch 1563, Training loss 120.61528778076172\n",
      "R2 values 0.9494, 0.8786, 0.8923; mean R2=0.9067\n",
      "Validation Error: Avg loss: 460.395721 \n",
      "\n",
      "2023-11-08 13:31:04.549785 Epoch 1564, Training loss 90.03372955322266\n",
      "R2 values 0.9589, 0.8484, 0.8863; mean R2=0.8978\n",
      "Validation Error: Avg loss: 354.044647 \n",
      "\n",
      "2023-11-08 13:31:05.038582 Epoch 1565, Training loss 81.60004425048828\n",
      "R2 values 0.9526, 0.8474, 0.8724; mean R2=0.8908\n",
      "Validation Error: Avg loss: 398.996155 \n",
      "\n",
      "2023-11-08 13:31:05.533891 Epoch 1566, Training loss 111.96592712402344\n",
      "R2 values 0.9513, 0.8052, 0.8687; mean R2=0.8751\n",
      "Validation Error: Avg loss: 479.933838 \n",
      "\n",
      "2023-11-08 13:31:06.025257 Epoch 1567, Training loss 88.68130493164062\n",
      "R2 values 0.9546, 0.8237, 0.8704; mean R2=0.8829\n",
      "Validation Error: Avg loss: 589.552307 \n",
      "\n",
      "2023-11-08 13:31:06.509009 Epoch 1568, Training loss 116.05840301513672\n",
      "R2 values 0.9597, 0.8401, 0.8556; mean R2=0.8851\n",
      "Validation Error: Avg loss: 472.495392 \n",
      "\n",
      "2023-11-08 13:31:07.004096 Epoch 1569, Training loss 115.3663330078125\n",
      "R2 values 0.9469, 0.8408, 0.8928; mean R2=0.8935\n",
      "Validation Error: Avg loss: 433.857269 \n",
      "\n",
      "2023-11-08 13:31:07.494939 Epoch 1570, Training loss 137.6397705078125\n",
      "R2 values 0.9616, 0.8480, 0.8666; mean R2=0.8920\n",
      "Validation Error: Avg loss: 424.432587 \n",
      "\n",
      "2023-11-08 13:31:08.205420 Epoch 1571, Training loss 105.96961212158203\n",
      "R2 values 0.9459, 0.8121, 0.8801; mean R2=0.8794\n",
      "Validation Error: Avg loss: 555.550476 \n",
      "\n",
      "2023-11-08 13:31:08.746903 Epoch 1572, Training loss 105.33988952636719\n",
      "R2 values 0.9520, 0.8134, 0.8916; mean R2=0.8857\n",
      "Validation Error: Avg loss: 475.493683 \n",
      "\n",
      "2023-11-08 13:31:09.222153 Epoch 1573, Training loss 112.71996307373047\n",
      "R2 values 0.9580, 0.8381, 0.8954; mean R2=0.8972\n",
      "Validation Error: Avg loss: 372.978943 \n",
      "\n",
      "2023-11-08 13:31:09.715269 Epoch 1574, Training loss 75.0028305053711\n",
      "R2 values 0.9373, 0.7934, 0.8667; mean R2=0.8658\n",
      "Validation Error: Avg loss: 508.713623 \n",
      "\n",
      "2023-11-08 13:31:10.205886 Epoch 1575, Training loss 112.52388000488281\n",
      "R2 values 0.9439, 0.8001, 0.8783; mean R2=0.8741\n",
      "Validation Error: Avg loss: 532.967163 \n",
      "\n",
      "2023-11-08 13:31:10.693638 Epoch 1576, Training loss 124.15003967285156\n",
      "R2 values 0.9542, 0.8278, 0.8671; mean R2=0.8830\n",
      "Validation Error: Avg loss: 448.065399 \n",
      "\n",
      "2023-11-08 13:31:11.190003 Epoch 1577, Training loss 89.87252044677734\n",
      "R2 values 0.9560, 0.8179, 0.8973; mean R2=0.8904\n",
      "Validation Error: Avg loss: 399.766113 \n",
      "\n",
      "2023-11-08 13:31:11.662860 Epoch 1578, Training loss 99.81670379638672\n",
      "R2 values 0.9460, 0.8231, 0.8769; mean R2=0.8820\n",
      "Validation Error: Avg loss: 464.943542 \n",
      "\n",
      "2023-11-08 13:31:12.148786 Epoch 1579, Training loss 82.49398040771484\n",
      "R2 values 0.9541, 0.8527, 0.8898; mean R2=0.8989\n",
      "Validation Error: Avg loss: 387.812195 \n",
      "\n",
      "2023-11-08 13:31:12.639326 Epoch 1580, Training loss 102.95744323730469\n",
      "R2 values 0.9485, 0.8488, 0.8906; mean R2=0.8960\n",
      "Validation Error: Avg loss: 487.359924 \n",
      "\n",
      "2023-11-08 13:31:13.113246 Epoch 1581, Training loss 110.36390686035156\n",
      "R2 values 0.9577, 0.8433, 0.9010; mean R2=0.9007\n",
      "Validation Error: Avg loss: 507.376160 \n",
      "\n",
      "2023-11-08 13:31:13.590717 Epoch 1582, Training loss 87.16576385498047\n",
      "R2 values 0.9563, 0.8161, 0.8899; mean R2=0.8874\n",
      "Validation Error: Avg loss: 395.693970 \n",
      "\n",
      "2023-11-08 13:31:14.066310 Epoch 1583, Training loss 68.6304931640625\n",
      "R2 values 0.9483, 0.8217, 0.9062; mean R2=0.8921\n",
      "Validation Error: Avg loss: 420.329285 \n",
      "\n",
      "2023-11-08 13:31:14.538370 Epoch 1584, Training loss 82.40081024169922\n",
      "R2 values 0.9444, 0.8650, 0.8571; mean R2=0.8889\n",
      "Validation Error: Avg loss: 525.215515 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:31:15.015305 Epoch 1585, Training loss 94.09825897216797\n",
      "R2 values 0.9402, 0.8226, 0.8964; mean R2=0.8864\n",
      "Validation Error: Avg loss: 526.011353 \n",
      "\n",
      "2023-11-08 13:31:15.492485 Epoch 1586, Training loss 84.2928695678711\n",
      "R2 values 0.9458, 0.8789, 0.8700; mean R2=0.8983\n",
      "Validation Error: Avg loss: 514.228882 \n",
      "\n",
      "2023-11-08 13:31:16.061548 Epoch 1587, Training loss 94.21589660644531\n",
      "R2 values 0.9509, 0.8656, 0.8985; mean R2=0.9050\n",
      "Validation Error: Avg loss: 432.786346 \n",
      "\n",
      "2023-11-08 13:31:16.591614 Epoch 1588, Training loss 79.4885025024414\n",
      "R2 values 0.9519, 0.8542, 0.9046; mean R2=0.9036\n",
      "Validation Error: Avg loss: 426.384338 \n",
      "\n",
      "2023-11-08 13:31:17.072531 Epoch 1589, Training loss 76.83616638183594\n",
      "R2 values 0.9430, 0.8541, 0.8799; mean R2=0.8923\n",
      "Validation Error: Avg loss: 480.152466 \n",
      "\n",
      "2023-11-08 13:31:17.556877 Epoch 1590, Training loss 68.13670349121094\n",
      "R2 values 0.9368, 0.8338, 0.8731; mean R2=0.8812\n",
      "Validation Error: Avg loss: 594.280457 \n",
      "\n",
      "2023-11-08 13:31:18.049388 Epoch 1591, Training loss 86.97588348388672\n",
      "R2 values 0.9541, 0.8326, 0.8716; mean R2=0.8861\n",
      "Validation Error: Avg loss: 477.732697 \n",
      "\n",
      "2023-11-08 13:31:18.533893 Epoch 1592, Training loss 73.60375213623047\n",
      "R2 values 0.9481, 0.8628, 0.8593; mean R2=0.8901\n",
      "Validation Error: Avg loss: 468.399841 \n",
      "\n",
      "2023-11-08 13:31:19.021796 Epoch 1593, Training loss 90.63394165039062\n",
      "R2 values 0.9390, 0.8142, 0.8758; mean R2=0.8763\n",
      "Validation Error: Avg loss: 513.391052 \n",
      "\n",
      "2023-11-08 13:31:19.498372 Epoch 1594, Training loss 90.83802795410156\n",
      "R2 values 0.9526, 0.8445, 0.8951; mean R2=0.8974\n",
      "Validation Error: Avg loss: 516.782837 \n",
      "\n",
      "2023-11-08 13:31:19.987262 Epoch 1595, Training loss 86.77184295654297\n",
      "R2 values 0.9412, 0.8410, 0.9151; mean R2=0.8991\n",
      "Validation Error: Avg loss: 583.593445 \n",
      "\n",
      "2023-11-08 13:31:20.482379 Epoch 1596, Training loss 131.6312255859375\n",
      "R2 values 0.9494, 0.8483, 0.8979; mean R2=0.8985\n",
      "Validation Error: Avg loss: 396.551758 \n",
      "\n",
      "2023-11-08 13:31:20.957016 Epoch 1597, Training loss 104.9517593383789\n",
      "R2 values 0.9622, 0.8254, 0.8934; mean R2=0.8937\n",
      "Validation Error: Avg loss: 338.536530 \n",
      "\n",
      "2023-11-08 13:31:21.440403 Epoch 1598, Training loss 77.03175354003906\n",
      "R2 values 0.9469, 0.8448, 0.8931; mean R2=0.8949\n",
      "Validation Error: Avg loss: 452.392120 \n",
      "\n",
      "2023-11-08 13:31:21.909799 Epoch 1599, Training loss 68.45149993896484\n",
      "R2 values 0.9487, 0.8280, 0.8761; mean R2=0.8843\n",
      "Validation Error: Avg loss: 569.935242 \n",
      "\n",
      "2023-11-08 13:31:22.381065 Epoch 1600, Training loss 64.21360778808594\n",
      "R2 values 0.9524, 0.8469, 0.8806; mean R2=0.8933\n",
      "Validation Error: Avg loss: 506.100311 \n",
      "\n",
      "2023-11-08 13:31:22.860078 Epoch 1601, Training loss 82.6044692993164\n",
      "R2 values 0.9561, 0.8397, 0.8874; mean R2=0.8944\n",
      "Validation Error: Avg loss: 377.424622 \n",
      "\n",
      "2023-11-08 13:31:23.335738 Epoch 1602, Training loss 79.25596618652344\n",
      "R2 values 0.9485, 0.8437, 0.8596; mean R2=0.8839\n",
      "Validation Error: Avg loss: 426.748383 \n",
      "\n",
      "2023-11-08 13:31:23.841397 Epoch 1603, Training loss 92.33349609375\n",
      "R2 values 0.9627, 0.8113, 0.8684; mean R2=0.8808\n",
      "Validation Error: Avg loss: 377.822052 \n",
      "\n",
      "2023-11-08 13:31:24.315588 Epoch 1604, Training loss 69.8899917602539\n",
      "R2 values 0.9463, 0.8531, 0.9139; mean R2=0.9044\n",
      "Validation Error: Avg loss: 573.375000 \n",
      "\n",
      "2023-11-08 13:31:24.797787 Epoch 1605, Training loss 99.65308380126953\n",
      "R2 values 0.9535, 0.8205, 0.8764; mean R2=0.8835\n",
      "Validation Error: Avg loss: 497.168091 \n",
      "\n",
      "2023-11-08 13:31:25.273689 Epoch 1606, Training loss 59.28883743286133\n",
      "R2 values 0.9458, 0.8415, 0.8776; mean R2=0.8883\n",
      "Validation Error: Avg loss: 451.921631 \n",
      "\n",
      "2023-11-08 13:31:25.806327 Epoch 1607, Training loss 82.54171752929688\n",
      "R2 values 0.9488, 0.8439, 0.8779; mean R2=0.8902\n",
      "Validation Error: Avg loss: 428.780212 \n",
      "\n",
      "2023-11-08 13:31:26.317031 Epoch 1608, Training loss 84.85748291015625\n",
      "R2 values 0.9512, 0.8394, 0.8930; mean R2=0.8945\n",
      "Validation Error: Avg loss: 443.668732 \n",
      "\n",
      "2023-11-08 13:31:26.802245 Epoch 1609, Training loss 100.61354064941406\n",
      "R2 values 0.9561, 0.8239, 0.8865; mean R2=0.8888\n",
      "Validation Error: Avg loss: 408.706421 \n",
      "\n",
      "2023-11-08 13:31:27.276415 Epoch 1610, Training loss 61.02983093261719\n",
      "R2 values 0.9655, 0.8586, 0.8875; mean R2=0.9039\n",
      "Validation Error: Avg loss: 380.080353 \n",
      "\n",
      "2023-11-08 13:31:27.767991 Epoch 1611, Training loss 68.45323181152344\n",
      "R2 values 0.9473, 0.8169, 0.9055; mean R2=0.8899\n",
      "Validation Error: Avg loss: 455.364807 \n",
      "\n",
      "2023-11-08 13:31:28.254378 Epoch 1612, Training loss 79.8705062866211\n",
      "R2 values 0.9432, 0.8527, 0.8834; mean R2=0.8931\n",
      "Validation Error: Avg loss: 453.873199 \n",
      "\n",
      "2023-11-08 13:31:28.737025 Epoch 1613, Training loss 88.38113403320312\n",
      "R2 values 0.9363, 0.8497, 0.8932; mean R2=0.8931\n",
      "Validation Error: Avg loss: 565.469727 \n",
      "\n",
      "2023-11-08 13:31:29.230054 Epoch 1614, Training loss 99.44141387939453\n",
      "R2 values 0.9465, 0.8558, 0.8942; mean R2=0.8988\n",
      "Validation Error: Avg loss: 506.235565 \n",
      "\n",
      "2023-11-08 13:31:29.704652 Epoch 1615, Training loss 91.56580352783203\n",
      "R2 values 0.9557, 0.8481, 0.8835; mean R2=0.8957\n",
      "Validation Error: Avg loss: 397.041473 \n",
      "\n",
      "2023-11-08 13:31:30.181214 Epoch 1616, Training loss 89.1932601928711\n",
      "R2 values 0.9612, 0.8303, 0.9142; mean R2=0.9019\n",
      "Validation Error: Avg loss: 419.574982 \n",
      "\n",
      "2023-11-08 13:31:30.671502 Epoch 1617, Training loss 122.83992004394531\n",
      "R2 values 0.9621, 0.8212, 0.8794; mean R2=0.8876\n",
      "Validation Error: Avg loss: 477.252533 \n",
      "\n",
      "2023-11-08 13:31:31.151948 Epoch 1618, Training loss 141.31727600097656\n",
      "R2 values 0.9557, 0.8220, 0.8872; mean R2=0.8883\n",
      "Validation Error: Avg loss: 429.360077 \n",
      "\n",
      "2023-11-08 13:31:31.634207 Epoch 1619, Training loss 76.86304473876953\n",
      "R2 values 0.9635, 0.8271, 0.8895; mean R2=0.8934\n",
      "Validation Error: Avg loss: 362.649780 \n",
      "\n",
      "2023-11-08 13:31:32.108423 Epoch 1620, Training loss 95.8914566040039\n",
      "R2 values 0.9502, 0.8402, 0.8975; mean R2=0.8960\n",
      "Validation Error: Avg loss: 398.370667 \n",
      "\n",
      "2023-11-08 13:31:32.755110 Epoch 1621, Training loss 105.05003356933594\n",
      "R2 values 0.9496, 0.8074, 0.8630; mean R2=0.8733\n",
      "Validation Error: Avg loss: 443.356598 \n",
      "\n",
      "2023-11-08 13:31:33.304983 Epoch 1622, Training loss 108.2318344116211\n",
      "R2 values 0.9342, 0.7968, 0.8991; mean R2=0.8767\n",
      "Validation Error: Avg loss: 700.059814 \n",
      "\n",
      "2023-11-08 13:31:33.795157 Epoch 1623, Training loss 111.69408416748047\n",
      "R2 values 0.9498, 0.8296, 0.9015; mean R2=0.8936\n",
      "Validation Error: Avg loss: 554.140564 \n",
      "\n",
      "2023-11-08 13:31:34.275354 Epoch 1624, Training loss 149.98892211914062\n",
      "R2 values 0.9500, 0.8253, 0.9067; mean R2=0.8940\n",
      "Validation Error: Avg loss: 406.684235 \n",
      "\n",
      "2023-11-08 13:31:34.756211 Epoch 1625, Training loss 68.8991928100586\n",
      "R2 values 0.9598, 0.8803, 0.8812; mean R2=0.9071\n",
      "Validation Error: Avg loss: 345.953064 \n",
      "\n",
      "2023-11-08 13:31:35.232338 Epoch 1626, Training loss 123.427978515625\n",
      "R2 values 0.9484, 0.8409, 0.8964; mean R2=0.8952\n",
      "Validation Error: Avg loss: 420.697876 \n",
      "\n",
      "2023-11-08 13:31:35.770389 Epoch 1627, Training loss 119.80056762695312\n",
      "R2 values 0.9489, 0.8349, 0.9110; mean R2=0.8983\n",
      "Validation Error: Avg loss: 496.464996 \n",
      "\n",
      "2023-11-08 13:31:36.246917 Epoch 1628, Training loss 97.9415512084961\n",
      "R2 values 0.9484, 0.8342, 0.8894; mean R2=0.8907\n",
      "Validation Error: Avg loss: 574.201843 \n",
      "\n",
      "2023-11-08 13:31:36.716100 Epoch 1629, Training loss 118.3674545288086\n",
      "R2 values 0.9559, 0.8649, 0.8842; mean R2=0.9017\n",
      "Validation Error: Avg loss: 454.222931 \n",
      "\n",
      "2023-11-08 13:31:37.194789 Epoch 1630, Training loss 119.5780258178711\n",
      "R2 values 0.9520, 0.8321, 0.9002; mean R2=0.8948\n",
      "Validation Error: Avg loss: 387.833740 \n",
      "\n",
      "2023-11-08 13:31:37.681177 Epoch 1631, Training loss 119.8743667602539\n",
      "R2 values 0.9462, 0.8546, 0.8970; mean R2=0.8993\n",
      "Validation Error: Avg loss: 436.094177 \n",
      "\n",
      "2023-11-08 13:31:38.150459 Epoch 1632, Training loss 92.35711669921875\n",
      "R2 values 0.9467, 0.8328, 0.8833; mean R2=0.8876\n",
      "Validation Error: Avg loss: 582.885742 \n",
      "\n",
      "2023-11-08 13:31:38.633558 Epoch 1633, Training loss 94.96361541748047\n",
      "R2 values 0.9429, 0.7735, 0.8690; mean R2=0.8618\n",
      "Validation Error: Avg loss: 540.756592 \n",
      "\n",
      "2023-11-08 13:31:39.114709 Epoch 1634, Training loss 94.1679916381836\n",
      "R2 values 0.9451, 0.8103, 0.8760; mean R2=0.8772\n",
      "Validation Error: Avg loss: 505.857086 \n",
      "\n",
      "2023-11-08 13:31:39.586478 Epoch 1635, Training loss 80.81517791748047\n",
      "R2 values 0.9525, 0.8380, 0.8897; mean R2=0.8934\n",
      "Validation Error: Avg loss: 403.418945 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:31:40.059833 Epoch 1636, Training loss 100.83221435546875\n",
      "R2 values 0.9531, 0.8487, 0.8947; mean R2=0.8988\n",
      "Validation Error: Avg loss: 418.080231 \n",
      "\n",
      "2023-11-08 13:31:40.547435 Epoch 1637, Training loss 89.14922332763672\n",
      "R2 values 0.9496, 0.8293, 0.9096; mean R2=0.8962\n",
      "Validation Error: Avg loss: 513.205750 \n",
      "\n",
      "2023-11-08 13:31:41.131702 Epoch 1638, Training loss 98.65996551513672\n",
      "R2 values 0.9491, 0.8751, 0.9062; mean R2=0.9101\n",
      "Validation Error: Avg loss: 470.914978 \n",
      "\n",
      "2023-11-08 13:31:41.733800 Epoch 1639, Training loss 87.99018096923828\n",
      "R2 values 0.9392, 0.8196, 0.8993; mean R2=0.8860\n",
      "Validation Error: Avg loss: 506.186279 \n",
      "\n",
      "2023-11-08 13:31:42.210564 Epoch 1640, Training loss 74.39391326904297\n",
      "R2 values 0.9389, 0.8469, 0.9018; mean R2=0.8959\n",
      "Validation Error: Avg loss: 495.558411 \n",
      "\n",
      "2023-11-08 13:31:42.698957 Epoch 1641, Training loss 85.47087097167969\n",
      "R2 values 0.9544, 0.8653, 0.8993; mean R2=0.9063\n",
      "Validation Error: Avg loss: 420.588562 \n",
      "\n",
      "2023-11-08 13:31:43.175386 Epoch 1642, Training loss 88.85870361328125\n",
      "R2 values 0.9539, 0.8455, 0.8660; mean R2=0.8885\n",
      "Validation Error: Avg loss: 463.414490 \n",
      "\n",
      "2023-11-08 13:31:43.653056 Epoch 1643, Training loss 100.8351821899414\n",
      "R2 values 0.9569, 0.8379, 0.8445; mean R2=0.8797\n",
      "Validation Error: Avg loss: 473.414154 \n",
      "\n",
      "2023-11-08 13:31:44.146752 Epoch 1644, Training loss 74.09971618652344\n",
      "R2 values 0.9555, 0.8742, 0.8836; mean R2=0.9044\n",
      "Validation Error: Avg loss: 402.993713 \n",
      "\n",
      "2023-11-08 13:31:44.633779 Epoch 1645, Training loss 66.798583984375\n",
      "R2 values 0.9541, 0.8714, 0.8955; mean R2=0.9070\n",
      "Validation Error: Avg loss: 391.647583 \n",
      "\n",
      "2023-11-08 13:31:45.109284 Epoch 1646, Training loss 71.58417510986328\n",
      "R2 values 0.9583, 0.8349, 0.8781; mean R2=0.8904\n",
      "Validation Error: Avg loss: 413.707428 \n",
      "\n",
      "2023-11-08 13:31:45.591685 Epoch 1647, Training loss 78.1952133178711\n",
      "R2 values 0.9567, 0.8726, 0.9064; mean R2=0.9119\n",
      "Validation Error: Avg loss: 437.497589 \n",
      "\n",
      "2023-11-08 13:31:46.070973 Epoch 1648, Training loss 83.43995666503906\n",
      "R2 values 0.9501, 0.8184, 0.9041; mean R2=0.8909\n",
      "Validation Error: Avg loss: 432.334412 \n",
      "\n",
      "2023-11-08 13:31:46.545073 Epoch 1649, Training loss 71.93318176269531\n",
      "R2 values 0.9464, 0.8272, 0.9040; mean R2=0.8926\n",
      "Validation Error: Avg loss: 475.132111 \n",
      "\n",
      "2023-11-08 13:31:47.022219 Epoch 1650, Training loss 83.42691040039062\n",
      "R2 values 0.9455, 0.8375, 0.8852; mean R2=0.8894\n",
      "Validation Error: Avg loss: 470.351654 \n",
      "\n",
      "2023-11-08 13:31:47.512047 Epoch 1651, Training loss 72.82676696777344\n",
      "R2 values 0.9409, 0.8304, 0.9197; mean R2=0.8970\n",
      "Validation Error: Avg loss: 504.614807 \n",
      "\n",
      "2023-11-08 13:31:47.998870 Epoch 1652, Training loss 83.49052429199219\n",
      "R2 values 0.9454, 0.8163, 0.9209; mean R2=0.8942\n",
      "Validation Error: Avg loss: 553.178894 \n",
      "\n",
      "2023-11-08 13:31:48.480824 Epoch 1653, Training loss 86.7791519165039\n",
      "R2 values 0.9474, 0.8387, 0.8973; mean R2=0.8945\n",
      "Validation Error: Avg loss: 523.236206 \n",
      "\n",
      "2023-11-08 13:31:48.972352 Epoch 1654, Training loss 81.0423355102539\n",
      "R2 values 0.9460, 0.8340, 0.8862; mean R2=0.8887\n",
      "Validation Error: Avg loss: 475.682922 \n",
      "\n",
      "2023-11-08 13:31:49.451302 Epoch 1655, Training loss 112.20283508300781\n",
      "R2 values 0.9606, 0.8277, 0.9094; mean R2=0.8993\n",
      "Validation Error: Avg loss: 396.107635 \n",
      "\n",
      "2023-11-08 13:31:49.924665 Epoch 1656, Training loss 76.59375\n",
      "R2 values 0.9458, 0.8258, 0.8864; mean R2=0.8860\n",
      "Validation Error: Avg loss: 528.319641 \n",
      "\n",
      "2023-11-08 13:31:50.540757 Epoch 1657, Training loss 82.72700500488281\n",
      "R2 values 0.9532, 0.8342, 0.9016; mean R2=0.8964\n",
      "Validation Error: Avg loss: 437.572327 \n",
      "\n",
      "2023-11-08 13:31:51.072611 Epoch 1658, Training loss 86.03463745117188\n",
      "R2 values 0.9450, 0.8010, 0.8957; mean R2=0.8806\n",
      "Validation Error: Avg loss: 511.819733 \n",
      "\n",
      "2023-11-08 13:31:51.553461 Epoch 1659, Training loss 64.8068618774414\n",
      "R2 values 0.9480, 0.8374, 0.9053; mean R2=0.8969\n",
      "Validation Error: Avg loss: 486.028046 \n",
      "\n",
      "2023-11-08 13:31:52.041871 Epoch 1660, Training loss 101.60342407226562\n",
      "R2 values 0.9528, 0.8539, 0.9041; mean R2=0.9036\n",
      "Validation Error: Avg loss: 486.659760 \n",
      "\n",
      "2023-11-08 13:31:52.523033 Epoch 1661, Training loss 86.47472381591797\n",
      "R2 values 0.9426, 0.8299, 0.8730; mean R2=0.8818\n",
      "Validation Error: Avg loss: 641.026245 \n",
      "\n",
      "2023-11-08 13:31:53.006802 Epoch 1662, Training loss 96.04666900634766\n",
      "R2 values 0.9411, 0.8158, 0.8833; mean R2=0.8800\n",
      "Validation Error: Avg loss: 497.234863 \n",
      "\n",
      "2023-11-08 13:31:53.503623 Epoch 1663, Training loss 84.41358947753906\n",
      "R2 values 0.9525, 0.8627, 0.8782; mean R2=0.8978\n",
      "Validation Error: Avg loss: 396.618011 \n",
      "\n",
      "2023-11-08 13:31:54.008659 Epoch 1664, Training loss 91.59339904785156\n",
      "R2 values 0.9549, 0.8340, 0.9010; mean R2=0.8966\n",
      "Validation Error: Avg loss: 400.674561 \n",
      "\n",
      "2023-11-08 13:31:54.517095 Epoch 1665, Training loss 80.9240493774414\n",
      "R2 values 0.9558, 0.8291, 0.8757; mean R2=0.8869\n",
      "Validation Error: Avg loss: 521.541016 \n",
      "\n",
      "2023-11-08 13:31:54.998726 Epoch 1666, Training loss 105.01904296875\n",
      "R2 values 0.9587, 0.8516, 0.8895; mean R2=0.9000\n",
      "Validation Error: Avg loss: 411.413483 \n",
      "\n",
      "2023-11-08 13:31:55.474738 Epoch 1667, Training loss 96.65746307373047\n",
      "R2 values 0.9548, 0.8538, 0.8743; mean R2=0.8943\n",
      "Validation Error: Avg loss: 404.706390 \n",
      "\n",
      "2023-11-08 13:31:55.954962 Epoch 1668, Training loss 82.41610717773438\n",
      "R2 values 0.9459, 0.8484, 0.8997; mean R2=0.8980\n",
      "Validation Error: Avg loss: 450.376434 \n",
      "\n",
      "2023-11-08 13:31:56.433129 Epoch 1669, Training loss 94.53619384765625\n",
      "R2 values 0.9417, 0.8399, 0.8747; mean R2=0.8854\n",
      "Validation Error: Avg loss: 479.131561 \n",
      "\n",
      "2023-11-08 13:31:56.911896 Epoch 1670, Training loss 75.42841339111328\n",
      "R2 values 0.9467, 0.8012, 0.8834; mean R2=0.8771\n",
      "Validation Error: Avg loss: 502.601868 \n",
      "\n",
      "2023-11-08 13:31:57.392177 Epoch 1671, Training loss 82.6741714477539\n",
      "R2 values 0.9525, 0.8396, 0.8768; mean R2=0.8897\n",
      "Validation Error: Avg loss: 554.713806 \n",
      "\n",
      "2023-11-08 13:31:57.885480 Epoch 1672, Training loss 76.18061828613281\n",
      "R2 values 0.9388, 0.8808, 0.9131; mean R2=0.9109\n",
      "Validation Error: Avg loss: 549.793823 \n",
      "\n",
      "2023-11-08 13:31:58.375257 Epoch 1673, Training loss 75.2353515625\n",
      "R2 values 0.9502, 0.8473, 0.8915; mean R2=0.8963\n",
      "Validation Error: Avg loss: 454.915833 \n",
      "\n",
      "2023-11-08 13:31:58.905386 Epoch 1674, Training loss 83.90419006347656\n",
      "R2 values 0.9479, 0.8195, 0.9116; mean R2=0.8930\n",
      "Validation Error: Avg loss: 410.315826 \n",
      "\n",
      "2023-11-08 13:31:59.438929 Epoch 1675, Training loss 86.4871826171875\n",
      "R2 values 0.9593, 0.8883, 0.8851; mean R2=0.9109\n",
      "Validation Error: Avg loss: 363.694855 \n",
      "\n",
      "2023-11-08 13:31:59.991352 Epoch 1676, Training loss 75.97554016113281\n",
      "R2 values 0.9591, 0.8363, 0.9002; mean R2=0.8986\n",
      "Validation Error: Avg loss: 420.512115 \n",
      "\n",
      "2023-11-08 13:32:00.470385 Epoch 1677, Training loss 82.32440185546875\n",
      "R2 values 0.9443, 0.8348, 0.9232; mean R2=0.9008\n",
      "Validation Error: Avg loss: 578.073853 \n",
      "\n",
      "2023-11-08 13:32:00.953789 Epoch 1678, Training loss 87.02315521240234\n",
      "R2 values 0.9469, 0.8077, 0.9056; mean R2=0.8867\n",
      "Validation Error: Avg loss: 499.669464 \n",
      "\n",
      "2023-11-08 13:32:01.435697 Epoch 1679, Training loss 63.63125228881836\n",
      "R2 values 0.9507, 0.8535, 0.8989; mean R2=0.9010\n",
      "Validation Error: Avg loss: 432.255127 \n",
      "\n",
      "2023-11-08 13:32:01.968141 Epoch 1680, Training loss 60.711181640625\n",
      "R2 values 0.9502, 0.8621, 0.9042; mean R2=0.9055\n",
      "Validation Error: Avg loss: 397.685211 \n",
      "\n",
      "2023-11-08 13:32:02.493480 Epoch 1681, Training loss 77.97074127197266\n",
      "R2 values 0.9523, 0.8168, 0.8861; mean R2=0.8851\n",
      "Validation Error: Avg loss: 409.585602 \n",
      "\n",
      "2023-11-08 13:32:02.978371 Epoch 1682, Training loss 74.7574234008789\n",
      "R2 values 0.9575, 0.8366, 0.8885; mean R2=0.8942\n",
      "Validation Error: Avg loss: 410.600250 \n",
      "\n",
      "2023-11-08 13:32:03.456641 Epoch 1683, Training loss 74.5247802734375\n",
      "R2 values 0.9475, 0.8304, 0.9115; mean R2=0.8965\n",
      "Validation Error: Avg loss: 460.332306 \n",
      "\n",
      "2023-11-08 13:32:03.939506 Epoch 1684, Training loss 63.6705436706543\n",
      "R2 values 0.9569, 0.8431, 0.8998; mean R2=0.8999\n",
      "Validation Error: Avg loss: 385.867615 \n",
      "\n",
      "2023-11-08 13:32:04.412700 Epoch 1685, Training loss 77.27852630615234\n",
      "R2 values 0.9522, 0.8628, 0.8963; mean R2=0.9037\n",
      "Validation Error: Avg loss: 390.671906 \n",
      "\n",
      "2023-11-08 13:32:04.890466 Epoch 1686, Training loss 81.01222229003906\n",
      "R2 values 0.9501, 0.8353, 0.8989; mean R2=0.8948\n",
      "Validation Error: Avg loss: 444.602081 \n",
      "\n",
      "2023-11-08 13:32:05.364523 Epoch 1687, Training loss 85.4410400390625\n",
      "R2 values 0.9558, 0.8620, 0.8594; mean R2=0.8924\n",
      "Validation Error: Avg loss: 422.802765 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:32:05.856826 Epoch 1688, Training loss 60.818538665771484\n",
      "R2 values 0.9468, 0.8412, 0.9122; mean R2=0.9001\n",
      "Validation Error: Avg loss: 462.781555 \n",
      "\n",
      "2023-11-08 13:32:06.338605 Epoch 1689, Training loss 76.07344055175781\n",
      "R2 values 0.9457, 0.8453, 0.8579; mean R2=0.8830\n",
      "Validation Error: Avg loss: 506.501160 \n",
      "\n",
      "2023-11-08 13:32:06.821328 Epoch 1690, Training loss 80.53321838378906\n",
      "R2 values 0.9393, 0.8597, 0.8953; mean R2=0.8981\n",
      "Validation Error: Avg loss: 661.418701 \n",
      "\n",
      "2023-11-08 13:32:07.582810 Epoch 1691, Training loss 89.17701721191406\n",
      "R2 values 0.9483, 0.8489, 0.8843; mean R2=0.8938\n",
      "Validation Error: Avg loss: 513.194397 \n",
      "\n",
      "2023-11-08 13:32:08.082047 Epoch 1692, Training loss 84.15596008300781\n",
      "R2 values 0.9564, 0.8475, 0.8863; mean R2=0.8968\n",
      "Validation Error: Avg loss: 386.839783 \n",
      "\n",
      "2023-11-08 13:32:08.578816 Epoch 1693, Training loss 66.7990951538086\n",
      "R2 values 0.9586, 0.8567, 0.8927; mean R2=0.9027\n",
      "Validation Error: Avg loss: 363.887177 \n",
      "\n",
      "2023-11-08 13:32:09.079074 Epoch 1694, Training loss 105.34140014648438\n",
      "R2 values 0.9487, 0.8474, 0.8970; mean R2=0.8977\n",
      "Validation Error: Avg loss: 467.553589 \n",
      "\n",
      "2023-11-08 13:32:09.567590 Epoch 1695, Training loss 67.78065490722656\n",
      "R2 values 0.9461, 0.8363, 0.9171; mean R2=0.8998\n",
      "Validation Error: Avg loss: 558.048889 \n",
      "\n",
      "2023-11-08 13:32:10.051048 Epoch 1696, Training loss 110.55186462402344\n",
      "R2 values 0.9469, 0.8318, 0.8894; mean R2=0.8893\n",
      "Validation Error: Avg loss: 467.296997 \n",
      "\n",
      "2023-11-08 13:32:10.528700 Epoch 1697, Training loss 55.41502380371094\n",
      "R2 values 0.9560, 0.8257, 0.8885; mean R2=0.8901\n",
      "Validation Error: Avg loss: 397.693817 \n",
      "\n",
      "2023-11-08 13:32:11.031453 Epoch 1698, Training loss 103.78470611572266\n",
      "R2 values 0.9482, 0.8482, 0.8869; mean R2=0.8944\n",
      "Validation Error: Avg loss: 431.184662 \n",
      "\n",
      "2023-11-08 13:32:11.518585 Epoch 1699, Training loss 72.4382553100586\n",
      "R2 values 0.9488, 0.8590, 0.8750; mean R2=0.8943\n",
      "Validation Error: Avg loss: 504.687805 \n",
      "\n",
      "2023-11-08 13:32:11.994421 Epoch 1700, Training loss 105.30024719238281\n",
      "R2 values 0.9474, 0.8397, 0.8752; mean R2=0.8874\n",
      "Validation Error: Avg loss: 520.860596 \n",
      "\n",
      "2023-11-08 13:32:12.470885 Epoch 1701, Training loss 79.04547119140625\n",
      "R2 values 0.9493, 0.8095, 0.8988; mean R2=0.8858\n",
      "Validation Error: Avg loss: 469.357422 \n",
      "\n",
      "2023-11-08 13:32:12.956430 Epoch 1702, Training loss 98.78130340576172\n",
      "R2 values 0.9566, 0.8400, 0.8826; mean R2=0.8930\n",
      "Validation Error: Avg loss: 387.404877 \n",
      "\n",
      "2023-11-08 13:32:13.438778 Epoch 1703, Training loss 85.91475677490234\n",
      "R2 values 0.9517, 0.8257, 0.8999; mean R2=0.8924\n",
      "Validation Error: Avg loss: 465.172760 \n",
      "\n",
      "2023-11-08 13:32:13.926653 Epoch 1704, Training loss 71.20072937011719\n",
      "R2 values 0.9453, 0.8341, 0.9053; mean R2=0.8949\n",
      "Validation Error: Avg loss: 479.895660 \n",
      "\n",
      "2023-11-08 13:32:14.466665 Epoch 1705, Training loss 111.52469635009766\n",
      "R2 values 0.9485, 0.8609, 0.8902; mean R2=0.8999\n",
      "Validation Error: Avg loss: 451.401947 \n",
      "\n",
      "2023-11-08 13:32:14.942591 Epoch 1706, Training loss 71.06227111816406\n",
      "R2 values 0.9530, 0.8477, 0.8929; mean R2=0.8979\n",
      "Validation Error: Avg loss: 404.929321 \n",
      "\n",
      "2023-11-08 13:32:15.431995 Epoch 1707, Training loss 62.759605407714844\n",
      "R2 values 0.9443, 0.8376, 0.9129; mean R2=0.8983\n",
      "Validation Error: Avg loss: 493.159943 \n",
      "\n",
      "2023-11-08 13:32:15.915228 Epoch 1708, Training loss 81.45637512207031\n",
      "R2 values 0.9606, 0.8416, 0.9194; mean R2=0.9072\n",
      "Validation Error: Avg loss: 408.192871 \n",
      "\n",
      "2023-11-08 13:32:16.399816 Epoch 1709, Training loss 72.03348541259766\n",
      "R2 values 0.9541, 0.8415, 0.8864; mean R2=0.8940\n",
      "Validation Error: Avg loss: 420.854919 \n",
      "\n",
      "2023-11-08 13:32:17.065159 Epoch 1710, Training loss 72.34532165527344\n",
      "R2 values 0.9429, 0.8592, 0.9066; mean R2=0.9029\n",
      "Validation Error: Avg loss: 455.568604 \n",
      "\n",
      "2023-11-08 13:32:17.544473 Epoch 1711, Training loss 71.34516906738281\n",
      "R2 values 0.9482, 0.8066, 0.8994; mean R2=0.8847\n",
      "Validation Error: Avg loss: 423.906036 \n",
      "\n",
      "2023-11-08 13:32:18.042497 Epoch 1712, Training loss 80.92037200927734\n",
      "R2 values 0.9547, 0.8396, 0.9035; mean R2=0.8993\n",
      "Validation Error: Avg loss: 443.686157 \n",
      "\n",
      "2023-11-08 13:32:18.523254 Epoch 1713, Training loss 55.464378356933594\n",
      "R2 values 0.9521, 0.8666, 0.8749; mean R2=0.8979\n",
      "Validation Error: Avg loss: 513.995422 \n",
      "\n",
      "2023-11-08 13:32:19.020335 Epoch 1714, Training loss 66.3045654296875\n",
      "R2 values 0.9531, 0.8479, 0.8652; mean R2=0.8887\n",
      "Validation Error: Avg loss: 430.962830 \n",
      "\n",
      "2023-11-08 13:32:19.499834 Epoch 1715, Training loss 82.35325622558594\n",
      "R2 values 0.9543, 0.8279, 0.8901; mean R2=0.8908\n",
      "Validation Error: Avg loss: 399.126648 \n",
      "\n",
      "2023-11-08 13:32:19.974473 Epoch 1716, Training loss 86.77617645263672\n",
      "R2 values 0.9599, 0.8226, 0.8936; mean R2=0.8920\n",
      "Validation Error: Avg loss: 347.988068 \n",
      "\n",
      "2023-11-08 13:32:20.454180 Epoch 1717, Training loss 94.36448669433594\n",
      "R2 values 0.9366, 0.8407, 0.9150; mean R2=0.8974\n",
      "Validation Error: Avg loss: 577.250488 \n",
      "\n",
      "2023-11-08 13:32:20.958928 Epoch 1718, Training loss 105.38299560546875\n",
      "R2 values 0.9492, 0.8451, 0.9117; mean R2=0.9020\n",
      "Validation Error: Avg loss: 464.583771 \n",
      "\n",
      "2023-11-08 13:32:21.509627 Epoch 1719, Training loss 79.56647491455078\n",
      "R2 values 0.9409, 0.8094, 0.8954; mean R2=0.8819\n",
      "Validation Error: Avg loss: 495.979919 \n",
      "\n",
      "2023-11-08 13:32:21.989176 Epoch 1720, Training loss 76.70762634277344\n",
      "R2 values 0.9427, 0.8304, 0.9084; mean R2=0.8938\n",
      "Validation Error: Avg loss: 480.761322 \n",
      "\n",
      "2023-11-08 13:32:22.469642 Epoch 1721, Training loss 91.16771697998047\n",
      "R2 values 0.9393, 0.8261, 0.9091; mean R2=0.8915\n",
      "Validation Error: Avg loss: 495.979706 \n",
      "\n",
      "2023-11-08 13:32:22.952129 Epoch 1722, Training loss 62.20292663574219\n",
      "R2 values 0.9469, 0.8475, 0.8995; mean R2=0.8980\n",
      "Validation Error: Avg loss: 450.561310 \n",
      "\n",
      "2023-11-08 13:32:23.659019 Epoch 1723, Training loss 78.71420288085938\n",
      "R2 values 0.9562, 0.8199, 0.8913; mean R2=0.8892\n",
      "Validation Error: Avg loss: 404.984161 \n",
      "\n",
      "2023-11-08 13:32:24.146546 Epoch 1724, Training loss 80.85199737548828\n",
      "R2 values 0.9428, 0.8486, 0.9009; mean R2=0.8974\n",
      "Validation Error: Avg loss: 472.303253 \n",
      "\n",
      "2023-11-08 13:32:24.631709 Epoch 1725, Training loss 76.00099182128906\n",
      "R2 values 0.9562, 0.8605, 0.8843; mean R2=0.9004\n",
      "Validation Error: Avg loss: 397.896454 \n",
      "\n",
      "2023-11-08 13:32:25.120293 Epoch 1726, Training loss 79.48768615722656\n",
      "R2 values 0.9508, 0.8653, 0.8806; mean R2=0.8989\n",
      "Validation Error: Avg loss: 467.406952 \n",
      "\n",
      "2023-11-08 13:32:25.607089 Epoch 1727, Training loss 75.65792083740234\n",
      "R2 values 0.9292, 0.8205, 0.8992; mean R2=0.8830\n",
      "Validation Error: Avg loss: 577.198364 \n",
      "\n",
      "2023-11-08 13:32:26.087384 Epoch 1728, Training loss 60.91664123535156\n",
      "R2 values 0.9585, 0.8361, 0.9002; mean R2=0.8983\n",
      "Validation Error: Avg loss: 441.369202 \n",
      "\n",
      "2023-11-08 13:32:26.567166 Epoch 1729, Training loss 94.61569213867188\n",
      "R2 values 0.9506, 0.8265, 0.8947; mean R2=0.8906\n",
      "Validation Error: Avg loss: 437.750519 \n",
      "\n",
      "2023-11-08 13:32:27.043336 Epoch 1730, Training loss 62.5698127746582\n",
      "R2 values 0.9580, 0.8364, 0.9101; mean R2=0.9015\n",
      "Validation Error: Avg loss: 388.315063 \n",
      "\n",
      "2023-11-08 13:32:27.589841 Epoch 1731, Training loss 52.063575744628906\n",
      "R2 values 0.9469, 0.8357, 0.9150; mean R2=0.8992\n",
      "Validation Error: Avg loss: 465.718231 \n",
      "\n",
      "2023-11-08 13:32:28.065957 Epoch 1732, Training loss 82.92224884033203\n",
      "R2 values 0.9466, 0.8546, 0.9009; mean R2=0.9007\n",
      "Validation Error: Avg loss: 449.670959 \n",
      "\n",
      "2023-11-08 13:32:28.557367 Epoch 1733, Training loss 61.22162628173828\n",
      "R2 values 0.9502, 0.8353, 0.9073; mean R2=0.8976\n",
      "Validation Error: Avg loss: 487.501526 \n",
      "\n",
      "2023-11-08 13:32:29.039054 Epoch 1734, Training loss 64.78289794921875\n",
      "R2 values 0.9578, 0.8370, 0.8787; mean R2=0.8912\n",
      "Validation Error: Avg loss: 489.684509 \n",
      "\n",
      "2023-11-08 13:32:29.521098 Epoch 1735, Training loss 73.84415435791016\n",
      "R2 values 0.9629, 0.8593, 0.9030; mean R2=0.9084\n",
      "Validation Error: Avg loss: 390.700745 \n",
      "\n",
      "2023-11-08 13:32:30.150895 Epoch 1736, Training loss 75.673828125\n",
      "R2 values 0.9540, 0.8627, 0.8901; mean R2=0.9023\n",
      "Validation Error: Avg loss: 392.502411 \n",
      "\n",
      "2023-11-08 13:32:30.656049 Epoch 1737, Training loss 69.73200988769531\n",
      "R2 values 0.9443, 0.8607, 0.8940; mean R2=0.8996\n",
      "Validation Error: Avg loss: 473.452087 \n",
      "\n",
      "2023-11-08 13:32:31.149066 Epoch 1738, Training loss 83.05060577392578\n",
      "R2 values 0.9442, 0.8461, 0.9036; mean R2=0.8980\n",
      "Validation Error: Avg loss: 494.294373 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:32:31.641062 Epoch 1739, Training loss 82.92815399169922\n",
      "R2 values 0.9460, 0.8313, 0.9234; mean R2=0.9003\n",
      "Validation Error: Avg loss: 435.022797 \n",
      "\n",
      "2023-11-08 13:32:32.135571 Epoch 1740, Training loss 49.42388916015625\n",
      "R2 values 0.9540, 0.8346, 0.9082; mean R2=0.8989\n",
      "Validation Error: Avg loss: 367.393524 \n",
      "\n",
      "2023-11-08 13:32:32.616226 Epoch 1741, Training loss 76.98014068603516\n",
      "R2 values 0.9510, 0.8273, 0.8756; mean R2=0.8846\n",
      "Validation Error: Avg loss: 406.846710 \n",
      "\n",
      "2023-11-08 13:32:33.091602 Epoch 1742, Training loss 79.29022216796875\n",
      "R2 values 0.9601, 0.8402, 0.8957; mean R2=0.8987\n",
      "Validation Error: Avg loss: 376.573395 \n",
      "\n",
      "2023-11-08 13:32:33.584053 Epoch 1743, Training loss 60.92411422729492\n",
      "R2 values 0.9511, 0.8565, 0.9279; mean R2=0.9118\n",
      "Validation Error: Avg loss: 473.472565 \n",
      "\n",
      "2023-11-08 13:32:34.072028 Epoch 1744, Training loss 59.915279388427734\n",
      "R2 values 0.9558, 0.8555, 0.9133; mean R2=0.9082\n",
      "Validation Error: Avg loss: 448.946045 \n",
      "\n",
      "2023-11-08 13:32:34.552784 Epoch 1745, Training loss 70.24968719482422\n",
      "R2 values 0.9545, 0.8504, 0.9165; mean R2=0.9071\n",
      "Validation Error: Avg loss: 433.913605 \n",
      "\n",
      "2023-11-08 13:32:35.037998 Epoch 1746, Training loss 70.17748260498047\n",
      "R2 values 0.9290, 0.8562, 0.9004; mean R2=0.8952\n",
      "Validation Error: Avg loss: 563.788208 \n",
      "\n",
      "2023-11-08 13:32:35.516585 Epoch 1747, Training loss 70.90486907958984\n",
      "R2 values 0.9480, 0.8801, 0.8949; mean R2=0.9077\n",
      "Validation Error: Avg loss: 426.131775 \n",
      "\n",
      "2023-11-08 13:32:36.232267 Epoch 1748, Training loss 64.51583862304688\n",
      "R2 values 0.9427, 0.8357, 0.9055; mean R2=0.8946\n",
      "Validation Error: Avg loss: 557.567688 \n",
      "\n",
      "2023-11-08 13:32:36.762000 Epoch 1749, Training loss 80.69146728515625\n",
      "R2 values 0.9434, 0.8280, 0.8839; mean R2=0.8851\n",
      "Validation Error: Avg loss: 484.572418 \n",
      "\n",
      "2023-11-08 13:32:37.230832 Epoch 1750, Training loss 85.07747650146484\n",
      "R2 values 0.9601, 0.8793, 0.9123; mean R2=0.9172\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 343.129028 \n",
      "\n",
      "2023-11-08 13:32:37.749583 Epoch 1751, Training loss 59.94780731201172\n",
      "R2 values 0.9468, 0.8491, 0.8717; mean R2=0.8892\n",
      "Validation Error: Avg loss: 458.017853 \n",
      "\n",
      "2023-11-08 13:32:38.228360 Epoch 1752, Training loss 68.77962493896484\n",
      "R2 values 0.9522, 0.8122, 0.8728; mean R2=0.8791\n",
      "Validation Error: Avg loss: 449.225250 \n",
      "\n",
      "2023-11-08 13:32:38.710088 Epoch 1753, Training loss 78.7294921875\n",
      "R2 values 0.9484, 0.8582, 0.9041; mean R2=0.9036\n",
      "Validation Error: Avg loss: 500.522400 \n",
      "\n",
      "2023-11-08 13:32:39.236652 Epoch 1754, Training loss 97.20707702636719\n",
      "R2 values 0.9525, 0.8375, 0.8948; mean R2=0.8950\n",
      "Validation Error: Avg loss: 430.884583 \n",
      "\n",
      "2023-11-08 13:32:39.721948 Epoch 1755, Training loss 70.6559066772461\n",
      "R2 values 0.9522, 0.8544, 0.9074; mean R2=0.9046\n",
      "Validation Error: Avg loss: 396.213715 \n",
      "\n",
      "2023-11-08 13:32:40.217995 Epoch 1756, Training loss 88.57518005371094\n",
      "R2 values 0.9441, 0.8214, 0.9054; mean R2=0.8903\n",
      "Validation Error: Avg loss: 448.823547 \n",
      "\n",
      "2023-11-08 13:32:40.704120 Epoch 1757, Training loss 62.6695556640625\n",
      "R2 values 0.9351, 0.8163, 0.8985; mean R2=0.8833\n",
      "Validation Error: Avg loss: 589.414917 \n",
      "\n",
      "2023-11-08 13:32:41.194006 Epoch 1758, Training loss 68.57982635498047\n",
      "R2 values 0.9361, 0.8311, 0.8900; mean R2=0.8857\n",
      "Validation Error: Avg loss: 692.831360 \n",
      "\n",
      "2023-11-08 13:32:41.671928 Epoch 1759, Training loss 95.3342514038086\n",
      "R2 values 0.9572, 0.8277, 0.8962; mean R2=0.8937\n",
      "Validation Error: Avg loss: 392.912476 \n",
      "\n",
      "2023-11-08 13:32:42.158887 Epoch 1760, Training loss 58.154052734375\n",
      "R2 values 0.9419, 0.8283, 0.8834; mean R2=0.8845\n",
      "Validation Error: Avg loss: 472.816895 \n",
      "\n",
      "2023-11-08 13:32:42.643890 Epoch 1761, Training loss 97.47219848632812\n",
      "R2 values 0.9602, 0.8377, 0.9035; mean R2=0.9005\n",
      "Validation Error: Avg loss: 370.264648 \n",
      "\n",
      "2023-11-08 13:32:43.193961 Epoch 1762, Training loss 82.80768585205078\n",
      "R2 values 0.9507, 0.8500, 0.9092; mean R2=0.9033\n",
      "Validation Error: Avg loss: 543.771118 \n",
      "\n",
      "2023-11-08 13:32:43.679620 Epoch 1763, Training loss 72.54212951660156\n",
      "R2 values 0.9415, 0.8186, 0.8811; mean R2=0.8804\n",
      "Validation Error: Avg loss: 581.908264 \n",
      "\n",
      "2023-11-08 13:32:44.153211 Epoch 1764, Training loss 100.37857818603516\n",
      "R2 values 0.9526, 0.8657, 0.8911; mean R2=0.9031\n",
      "Validation Error: Avg loss: 397.142761 \n",
      "\n",
      "2023-11-08 13:32:44.642622 Epoch 1765, Training loss 79.49659729003906\n",
      "R2 values 0.9493, 0.8537, 0.8864; mean R2=0.8965\n",
      "Validation Error: Avg loss: 441.105377 \n",
      "\n",
      "2023-11-08 13:32:45.123123 Epoch 1766, Training loss 114.0345230102539\n",
      "R2 values 0.9528, 0.8141, 0.8730; mean R2=0.8800\n",
      "Validation Error: Avg loss: 435.120972 \n",
      "\n",
      "2023-11-08 13:32:45.778425 Epoch 1767, Training loss 56.591835021972656\n",
      "R2 values 0.9542, 0.8464, 0.8928; mean R2=0.8978\n",
      "Validation Error: Avg loss: 512.801880 \n",
      "\n",
      "2023-11-08 13:32:46.265132 Epoch 1768, Training loss 84.61075592041016\n",
      "R2 values 0.9519, 0.8265, 0.9075; mean R2=0.8953\n",
      "Validation Error: Avg loss: 602.002686 \n",
      "\n",
      "2023-11-08 13:32:46.756164 Epoch 1769, Training loss 100.54986572265625\n",
      "R2 values 0.9531, 0.8377, 0.8593; mean R2=0.8834\n",
      "Validation Error: Avg loss: 451.060638 \n",
      "\n",
      "2023-11-08 13:32:47.249083 Epoch 1770, Training loss 78.36026763916016\n",
      "R2 values 0.9560, 0.7918, 0.8783; mean R2=0.8753\n",
      "Validation Error: Avg loss: 393.032745 \n",
      "\n",
      "2023-11-08 13:32:47.738339 Epoch 1771, Training loss 133.77012634277344\n",
      "R2 values 0.9461, 0.8432, 0.9121; mean R2=0.9005\n",
      "Validation Error: Avg loss: 474.232574 \n",
      "\n",
      "2023-11-08 13:32:48.219524 Epoch 1772, Training loss 74.14337921142578\n",
      "R2 values 0.9492, 0.8193, 0.8958; mean R2=0.8881\n",
      "Validation Error: Avg loss: 515.421326 \n",
      "\n",
      "2023-11-08 13:32:48.721113 Epoch 1773, Training loss 75.18688201904297\n",
      "R2 values 0.9405, 0.7788, 0.8869; mean R2=0.8688\n",
      "Validation Error: Avg loss: 562.180725 \n",
      "\n",
      "2023-11-08 13:32:49.214274 Epoch 1774, Training loss 91.17726135253906\n",
      "R2 values 0.9589, 0.8708, 0.8996; mean R2=0.9098\n",
      "Validation Error: Avg loss: 410.332916 \n",
      "\n",
      "2023-11-08 13:32:49.692680 Epoch 1775, Training loss 61.35322189331055\n",
      "R2 values 0.9511, 0.8310, 0.9001; mean R2=0.8941\n",
      "Validation Error: Avg loss: 451.321472 \n",
      "\n",
      "2023-11-08 13:32:50.176053 Epoch 1776, Training loss 91.27787780761719\n",
      "R2 values 0.9500, 0.8272, 0.8976; mean R2=0.8916\n",
      "Validation Error: Avg loss: 453.957031 \n",
      "\n",
      "2023-11-08 13:32:50.655934 Epoch 1777, Training loss 61.435340881347656\n",
      "R2 values 0.9473, 0.8458, 0.9015; mean R2=0.8982\n",
      "Validation Error: Avg loss: 519.392273 \n",
      "\n",
      "2023-11-08 13:32:51.149293 Epoch 1778, Training loss 117.7389907836914\n",
      "R2 values 0.9602, 0.8212, 0.8972; mean R2=0.8929\n",
      "Validation Error: Avg loss: 410.112274 \n",
      "\n",
      "2023-11-08 13:32:51.631317 Epoch 1779, Training loss 91.5941390991211\n",
      "R2 values 0.9476, 0.8198, 0.9000; mean R2=0.8891\n",
      "Validation Error: Avg loss: 420.475525 \n",
      "\n",
      "2023-11-08 13:32:52.163147 Epoch 1780, Training loss 82.08477020263672\n",
      "R2 values 0.9484, 0.8163, 0.8807; mean R2=0.8818\n",
      "Validation Error: Avg loss: 423.091431 \n",
      "\n",
      "2023-11-08 13:32:52.654513 Epoch 1781, Training loss 106.75328826904297\n",
      "R2 values 0.9409, 0.8470, 0.8868; mean R2=0.8916\n",
      "Validation Error: Avg loss: 523.961243 \n",
      "\n",
      "2023-11-08 13:32:53.142936 Epoch 1782, Training loss 85.25798034667969\n",
      "R2 values 0.9408, 0.8530, 0.8780; mean R2=0.8906\n",
      "Validation Error: Avg loss: 638.380432 \n",
      "\n",
      "2023-11-08 13:32:53.637697 Epoch 1783, Training loss 92.05876159667969\n",
      "R2 values 0.9436, 0.8548, 0.9019; mean R2=0.9001\n",
      "Validation Error: Avg loss: 538.866943 \n",
      "\n",
      "2023-11-08 13:32:54.129222 Epoch 1784, Training loss 83.03581237792969\n",
      "R2 values 0.9450, 0.8408, 0.8926; mean R2=0.8928\n",
      "Validation Error: Avg loss: 429.964905 \n",
      "\n",
      "2023-11-08 13:32:54.617159 Epoch 1785, Training loss 83.06219482421875\n",
      "R2 values 0.9407, 0.8601, 0.9012; mean R2=0.9007\n",
      "Validation Error: Avg loss: 452.088287 \n",
      "\n",
      "2023-11-08 13:32:55.101937 Epoch 1786, Training loss 81.53511047363281\n",
      "R2 values 0.9491, 0.8450, 0.9097; mean R2=0.9013\n",
      "Validation Error: Avg loss: 408.945862 \n",
      "\n",
      "2023-11-08 13:32:55.652448 Epoch 1787, Training loss 71.29129791259766\n",
      "R2 values 0.9523, 0.8625, 0.9053; mean R2=0.9067\n",
      "Validation Error: Avg loss: 518.715149 \n",
      "\n",
      "2023-11-08 13:32:56.139902 Epoch 1788, Training loss 78.66645812988281\n",
      "R2 values 0.9536, 0.8738, 0.8785; mean R2=0.9020\n",
      "Validation Error: Avg loss: 483.850861 \n",
      "\n",
      "2023-11-08 13:32:56.623595 Epoch 1789, Training loss 89.50811004638672\n",
      "R2 values 0.9524, 0.8411, 0.8734; mean R2=0.8890\n",
      "Validation Error: Avg loss: 469.992279 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:32:57.102997 Epoch 1790, Training loss 87.68730926513672\n",
      "R2 values 0.9562, 0.8628, 0.8958; mean R2=0.9049\n",
      "Validation Error: Avg loss: 390.872955 \n",
      "\n",
      "2023-11-08 13:32:57.586660 Epoch 1791, Training loss 88.06410217285156\n",
      "R2 values 0.9425, 0.8612, 0.8821; mean R2=0.8952\n",
      "Validation Error: Avg loss: 447.905701 \n",
      "\n",
      "2023-11-08 13:32:58.072298 Epoch 1792, Training loss 106.27934265136719\n",
      "R2 values 0.9372, 0.7826, 0.8484; mean R2=0.8561\n",
      "Validation Error: Avg loss: 524.296509 \n",
      "\n",
      "2023-11-08 13:32:58.550254 Epoch 1793, Training loss 62.975276947021484\n",
      "R2 values 0.9379, 0.8469, 0.8629; mean R2=0.8826\n",
      "Validation Error: Avg loss: 603.435852 \n",
      "\n",
      "2023-11-08 13:32:59.054591 Epoch 1794, Training loss 78.27533721923828\n",
      "R2 values 0.9543, 0.8218, 0.9133; mean R2=0.8964\n",
      "Validation Error: Avg loss: 415.979736 \n",
      "\n",
      "2023-11-08 13:32:59.634905 Epoch 1795, Training loss 75.0024185180664\n",
      "R2 values 0.9554, 0.8161, 0.8724; mean R2=0.8813\n",
      "Validation Error: Avg loss: 441.742676 \n",
      "\n",
      "2023-11-08 13:33:00.118757 Epoch 1796, Training loss 107.52943420410156\n",
      "R2 values 0.9447, 0.8252, 0.9078; mean R2=0.8926\n",
      "Validation Error: Avg loss: 499.632172 \n",
      "\n",
      "2023-11-08 13:33:00.598113 Epoch 1797, Training loss 74.46851348876953\n",
      "R2 values 0.9485, 0.8096, 0.8726; mean R2=0.8769\n",
      "Validation Error: Avg loss: 524.475830 \n",
      "\n",
      "2023-11-08 13:33:01.096414 Epoch 1798, Training loss 73.42770385742188\n",
      "R2 values 0.9526, 0.8504, 0.8917; mean R2=0.8982\n",
      "Validation Error: Avg loss: 421.907593 \n",
      "\n",
      "2023-11-08 13:33:01.586364 Epoch 1799, Training loss 102.31541442871094\n",
      "R2 values 0.9595, 0.8716, 0.9029; mean R2=0.9113\n",
      "Validation Error: Avg loss: 356.664154 \n",
      "\n",
      "2023-11-08 13:33:02.065778 Epoch 1800, Training loss 75.97421264648438\n",
      "R2 values 0.9534, 0.8537, 0.9061; mean R2=0.9044\n",
      "Validation Error: Avg loss: 392.872070 \n",
      "\n",
      "2023-11-08 13:33:02.548835 Epoch 1801, Training loss 125.37017822265625\n",
      "R2 values 0.9435, 0.8407, 0.9076; mean R2=0.8973\n",
      "Validation Error: Avg loss: 489.617615 \n",
      "\n",
      "2023-11-08 13:33:03.019244 Epoch 1802, Training loss 63.18562316894531\n",
      "R2 values 0.9494, 0.8481, 0.8914; mean R2=0.8963\n",
      "Validation Error: Avg loss: 554.882690 \n",
      "\n",
      "2023-11-08 13:33:03.496431 Epoch 1803, Training loss 88.36727142333984\n",
      "R2 values 0.9545, 0.8543, 0.9002; mean R2=0.9030\n",
      "Validation Error: Avg loss: 434.446991 \n",
      "\n",
      "2023-11-08 13:33:03.979769 Epoch 1804, Training loss 73.62077331542969\n",
      "R2 values 0.9480, 0.8343, 0.8775; mean R2=0.8866\n",
      "Validation Error: Avg loss: 437.391418 \n",
      "\n",
      "2023-11-08 13:33:04.462381 Epoch 1805, Training loss 87.2310562133789\n",
      "R2 values 0.9497, 0.8447, 0.9147; mean R2=0.9030\n",
      "Validation Error: Avg loss: 439.539215 \n",
      "\n",
      "2023-11-08 13:33:04.974545 Epoch 1806, Training loss 54.303043365478516\n",
      "R2 values 0.9512, 0.8480, 0.8881; mean R2=0.8958\n",
      "Validation Error: Avg loss: 432.835815 \n",
      "\n",
      "2023-11-08 13:33:05.456860 Epoch 1807, Training loss 79.98040008544922\n",
      "R2 values 0.9409, 0.8329, 0.8932; mean R2=0.8890\n",
      "Validation Error: Avg loss: 481.379364 \n",
      "\n",
      "2023-11-08 13:33:05.935691 Epoch 1808, Training loss 59.956783294677734\n",
      "R2 values 0.9500, 0.8547, 0.9050; mean R2=0.9032\n",
      "Validation Error: Avg loss: 486.614929 \n",
      "\n",
      "2023-11-08 13:33:06.415068 Epoch 1809, Training loss 55.007266998291016\n",
      "R2 values 0.9446, 0.8541, 0.8891; mean R2=0.8959\n",
      "Validation Error: Avg loss: 491.531464 \n",
      "\n",
      "2023-11-08 13:33:06.887974 Epoch 1810, Training loss 62.482608795166016\n",
      "R2 values 0.9517, 0.8475, 0.8592; mean R2=0.8862\n",
      "Validation Error: Avg loss: 440.498230 \n",
      "\n",
      "2023-11-08 13:33:07.362865 Epoch 1811, Training loss 65.1434326171875\n",
      "R2 values 0.9534, 0.8439, 0.9312; mean R2=0.9095\n",
      "Validation Error: Avg loss: 394.647278 \n",
      "\n",
      "2023-11-08 13:33:07.860243 Epoch 1812, Training loss 89.51461791992188\n",
      "R2 values 0.9398, 0.8266, 0.9034; mean R2=0.8900\n",
      "Validation Error: Avg loss: 584.423767 \n",
      "\n",
      "2023-11-08 13:33:08.345741 Epoch 1813, Training loss 76.68038177490234\n",
      "R2 values 0.9472, 0.8183, 0.9122; mean R2=0.8926\n",
      "Validation Error: Avg loss: 450.822205 \n",
      "\n",
      "2023-11-08 13:33:08.844224 Epoch 1814, Training loss 72.9074935913086\n",
      "R2 values 0.9543, 0.8845, 0.8655; mean R2=0.9014\n",
      "Validation Error: Avg loss: 392.189056 \n",
      "\n",
      "2023-11-08 13:33:09.336770 Epoch 1815, Training loss 81.60540771484375\n",
      "R2 values 0.9415, 0.8261, 0.9112; mean R2=0.8929\n",
      "Validation Error: Avg loss: 477.767273 \n",
      "\n",
      "2023-11-08 13:33:09.823840 Epoch 1816, Training loss 75.68778228759766\n",
      "R2 values 0.9529, 0.8293, 0.8973; mean R2=0.8931\n",
      "Validation Error: Avg loss: 493.582489 \n",
      "\n",
      "2023-11-08 13:33:10.310593 Epoch 1817, Training loss 85.4847640991211\n",
      "R2 values 0.9497, 0.8110, 0.9112; mean R2=0.8907\n",
      "Validation Error: Avg loss: 488.585480 \n",
      "\n",
      "2023-11-08 13:33:10.851467 Epoch 1818, Training loss 85.40023040771484\n",
      "R2 values 0.9464, 0.8309, 0.9023; mean R2=0.8932\n",
      "Validation Error: Avg loss: 432.566254 \n",
      "\n",
      "2023-11-08 13:33:11.367263 Epoch 1819, Training loss 74.35771942138672\n",
      "R2 values 0.9627, 0.8391, 0.8933; mean R2=0.8983\n",
      "Validation Error: Avg loss: 350.077576 \n",
      "\n",
      "2023-11-08 13:33:11.858359 Epoch 1820, Training loss 103.20001983642578\n",
      "R2 values 0.9553, 0.8099, 0.8828; mean R2=0.8827\n",
      "Validation Error: Avg loss: 401.331818 \n",
      "\n",
      "2023-11-08 13:33:12.343969 Epoch 1821, Training loss 83.3794937133789\n",
      "R2 values 0.9587, 0.8220, 0.8824; mean R2=0.8877\n",
      "Validation Error: Avg loss: 502.520203 \n",
      "\n",
      "2023-11-08 13:33:12.823181 Epoch 1822, Training loss 108.99655151367188\n",
      "R2 values 0.9557, 0.8440, 0.8927; mean R2=0.8975\n",
      "Validation Error: Avg loss: 423.319122 \n",
      "\n",
      "2023-11-08 13:33:13.306713 Epoch 1823, Training loss 65.49390411376953\n",
      "R2 values 0.9561, 0.8627, 0.9047; mean R2=0.9078\n",
      "Validation Error: Avg loss: 373.718445 \n",
      "\n",
      "2023-11-08 13:33:13.798873 Epoch 1824, Training loss 87.13398742675781\n",
      "R2 values 0.9418, 0.8503, 0.9090; mean R2=0.9004\n",
      "Validation Error: Avg loss: 496.964966 \n",
      "\n",
      "2023-11-08 13:33:14.293040 Epoch 1825, Training loss 61.416500091552734\n",
      "R2 values 0.9551, 0.8625, 0.8972; mean R2=0.9049\n",
      "Validation Error: Avg loss: 460.476440 \n",
      "\n",
      "2023-11-08 13:33:14.775292 Epoch 1826, Training loss 63.042362213134766\n",
      "R2 values 0.9578, 0.8185, 0.9111; mean R2=0.8958\n",
      "Validation Error: Avg loss: 406.954956 \n",
      "\n",
      "2023-11-08 13:33:15.258375 Epoch 1827, Training loss 75.06488800048828\n",
      "R2 values 0.9512, 0.8502, 0.8768; mean R2=0.8928\n",
      "Validation Error: Avg loss: 467.341888 \n",
      "\n",
      "2023-11-08 13:33:15.747216 Epoch 1828, Training loss 55.00507736206055\n",
      "R2 values 0.9533, 0.8655, 0.8978; mean R2=0.9055\n",
      "Validation Error: Avg loss: 429.400726 \n",
      "\n",
      "2023-11-08 13:33:16.237996 Epoch 1829, Training loss 62.53703689575195\n",
      "R2 values 0.9505, 0.8479, 0.8953; mean R2=0.8979\n",
      "Validation Error: Avg loss: 450.626190 \n",
      "\n",
      "2023-11-08 13:33:16.725939 Epoch 1830, Training loss 54.71211624145508\n",
      "R2 values 0.9528, 0.8046, 0.8864; mean R2=0.8813\n",
      "Validation Error: Avg loss: 509.068604 \n",
      "\n",
      "2023-11-08 13:33:17.226326 Epoch 1831, Training loss 88.33922576904297\n",
      "R2 values 0.9548, 0.8266, 0.9019; mean R2=0.8944\n",
      "Validation Error: Avg loss: 414.385773 \n",
      "\n",
      "2023-11-08 13:33:17.711260 Epoch 1832, Training loss 57.631553649902344\n",
      "R2 values 0.9538, 0.8854, 0.9054; mean R2=0.9149\n",
      "Validation Error: Avg loss: 387.458557 \n",
      "\n",
      "2023-11-08 13:33:18.198820 Epoch 1833, Training loss 79.0947494506836\n",
      "R2 values 0.9431, 0.8101, 0.8837; mean R2=0.8790\n",
      "Validation Error: Avg loss: 484.584564 \n",
      "\n",
      "2023-11-08 13:33:18.692275 Epoch 1834, Training loss 51.64237976074219\n",
      "R2 values 0.9466, 0.8190, 0.9104; mean R2=0.8920\n",
      "Validation Error: Avg loss: 473.267853 \n",
      "\n",
      "2023-11-08 13:33:19.176347 Epoch 1835, Training loss 67.64242553710938\n",
      "R2 values 0.9550, 0.8429, 0.9014; mean R2=0.8998\n",
      "Validation Error: Avg loss: 445.949341 \n",
      "\n",
      "2023-11-08 13:33:19.659574 Epoch 1836, Training loss 51.72117233276367\n",
      "R2 values 0.9520, 0.8586, 0.9008; mean R2=0.9038\n",
      "Validation Error: Avg loss: 463.272247 \n",
      "\n",
      "2023-11-08 13:33:20.145528 Epoch 1837, Training loss 59.88801956176758\n",
      "R2 values 0.9556, 0.8240, 0.9167; mean R2=0.8987\n",
      "Validation Error: Avg loss: 380.230530 \n",
      "\n",
      "2023-11-08 13:33:20.724239 Epoch 1838, Training loss 58.763545989990234\n",
      "R2 values 0.9579, 0.8754, 0.9090; mean R2=0.9141\n",
      "Validation Error: Avg loss: 404.049103 \n",
      "\n",
      "2023-11-08 13:33:21.220881 Epoch 1839, Training loss 53.12495422363281\n",
      "R2 values 0.9394, 0.8371, 0.8884; mean R2=0.8883\n",
      "Validation Error: Avg loss: 562.647522 \n",
      "\n",
      "2023-11-08 13:33:21.769053 Epoch 1840, Training loss 81.42015838623047\n",
      "R2 values 0.9501, 0.8525, 0.8986; mean R2=0.9004\n",
      "Validation Error: Avg loss: 432.968964 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:33:22.262687 Epoch 1841, Training loss 76.1491928100586\n",
      "R2 values 0.9474, 0.8515, 0.8924; mean R2=0.8971\n",
      "Validation Error: Avg loss: 428.939606 \n",
      "\n",
      "2023-11-08 13:33:22.749210 Epoch 1842, Training loss 83.14629364013672\n",
      "R2 values 0.9479, 0.8627, 0.8947; mean R2=0.9017\n",
      "Validation Error: Avg loss: 417.301270 \n",
      "\n",
      "2023-11-08 13:33:23.250017 Epoch 1843, Training loss 79.90323638916016\n",
      "R2 values 0.9389, 0.8911, 0.9108; mean R2=0.9136\n",
      "Validation Error: Avg loss: 487.843231 \n",
      "\n",
      "2023-11-08 13:33:23.733292 Epoch 1844, Training loss 74.20509338378906\n",
      "R2 values 0.9429, 0.8329, 0.8703; mean R2=0.8820\n",
      "Validation Error: Avg loss: 488.696075 \n",
      "\n",
      "2023-11-08 13:33:24.211122 Epoch 1845, Training loss 73.60285186767578\n",
      "R2 values 0.9447, 0.8344, 0.9034; mean R2=0.8942\n",
      "Validation Error: Avg loss: 432.428009 \n",
      "\n",
      "2023-11-08 13:33:24.698068 Epoch 1846, Training loss 79.63090515136719\n",
      "R2 values 0.9459, 0.8251, 0.8928; mean R2=0.8880\n",
      "Validation Error: Avg loss: 455.979126 \n",
      "\n",
      "2023-11-08 13:33:25.192099 Epoch 1847, Training loss 62.29224395751953\n",
      "R2 values 0.9499, 0.8579, 0.8710; mean R2=0.8929\n",
      "Validation Error: Avg loss: 480.409576 \n",
      "\n",
      "2023-11-08 13:33:25.668857 Epoch 1848, Training loss 82.27393341064453\n",
      "R2 values 0.9508, 0.8511, 0.9012; mean R2=0.9011\n",
      "Validation Error: Avg loss: 520.669983 \n",
      "\n",
      "2023-11-08 13:33:26.155162 Epoch 1849, Training loss 86.59620666503906\n",
      "R2 values 0.9554, 0.8272, 0.8761; mean R2=0.8862\n",
      "Validation Error: Avg loss: 377.868713 \n",
      "\n",
      "2023-11-08 13:33:26.642908 Epoch 1850, Training loss 69.67639923095703\n",
      "R2 values 0.9525, 0.8590, 0.8964; mean R2=0.9026\n",
      "Validation Error: Avg loss: 396.905548 \n",
      "\n",
      "2023-11-08 13:33:27.126758 Epoch 1851, Training loss 98.39726257324219\n",
      "R2 values 0.9503, 0.8492, 0.8968; mean R2=0.8988\n",
      "Validation Error: Avg loss: 464.444092 \n",
      "\n",
      "2023-11-08 13:33:27.615215 Epoch 1852, Training loss 74.18145751953125\n",
      "R2 values 0.9562, 0.8192, 0.8742; mean R2=0.8832\n",
      "Validation Error: Avg loss: 567.852722 \n",
      "\n",
      "2023-11-08 13:33:28.098709 Epoch 1853, Training loss 83.93063354492188\n",
      "R2 values 0.9425, 0.8322, 0.8756; mean R2=0.8835\n",
      "Validation Error: Avg loss: 549.165771 \n",
      "\n",
      "2023-11-08 13:33:28.642517 Epoch 1854, Training loss 91.35332489013672\n",
      "R2 values 0.9550, 0.8299, 0.8782; mean R2=0.8877\n",
      "Validation Error: Avg loss: 394.073547 \n",
      "\n",
      "2023-11-08 13:33:29.137071 Epoch 1855, Training loss 70.73467254638672\n",
      "R2 values 0.9497, 0.8560, 0.9085; mean R2=0.9047\n",
      "Validation Error: Avg loss: 404.225769 \n",
      "\n",
      "2023-11-08 13:33:29.626092 Epoch 1856, Training loss 90.95783233642578\n",
      "R2 values 0.9583, 0.8552, 0.8969; mean R2=0.9035\n",
      "Validation Error: Avg loss: 383.212738 \n",
      "\n",
      "2023-11-08 13:33:30.102730 Epoch 1857, Training loss 56.61738586425781\n",
      "R2 values 0.9472, 0.8106, 0.8680; mean R2=0.8753\n",
      "Validation Error: Avg loss: 505.659668 \n",
      "\n",
      "2023-11-08 13:33:30.593597 Epoch 1858, Training loss 88.41358947753906\n",
      "R2 values 0.9500, 0.8535, 0.8954; mean R2=0.8996\n",
      "Validation Error: Avg loss: 511.648163 \n",
      "\n",
      "2023-11-08 13:33:31.126446 Epoch 1859, Training loss 69.53530883789062\n",
      "R2 values 0.9581, 0.8723, 0.9082; mean R2=0.9129\n",
      "Validation Error: Avg loss: 360.622284 \n",
      "\n",
      "2023-11-08 13:33:31.608799 Epoch 1860, Training loss 90.47578430175781\n",
      "R2 values 0.9357, 0.8488, 0.8960; mean R2=0.8935\n",
      "Validation Error: Avg loss: 509.794159 \n",
      "\n",
      "2023-11-08 13:33:32.103786 Epoch 1861, Training loss 71.72893524169922\n",
      "R2 values 0.9476, 0.8458, 0.8942; mean R2=0.8959\n",
      "Validation Error: Avg loss: 465.427307 \n",
      "\n",
      "2023-11-08 13:33:32.584163 Epoch 1862, Training loss 52.05868911743164\n",
      "R2 values 0.9459, 0.8536, 0.9125; mean R2=0.9040\n",
      "Validation Error: Avg loss: 517.246643 \n",
      "\n",
      "2023-11-08 13:33:33.066107 Epoch 1863, Training loss 83.36408233642578\n",
      "R2 values 0.9521, 0.8702, 0.9035; mean R2=0.9086\n",
      "Validation Error: Avg loss: 488.487915 \n",
      "\n",
      "2023-11-08 13:33:33.549486 Epoch 1864, Training loss 60.21839904785156\n",
      "R2 values 0.9547, 0.8744, 0.8955; mean R2=0.9082\n",
      "Validation Error: Avg loss: 453.374329 \n",
      "\n",
      "2023-11-08 13:33:34.058311 Epoch 1865, Training loss 58.94149398803711\n",
      "R2 values 0.9510, 0.8273, 0.9166; mean R2=0.8983\n",
      "Validation Error: Avg loss: 415.174622 \n",
      "\n",
      "2023-11-08 13:33:34.545444 Epoch 1866, Training loss 50.170040130615234\n",
      "R2 values 0.9578, 0.8393, 0.9024; mean R2=0.8998\n",
      "Validation Error: Avg loss: 397.965454 \n",
      "\n",
      "2023-11-08 13:33:35.029100 Epoch 1867, Training loss 64.31805419921875\n",
      "R2 values 0.9519, 0.8573, 0.9100; mean R2=0.9064\n",
      "Validation Error: Avg loss: 394.401520 \n",
      "\n",
      "2023-11-08 13:33:35.507885 Epoch 1868, Training loss 70.60086822509766\n",
      "R2 values 0.9522, 0.8403, 0.8951; mean R2=0.8959\n",
      "Validation Error: Avg loss: 431.848633 \n",
      "\n",
      "2023-11-08 13:33:35.996600 Epoch 1869, Training loss 62.66612243652344\n",
      "R2 values 0.9570, 0.8517, 0.9099; mean R2=0.9062\n",
      "Validation Error: Avg loss: 397.871399 \n",
      "\n",
      "2023-11-08 13:33:36.480543 Epoch 1870, Training loss 77.31343078613281\n",
      "R2 values 0.9469, 0.8335, 0.9192; mean R2=0.8999\n",
      "Validation Error: Avg loss: 473.482666 \n",
      "\n",
      "2023-11-08 13:33:36.953264 Epoch 1871, Training loss 52.41568374633789\n",
      "R2 values 0.9570, 0.8515, 0.9004; mean R2=0.9030\n",
      "Validation Error: Avg loss: 387.928650 \n",
      "\n",
      "2023-11-08 13:33:37.435267 Epoch 1872, Training loss 71.353515625\n",
      "R2 values 0.9508, 0.8482, 0.8888; mean R2=0.8959\n",
      "Validation Error: Avg loss: 393.316132 \n",
      "\n",
      "2023-11-08 13:33:37.978696 Epoch 1873, Training loss 64.57466125488281\n",
      "R2 values 0.9540, 0.8557, 0.8813; mean R2=0.8970\n",
      "Validation Error: Avg loss: 383.150665 \n",
      "\n",
      "2023-11-08 13:33:38.467395 Epoch 1874, Training loss 66.62084197998047\n",
      "R2 values 0.9639, 0.8744, 0.8933; mean R2=0.9105\n",
      "Validation Error: Avg loss: 338.288849 \n",
      "\n",
      "2023-11-08 13:33:38.953386 Epoch 1875, Training loss 62.42387390136719\n",
      "R2 values 0.9585, 0.8171, 0.8890; mean R2=0.8882\n",
      "Validation Error: Avg loss: 451.464752 \n",
      "\n",
      "2023-11-08 13:33:39.433985 Epoch 1876, Training loss 86.59991455078125\n",
      "R2 values 0.9511, 0.8582, 0.8804; mean R2=0.8966\n",
      "Validation Error: Avg loss: 453.179413 \n",
      "\n",
      "2023-11-08 13:33:40.077835 Epoch 1877, Training loss 77.29508972167969\n",
      "R2 values 0.9580, 0.8462, 0.8696; mean R2=0.8912\n",
      "Validation Error: Avg loss: 367.402985 \n",
      "\n",
      "2023-11-08 13:33:40.567677 Epoch 1878, Training loss 66.93598937988281\n",
      "R2 values 0.9510, 0.8075, 0.8965; mean R2=0.8850\n",
      "Validation Error: Avg loss: 457.290283 \n",
      "\n",
      "2023-11-08 13:33:41.070407 Epoch 1879, Training loss 63.67604064941406\n",
      "R2 values 0.9591, 0.8279, 0.8879; mean R2=0.8916\n",
      "Validation Error: Avg loss: 429.937225 \n",
      "\n",
      "2023-11-08 13:33:41.571841 Epoch 1880, Training loss 82.88768768310547\n",
      "R2 values 0.9346, 0.8227, 0.8759; mean R2=0.8777\n",
      "Validation Error: Avg loss: 572.576416 \n",
      "\n",
      "2023-11-08 13:33:42.054188 Epoch 1881, Training loss 62.04886245727539\n",
      "R2 values 0.9371, 0.8268, 0.8870; mean R2=0.8836\n",
      "Validation Error: Avg loss: 523.863892 \n",
      "\n",
      "2023-11-08 13:33:42.535192 Epoch 1882, Training loss 73.97412109375\n",
      "R2 values 0.9430, 0.8012, 0.8721; mean R2=0.8721\n",
      "Validation Error: Avg loss: 520.901245 \n",
      "\n",
      "2023-11-08 13:33:43.043733 Epoch 1883, Training loss 82.63829040527344\n",
      "R2 values 0.9495, 0.7811, 0.8975; mean R2=0.8761\n",
      "Validation Error: Avg loss: 457.241302 \n",
      "\n",
      "2023-11-08 13:33:43.523912 Epoch 1884, Training loss 97.66818237304688\n",
      "R2 values 0.9609, 0.8366, 0.8747; mean R2=0.8907\n",
      "Validation Error: Avg loss: 383.151062 \n",
      "\n",
      "2023-11-08 13:33:44.025963 Epoch 1885, Training loss 75.4875259399414\n",
      "R2 values 0.9408, 0.8474, 0.8846; mean R2=0.8909\n",
      "Validation Error: Avg loss: 481.208679 \n",
      "\n",
      "2023-11-08 13:33:44.510775 Epoch 1886, Training loss 62.66535949707031\n",
      "R2 values 0.9514, 0.8513, 0.9051; mean R2=0.9026\n",
      "Validation Error: Avg loss: 431.486786 \n",
      "\n",
      "2023-11-08 13:33:45.000078 Epoch 1887, Training loss 89.05046844482422\n",
      "R2 values 0.9512, 0.8381, 0.8933; mean R2=0.8942\n",
      "Validation Error: Avg loss: 468.772247 \n",
      "\n",
      "2023-11-08 13:33:45.488368 Epoch 1888, Training loss 68.30030822753906\n",
      "R2 values 0.9624, 0.8491, 0.9044; mean R2=0.9053\n",
      "Validation Error: Avg loss: 426.413177 \n",
      "\n",
      "2023-11-08 13:33:45.970210 Epoch 1889, Training loss 55.01189422607422\n",
      "R2 values 0.9523, 0.8415, 0.9155; mean R2=0.9031\n",
      "Validation Error: Avg loss: 434.935455 \n",
      "\n",
      "2023-11-08 13:33:46.447851 Epoch 1890, Training loss 63.90943908691406\n",
      "R2 values 0.9497, 0.8270, 0.8882; mean R2=0.8883\n",
      "Validation Error: Avg loss: 459.649261 \n",
      "\n",
      "2023-11-08 13:33:47.000055 Epoch 1891, Training loss 72.01261138916016\n",
      "R2 values 0.9573, 0.8562, 0.9092; mean R2=0.9076\n",
      "Validation Error: Avg loss: 440.461975 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:33:47.487938 Epoch 1892, Training loss 69.22693634033203\n",
      "R2 values 0.9557, 0.8686, 0.8886; mean R2=0.9043\n",
      "Validation Error: Avg loss: 395.355988 \n",
      "\n",
      "2023-11-08 13:33:47.960080 Epoch 1893, Training loss 73.52107238769531\n",
      "R2 values 0.9443, 0.8642, 0.8600; mean R2=0.8895\n",
      "Validation Error: Avg loss: 509.974976 \n",
      "\n",
      "2023-11-08 13:33:48.445673 Epoch 1894, Training loss 63.346561431884766\n",
      "R2 values 0.9547, 0.8621, 0.8785; mean R2=0.8984\n",
      "Validation Error: Avg loss: 421.042297 \n",
      "\n",
      "2023-11-08 13:33:48.941237 Epoch 1895, Training loss 67.40741729736328\n",
      "R2 values 0.9481, 0.8527, 0.9067; mean R2=0.9025\n",
      "Validation Error: Avg loss: 487.750763 \n",
      "\n",
      "2023-11-08 13:33:49.679311 Epoch 1896, Training loss 49.735389709472656\n",
      "R2 values 0.9529, 0.8512, 0.9139; mean R2=0.9060\n",
      "Validation Error: Avg loss: 388.427002 \n",
      "\n",
      "2023-11-08 13:33:50.180489 Epoch 1897, Training loss 72.00267791748047\n",
      "R2 values 0.9629, 0.8562, 0.8794; mean R2=0.8995\n",
      "Validation Error: Avg loss: 376.814941 \n",
      "\n",
      "2023-11-08 13:33:50.660493 Epoch 1898, Training loss 59.204280853271484\n",
      "R2 values 0.9469, 0.8461, 0.8931; mean R2=0.8954\n",
      "Validation Error: Avg loss: 458.367615 \n",
      "\n",
      "2023-11-08 13:33:51.141403 Epoch 1899, Training loss 97.5114974975586\n",
      "R2 values 0.9479, 0.8262, 0.8880; mean R2=0.8874\n",
      "Validation Error: Avg loss: 509.336365 \n",
      "\n",
      "2023-11-08 13:33:51.640173 Epoch 1900, Training loss 68.01750946044922\n",
      "R2 values 0.9456, 0.8392, 0.8896; mean R2=0.8915\n",
      "Validation Error: Avg loss: 543.111816 \n",
      "\n",
      "2023-11-08 13:33:52.195522 Epoch 1901, Training loss 104.6527328491211\n",
      "R2 values 0.9456, 0.8210, 0.9038; mean R2=0.8901\n",
      "Validation Error: Avg loss: 451.863525 \n",
      "\n",
      "2023-11-08 13:33:52.741673 Epoch 1902, Training loss 55.32976531982422\n",
      "R2 values 0.9488, 0.8044, 0.8783; mean R2=0.8772\n",
      "Validation Error: Avg loss: 463.147858 \n",
      "\n",
      "2023-11-08 13:33:53.237394 Epoch 1903, Training loss 86.06306457519531\n",
      "R2 values 0.9452, 0.8210, 0.8917; mean R2=0.8860\n",
      "Validation Error: Avg loss: 465.983337 \n",
      "\n",
      "2023-11-08 13:33:53.728114 Epoch 1904, Training loss 108.56999206542969\n",
      "R2 values 0.9476, 0.8372, 0.8906; mean R2=0.8918\n",
      "Validation Error: Avg loss: 469.241180 \n",
      "\n",
      "2023-11-08 13:33:54.222809 Epoch 1905, Training loss 68.78028106689453\n",
      "R2 values 0.9495, 0.8659, 0.8945; mean R2=0.9033\n",
      "Validation Error: Avg loss: 432.933044 \n",
      "\n",
      "2023-11-08 13:33:54.701662 Epoch 1906, Training loss 63.211265563964844\n",
      "R2 values 0.9563, 0.8289, 0.8764; mean R2=0.8872\n",
      "Validation Error: Avg loss: 439.355499 \n",
      "\n",
      "2023-11-08 13:33:55.177155 Epoch 1907, Training loss 64.57637786865234\n",
      "R2 values 0.9454, 0.8397, 0.8791; mean R2=0.8881\n",
      "Validation Error: Avg loss: 472.939606 \n",
      "\n",
      "2023-11-08 13:33:55.664177 Epoch 1908, Training loss 69.91448211669922\n",
      "R2 values 0.9566, 0.8360, 0.9004; mean R2=0.8976\n",
      "Validation Error: Avg loss: 392.451019 \n",
      "\n",
      "2023-11-08 13:33:56.148914 Epoch 1909, Training loss 60.61460876464844\n",
      "R2 values 0.9505, 0.8332, 0.8878; mean R2=0.8905\n",
      "Validation Error: Avg loss: 443.373810 \n",
      "\n",
      "2023-11-08 13:33:56.634465 Epoch 1910, Training loss 62.06173324584961\n",
      "R2 values 0.9522, 0.8321, 0.9076; mean R2=0.8973\n",
      "Validation Error: Avg loss: 398.576141 \n",
      "\n",
      "2023-11-08 13:33:57.119349 Epoch 1911, Training loss 69.3743667602539\n",
      "R2 values 0.9531, 0.8580, 0.8861; mean R2=0.8990\n",
      "Validation Error: Avg loss: 453.366150 \n",
      "\n",
      "2023-11-08 13:33:57.609866 Epoch 1912, Training loss 50.825035095214844\n",
      "R2 values 0.9350, 0.8363, 0.8926; mean R2=0.8880\n",
      "Validation Error: Avg loss: 529.490784 \n",
      "\n",
      "2023-11-08 13:33:58.095413 Epoch 1913, Training loss 86.8539047241211\n",
      "R2 values 0.9420, 0.8455, 0.9199; mean R2=0.9025\n",
      "Validation Error: Avg loss: 472.197296 \n",
      "\n",
      "2023-11-08 13:33:58.678751 Epoch 1914, Training loss 62.64024353027344\n",
      "R2 values 0.9465, 0.8368, 0.8852; mean R2=0.8895\n",
      "Validation Error: Avg loss: 465.834961 \n",
      "\n",
      "2023-11-08 13:33:59.171109 Epoch 1915, Training loss 70.92755889892578\n",
      "R2 values 0.9473, 0.8302, 0.9165; mean R2=0.8980\n",
      "Validation Error: Avg loss: 451.785339 \n",
      "\n",
      "2023-11-08 13:33:59.659761 Epoch 1916, Training loss 52.547889709472656\n",
      "R2 values 0.9534, 0.8126, 0.9055; mean R2=0.8905\n",
      "Validation Error: Avg loss: 413.491150 \n",
      "\n",
      "2023-11-08 13:34:00.269526 Epoch 1917, Training loss 76.94966888427734\n",
      "R2 values 0.9535, 0.8617, 0.8928; mean R2=0.9026\n",
      "Validation Error: Avg loss: 409.522400 \n",
      "\n",
      "2023-11-08 13:34:00.755105 Epoch 1918, Training loss 61.05138397216797\n",
      "R2 values 0.9566, 0.8610, 0.9150; mean R2=0.9109\n",
      "Validation Error: Avg loss: 353.277069 \n",
      "\n",
      "2023-11-08 13:34:01.251807 Epoch 1919, Training loss 69.1919937133789\n",
      "R2 values 0.9528, 0.8373, 0.8867; mean R2=0.8923\n",
      "Validation Error: Avg loss: 419.018921 \n",
      "\n",
      "2023-11-08 13:34:01.730658 Epoch 1920, Training loss 48.164188385009766\n",
      "R2 values 0.9535, 0.8656, 0.9008; mean R2=0.9066\n",
      "Validation Error: Avg loss: 427.992310 \n",
      "\n",
      "2023-11-08 13:34:02.216608 Epoch 1921, Training loss 54.7359733581543\n",
      "R2 values 0.9431, 0.8230, 0.9107; mean R2=0.8923\n",
      "Validation Error: Avg loss: 605.050842 \n",
      "\n",
      "2023-11-08 13:34:02.707604 Epoch 1922, Training loss 65.20802307128906\n",
      "R2 values 0.9485, 0.8507, 0.9055; mean R2=0.9015\n",
      "Validation Error: Avg loss: 475.658417 \n",
      "\n",
      "2023-11-08 13:34:03.184738 Epoch 1923, Training loss 69.70648956298828\n",
      "R2 values 0.9613, 0.8227, 0.9036; mean R2=0.8959\n",
      "Validation Error: Avg loss: 357.192383 \n",
      "\n",
      "2023-11-08 13:34:03.670392 Epoch 1924, Training loss 64.23384857177734\n",
      "R2 values 0.9547, 0.8624, 0.9063; mean R2=0.9078\n",
      "Validation Error: Avg loss: 373.225433 \n",
      "\n",
      "2023-11-08 13:34:04.160618 Epoch 1925, Training loss 72.81275177001953\n",
      "R2 values 0.9564, 0.8566, 0.9172; mean R2=0.9101\n",
      "Validation Error: Avg loss: 468.375885 \n",
      "\n",
      "2023-11-08 13:34:04.644807 Epoch 1926, Training loss 77.34162902832031\n",
      "R2 values 0.9526, 0.8476, 0.8949; mean R2=0.8984\n",
      "Validation Error: Avg loss: 592.597778 \n",
      "\n",
      "2023-11-08 13:34:05.131757 Epoch 1927, Training loss 80.68643951416016\n",
      "R2 values 0.9591, 0.8659, 0.8970; mean R2=0.9073\n",
      "Validation Error: Avg loss: 384.245087 \n",
      "\n",
      "2023-11-08 13:34:05.619291 Epoch 1928, Training loss 58.60837173461914\n",
      "R2 values 0.9601, 0.8599, 0.8906; mean R2=0.9035\n",
      "Validation Error: Avg loss: 333.333893 \n",
      "\n",
      "2023-11-08 13:34:06.096352 Epoch 1929, Training loss 64.72228240966797\n",
      "R2 values 0.9465, 0.8525, 0.9103; mean R2=0.9031\n",
      "Validation Error: Avg loss: 414.685730 \n",
      "\n",
      "2023-11-08 13:34:06.573346 Epoch 1930, Training loss 84.8010025024414\n",
      "R2 values 0.9550, 0.8339, 0.9048; mean R2=0.8979\n",
      "Validation Error: Avg loss: 414.513153 \n",
      "\n",
      "2023-11-08 13:34:07.295175 Epoch 1931, Training loss 83.20113372802734\n",
      "R2 values 0.9499, 0.8464, 0.8974; mean R2=0.8979\n",
      "Validation Error: Avg loss: 479.994690 \n",
      "\n",
      "2023-11-08 13:34:07.781532 Epoch 1932, Training loss 55.548030853271484\n",
      "R2 values 0.9565, 0.8428, 0.8871; mean R2=0.8955\n",
      "Validation Error: Avg loss: 411.843628 \n",
      "\n",
      "2023-11-08 13:34:08.262831 Epoch 1933, Training loss 55.56433868408203\n",
      "R2 values 0.9621, 0.8372, 0.9001; mean R2=0.8998\n",
      "Validation Error: Avg loss: 333.245697 \n",
      "\n",
      "2023-11-08 13:34:08.755154 Epoch 1934, Training loss 54.505531311035156\n",
      "R2 values 0.9572, 0.8661, 0.9027; mean R2=0.9087\n",
      "Validation Error: Avg loss: 409.715302 \n",
      "\n",
      "2023-11-08 13:34:09.237377 Epoch 1935, Training loss 85.48680114746094\n",
      "R2 values 0.9534, 0.8242, 0.8945; mean R2=0.8907\n",
      "Validation Error: Avg loss: 445.748718 \n",
      "\n",
      "2023-11-08 13:34:09.719501 Epoch 1936, Training loss 65.7881851196289\n",
      "R2 values 0.9452, 0.8420, 0.9118; mean R2=0.8996\n",
      "Validation Error: Avg loss: 543.055664 \n",
      "\n",
      "2023-11-08 13:34:10.198890 Epoch 1937, Training loss 61.27942657470703\n",
      "R2 values 0.9484, 0.8589, 0.8813; mean R2=0.8962\n",
      "Validation Error: Avg loss: 470.408997 \n",
      "\n",
      "2023-11-08 13:34:10.678184 Epoch 1938, Training loss 51.69944763183594\n",
      "R2 values 0.9599, 0.8491, 0.9035; mean R2=0.9042\n",
      "Validation Error: Avg loss: 385.729156 \n",
      "\n",
      "2023-11-08 13:34:11.167184 Epoch 1939, Training loss 74.01278686523438\n",
      "R2 values 0.9533, 0.8502, 0.8932; mean R2=0.8989\n",
      "Validation Error: Avg loss: 429.505463 \n",
      "\n",
      "2023-11-08 13:34:11.661650 Epoch 1940, Training loss 61.85543441772461\n",
      "R2 values 0.9493, 0.8576, 0.8907; mean R2=0.8992\n",
      "Validation Error: Avg loss: 465.962402 \n",
      "\n",
      "2023-11-08 13:34:12.139898 Epoch 1941, Training loss 62.53481674194336\n",
      "R2 values 0.9501, 0.8452, 0.8813; mean R2=0.8922\n",
      "Validation Error: Avg loss: 491.542816 \n",
      "\n",
      "2023-11-08 13:34:12.625075 Epoch 1942, Training loss 55.31707763671875\n",
      "R2 values 0.9590, 0.8548, 0.8985; mean R2=0.9041\n",
      "Validation Error: Avg loss: 402.907135 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:34:13.101510 Epoch 1943, Training loss 76.74774169921875\n",
      "R2 values 0.9497, 0.8627, 0.8837; mean R2=0.8987\n",
      "Validation Error: Avg loss: 420.453064 \n",
      "\n",
      "2023-11-08 13:34:13.840232 Epoch 1944, Training loss 85.72233581542969\n",
      "R2 values 0.9587, 0.8657, 0.9068; mean R2=0.9104\n",
      "Validation Error: Avg loss: 358.424896 \n",
      "\n",
      "2023-11-08 13:34:14.356341 Epoch 1945, Training loss 61.69830322265625\n",
      "R2 values 0.9514, 0.8546, 0.9213; mean R2=0.9091\n",
      "Validation Error: Avg loss: 484.041901 \n",
      "\n",
      "2023-11-08 13:34:14.840852 Epoch 1946, Training loss 63.69737243652344\n",
      "R2 values 0.9430, 0.8418, 0.9188; mean R2=0.9012\n",
      "Validation Error: Avg loss: 530.529053 \n",
      "\n",
      "2023-11-08 13:34:15.324031 Epoch 1947, Training loss 101.55968475341797\n",
      "R2 values 0.9466, 0.8115, 0.8981; mean R2=0.8854\n",
      "Validation Error: Avg loss: 542.932739 \n",
      "\n",
      "2023-11-08 13:34:15.799645 Epoch 1948, Training loss 51.67051696777344\n",
      "R2 values 0.9444, 0.8301, 0.9083; mean R2=0.8943\n",
      "Validation Error: Avg loss: 453.762268 \n",
      "\n",
      "2023-11-08 13:34:16.278963 Epoch 1949, Training loss 58.76096725463867\n",
      "R2 values 0.9524, 0.8429, 0.8774; mean R2=0.8909\n",
      "Validation Error: Avg loss: 429.720795 \n",
      "\n",
      "2023-11-08 13:34:16.791936 Epoch 1950, Training loss 55.439823150634766\n",
      "R2 values 0.9516, 0.8663, 0.8971; mean R2=0.9050\n",
      "Validation Error: Avg loss: 422.670105 \n",
      "\n",
      "2023-11-08 13:34:17.263873 Epoch 1951, Training loss 65.18133544921875\n",
      "R2 values 0.9400, 0.8598, 0.8895; mean R2=0.8964\n",
      "Validation Error: Avg loss: 496.654358 \n",
      "\n",
      "2023-11-08 13:34:17.747925 Epoch 1952, Training loss 63.69536590576172\n",
      "R2 values 0.9536, 0.8137, 0.8840; mean R2=0.8837\n",
      "Validation Error: Avg loss: 471.933502 \n",
      "\n",
      "2023-11-08 13:34:18.232508 Epoch 1953, Training loss 81.3592758178711\n",
      "R2 values 0.9532, 0.8225, 0.9377; mean R2=0.9045\n",
      "Validation Error: Avg loss: 399.578766 \n",
      "\n",
      "2023-11-08 13:34:18.705730 Epoch 1954, Training loss 86.13072204589844\n",
      "R2 values 0.9495, 0.8454, 0.9033; mean R2=0.8994\n",
      "Validation Error: Avg loss: 416.208923 \n",
      "\n",
      "2023-11-08 13:34:19.185556 Epoch 1955, Training loss 60.29296875\n",
      "R2 values 0.9558, 0.8486, 0.8713; mean R2=0.8919\n",
      "Validation Error: Avg loss: 474.094238 \n",
      "\n",
      "2023-11-08 13:34:19.679752 Epoch 1956, Training loss 52.47257614135742\n",
      "R2 values 0.9446, 0.8535, 0.9066; mean R2=0.9016\n",
      "Validation Error: Avg loss: 467.322815 \n",
      "\n",
      "2023-11-08 13:34:20.175772 Epoch 1957, Training loss 60.46381759643555\n",
      "R2 values 0.9445, 0.7884, 0.8838; mean R2=0.8722\n",
      "Validation Error: Avg loss: 489.409302 \n",
      "\n",
      "2023-11-08 13:34:20.667807 Epoch 1958, Training loss 74.11351776123047\n",
      "R2 values 0.9552, 0.8452, 0.8797; mean R2=0.8934\n",
      "Validation Error: Avg loss: 388.880432 \n",
      "\n",
      "2023-11-08 13:34:21.150051 Epoch 1959, Training loss 78.71997833251953\n",
      "R2 values 0.9481, 0.8532, 0.9001; mean R2=0.9005\n",
      "Validation Error: Avg loss: 421.923584 \n",
      "\n",
      "2023-11-08 13:34:21.886102 Epoch 1960, Training loss 56.488407135009766\n",
      "R2 values 0.9457, 0.8380, 0.8963; mean R2=0.8933\n",
      "Validation Error: Avg loss: 453.073608 \n",
      "\n",
      "2023-11-08 13:34:22.418007 Epoch 1961, Training loss 72.92464447021484\n",
      "R2 values 0.9451, 0.8387, 0.9153; mean R2=0.8997\n",
      "Validation Error: Avg loss: 576.308960 \n",
      "\n",
      "2023-11-08 13:34:22.895238 Epoch 1962, Training loss 74.87007904052734\n",
      "R2 values 0.9515, 0.8775, 0.9064; mean R2=0.9118\n",
      "Validation Error: Avg loss: 488.228821 \n",
      "\n",
      "2023-11-08 13:34:23.381673 Epoch 1963, Training loss 58.35637283325195\n",
      "R2 values 0.9504, 0.8484, 0.9124; mean R2=0.9038\n",
      "Validation Error: Avg loss: 434.118073 \n",
      "\n",
      "2023-11-08 13:34:23.859726 Epoch 1964, Training loss 67.74910736083984\n",
      "R2 values 0.9549, 0.8356, 0.9050; mean R2=0.8985\n",
      "Validation Error: Avg loss: 374.528015 \n",
      "\n",
      "2023-11-08 13:34:24.335449 Epoch 1965, Training loss 91.47041320800781\n",
      "R2 values 0.9548, 0.8482, 0.9121; mean R2=0.9050\n",
      "Validation Error: Avg loss: 413.526459 \n",
      "\n",
      "2023-11-08 13:34:24.811838 Epoch 1966, Training loss 69.62110900878906\n",
      "R2 values 0.9430, 0.8360, 0.8905; mean R2=0.8898\n",
      "Validation Error: Avg loss: 492.949799 \n",
      "\n",
      "2023-11-08 13:34:25.286448 Epoch 1967, Training loss 50.9800910949707\n",
      "R2 values 0.9534, 0.8334, 0.8761; mean R2=0.8876\n",
      "Validation Error: Avg loss: 453.245026 \n",
      "\n",
      "2023-11-08 13:34:25.765168 Epoch 1968, Training loss 58.01055145263672\n",
      "R2 values 0.9349, 0.8623, 0.9158; mean R2=0.9044\n",
      "Validation Error: Avg loss: 497.561493 \n",
      "\n",
      "2023-11-08 13:34:26.248643 Epoch 1969, Training loss 86.18041229248047\n",
      "R2 values 0.9311, 0.8605, 0.9064; mean R2=0.8993\n",
      "Validation Error: Avg loss: 568.721436 \n",
      "\n",
      "2023-11-08 13:34:26.723289 Epoch 1970, Training loss 53.72246551513672\n",
      "R2 values 0.9418, 0.8517, 0.8958; mean R2=0.8964\n",
      "Validation Error: Avg loss: 660.557007 \n",
      "\n",
      "2023-11-08 13:34:27.199664 Epoch 1971, Training loss 112.3553466796875\n",
      "R2 values 0.9546, 0.8592, 0.8955; mean R2=0.9031\n",
      "Validation Error: Avg loss: 499.812347 \n",
      "\n",
      "2023-11-08 13:34:27.671882 Epoch 1972, Training loss 68.72791290283203\n",
      "R2 values 0.9446, 0.8432, 0.9072; mean R2=0.8983\n",
      "Validation Error: Avg loss: 449.466461 \n",
      "\n",
      "2023-11-08 13:34:28.151843 Epoch 1973, Training loss 86.68023681640625\n",
      "R2 values 0.9388, 0.8254, 0.9146; mean R2=0.8929\n",
      "Validation Error: Avg loss: 476.703857 \n",
      "\n",
      "2023-11-08 13:34:28.625637 Epoch 1974, Training loss 99.44845581054688\n",
      "R2 values 0.9491, 0.8359, 0.9160; mean R2=0.9003\n",
      "Validation Error: Avg loss: 492.149628 \n",
      "\n",
      "2023-11-08 13:34:29.111882 Epoch 1975, Training loss 64.17618560791016\n",
      "R2 values 0.9508, 0.8511, 0.8997; mean R2=0.9005\n",
      "Validation Error: Avg loss: 577.382324 \n",
      "\n",
      "2023-11-08 13:34:29.598087 Epoch 1976, Training loss 118.14024353027344\n",
      "R2 values 0.9500, 0.8148, 0.8891; mean R2=0.8846\n",
      "Validation Error: Avg loss: 464.540863 \n",
      "\n",
      "2023-11-08 13:34:30.074616 Epoch 1977, Training loss 60.55900192260742\n",
      "R2 values 0.9513, 0.8513, 0.8824; mean R2=0.8950\n",
      "Validation Error: Avg loss: 419.301666 \n",
      "\n",
      "2023-11-08 13:34:30.769869 Epoch 1978, Training loss 67.73509979248047\n",
      "R2 values 0.9439, 0.8277, 0.8907; mean R2=0.8874\n",
      "Validation Error: Avg loss: 439.219940 \n",
      "\n",
      "2023-11-08 13:34:31.240385 Epoch 1979, Training loss 81.23601531982422\n",
      "R2 values 0.9499, 0.8181, 0.8719; mean R2=0.8799\n",
      "Validation Error: Avg loss: 507.011749 \n",
      "\n",
      "2023-11-08 13:34:31.733509 Epoch 1980, Training loss 98.08528900146484\n",
      "R2 values 0.9529, 0.8335, 0.8918; mean R2=0.8927\n",
      "Validation Error: Avg loss: 457.589752 \n",
      "\n",
      "2023-11-08 13:34:32.227649 Epoch 1981, Training loss 51.951107025146484\n",
      "R2 values 0.9589, 0.8659, 0.8871; mean R2=0.9040\n",
      "Validation Error: Avg loss: 400.125702 \n",
      "\n",
      "2023-11-08 13:34:32.705926 Epoch 1982, Training loss 80.40193176269531\n",
      "R2 values 0.9503, 0.8466, 0.8822; mean R2=0.8931\n",
      "Validation Error: Avg loss: 464.900085 \n",
      "\n",
      "2023-11-08 13:34:33.189107 Epoch 1983, Training loss 53.75249481201172\n",
      "R2 values 0.9528, 0.8500, 0.9033; mean R2=0.9020\n",
      "Validation Error: Avg loss: 468.583435 \n",
      "\n",
      "2023-11-08 13:34:33.666778 Epoch 1984, Training loss 54.67652130126953\n",
      "R2 values 0.9472, 0.8405, 0.8748; mean R2=0.8875\n",
      "Validation Error: Avg loss: 469.737091 \n",
      "\n",
      "2023-11-08 13:34:34.144845 Epoch 1985, Training loss 61.601898193359375\n",
      "R2 values 0.9481, 0.8543, 0.8904; mean R2=0.8976\n",
      "Validation Error: Avg loss: 440.241516 \n",
      "\n",
      "2023-11-08 13:34:34.638632 Epoch 1986, Training loss 69.61618041992188\n",
      "R2 values 0.9488, 0.8432, 0.8889; mean R2=0.8936\n",
      "Validation Error: Avg loss: 456.388947 \n",
      "\n",
      "2023-11-08 13:34:35.120487 Epoch 1987, Training loss 56.41591262817383\n",
      "R2 values 0.9470, 0.8412, 0.8916; mean R2=0.8933\n",
      "Validation Error: Avg loss: 534.698303 \n",
      "\n",
      "2023-11-08 13:34:35.588240 Epoch 1988, Training loss 43.083587646484375\n",
      "R2 values 0.9480, 0.8528, 0.9154; mean R2=0.9054\n",
      "Validation Error: Avg loss: 437.462738 \n",
      "\n",
      "2023-11-08 13:34:36.068321 Epoch 1989, Training loss 67.22869110107422\n",
      "R2 values 0.9478, 0.8804, 0.8957; mean R2=0.9080\n",
      "Validation Error: Avg loss: 464.790619 \n",
      "\n",
      "2023-11-08 13:34:36.548931 Epoch 1990, Training loss 53.08393478393555\n",
      "R2 values 0.9319, 0.8272, 0.9108; mean R2=0.8900\n",
      "Validation Error: Avg loss: 536.030823 \n",
      "\n",
      "2023-11-08 13:34:37.315637 Epoch 1991, Training loss 59.950927734375\n",
      "R2 values 0.9518, 0.8404, 0.9089; mean R2=0.9003\n",
      "Validation Error: Avg loss: 412.849243 \n",
      "\n",
      "2023-11-08 13:34:37.797846 Epoch 1992, Training loss 48.18089294433594\n",
      "R2 values 0.9447, 0.8387, 0.9189; mean R2=0.9007\n",
      "Validation Error: Avg loss: 484.469330 \n",
      "\n",
      "2023-11-08 13:34:38.273431 Epoch 1993, Training loss 61.357017517089844\n",
      "R2 values 0.9504, 0.8660, 0.9038; mean R2=0.9067\n",
      "Validation Error: Avg loss: 489.432037 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:34:38.755968 Epoch 1994, Training loss 65.74826049804688\n",
      "R2 values 0.9575, 0.8658, 0.8936; mean R2=0.9056\n",
      "Validation Error: Avg loss: 420.591431 \n",
      "\n",
      "2023-11-08 13:34:39.245036 Epoch 1995, Training loss 50.5992317199707\n",
      "R2 values 0.9515, 0.8634, 0.8962; mean R2=0.9037\n",
      "Validation Error: Avg loss: 423.478516 \n",
      "\n",
      "2023-11-08 13:34:39.826719 Epoch 1996, Training loss 57.688655853271484\n",
      "R2 values 0.9493, 0.8250, 0.9026; mean R2=0.8923\n",
      "Validation Error: Avg loss: 415.014832 \n",
      "\n",
      "2023-11-08 13:34:40.313007 Epoch 1997, Training loss 42.81220245361328\n",
      "R2 values 0.9622, 0.8484, 0.8972; mean R2=0.9026\n",
      "Validation Error: Avg loss: 369.383301 \n",
      "\n",
      "2023-11-08 13:34:40.804265 Epoch 1998, Training loss 60.494972229003906\n",
      "R2 values 0.9483, 0.8233, 0.9085; mean R2=0.8934\n",
      "Validation Error: Avg loss: 469.131042 \n",
      "\n",
      "2023-11-08 13:34:41.289804 Epoch 1999, Training loss 58.54547882080078\n",
      "R2 values 0.9636, 0.8546, 0.9009; mean R2=0.9064\n",
      "Validation Error: Avg loss: 337.971558 \n",
      "\n",
      "2023-11-08 13:34:41.796250 Epoch 2000, Training loss 56.23981475830078\n",
      "R2 values 0.9462, 0.8443, 0.8883; mean R2=0.8929\n",
      "Validation Error: Avg loss: 426.245148 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose between 'Mixed', 'ICCD', or 'Params'\n",
    "features_to_use = 'ICCD' \n",
    "\n",
    "n_epochs=2000\n",
    "# the hyperparameters below were found to be optimal for this model during tuning\n",
    "learning_rate = 0.001055047107715595\n",
    "L2 = 0.0018287918531623708\n",
    "\n",
    "checkpoint_name = 'Anomaly ICCD Input Checkpoint'\n",
    "\n",
    "model = MixedICCDNet(features=features_to_use,\n",
    "                     l1=64,        # MLP nodes layer 1 for ICCD features\n",
    "                     l2=32,        # MLP nodes layer 2 for ICCD features\n",
    "                     param_l1=48,  # MLP nodes layer 1 for parameter features\n",
    "                     param_out=32, # MLP nodes layer 2 for parameter features\n",
    "                     c1=16,        # MLP nodes layer 1 for combined features\n",
    "                     c2=24,        # MLP nodes layer 1 for combined features\n",
    "                     c3=32)        # MLP nodes layer 1 for combined features\n",
    "\n",
    "# Train the model\n",
    "results = train(model,train_loader,val_loader, n_epochs, learning_rate, L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f4fae",
   "metadata": {},
   "source": [
    "# Visualize the training results\n",
    "Plot the learning curves and the predicted vs actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49f0841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, val_loss_list, r2_list, best_R2, best_val_predictions,\\\n",
    "best_val_actuals,best_train_predictions, best_train_actuals = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ea2fc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best r2 value was: 0.9172193787071231\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('The best r2 value was:', best_R2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_loss_list, label='Train',alpha=0.8)\n",
    "ax.plot(val_loss_list,label='Test',alpha=0.8)\n",
    "\n",
    "#ax.set_ylim(0,2000)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MSE Loss')\n",
    "ax.legend()\n",
    "\n",
    "#plt.savefig('101923 Mixed ICCD 3HL predict s0s1J optimized model Learning Curve.png',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c7c286f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r2_array = np.array(r2_list)\n",
    "labels = ['P', 'E$_1$', 'E$_2$', 'mean']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(r2_array.shape[1]):\n",
    "    ax.plot(r2_array[:,i],label=labels[i],alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('r$^2$')\n",
    "ax.legend()\n",
    "ax.tick_params(axis='both')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53b2eac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHVCAYAAAB8NLYkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB1jklEQVR4nO3deVxU9foH8M+ZYZdF0ZBVJE1tBMKNlGtm5oILbnXr6hXSbDPr5jXLa101LDUrTbv+smu7eqOyssRbmFZuqVGZKaKlXtxYJEFnAAVh5vz+GGdkmIXZ5zB83q8XL51zvnPm4YwOD9/l+QqiKIogIiIiohZP5ukAiIiIiMg5mNgREREReQkmdkRERERegokdERERkZdgYkdERETkJZjYEREREXkJJnZEREREXsLH0wG4kkajQUlJCUJCQiAIgqfDISIiIrKZKIqoqqpCdHQ0ZDLLfXJendiVlJQgLi7O02EQEREROezs2bOIjY212MarE7uQkBAA2hsRGhrq4WiIiIiIbKdSqRAXF6fPayzx6sRON/waGhrKxI6IiIhaNGumlXHxBBEREZGXYGJHRERE5CWY2BERERF5Ca+eY0dEnqVWq1FfX+/pMMgJfH19IZfLPR0GETVDUondq6++irfeeguiKGLo0KFYtWoVfvzxR0ybNg11dXXIysrCggULPB0mETVDFEWUlZXh0qVLng6FnKht27aIjIxkXVAiCZNMYvfHH39g9erVOHLkCHx9fTFo0CDs378ff/vb35CTkwOFQoEBAwZg4sSJSExM9HS4RGSBLqmLiIhAUFAQE4EWThRFXL58GeXl5QCAqKgoD0dEROZIJrEDgIaGBtTW1gIA6uvrodFo0NDQgOTkZADA5MmTkZubazaxq6urQ11dnf6xSqVyfdBEZECtVuuTuvbt23s6HHKSwMBAAEB5eTkiIiI4LEskUZJZPHHDDTdgzpw56NSpE6KjozF06FD4+/sjJiZG3yY2NhbFxcVmr7F06VKEhYXpv7jrBJH76ebUBQUFeTgScjbde8p5k0TSJZnE7uLFi9iyZQtOnTqF4uJi7N27FzU1NUbtLA3pzJs3D0qlUv919uxZp8R29uxZDB48GAqFAsnJydi4caNTrkvkzTj86n34nhJJn2SGYrdv346uXbsiPDwcADB69Gjs3LnToIfu3LlzFud2+Pv7w9/f3+mx+fj4YOXKlUhJSUF5eTl69+6NUaNGoU2bNk5/LSIiIiJ7SabHLi4uDnv37kVtbS3UajV27NiBW265BXK5HIcOHUJDQwNycnKQkZHh9tiioqKQkpICAIiIiEB4eDgqKyvdHgcRERGRJZJJ7Pr3749Ro0ahV69eSE5ORpcuXTB27FisXr0akyZNQvfu3TFq1CgkJSV5NM6ffvoJGo2mRczfe/3115GQkICAgAD06dMHu3fvtti+qqoKs2bNQnx8PAIDA5GWloYff/zRoM2uXbuQkZGB6OhoCIKAzz//3Og6nTt3hiAIRl8zZ840+bpLly6FIAiYNWuWvd8qkWQNHjyY/7aJnECtEbHvZAW+OFiMfScroNaIng5JkiQzFAsAixcvxuLFiw2O9e/fH0eOHPFQRFpXr16Fn58fKioqkJWVhbfeesuj8Vjjo48+wqxZs/D666/jT3/6E/79739j5MiRKCwsRKdOnUw+54EHHkBBQQHWr1+P6OhobNiwAUOHDkVhYaF+EUtNTQ1uueUWTJs2DXfddZfJ6/z4449Qq9X6xwUFBRg2bBj+/Oc/m2y7du1a/cpnosbUGhH5RZUor6pFREgAUhPCIZe5Zp5Xc/PH7rvvPrz33ns2X/ezzz6Dr6+vnVEREQDkFZQiO7cQpcpa/bGosAAszFAgPZHldxoTRFH02pRXpVIhLCwMSqUSoaGhVj9v8ODBSExMhJ+fH9atW4eePXvi66+/xrBhw/Dggw8iMzPThVE7x6233orevXtjzZo1+mM333wzxo8fj6VLlxq1v3LlCkJCQvDFF19g9OjR+uMpKSkYM2YMXnjhBaPnCIKATZs2Yfz48RZjmTVrFrZs2YLjx48b/PCsrq5G79698frrr+OFF15ASkoKVq5cafs3S5JSW1uLoqIifW+xvdz9QV5WVqb/+0cffYQFCxbgt99+0x8LDAxEWFiY/nF9fX2rS9ic9d4S2SKvoBQzNhxA02RF99NkzZTeXp/c2ZLPSGYoVmref/99+Pj44Pvvv8cbb7yBqVOnYsiQIW5L6pYsWYLg4GCLX+aGVq9evYqff/4Zw4cPNzg+fPhw7N271+RzGhoaoFarjT6sAwMDsWfPHru/j6tXr2LDhg24//77jXpEZs6cidGjR2Po0KF2X5+8k+6DvHFSBwBlylrM2HAAeQWlTn/NyMhI/VdYWBgEQdA/rq2tRdu2bfHxxx9j8ODBCAgIwIYNG1BRUYFJkyYhNjYWQUFBSEpKQk5OjsF1mw7Fdu7cGUuWLMH999+PkJAQdOrUCWvXrnX690PkDdQaEdm5hUZJHQD9sezcQg7LNiKpoVgp6dq1K1566SUAwJ49e/DRRx8hOTlZP6ds/fr1Lp3v98gjj+Cee+6x2KZxjb/GLly4ALVajY4dOxoc79ixo0GvRGMhISEYMGAAnn/+edx8883o2LEjcnJy8MMPP+Cmm26y75sA8Pnnn+PSpUuYOnWqwfEPP/wQBw4cMJrDR9TcB7kA7Qf5MEWky4ZlzZk7dy6WL1+Od999F/7+/qitrUWfPn0wd+5chIaG4r///S8yMzNx44034tZbbzV7neXLl+P555/HM888g08++QQzZszAoEGD0KNHDzd+N0TSl19UafQLXmMigFJlLfKLKjGgCwuiA0zszOrbt6/+7wMHDoRGo3Hr64eHh+tLv9iraQ+ZKIoW5xGtX78e999/P2JiYiCXy9G7d29MnjwZBw4csDuGt99+GyNHjkR0dLT+2NmzZ/HEE0/g66+/5nAOGZHyB/msWbMwceJEg2Nz5szR//3xxx9HXl4eNm7caDGxGzVqFB599FEA2mTx1VdfxY4dO5jYETVRXmX+s8Cedq0Bh2LNaFqj7n//+x9yc3Ntvs727dvx6quv2vw8R4ZiO3ToALlcbtQ7V15ebtSL11iXLl2wc+dOVFdX4+zZs8jPz0d9fT0SEhJsjh8ATp8+je3bt+OBBx4wOP7zzz+jvLwcffr0gY+PD3x8fLBz50689tpr8PHxMVh4Qa2PlD/IG//CB2i3T1u8eDGSk5PRvn17BAcH4+uvv8aZM2csXqfxYiHdkK9uH1Yiui4ixLpf/q1t1xqwx85KX331FS5fvmyyjp5arTa7b+LQoUPtmkPmyFCsn58f+vTpg23btmHChAn649u2bcO4ceOafe02bdqgTZs2uHjxIrZu3aofkrbVu+++i4iICIPFGABw55134vDhwwbHpk2bhh49emDu3Lncg7KVk/IHedNf+JYvX45XX30VK1euRFJSEtq0aYNZs2bh6tWrFq/TdNGFIAhuHxUgaglSE8IRFRaAMmWtyekZAoDIMO2KedJiYmeFnTt34p///CduuOEGfPDBB9i7dy8mTpyIpKQk7N+/H9OmTYOPjw9Wr16Ny5cvIyEhAZ988gn8/PwwcuRIrFixAjfffDNGjhyJ1NRUbN26FaWlpfjqq6+gUChMvqajQ7GzZ89GZmYm+vbtiwEDBmDt2rU4c+YMHnnkEX2b1atXY9OmTfjmm28AAFu3boUoiujevTtOnDiBp556Ct27d8e0adP0z6mursaJEyf0j4uKinDw4EGEh4cblFHRaDR49913cd9998HHx/CfWUhICBITEw2OtWnTBu3btzc6Tq1PS/og3717N8aNG4cpU6YA0P67P378OG6++WYPR0bkHeQyAQszFJix4QAEwOAzQTexaGGGwu3zbaWMQ7FWuP3225GYmIhvvvkGv/zyCwIDA1FQUICYmBjs2rUL06ZNw6hRo/DDDz/g8OHD6NChg36Y9Pjx4/rFBwUFBUhISMD+/fvx4IMP2jW0a617770XK1euxKJFi5CSkoJdu3bhyy+/RHx8vL7NhQsXcPLkSf1jpVKJmTNnokePHsjKysLAgQPx9ddfG/Qu/PTTT+jVqxd69eoFQJtA9urVCwsWLDB4/e3bt+PMmTO4//77XfY9knfSfZAD1z+4daT2Qd61a1ds27YNe/fuxdGjR/Hwww+bXaBERPZJT4zCmim9ERlm2EsfGRbQKkqd2Io9dibs2LHD6Ni5c+f0u00olUoIgoAnnngCgHZRwtq1a/HZZ5/h6tWrOHPmDKZPnw6lUong4GD4+PhAqVTC19dXvzrUz8/PoCaWKzz66KP6CdqmPPfcc3juuef0j++5555mh38HDx4Ma0ofDh8+3Kp2OqbuObVeug/ypnXsIiVWkHT+/PkoKirCiBEjEBQUhIceegjjx4+HUqn0dGhEXiU9MQrDFJFuK1jekjGxs8K5c+cM5rMVFBQgLS1N//i9997DiRMnsGvXLgQGBiI+Ph4KhQIFBQXo2bOn/jmpqakG13jooYfc900QtTCe/CCfOnWqQYmezp07m/xFJTw83OS2eo01/aXl1KlTRm0OHjxoe5BErYxcJrCkiRWY2FmhqKjIoFxHQUGBQQ27I0eOIC0tDYGBgVi1ahU0Gg3atWuHgoIC/Zyxps85fPgw55MRNYMf5EREtuEcOyskJibi+PHjSEpKwrFjx3DkyBGDJC0zMxPPP/88br/9dlRUVOjPHTlyRJ+8NX5OQ0MDqqur0bZtW7d/L0REROS9uFcsETkV9xP1XnxviTyDe8USERERtUJM7IiIiIi8BBM7IiIiIi/BxI6IiIjISzCxIyIiIvISTOyIiJxk8ODBmDVrlv5x586dsXLlSovPEQSh2SLH1nDWdYioZWNiR0QEICMjA0OHDjV5bt++fRAEAQcOHLDpmj/++KPTd5h57rnnkJKSYnS8tLQUI0eOdOprEVHLw8TOCmfPnsXgwYOhUCiQnJyMjRs3ejokotZBowaKdgOHP9H+qVG77KWmT5+Ob7/9FqdPnzY698477yAlJQW9e/e26Zo33HADgoKCnBWiRZGRkfD393fLaxGRdDGxs4KPjw9WrlyJwsJCbN++HX//+99RU1Pj6bCIvFvhZmBlIvD+GODT6do/VyZqj7vAmDFjEBERgffee8/g+OXLl/HRRx9h/PjxmDRpEmJjYxEUFISkpCTk5ORYvGbTodjjx49j0KBBCAgIgEKhwLZt24yeM3fuXHTr1g1BQUG48cYbMX/+fNTX1wPQ7kudnZ2NX3/9FYIgQBAEfbxNh2IPHz6MIUOGIDAwEO3bt8dDDz2E6upq/fmpU6di/PjxeOWVVxAVFYX27dtj5syZ+tciopaJiZ0VoqKi9EMfERERCA8PR2VlpWeDIvJmhZuBj7MAVYnhcVWp9rgLkjsfHx9kZWXhvffeQ+MNeTZu3IirV6/igQceQJ8+fbBlyxYUFBTgoYceQmZmJn744Qerrq/RaDBx4kTI5XLs378fb7zxBubOnWvULiQkBO+99x4KCwuxatUqvPnmm3j11VcBAPfeey+efPJJ9OzZE6WlpSgtLcW9995rdI3Lly8jPT0d7dq1w48//oiNGzdi+/bteOyxxwzafffddzh58iS+++47vP/++3jvvfeMElsialmY2Nnop59+gkajQVxcnKdDweuvv67f2qdPnz7YvXu3xfYNDQ345z//iYSEBAQGBuLGG2/EokWLoNFoAGh7F3S9AI2/Zs6cqb9GVVUVZs2ahfj4eAQGBiItLQ0//vijweusWbMGycnJCA0NRWhoKAYMGICvvvrK+TeAvJNGDeTNBWBqt8Nrx/L+4ZJh2fvvvx+nTp3Cjh079MfeeecdTJw4ETExMZgzZw5SUlJw44034vHHH8eIESOsnpqxfft2HD16FOvXr0dKSgoGDRqEJUuWGLX75z//ibS0NHTu3BkZGRl48skn8fHHHwMAAgMDERwcDB8fH0RGRiIyMhKBgYFG1/jPf/6DK1euYN26dUhMTMSQIUOwevVqrF+/HufPn9e3a9euHVavXo0ePXpgzJgxGD16NL755hsb7xoRSQkTOytcvXoVAFBRUYGsrCysXbvWwxEBH330EWbNmoVnn30Wv/zyC2677TaMHDkSZ86cMfucZcuW4Y033sDq1atx9OhRvPTSS3j55Zfxr3/9C4B2oreuF6C0tFQ/TPTnP/9Zf40HHngA27Ztw/r163H48GEMHz4cQ4cORXFxsb5NbGwsXnzxRfz000/46aefMGTIEIwbNw5Hjhxx0d0gr3J6r3FPnQERUBVr2zlZjx49kJaWhnfeeQcAcPLkSezevRv3338/1Go1Fi9ejOTkZLRv3x7BwcH4+uuvLf6fa+zo0aPo1KkTYmNj9ccGDBhg1O6TTz7BwIEDERkZieDgYMyfP9/q12j8WrfccgvatGmjP/anP/0JGo0Gv/32m/5Yz549IZfL9Y+joqJQXl5u02sRkbQwsTNh8ODBeOyxxzB79mx06NABw4YNQ11dHSZMmIB58+YhLS3N0yFixYoVmD59Oh544AHcfPPNWLlyJeLi4rBmzRqzz9m3bx/GjRuH0aNHo3Pnzrj77rsxfPhw/PTTTwC0E711vQCRkZHYsmULunTpgttvvx0AcOXKFXz66ad46aWXMGjQIHTt2hXPPfccEhISDF43IyMDo0aNQrdu3dCtWzcsXrwYwcHB2L9/v2tvCnmH6vPNt7GlnY2mT5+OTz/9FCqVCu+++y7i4+Nx5513Yvny5Xj11Vfx9NNP49tvv8XBgwcxYsQI/S9+zWk8vKsjCILB4/379+Mvf/kLRo4ciS1btuCXX37Bs88+a/VrNH6tptc29Zq+vr5G53Q9+ETUMjGxM+P999+Hj48Pvv/+e7zxxhuYOnUqhgwZgszMTKdcf8mSJQgODrb4ZW5o9erVq/j5558xfPhwg+PDhw/H3r3mezEGDhyIb775Br///jsA4Ndff8WePXswatQok6+xYcMG3H///fofBA0NDVCr1QgICDBoGxgYiD179ph8TbVajQ8//BA1NTUmeyeIjAR3dG47G91zzz2Qy+X44IMP8P7772PatGkQBAG7d+/GuHHjMGXKFNxyyy248cYbcfz4cauvq1AocObMGZSUXO+N3Ldvn0Gb77//HvHx8Xj22WfRt29f3HTTTUardP38/KBWWx6GVigUOHjwoMEir++//x4ymQzdunWzOmYianl8PB2AVHXt2hUvvfQSAGDPnj346KOPkJycrF91tn79eiQlJdl9/UceeQT33HOPxTYxMTEmj1+4cAFqtRodOxr+YOvYsSPKysrMXm/u3LlQKpXo0aMH5HK5fmhp0qRJRm0///xzXLp0CVOnTtUfCwkJwYABA/D888/j5ptvRseOHZGTk4MffvgBN910k8HzDx8+jAEDBqC2thbBwcHYtGkTFAqFxe+XCAAQnwaERmsXSpicZydoz8e7puc8ODgY9957L5555hkolUr9/4GuXbvi008/xd69e9GuXTusWLECZWVluPnmm6267tChQ9G9e3dkZWVh+fLlUKlUePbZZw3adO3aFWfOnMGHH36Ifv364b///S82bdpk0KZz584oKirCwYMHERsbi5CQEKMyJ3/961+xcOFC3HfffXjuuefwxx9/4PHHH0dmZqbR5wYReRf22JnRt29f/d8HDhwIjUaDgwcP6r8cSeoAIDw8HF27drX4ZWpSdGNNh1osDb8A2nl5GzZswAcffIADBw7g/fffxyuvvIL333/fqO3bb7+NkSNHIjo62uD4+vXrIYoiYmJi4O/vj9deew2TJ082mKcDAN27d8fBgwexf/9+zJgxA/fddx8KCwubuy1EgEwOpC+79qDpv+drj9Nf1LZzkenTp+PixYsYOnQoOnXqBACYP38+evfujREjRmDw4MGIjIzE+PHjrb6mTCbDpk2bUFdXh9TUVDzwwANYvHixQZtx48bh73//Ox577DGkpKRg7969mD9/vkGbu+66C+np6bjjjjtwww03mCy5EhQUhK1bt6KyshL9+vXD3XffjTvvvBOrV6+2/WYQUYsiiKYmfngJlUqFsLAwKJVKhIaGWv28wYMHIyUlpdmtgCz5/PPPsWPHDrPXWLJkickVcY199dVXuO2224yOX716FUFBQdi4cSMmTJigP/7EE0/g4MGD2Llzp8nrxcXF4R//+IfBKtcXXngBGzZswLFjx/THTp8+jRtvvBGfffYZxo0bZ/JaNTU1UKlUiIqKwr333ovq6mr897//Nfu9DB06FF26dMG///1vi98ztXy1tbUoKirSr9i2W+Fm7erYxgspQmO0SZ1irOOBks2c9t4SkU1syWc4FOsihw4dQnJystnzjgzF+vn5oU+fPti2bZtBYrdt2zaziRigrW0lkxl20srlcqPJ0u+++y4iIiIwevRos9dq06YN2rRpg4sXL2Lr1q36YWtzRFFEXV2dxTZEBhRjgR6jtatfq89r59TFp7m0p46IqKVjYmeF/fv3Y/HixcjNzQUA5ObmYtOmTXjnnXewfv16rF69GpcvX0ZCQgI++eQT+Pn54dChQyYXJeiEh4cjPDzc7phmz56NzMxM9O3bFwMGDMDatWtx5swZPPLIIwCA1atXY9OmTQY1qTIyMrB48WJ06tQJPXv2xC+//IIVK1bg/vvv17fRaDR49913cd9998HHx/ifx9atWyGKIrp3744TJ07gqaeeQvfu3TFt2jR9m2eeeQYjR45EXFwcqqqq8OGHH2LHjh3Iy8uz+/ulVkomBxKMe62JiMg0JnZWUCgUBrWflixZgv/85z8AgFGjRulXyt5///3YvXs37rzzThw5cgQ9e/Z0WUz33nsvKioqsGjRIpSWliIxMRFffvkl4uPjAWgXWJw8edLgOf/6178wf/58PProoygvL0d0dDQefvhhLFiwQN9m+/btOHPmjEGy15hSqcS8efNw7tw5hIeH46677sLixYsNyiacP38emZmZKC0tRVhYGJKTk5GXl4dhw4a54E4QERGRDufYWSk+Ph4nTpxAXl4evvjiC7z11lsQRREvvvgiPvvsM1y9ehVnzpzBli1b0KtXL/Tr148FealV4jws78X3lsgzOMfOBW666SacOHECS5cuxQcffABAuyH3iRMnsGvXLgQGBiI+Ph4KhQIFBQUu7a0jagm8+HfGVovvKZH0sdyJlRQKBV555RUkJSWhc+fOAIAjR44gLS0NgYGBWLVqFTQaDdq1a9fswgkib6Yblr98+bKHIyFn072nTXesICLpYI+dlW6++WbMmjXLoNJ8ZmYmxo0bh3Xr1uH222/X17Y7fPgw7rzzTk+FSuRRcrkcbdu21e85GhQUZLG+IkmfKIq4fPkyysvL0bZtW6O6lUQkHZxjR0ROJ4oiysrKcOnSJU+HQk7Utm1bREZGMlEncrMWOcfut99+w7333mvwOCcnB9HR0Zg2bRrq6uqQlZVlsIKTiKRJEARERUUhIiIC9fX1ng6HnMDX15c9dUQtgGQSO90WVABQXV2Nzp07Y9iwYRg8eDBycnKgUCgwYMAATJw4EYmJiZ4NloisIpfLmQwQEbmRJBdPbN68GXfeeSeUSiUaGhqQnJwMHx8fTJ48WV8k2JS6ujqoVCqDLyIiIqLWQpKJ3ccff4x7770XJSUlBttqxcbGori42Ozzli5dirCwMP1XXFycO8IlIiIikgTJJXYqlQrff/89Ro0aZbJmkqVJu/PmzYNSqdR/nT171pWhEhEREUmKZObY6XzxxRcYMWIEAgICEBMTY9BDd+7cOURFRZl9rr+/P/z9/d0RJhEREZHkSK7HTjcMCwDR0dGQy+U4dOgQGhoakJOTg4yMDA9HSERERCRNkkrslEol8vPzMWLECP2x1atXY9KkSejevTtGjRqlLwJMRERERIZYoJiIiIhIwmzJZyTVY0dERERE9mNiR0REROQlmNgREREReQkmdkRERERegokdERERkZdgYkdERETkJSS38wQRERGR1Kk1IvKLKlFeVYuIkACkJoRDLjO/7am7MLEjIiIiskFeQSmycwtRqqzVH4sKC8DCDAXSE81vfeoOHIolIiIislJeQSlmbDhgkNQBQJmyFjM2HEBeQamHItNiYkdERERkBbVGRHZuIUxt2aU7lp1bCLXGc5t6MbEjIiIiskJ+UaVRT11jIoBSZS3yiyrdF1QTTOyIiIiIrFBeZT6ps6edKzCxIyIiIrJCREiAU9u5AhM7IiIiIiukJoQjKiwA5oqaCNCujk1NCHdnWAaY2BERERFZQS4TsDBDAQBGyZ3u8cIMhUfr2TGxIyIiIrJSemIU1kzpjcgww+HWyLAArJnS2+N17FigmIiIiMgG6YlRGKaIRH5RJfIP/ILU3r248wQRERFRS+UjNxz0FEXP1a5rjIkdERERkZUEwfO9cpZwjh0RERFRMxITE00mdR1j47H3xAWP7jbRGHvsiIiIiMz46KOP8Je//MXkufi5WwAAk97cj6iwACzMUHDxBBEREZHUXLx4EeHhpuvRdZ67xWi/2DJlLWZsOODxlbEciiUiIiJqRBAEk0ldReVF9F+y3SipA6A/lp1b6NFhWSZ2RERERNAmdKbm0X366acQRRG/VapRqjS/D6wIoFRZi/yiShdGaRmHYomIiKhVi4+Px5kzZ4yO9+nTBz/99JP+cXmV+aSuMWvbuQJ77IiIiKhVeueddyAIgsmkThRFg6QOACJCAozamWJtO1dgjx0RERG1KuXl5ejYsaPJc5YKDacmhCMqLABlylqT8+wEaLcWS00wvejCHdhjR0RERK2GIAgmk7rq6upmd4+QywQszFCYTOoA7Ry7hRkKj24txsSOiIiIvJ65hRFffvklRFFEmzZtbLqeDBr0lxVirGwv+ssKIYPGWaE6hEOxRERE5LVCQ0NRVVVldHzIkCH45ptvbLqWWiMiO7cQI2T5WOi7DtHC9dWvJWI4FtVnITs3AMMUkR7rtWOPHREREXmd//u//4MgCCaTOlEUbU7qACC/qBLJVbuwxnclImFY0iQSlXjddyWSq3ax3AkRERGRMxQXFyM2Ntbkuebm0DWnXFWDhb7rAABNO+RkAqARgYW+6/GjajqA9g69lr2Y2BEREZFXMDWHDgCuXLmCgADHS5B0vXzYYPi1KZkARKMCXS8fBtDJ4dezB4diiYiIqEUztzDiu+++gyiKTknqAODmkMtObecK7LEjIiIi6dCogdN7gerzQHBHID4NkMlNNjXXQzdhwgR89tlnTg9NFhLp1HauwMSOiIiIpKFwM5A3F1CVXD8WGg2kL4O6RwbyiypRXlWLrR+sxZqXF5m8hKPz6CyKTwNCoyGqSiGYqGYnQoAQGq1t5yFM7IiIiLydDb1gHlO4Gfg4C2iaMKlKIX6chWd9nsL6sx1RsvZBk093aUKnI5MD6csgfJylTeIaxap9DCD9RY/eW0F0y53wDJVKhbCwMCiVSoSGhno6HCIiIvez0AsGxVjPxdWYRg2sTDSMsRG1RoTP88ZlSwBg84FTyOgV78rojJm8pzHapM4F99SWfIaJHRERkbcy1wuGa3PT7lknjeSuaDfw/hiTp4RslcnjkVNeQUBMD0SGBWDP3CHuLwjccBX48U3g4imgXWeg34OAj59LXsqWfEZSq2KLiopwxx13QKFQICkpCTU1NcjPz0fPnj3RtWtXLFpkejydiIiImtCotb1KJnc2vXYs7x/adp5Wfd7okJCtMpnUCX6BiJ+7Bf4xPSACKFXWur8gcOFm4LVbgK3PAPlrtX++dov2uIdJKrGbOnUqFi1ahMLCQuzcuRP+/v6YOXMmcnJycOzYMeTm5qKgoMDTYRIREUnf6b1mhza1REBVrG3nacEd9X8NeMF0QgcA9857CZ3+vtHoeHlVrctCM6LrBW16b1Wl2uMeTu4ks3jiyJEj8PX1xW233QYACA8PR0lJCRoaGpCcnAwAmDx5MnJzc5GYmGjyGnV1dairq9M/VqlM/8MgIiKSCrVG1K/2jAgJQGpCuHOGFU30gjnUzpXi0/BVcShGvXXO5Gn1glCUoT0G1vUweT4ixDl16prVbC+ooO0F7THaYwsoJJPYHT9+HMHBwRg7dizOnTuHu+++G8OHD0dMTIy+TWxsLHbu3Gn2GkuXLkV2drY7wiUiInJYXkEpsnMLUaq83uMUFRaAhRkKpCdGOXbxRr1gtrZzWbJpgkajgVxuOh2p+2cIfOQCIALZ9ZnQmBhojArTxucWtvSCJtzmnpiakExiV19fj927d+PgwYOIiIhAeno6fH19jdqZK0YIAPPmzcPs2bP1j1UqFeLi4lwSLxERkSPyCkoxY8MBo76fMmUtZmw4gDVTejuW3F2ruQZVKUz3MAna801qrrk02WwagZmf6evGByDzFu1CBKVfBJ6unoytmlSTbcfeEuW+hRMtoBdUMnPsYmNj0a9fP8TFxcHf3x+jRo3C5cuXUVxcrG9z7tw5REWZ/0fl7++P0NBQgy8iIiKpUWtEZOcWWlrWgOzcQqg1DhSuuFZzTatp4nPtcZOaa7pks3FSB1xPNvMKSu2Pp/Grm9kCDABEdQMyV3wN3PU21Fm5GIX/M5vUAcDmX0sdu0+2cKAX1F0kk9j169cP58+fx8WLF6HRaLBr1y706dMHcrkchw4dQkNDA3JycpCRkeHpUImIiBySX1RplDw15rTVnoqx2pImoU06RUKjjUqduCPZtJjQiaK2yLBMrh3GTLob+WJPFKvqLV7Tratidb2gRomyjqCtZ8edJwAfHx8sWbIEgwYNgiiKGD58OMaMGYMOHTpg0qRJqK2tRWZmJpKSkjwdKhERkUOsXcXplNWeirHayfzN7DxhS7I5oEt7m0L46KOP8Je//MX0dS2U03XrfbKGrhf04yxok7vGsZvuBXU3ySR2ADBy5EiMHDnS4Fj//v1x5MgRD0VERETkfNau4nTaak9dL5gFrkii6uvr4ednumhvQ0MD5HLLCZDb75M1dL2gJnfzcM3OE7aQVGJHRETUGqQmhCMqLABlylpzyxoQ6c7VnnB+EmVuyPXzzz/HuHHjrLqGFO8TAKt7QT1BMnPsiIiIWgu5TMDCDAUAs8sasDBD4dZtsnRJlIXZY1aVFmluHp21SR0gzfuk12guIBJuk0RSBzCxIyIi8oj0xCismdIbkWGGPWCRYQGOlzqxg6NJlFULI+wgtfskdYJo751uAWzZNJeIiMgT3FkM2Bq21rF788038dBDD5m8ljNTDKndJ3eyJZ9hYkdEREQGrEmiamtrERgYaPL5Go3G4oYCZBtb8hkuniAiIiIDcplgsaSJuaRt+/btuPPOO10VFlmBiR0REZEHtaQhRnMJXYcOHfDHH3+4ORoyhYkdERGRh7hzX1ZHWBpW9eIZXS0SV8USERF5gLv2ZXXEyy+/7JKVruQ67LEjIiJys+b2ZRWg3Zd1mCLSI8OyFy9eRHi46Xp1XBghbeyxIyIicjNb9mV1N0EQTCZ1+/fvhyiKTOquUWtE7DtZgS8OFmPfyQqoNdLovWSPHRERkZtJbnN7mJ9H17lLN5z4/ZhkF3R4gpTnRrLHjoiIyM2ktLm9pR0j4udugXj3Cgxc9q0k5vxJgdTnRjKxIyIicjNn7cvqiIkTJ1pM6OLnbtE/lkrS4mnNzY0EtHMjPTksy8SOiIjIzTy5uX1paSkEQcCmTZuMzvVfst0godORStLiaVKeG6nDxI6IiMgDPLG5vSAIiI6ONjr+/fffY++JC5JPWjxNinMjm+LiCSIiIg9JT4zCMEWky3eeMDfk6uPjg/r6egDAFweLrbqWq5MWKe/EIaW5keYwsSMiIvKg5vZldYQtO0ZIIWmR8mpT4PrcyDJlrcl5dgK0Pa6unBvZHA7FEhEReZm0tDTzO0b8bxdEdYPRcU8v6JD6alPAs3MjrcXEjoiIyEsUFRVBEATs27fP6Jy4MBTiwlDg/THAykSgcLPBeU8mLS1htamOJ+ZG2kIQvXijN5VKhbCwMCiVSoSGhno6HCIiIiPOmlNmrofu0CPBSOrYtB/nWtt71gGKsQZnPDEcuu9kBSa9ub/ZdjkP9nfZsLWtrjZosH7fKZyuvIz48CBkDugMPx/X9JfZks9wjh0REZGHOCOJMpfQderUCaefCAJUJSbOXtuRNu8fQI/RgEyuP+OuBR2NtYTVpo2Zet/e2lMkibmAHIolIiLyAEfnlFnaMUIURZzescFMUqdvBaiKgdN7jc7oFnSMS4nBgC7tXT5nzJoFGTJo0LXmIHD4E6BoN6BRuzQmc6Q+F5CJHRERkZs5MqfspptuspjQ6WdYVZ+3Lhhr27lQakI42gb5mj0/QpaPvQFPoOe2ycCn083OE3S1ljAXkIkdERG1KmqNiH0nK/DFwWLsO1nhkR/C9uxgUFBQAEEQcOLECeP2jRM6neCO1gVjop0U7pHOCFk+1viuRAQqDI6LqlLg4yy3JnctYecJzrEjIqJWQyp10mydU2auh+7EiRPo0qWL6SfHpwGh0YCqFDBXdS00WtuuEU/co/yiSly6XG90XAYNFvquu/Z3QwJEiBAgmJgn6CotYS4ge+yIiKhVkNLcKGuL/I7vFWsyqbv11lshiqL5pA7QJjrpy649MFPAJP1Fg4TIU/eoTGU6EUqVHUO0UAlzU/wEC/MEXUEKRZybw8SOiIi8XuO5UTJo0F9WiLGyvegvK4QADQD3zo1qrhjw6WVjcHrZGJPnRFHE/v3NlwYBoC1lcs86ILRJT1totFGpE0/OH6usrjN5PAKXrHq+pqrMidGY1/h9a/rvSAaNy4s4W4NDsURE5PV0c6NGyPKx0HcdooXrc6BKxHBk12dhqzIV+UWVbqmTpisGPGPDAQi4njidWX4XxAbTSY7dZWcVY7VDlaf3ahdKBHfUDr82Gbq0Zf6Ys+9ReBs/k8f/gHU1aI+qAtDTmQGZoXvfPv/gDSww8e9oUX0Wxmc8wp0niIiIXKm8qlY/CT8ShhPbI1GJNb4rMUKW79a5UY13MKg9cwinl40xmdSZXBhhK5kcSLgNSLpb+6eJ+WienD8WGRbo0PMvXr7qpEialy77EWv8ViFSaPLvSKjEGr9VSJf96LZYTGGPHREReb2INr7XJ+E36UyRCYBGBBb6rsfpNjOtvqYzdoxIT4zCyKRok+eKi4sRHW36nCt4cv6YboizaY/hDVBZF5PMunYO06iBvLkQIBoNo+t7yty4mMMUJnZEROT1UuXHIBfMl6CQCUA0KtBRfgxARLPXc+WOEePGjcPnn39u1TWcSZdclSlrza2hRaSL5o81Hppu/NrlaGvV8xM6W1hE4kyn91pf9DnhNvfE1ASHYomIyOvJa8qd1s7VO0Z4IqkDridXgNk1tFiYoXDZ/DHd0HRU2PUewXxND5SI4TC3XkMjAiVie/wk9nBJTEZaQNFnJnZEROT9HCjW25gjK0ebS+gcnkfnBI3n/TUWGRaANVN6u7zWX3piFPbMHYKcB/tj1V9S8Ogd3ZBdnwUARsmd7nF2fSbKa4xr4LmEk/4duRKHYomIyPvFpwGB7YArF823CQw3KtbblD0rR9977z1MmzbNdHsJJHNNpSdGYZgi0uH5g/bS7VMLAPtOVmD1d6lY2zAGD/r8F40LLWsg4K2G0diqScVUd9WNs7PoszsxsSMiolbC8cTEWTtGuHthhK0aJ1eelJoQjr8EH8RD9VuMzskg4iGfLTgVqEBqwij3BKQr+vxxFmBQqAYwV/TZ3TgUS0RE3u/0XuBKM/t3XqlsdgcDR3eM6NKlC0RRlHRSJyXyxluKmVjNDAALfddBfq3ItFvYUPTZE9hjR0RE3s9Jk96bWzlqbrcIwPywqzPKpnit03sReKXMbGerTID2vLtXoVpZ9NkTJJXY+fj4IDExEQDQt29fvPXWW8jPz8e0adNQV1eHrKwsLFiwwMNREhFRi+OkSe/mdoywJ6EDnFM2xRUkk2xKeRWqruizxEgqsWvbti0OHjxocGzmzJnIycmBQqHAgAEDMHHiRH3yR0REZJX4NFwJjIT/5TKTG8prRKAuKBKBVkx6160czc4txLGvP8ClHe+YbNfcwghd2ZSmrXRlU9yxCtVcXJJJNlvAKlSpkfQcu5KSEjQ0NCA5ORk+Pj6YPHkycnNzzbavq6uDSqUy+CIiIs9Ra0TsO1mBLw4WY9/JCpdsIG9VHJBZUTYjC2orfywOV3TE/meGmkzqKisrm03qHCmbYg9r3wdHa/Q5nW4VqtmFLwIQGuPRVahSI6keO5VKhT59+iAwMBCLFy9GmzZtEBMToz8fGxuLnTt3mn3+0qVLkZ2d7Y5QiYioGVLq+ckvqsSH1Sm4KJuFhb7rEN1ov9gytEd2fSa21qVgnBUb3Jtb6Tp48GB89913Vsdja9kUe1n7PjSXbArQJpvDFJHuG5ZtAatQpUZSid2pU6cQHR2NgoICjB49GuvWrTNqY+4/FADMmzcPs2fP1j9WqVSIi4tzSaxERGSe1IYZdeVHtmpSsa2uL1JlxxCBSyhHW+RrekBzrafOUjkTSz9/bK1HZ2vZFHvZ8j40TjZl0Ji8R85KNm2iW4WaN9dwO6/QaG1S5+FVqFIjqcROt/w7MTERCoUCgiCguLhYf/7cuXOIijL/QeDv7w9/f3+Xx0lEROZJseencZkSDWTYr1E0207HmQmdpddxpJ0ptr4PuiRyhCxf26vZaG/dEjEc2fVZ2KpJdTjZtIuEV6FKjWTm2F28eBF1dXUAtAlcYWEhEhMTIZfLcejQITQ0NCAnJwcZGRkejpSIiCyxZZjRXfrEtzO5aKIxmaBtp/P444+7bAswe+Kxla3vQ0RIAEbI8rHGdyUiYfjeRKISa3xXYoQs36Fk0yG6VahJd2v/ZFJnkmR67I4ePYqHH34YMpkMgiBg1apVCA8Px+rVqzFp0iTU1tYiMzMTSUlJng6ViIgscNcwoy1+Pn3R7EbyOhpR265vp1D4+fmZbFNTU4OgoCC3xmPvsKet70NqfBhu9FsPiKaLAWtEINtvPW6In29XPOQekkns0tLScPjwYaPj/fv3x5EjRzwQERER2cMdw4y2sjbJSevaweTx8ePHY9OmTW6Px5Hk19b3QX52HzqiwmIx4EhUAGf3SbJ+G2lJJrEjIiLvoNudwdIwYFSYtuitu3RoY3n+tb0Fhu3ljuS3uV0yBACRjd8HKRcDJqtJZo4dERF5B7lMwNhbLK94HXtLlHt3MjDzUqeXjTGb1Dk6j84SXdJloTqbw8mvbpcM3fWaXh8AFmYorr8PLAbsFZjYERGRU6k1Ijb/armQ7eZfS91arPhCdZ3B4/JNiz2S0OnYnHTZSbdLRmSYYc9fZFiAcckZfTFgC1gMWPI4FEtERE7V3GpMwHzxXVftUaob0tTU1+LsirtNtuk053N8+MhAh1/LWo23Jmt8vyKdXMQ5PTEKwxSRzd9XmRxIvBvY+5r5iyXexdWoEsfEjoiInMrehQGu3KkiNSHcbA9dSO/RaD9shuF8MzexOulykFwmNL+6VqMGCj6x3KbgU2Doc55J7jRq1rGzgk2JXeNdHZqzYsUKm4MhIqKWz56FAa7cqcJSgeH4uVucOvRpD6uSLnc4vddwZwdTVMXadu5eFVu42czOE8u480QTNiV2v/zyi8Hjn3/+GWq1Gt27dwcA/P7775DL5ejTp4/zIiQiohbF1tWYrtqpormETsfZQ58tllRXxRZuvrZXbJN/IapS7fF71jG5a8SmxK7x5sYrVqxASEgI3n//fbRrp62MffHiRUybNg233cb6NkRErZVuYcCMDQfMbdtu0Dtmyw4J1vRsJSYmmq1/Koqiy+bxtXhSXBWrUWt76iyl/Xn/0G43xmFZAA6sil2+fDmWLl2qT+oAoF27dnjhhRewfPlypwRHREQtky2rMZ1VrLeyshKCIJhM6tRqtX6lq27oc1xKDAZ0ac+kTke/KtZCERZ3r4ptdnhYvD48TAAcWDyhUqlw/vx59OzZ0+B4eXk5qqqqHA6MiIhaNmsXBjijWK+5Yddnn30WL7zwgvVBt2YyuXbO2sdZ5tukv+jenjGpDg9LmN2J3YQJEzBt2jQsX74c/fv3BwDs378fTz31FCZOnOi0AImIqOWyZmGAzTskND5nYR6d2Vp0XF1pnmIskPY4sG81IGquHxdkwIDH3D+XTYrDwxJnd2L3xhtvYM6cOZgyZQrq6+u1F/PxwfTp0/Hyyy87LUAiInKclOeV2TonD7AzoQO4urI5hZuBvf+C0Zw2UdQej+3n3vukGx5WlRrHBEA7PBzNosmNCKKD5bVrampw8uRJiKKIrl27ok2bNs6KzWEqlQphYWFQKpUIDQ31dDhERB7hyvpwzmRNnG3atMHly5dNPr/ZH2fXVleKEA1mkYkQtI9b++pKjRpYmWhhTtu1JGrWYff2cOpXxQIm0/5W8L7Zks84nNhJGRM7ImrtzNWH0yU2jtSHcwVzPYvnzp1DXFycyedoNBqLPXjaRtqkRVSVmFwaIEKA4ImkRUqKdgPvmy7ibOC+LRKpYxejnfPn5UkdYFs+49DOE7t378a///1vnDx5Ep988gliYmKwfv16JCQkYOBA923LQkRExlxVH86VTM3JM5e0/d///R8effRR6y58bXWl+fWeoueK70qFlBcqKMZqS5pwbmSz7C538umnn2LEiBEIDAzEL7/8gro67QbLVVVVWLJkidMCJCIi+9hSH06KBEEwm9SJomh9UgdAU1Xm1HZeSeoLFWRybdKddLf2TyZ1Jtmd2L3wwgt444038Oabb8LX11d/PC0tDQcOHHBKcEREZD9n1Ydzt+YSOntmEB2tCnJqO68kxTp2ZDO7h2J/++03DBo0yOh4aGgoLl265EhMRERkh6sNGqzfdwqnKy8jPjwI3TqGWPU8a+vIuZrdK12tcCIoCe3EcESiEqZGnTUiUIb2OBGUhJ7Gp1sHgzp2ZtYnu7uOHdnM7sQuKioKJ06cQOfOnQ2O79mzBzfeeKOjcRERkQ2WflmIN3cXQdPoZ7FMAIL85LhyVW1zfTh3Onr0KBQKhclzzlrfFxHaBtn1WVjjuxIaEQbJne6eZddnYmqodCo7eIRirHaVqcmSMK1joUJLZ3di9/DDD+OJJ57AO++8A0EQUFJSgn379mHOnDlYsGCBM2MkIiILln5ZiH/vKjI6rhGBy1fVAMz2vxjVh3M3c710H330Ee655x6nvU5qQjhmhwzCo1XAAt91iMb1eYVlaI9F9Zk4FDLI40muJHh6oQILSDvE7sTu6aefhlKpxB133IHa2loMGjQI/v7+mDNnDh577DFnxkhERGZcbdDgzd3GSV1jggBEBPvjfFWd/likh+vYuXLY1ZTrRZBrsa2uL/rJjiECl1COtvhR0wMayLDGw0mupOgWKrgbC0g7zO46dmfOnEFsbCxqa2tRWFgIjUYDhUKBNm3a4OzZs+jUqZOzY7UZ69gRkbd7e/f/8Px/jzbb7tlRNyMxJszjO0+4O6FrqqUUa26V9IWIzVRdbAWFiM1xSx27hIQElJaWIiIiAn379tUfr6ioQEJCAtRqtb2XJiIiK52uNL0LQ1NnL17Gg4M8N//Z0wmdTnpiFIYpIiW7vVqrpVFre+osVV3M+4d2iJjDshbZndiZ+49YXV2NgABprLAiIvJ28eHWleewtp2z/fDDD+jfv7/Jc57a+MhUEWTysGsFpM1jAWlr2ZzYzZ49G4D2t68FCxYgKOj6h4VarcYPP/yAlJQUpwVIRETmZQ7ojMVfHjVYDduUTNC2czdzvXTbtm3D0KFD3RwNSZqUd71oYWxO7H755RcA2t+0Dh8+DD8/P/05Pz8/3HLLLZgzZ47zIiQiIrP8fGR48LYEk6tidR68LQF+PnbXo7eZVIZdXc3cvrZkB6nvetGC2JzYfffddwCAadOmYdWqVVyUQETkYfNGaWvAmapj9+BtCfrzrtZaEjqAizCcTrfrhaoUpufZCdrz3PWiWXavim0JuCqWiFxKYvW2rlxVY8mXhThVcRmd2wfhmVEKBPq5Pp7WlNAB2qRuxoYD5tZuYs2U3kzu7KFfFQuYrLrIVbFW5TN2980vXboU77zzjtHxd955B8uWLbP3skRELUPhZmBlIvD+GODT6do/VyZqj3tAXkEphizfgfX7z2D38QtYv/8MhizfgbyCUte9Zl6e0/d0lTq1RkR2bqHZtZsAkJ1bCLWlSY9kmm7Xi9AmSXFodKtO6mxld49d586d8cEHHyAtzbBb9IcffsBf/vIXFBVZLpjpDuyxIyKXkFi9LU/0IJlL6H788UeDEljeZt/JCkx6c3+z7XIe7M+Vt/aSWE+4FLiljl1ZWRmioow/KG644QaUlrruN0QiIo+SWL2t5nqQBGh7kIYpIp0ysb+1Dbs2VV5V23wjG9oBYCLTlKd2vfASdid2cXFx+P7775GQkGBw/Pvvv0d0dLTDgRERSZLE6m3lF1UaTOA3EQ1KlbXIL6p0qAeptSd0Oh2C/Z3ajltokbPZndg98MADmDVrFurr6zFkyBAAwDfffIOnn34aTz75pNMCJCKSFInV23JJD1Ij3pjQOVSmxNpv2Zp214b0RYho/OqiqhTCx1mcV0Z2sTuxe/rpp1FZWYlHH30UV69eBQAEBARg7ty5mDdvntMCJCICJFQzTGL1tiJCrNvpx9p2Oh988AH++te/mjzXUhM6wPEyJRdq6qx6nWbbXRvSb5rUAYBw7ajALbTIDnYndoIgYNmyZZg/fz6OHj2KwMBA3HTTTfD3t7L7mYjISpKqGSaxelupCeGICgtAmbLWXDSIDNMmwtYy10v322+/oVu3bvYFKgHmFpmUKWsxY8MBqxaZOC2Rvjakb+5XE4FbaJGdHC5FHhwcjH79+iExMZFJHRE5ne6HcdN5ZLofxq4s52GSTK6d/wQAJvpaAADpL7qtl0UuE7AwQ2EpGizMUFjVuykIgsXyJS05qXNWmRJdIm0+IdP+0tFcIq2pKmsuZJvaEenY1GM3e/ZsPP/882jTpo1+z1hzVqxY4VBgRETuXvFpNV29LZOT3l90+7yo9MQorJnS26hXM9LKXk1vnEfXlLMWmegS6RkbDkCAyTK6ViXSR6uC0NOKuK1tR6RjU2L3yy+/oL6+Xv93cyx9SBARWctdKz7tohirnf8kkTIV6YlRGKaItGkeYmtI6HScucjE0UQaAE4EJaGdGI5IVMLUW6QRgTK0x4mgJCZ2ZBObEjvdPrFN/+5Mly9fxs0334w///nPeOWVV5Cfn49p06ahrq4OWVlZWLBggUtel4ikx9UrPh0msXpbcplgNsFtvPjku0/fx6oXnjXZztsSOh1nLzKxJ5E2eJ3QNsiuz8Ia35XQiDBI7nSjwdn1mZga2saq6xHp2L14wlUWL16MW2+9Vf945syZyMnJgUKhwIABAzBx4kQkJiZ6MEIichdXrfj0VuZWDusWn5RcuoIzL2WYfG5xcbFX1yB1xSITS4m0NfHMDhmER6uABb7rEI1K/bkytMei+kwcChlkUzxEgB1z7Kxlzxy748eP49ixY8jIyEBBQQFKSkrQ0NCA5ORkAMDkyZORm5trNrGrq6tDXd31JeYqlcrmGIhIOlzxw9hbmVs5PPaWKKzdVYRTy8aYfF5IWDuoLlWaPOdNnDU3zvnx1GJbXV/0kx1DBC6hHG3xo6YHNJBhjRvjIe9h8xy7xn7++Weo1Wp0794dAPD7779DLpejT58+dgUzZ84cvPzyy9i7dy8AoKSkBDExMfrzsbGx2Llzp9nnL126FNnZ2Xa9NhFJj9R+GEuVuTIepcpaPDPa/AytznO3IDIsAGqN2CruoTPmxrkqnv1Khf64x0r5kFewe47dihUrEBISgvfffx/t2rUDAFy8eBHTpk3DbbfZPufkiy++QLdu3dCtWzd9Ymdqroelyb7z5s0z6FVUqVSIi4uzORYikg6p/TCWGnMrh0+b6aEDgPi5WwB4ePGJhzg6N87b46GWz+45dsuXL8fXX3+tT+oAoF27dnjhhRcwfPhwm7cV279/Pz788ENs3LgR1dXVqK+vR2hoKIqLi/Vtzp07h6go8x/i/v7+rKVH5IX4w8+8piuHL+3eAOXeD0221SV0TXls8YmHODI3zhWkFg+1bHYndiqVCufPn0fPnobd/OXl5aiqqrL5ekuXLsXSpUsBAO+99x4KCgqwYMECbN68GYcOHYJCoUBOTg7efvtte0MmohaMP/xM0yVloqjBmZdM18+Lm/URZP7mV1dy8QmR97A7sZswYQKmTZuG5cuXo3///gC0vW5PPfUUJk6c6LQAV69ejUmTJqG2thaZmZlISkpy2rWJqOWQzF6xEhMREmB22DUgoTc63rPI7HO5+ITI+wiinUWLLl++jDlz5uCdd97RFy328fHB9OnT8fLLL6NNG8/X3lGpVAgLC4NSqURoaKinwyEiO0lqr1gJsTTnuOmwq7nFJ9bsj0pEnmVLPmN3YqdTU1ODkydPQhRFdO3aVRIJnQ4TO6KWz9yKz9acmNiS0AFAG385Qvx9UKa6Xg6KiTFRy2FLPuNQgeLdu3fj3//+N/73v/9h48aNaNOmDdavX4+EhAQMHDjQkUsTEUl3r1gPeeCBB8zOMza3MAIAaurUWJvZFzJBkPxQNofciRxjd2L36aefIjMzE3/9619x4MABfWHgqqoqLFmyBF9++aXTgiSi1knSe8W60dWrV82u+P9o33E8/flvzV7jQnUdxqXENNvOkzjkTuQ4mb1PfOGFF/DGG2/gzTffhK+vr/54WloaDhw44JTgiKh1k/xesW4gCILJpG7ChAkQRRFxN7Qz8SxjUl/5qhtyb5rIlylrMWPDAeQVlHooMqKWxe4eu99++w2DBg0yOh4aGopLly45EhMREYDWvVespXl0jadGe8O2axxyJ3Ieu3vsoqKicOLECaPje/bswY033uhQUEREwPWkxdyPcgHaoTopJy22EgTBbFIniqLRjjy6bdcAGN2nlrLtmi1D7kRkmd2J3cMPP4wnnngCP/zwAwRBQElJCf7zn/9gzpw5ePTRR50ZIxG1UlJPWtQaEftOVuCLg8XYd7ICao39RQZGjBhhU0LXmG7btY6hhj2XkWEBLWLVMIfciZzH7qHYp59+GkqlEnfccQdqa2sxaNAg+Pv7Y86cOXjsscecGSMRtWJS3SvWWRP9q6urERISYvJcfX09fHxs+Zg2TP4crGblNo2H0mXQIFV2DBG4hHK0Rb6mBzTX+iC8ccidyNkcrmN3+fJlFBYWQqPRQKFQIDg42FmxOYx17Ii8h5TKYDirtp65HrrHH38cr732mtvj8RS1RsTAZd/ilqpdWOC7DtHC9SHXEjEci+qz8GvIIOyZO0TSQ8pEruLyOnb19fUYPnw4/v3vf6Nbt27o27evXYESEVlLKnvFOmOiv7ULI9wVj6fJZQJe730Ot+xdaXQuEpV43Xclfu19o2TjJ5ISu+bY+fr6oqCgwOKHExGRN3Jkor+tCyNcHY9kaNTodeRFCALQNHeTCdr71uvIMkCj9kx8rZFGDRTtBg5/ov2T977FsHvxRFZWltkK6ERE3sqeif6JiYlOT+hMvY4MGvSXFWKsbC/6ywohg8ZkO8k5vRdQlVhY/SwCqmJtO3K9ws3AykTg/THAp9O1f65M1B4nybN78cTVq1fx1ltvYdu2bejbt6/RHrErVqxwODgiIqmxpbbehQsXcMMNN5g8r9FonDLqoYtnhCwfC03MT8uuz8JWTaq0Fx5Un3duO7Jf4Wbg4yw0XYgDVan2+D3rAMVYj4RG1rE7sSsoKEDv3r0BAL///rvBOQ7REpG3Sk0IR9sgX1y6XG+2TdsgX6R17WDy3OLFi/HMM884NZ6/BB/EkvqVRuciUYk1vivxjO/TSE0Y5bTXdLrgjs5tR/bRqIG8uTBK6gDoZ2zm/QPoMRqQyd0cHFnL7sTuu+++c2YcREQWSWlVrCWnl43BaTPnXFF+RA4NFvquA+pNz0/TiMBC33WQ4x8AJPrDOD4NCI3W9gqZ2z8jNFrbjlzn2pC4eY2GxBNuc1tYZBu7E7vGdB9W7KkjIlfIKyjF85sPI676V319s7PBt2D+2CS3l/HIL6o02Vt3etkYs89xaT2503sReKXMuILzNTIB2vNS/mEskwPpy64NAQowTO6ufWPpL7KXyNU4JO4V7F48AQBvv/02EhMTERAQgICAACQmJuKtt95yVmxERMgrKMXnH7yBjXUP40O/F/Ca32p86PcCNtY9jM8/eMPtm8M3XYRwZsVdZpM6RxdGWMVbfhgrxmrnb4U2SdRDozmvy104JO4V7O6xmz9/Pl599VU8/vjjGDBgAABg3759+Pvf/45Tp07hhRdecFqQRNQ6qTUidnz+Dl73XWl0Tlff7JnP/TBM8YzbhmV1ixAaVOUoXnO/yTbxc7cg58H+bolH3SbCqgFWa9t5lGKsdv7W6b3aRDS4o3b4lT117sEhca9g984THTp0wL/+9S9MmjTJ4HhOTg4ef/xxXLhwwSkBOoI7TxC1bPuOlyN+w62IRKXR/DFAO3+sDO1xesp+DLgpwi0xqTUifOSmBzvC0x9H6C0jEBkW4LZdEqR4j6gF06+KBUwOibP31CNsyWfsHopVq9Umd5zo06cPGhoa7L0sEZGe+tT3iBZMJyyAdv5YtFAB9anv3RKPIAhmk7r4uVsQessIAMDCDIXbehDLa+qRXa/9Qaxp8mu67nF2fSbKa8yv4iXS45B4i2f3UOyUKVOwZs0ao3p1a9euxV//+leHAyMiihAuObWdvSwtDIufu0X/98iwACzMULh1QUdESAC2alIxo36Wto4drtexK0N7ZNdnYqsmFVOlXMeOpIVD4i2aQ6ti3377bXz99dfo3187l2T//v04e/YssrKyMHv2bH07FismalmuXFVjyZeFOFVxGZ3bB+GZUQoE+rn/Q73LjV2APVa2c4Hm9nSVQgmW1IRwRIUF4GtlKrbV9UWq7Jh+5XC+pgdEyBAVpo2NyGoyuXRXUZNFds+xu+OOO6x7AUHAt99+a89LOIxz7Ihs9+C6H7GtsNzo+DBFBN7M6ufeYDRqXHlZAf/LZWbnj9UFRSLwqUKn9iYUFhaiZ8+eJs+5fJWrHfIKSjFjwwEAJmdFYc2U3m4vC0NEzmNLPmN3YtcSMLEjso25pE7HI8ld4WaIH2dCFA0L8GpEQBAA4Z71Tp33Y66XbtOmTRg/frzTXsfZ8gpKkZ1biFLl9XIsUR4YGiYi57Mln3FKgWIiavmuXFVbTOoAYFthOa5cVbt1WDZP0w+fX52FBSbmjy26monxmn5Id8LrNDfsKnXpiVEYpoj0+NAwEXkWEzsiAgAs+bLQ6nbPj09ycTRaao2o7YXSpOJrE/PHNJDh19xCDFNE2p3AtPSErjG5TMCALu09HQYReRATOyICAJyquOzUds6QX1SpH1rUQIb9GoVRm1JlLfKLKm1OaLwpoSMi0nFoSzEi8h6d2wc5tZ0zlCmvOLUdoF29by6pc8sWYERELsTEjogAAM+MMu4Nc6SdM1TWXHVqO0EQ9FsgNrZjxw4mdETkFVya2P3888+uvDwROVGgnxzDFJa3nBqmiHDrwonwYH+ntBMEwWIv3e23325zbEREUuTSxG7ChAmuvDwROdmbWf3MJneeKHUSGWrdbgnm2jWX0LGXjoi8jcOLJ+655x6Tx0VRRGVlpclzRCRdb2b1k8zOE7pdFRrXZmvK1K4KXBhBRK2Vw4nd9u3bsX79egQHBxscF0URu3btcvTyROQBgX5yt5U0sUQuE7AwQ2FxV4WFGQp9qZMvv/wSo0ePNnktJnRE1Bo4nNgNHjwYwcHBJueo9OrVy9HLE7UKUthzVKrSE6OwZkpvPLe5EGWq6z13kU12VTDXS3fw4EHccsstbomViMjTHE7sPvvsM7Pn8vLyHL08kdeT5FZQGjVwei9QfR4I7gjEpzl1L1b7GPa46XrgOOxKRHSdzYsnRo0aBaVSqX+8ePFiXLp0Sf+4oqICCoX7yiEQtWS6zdubziErU9ZixoYDyCsodX9QhZuBlYnA+2OAT6dr/1yZqD3uAbp7VKaqMzj+w7PDMDIp2uRzuDCCiFormxO7rVu3oq7u+gfssmXLDBZJNDQ04LfffnNOdEReTLddlqn0Q3csO7cQao0bE5TCzcDHWYCqxPC4qlR73M3Jnal7dHrZGJxeNsZkeyZ0RNTa2ZzYNf3Q5IcokX0ab5dliojr22W5hUYN5M1F0yHP69EAyPuHtp2bNL5H1QXfmE3o9p644JnPIo0aKNoNHP5E+6cb7w0RkSncK5bIQ8qrzCd19rRz2Om9xj11BkRAVaxtl3CbW0LSfe/mErroh96Eb7so992jxgo3axPhxvcsNBpIXwYoxro/HiIi2NFjZ6rgp6XJy9aqqqpCv379kJKSgqSkJLz55psAgPz8fPTs2RNdu3bFokWLHH4dIqmICLGu+K617RxWfd657ZxgfK9Ys0ld/Nwt8G2nXVzitnukI7EhayIiHZt77ERRxNSpU+Hvr93Cp7a2Fo888gjatGkDAAbz72wRFBSEnTt3IigoCJcvX0ZiYiImTpyImTNnIicnBwqFAgMGDMDEiRORmJho12sQSYmu+G6Zstbk4KcAbUmPpsV3XSa4o3PbOcDSL4vxc7dcbwc33yPAiiFrQTtk3WO0BFYSE1FrY3Nid9999xk8njJlilGbrKwsmwORy+UICgoCoE0W1Wo1ampq0NDQgOTkZADA5MmTkZubazaxq6urM0gsVSqVzXEQuUvj4rsCmi++63LxadqhRFUpTCctgvZ8fJrLQrCU0HWeu8Xz9wiQ5JA1EZGOzYndu+++64o4AACXLl3C7bffjuPHj+Pll19GeXk5YmJi9OdjY2Oxc+dOs89funQpsrOzXRYfkbPpiu82rWPXtPiuW8jk2vlhH2cB5lLN9Bdd0gu1YsUKPPnkkybPiaJostafR+4RIMkhayIiHUktnmjbti1+/fVXnD9/HhMnTkTfvn2N2lj6jX7evHmYPXu2/rFKpUJcXJxLYiVylvTEKAxTREpj5wnFWOCedWYWBbzo9EUBoihCJjM91be0tBSRkZEAJHaPJDRkTUTUlKQSO52OHTsiOTkZx44dQ3Fxsf74uXPnEBVl/rdzf39//dw/opZELhMwoEt7T4ehpRirnR/m4p0nzP2SFhcXhzNnzhgdl8w9ksCQNRGROTavinWV8+fP6+fEqVQq7Nq1C7169YJcLsehQ4fQ0NCAnJwcZGRkeDhSolZAJtfOD0u6W/unE5M6UyvrdURRNJnUSYpuyBrA9Zl+MHzsoiFrIqLmSKbH7ty5c5g+fbq+cvxjjz2G5ORkrF69GpMmTUJtbS0yMzORlJTk6VCJyA5etaerm4esiYisJYgt7hPVeiqVCmFhYVAqlQgNDfV0OESt0lNPPYVXXnnF5LkW//GjUbt8yJqIyJZ8RjI9dkStmVojSmNhgBOp1Wr4+Jj+iPGWX7bUkCFfo0C5+kZEaAKQChmY1hGRJzGxI/IwU6U8ojxVysNJzA27Dhw4ELt373ZzNK7hje8bEbV8HIol8qC8glLM2HDAaG2lLi1aM6V3i0oSvGoenQXe9r4RkbTZks9IZlUsUWuj1ojIzi00uzEVAGTnFkKtkX5C1NxKV29K6rzpfSMi78PEjshD8osqDYbxmhIBlCprkV9U6b6gbJSVldVqEjodb3jfiMh7cY4dkYeUV5lPDuxp5051dXUICAgwee7KlStmz3mDxu+HDBqkyo4hApdQjrbI1/SA5trvy1J834jI+zGxI/KQiBDrkh9r27mLuR66yZMn4z//+Y+bo3E/3fsxQpaPhb7rEC1c75krEcORXZ+FrZpUyb1vRNQ6MLEj8pDUhHBEhQWgTFlrbmMqRIZpS59IQWtZGNGc1IRw/CX4IJbUrzQ6F4lKrPFdiWd8n0Zqwij3B0dErR7n2BF5iFwmYGGGAoDZjamwMEPh8Xp2rWlhhDXk0GCh7zoAQNO3Rvd4oe86yKFxc2REREzsiDwqPTEKa6b0RmSY4bBdZFiAx0tm3HnnnUzoTDm9F4FXyoySOh2ZAAReKdPuSEFE5GYciiXysPTEKAxTREpm54mqqiqzdZIaGhogl7fyvRWqzzu3HRGREzGxI5IAuUzAgC7tPR2G2R66J5980ux+r+4imW3Xgjs6tx0RkRMxsSMiyS+MkNT2XXG3AoIMEC3MoRPk2nZERG7GOXZEEqDWiNh3sgJfHCzGvpMVbtu1oCUsjNBt39W0KHCZshYzNhxAXkGpewM6+4PlpA4ARLW2HRGRm7HHjsjDPNEblZKSgl9//dXkOSkkczrWbt81TBHpvmFZzrEjIgljjx2RB7m7N+qPP/6AIAgmkzqNRiOppA5ofvsuwAPbd3GOHRFJGBM7Ig9x92bygiAgIiLC6PiqVasgiqLFeXaeUqayblsua9s5RXwaEBoN4+qDOgIQGqNtR0TkZhyKJfIQWzaTd2TFrNQXRlhSWV3n1HZOIZMD6cuAj7OgTe4a38Nr9zr9RW07IiI3Y48dkYdYu0m8vZvJt4SFEc0Jb+Pn1HZOoxgL3LMOCG0yBzI0WntcMda98RARXcMeOyIPsXaTeFs3k2/Xrh0uXbpk8lxLSOYaiwwLdGo7p1KMBXqM1u4wUX1eO6cuPo09dUTkUUzsiDwkNSEcUWEBKFPWmpxnJ0C7tVhqQrhV1zt9+jQ6d+5s8lxLS+h0dPfI0pB1lA33yOlkciDhNs+8NhGRCRyKJfIQuUzAwgwFAONp+LrHCzMUVpXxEATBZFK3YcOGFpvUAdfvkYVlClbfIyKi1oCJHZEHpSdGYc2U3ogMMxxujQwLwJopvZutY9fcPLq//vWvTovVU3T3KKrJPYqy8h4REbUmgtiSf51vhkqlQlhYGJRKpdlNzYmkwNZ9UFvySld7SWavWCIiN7Mln+EcOyIJkMsEq0qatMaETsfae0RE1JpxKJaoBThy5EiLL11CRESux8SOWh+NGijaDRz+RPunRu3piCwSBAGJiYlGx7/66ismdEREZIBDsdS6FG4G8uYCqpLrx0KjtTsJSKyobGsediUiIvuwx45aj8LN2m2gGid1AKAq1R4v3OyZuKBdGLDvZAW+OFjsFTtGEBGRZzCxo9ZBo9b21JksBXztWN4/PDIsm1dQioHLvkVa1w4Y3yvWZBt3J3SNE819Jyug1jCZJCJqCTgUS63D6b3GPXUGREBVrG3nxp0E8gpKcf9LOShd/6TJ818dLnF7nba8glJk5xYa7PYQFRaAhRkK1owjIpI4JnbUOlSfd247J1BrRIxMijZ5LnLKywiIuRnZuYUYpoh0W722vIJSzNhwwKhfs0xZixkbDrAgMBGRxHEollqH4I7ObecgQRDgIzf93+/eeS8hMKY7RAClylrkF1W6JSa1RkR2bqGlwWpk5xZyWJaISMKY2FGroI4bgPNoD3M5iUYEytAe6rgBLo3D4sKIhaEQF4biQ78XsMf/bxghywcAlFfVmmzvbPlFlQbDr0bxwb2JJhER2Y6JnZfhpHfT8k8rsal+AAQATdcgiKJ2M/nP6wcg/7TSJa9vKaFTLwiFeoHhFjGRqMQa35UYIctHREiAyec5m7UJpLsSTSIish3n2HkRTno3r1xVg3t8dgAAmuZXgqBN7u7x2YHdqhoAztu2avv27Rg2bJjJcw319bjwQjdArEDTKXQyQduLmO23HjfEz3daPJZYm0C6K9EkIiLbscfOS+gmvTcdStNNes8rKPVQZNLQteZXhAvVRkmdjiAA4UI1utb86rTXFATBZFJ39OhRiKII+dl96AjjpE5HJgCRqID87D6nxWRJakI4osICYG6ZhgDtLwqpCeFuiYeIiGzHxM4LcNJ7826uPeDUdpaYG3aVy+UQRRE9evTQHpDYSl25TMDCDAUAGCV3uscLMxRuW6FLRES2k0xid/bsWQwePBgKhQLJycnYuHEjACA/Px89e/ZE165dsWjRIg9HKU2c9N48marYqe1MaW7HiIaGBsODElupCwDpiVFYM6U3IsMMh1sjwwJY6oSIqAWQzBw7Hx8frFy5EikpKSgvL0fv3r0xatQozJw5Ezk5OVAoFBgwYAAmTpxockP01oyT3q0QanpHB7vbNWL3nq7xadp9alWlML0jhqA9H59mc0yOSE+MwjBFJPKLKlFeVYuIEO3wK3vqiIikTzI9dlFRUUhJSQEAREREIDw8HBcuXEBDQwOSk5Ph4+ODyZMnIzc31+w16urqoFKpDL5aA056t8KNtzu3HYCPP/7YsT1dZXIgfdm1B2YGP9Nf1LZzM7lMwIAu7TEuJQYDurRnUkdE1EJIJrFr7KeffoJGo8Eff/yBmJgY/fHY2FgUF5sfKlu6dCnCwsL0X3Fxce4I1+M46d0KnQcCgc18/4Hh2nZWEAQB9957r9HxM2fO2Lanq2IscM86ILTJEGdotPa4Yqz11yIiolZPcoldRUUFsrKysHbtWpM/IC0Ne82bNw9KpVL/dfbsWVeGKhmc9G4FmRzIWGW5TcaqZnvHzM2ji4+PhyiK9v0yoRgLzCoA7tsC3PW29s9Zh5nUERGRzSQzxw7QDqVOmDAB8+bNQ1paGkpKSgx66M6dO4eoKPOTt/39/eHv7++OUCVHN+m9aR27SNaxu04xFrhnPZA3F1CVXD8eGqMd8rSQSNk9j85aMjmQcJvj1yEiolZNMomdKIqYOnUqhgwZgszMTABAdHQ05HI5Dh06BIVCgZycHLz99tsejlS6OOndCoqxQI/RwOm92jIiwR21ixPM9NS5PKEjIiJyIkGUyE+nPXv2YNCgQUhOTtYfW79+PWpqajB9+nTU1tYiMzMTzz33nNXXVKlUCAsLg1KpRGhoaPNPILrmjTfewIwZM0yek8h/GSIiaiVsyWck02M3cOBAaDQak+eOHDni5miotRJFETKZ6amnFy5cQPv2zttujIiIyNkkt3iCyFMEQTCZ1P3pT3+CKIpM6oiISPIk02NH5CmcR0dERN6CPXbU6qg1IvadrGh2CzC3JnUaNVC0Gzj8ifZPjdp9r01ERF6DPXbUquQVlOLhuc/jzJdrTJ73SA9d4WYTJViitbtSsJYdERHZgD121Gr899dzGJkUbTKpi/v7J/jqcImJZ7lY4Wbg4yzDpA7Q7h/7cZb2PBERkZWY2FGrIAgCxqQY7woR1OM2xM/dAplfAOZ9dhhqjZuHX/PmAjD1mteO5f2Dw7JERGQ1Jnbk1SzNo3t83jPImJABGbRldi5ersf+/1W4L7jTe4176gyIgKpY246IiMgKnGNHXsnSStfiBZ0RLVQCWA0AKBHDkV2fha2aVOw7WYE/de3gniCrzzu3HRERtXrssSOv8uyzz5pN6h6atwDqBaGIRKXB8UhUYo3vSoyQ5cP0sKiLBHd0bjsiImr12GNHXqGurg4BAQEmz129ehX5/6tEwgf9AQBNt86VCYBGBBb6rkdR50ddHep18Wna1a+qUphOKAXt+fg098VEREQtGnvsqMUTBMFkUvfcc89BFEX4+vqiv+9viBYqjZI6HZkARAsV6O/7m4ujbfyicm1JEwBA08CuPU5/UduOiIjICuyxoxbLlh0j5DXlVl3T2nZOoxgL3LPOTB27F1nHjoiIbMLEjlocu7YAk/J8NsVYoMdo7erX6vPaGOLT2FNHREQ241AstRgPPvig/VuAxafhSmAkzJWp04jAlcBIz81nk8mBhNuApLu1fzKpIyIiOzCxI8mrrq6GIAh46623jM6p1WqrtgFTQ4bs+iwAMErudI+z67Og5n8JIiJqwfhTzMvoNrj/4mAx9p2scO9OCi4gCAJCQkKMjq9evRqiKEIms+6fcH5RJT6sTsGM+lkoQ7jBuTK0x4z6WfiwOgX5RZVmrkBERCR9nGPnRfIKSpGdW4hSZa3+WFRYABZmKJCeGOXByGxn1zw6C8qrtPdkqyYV2+r6IlV2DBG4hHK0Rb6mBzTXfsfRtSMiImqJmNh5ibyCUszYcMCoGlqZshYzNhzAmim9W0Ry5+yETici5Ho5FA1k2K9RNNuOiIiopeFQrBdQa0Rk5xZa2koe2bmFkh6WHTNmjP0LI6yQmhCOqLAAo2pxOgK0vZupCeFmWhAREUkfEzsvkF9UaTD82pQIoFRZK8n5YxUVFRAEAf/973+Nzmk0GocTOh25TMDCDG0vnZlSwFiYoYDcXAVjIiKiFoCJnRewdl6Y1OaPCYKADh06GB3PycmBKIoWh2XtkZ4YhYcGJaDpZQUBeGhQQosYqiYiIrKEc+y8gLXzwjwxf0ytEZFfVInyqlpEhGiHOn3k5n+fcFYPnSl5BaVYu6vIaMhaIwJrdxWhV6d2TO6IiKhFY2LnBXTzx8qUtea2kkekB+aPNV2le3rZGLNtXZnQAZbnIepk5xZimCKSw7FERNRicSjWC0hx/phulW6pshYXd603m9Q5Y2GENVryPEQiIiJrMbHzEumJUVgzpTciwwyHWyPDAtxe6kTXO6auq8HpZWOg2veRUZv+S7ajQa1xW0wtdR4iERGRLTgU60XSE6MwTBFpNKfN3UOL+UWV2P/MUJPnIu5+DoFd+up7xwZ0ae+WmKQ8D5GIiMhZmNh5GblMcFuyZIq5laxtEoegw+jZBsdKLl4G4J5YpToPkYiIyJk4FEtOIQiC2aQufu4Wo6QOAA6eu+TiqK6T4jxEIiIiZ2NiRw5ZunSpxYQufu4WC892bxIlpXmIRERErsChWC9jqm6cK3qhLly4gBtuuMHkubU7T2Lxl0ebvUan8CBnh9UsqcxDJCIicgUmdl6kad04QLv/6cIMhVN7o8z10J06dQrx8fHY/fsfVl2nR2SI02KyhafnIRIREbkKh2K9ROO6cY2VKWsxY8MB5BWUOvwa5ubRPfHEExBFEfHx8QCAystXrbqete2IiIjIOuyx8wKWdlUQoZ3J5siuCpb2bDVVXJilRYiIiDyDPXZewFW7KsydO9dsUmdpxwhdaRFz6aAA7RAxS4sQERE5F3vsvICzd1UoLi5GbGysyXPWbP+lKy0yY8MBs21YWoSIiMj52GPnBZw59CkIgsmkrqyszKY9XdMTo/DQoAT4CBr0lxVirGwv+ssK4SNo8NCgBJYWISIicgH22HmB1IRwtA3yxaXL9WbbtA3ytTj0aW7I9Z///Ceef/55m2PKKyjF6T0fYZffOkQL14eAS8RwLNqThbxOjzC5IyIicjImdq2E2fluNi6MsIZaI2LH5+/gdd+VRuciUYnXfVfimc/9MEzxDIdjiYiInIhDsV4gv6jSYm8dAFy8XG+weOKhhx6ya2GEVfGc/AN/q38LANA0b9M9/lv928g/aV29OyIiIrKOpBK7CRMmoF27drj77rv1x/Lz89GzZ0907doVixYt8mB00mXL4on//e9/EAQBb775ptF5RxM6HfWp7xEtVBoldToyAYgWKqA+9b3Dr0VERETXSSqx+9vf/oZ169YZHJs5cyZycnJw7Ngx5ObmoqCgwEPRSZe1iyfG94pFly5djI5XVlY6JaHTxyNccmo7IiIiso6kErs77rgDISHXt5kqKSlBQ0MDkpOT4ePjg8mTJyM3N9fs8+vq6qBSqQy+WoPm6sadXjYGp5eNMTr+yiuvQBRFtGvXzqnxdLnROHl0pB0RERFZR1KJXVMlJSWIiYnRP46NjUVxcbHZ9kuXLkVYWJj+Ky4uzh1hepyubpwIQIbr5UXMJXSAdtj1ySefdE08nf8ElV8ENGY6ATUioPSLgLzzn1zy+kRERK2VpBM7U8ODllZxzps3D0qlUv919uxZV4YnOSNk+djj/zeov3gG/1q6xGQbZ82js0QNGZZopgKAUXKne7xUMxVqaf/zIyIianEk/ZM1JibGoIfu3LlziIoyX/vM398foaGhBl+tga68SPbVFYhZdAqfFDYYtZn7/AtoUGvcEk9+USU+rE7BjPpZKINh7bwytMeM+ln4sDrF5i3OiIiIyDJJ17GLjo6GXC7HoUOHoFAokJOTg7ffftvTYUlO/sk/sGz+P7HMxLmqeSEI8hVQVv828k8+iAE3Rbg8njKVdpXuVk0qttX1RarsGCJwCeVoi3xND2iu/T6ha0dERETOIanEbsSIEThw4ABqamoQGxuLTZs2YfXq1Zg0aRJqa2uRmZmJpKQkT4cpKeaGpn98sA36Rsv1j6NRgZNFe4CbJro8psrqOv3fNZBhv0bRbDsiIiJynKQSu61bt5o8fuTIETdHIn0pKSn49ddfjY7PGeCHl4ebLn/SoCx1dVgAgPA2fk5tR0RERNaRVGJHzXv33Xdx//33mzwnLrQ8p9CnbbQrQjISGRbo1HZERERkHSZ2DlBrROQXVaK8qhYRIQFITQh32d6nxcXFiI2NNXlu7+/nEb/hVmhE07s9aETtogUfN5UX0dXVK1Wan0MXFaa9X0REROQ8TOzslFdQiuzcQoPkJSosAAszFEhPNL9y11aiKEImM714ub6+Hj4+PlBrRDzr+wCW1L8EjWi4P6uuvMhrvtOxuMsNTovLEl1dvRkbDsBUYRUBwMIMhcuSYCIiotZK0uVOpCqvoBQzNhww6pEqU9ZixoYDyCtwzlw2QRBMJnWHDx+GKIrw8dHm5XKZgMHj78ejZsqLPFo/C4PH3+/WRCo9MQprpvRGVJjhfL+osACsmdLbqckvERERaQmiq6vVepBKpUJYWBiUSqXTatqpNSIGLvvW7DCjACAyLAB75g6xO5FKSEjAqVOnjI4/99xzWLhwodnn5RWU4vnNhxFX/au+vMjZ4Fswf2ySxxIpdw5XExEReSNb8hkOxdoov6jS4twxEUCpshb5RZUY0KW9Tddes2YNHn30UdPXtSL/Tk+MwjBFJPKL+kgmkZLLBJvvAxEREdmHiZ2NyqusK6prbTsAOHXqFBISEkyes7VDlYkUERFR68XEzkYRIaZrxNnTztLCCLVabfYcERERkSnMHGzUJ76dyZIijckEbTtLzC2M+O233ywmfERERETmMHuw0c+nL+pLiJijEbXtTAkPDze5DdjLL78MURTRrVs3Z4RJRERErRCHYm1k7xy75cuXY86cOUbt2rZti4sXTSeBXkGjBk7vBarPA8Edgfg0QCZv/nlERERkMyZ2NrJ1jt3vv/+O7t27m2zjxZVmtAo3A3lzAVXJ9WOh0UD6MkAx1nNxEREReSkOxdpIt12WuWl2ArRFePt0CoMgCCaTOrVa3TqSuo+zDJM6AFCVao8XbvZMXERERF6MiZ2NdNtlATBK7nSP9z8zFP5+vkbPLSoqah0LIzRqbU+dyQ3Frh3L+4e2HRERETmNl2cYrqHbLqtjqOGw7KmXxuLUsjFG7f/v//4Poiiic+fOborQw07vNe6pMyACqmJtOyIiInIazrFziLb36dL3OVDu+Y/R2fj4eJNbg3m96vPObUdERERWYWJnh7yCUszYcAAigNMmeuiAVrAwwpLgjs5tR0RERFZhYmcjtUZEdm6hydljABD/dC6i2gZCrRFb72b38Wna1a+qUpieZydoz8enuTsyIiIir8Y5djbKL6pEqfJ6jbrQW+8CAMTMeA/xc7cAgoBSZS3yiyo9FaLnyeTakiYAzC4xSX+R9eyIiIicjImdjZoWHm43eBri526BT2gHi+1aHcVY4J51QGiU4fHQaO1x1rEjIiJyOiZ2NrK1QHGr13SuoajxTBxEREStABM7G1lboDg1IdydYUmPrkBxVanh8aoyFigmIiJyESZ2NrKmQPHCDEXrXTgBsEAxERGRhzCxs4OuQHFkmOFwa2RYANZM6Y30xCgzz3Q9tUbEvpMV+OJgMfadrIBa44GyKyxQTERE5BEsd2Kn9MQoDFNEIr+oEuVVtYgI0Q6/erKnLq+gFNm5hQardqPCArAwQ+HeZJMFiomIiDyCiZ0D5DIBA7q093QYAAyLJjdWpqzFjA0H3NuTyALFREREHsGhWC9gqWiy7lh2bqH7hmV1BYotLTEJjWGBYiIiIidjYucFmhZNbkoE3Fs0mQWKiYiIPIKJnRewthiyW4sms0AxERGR23GOnReQbNFkxVigx2jt6tfq89o5dfFp7KkjIiJyESZ2XkBXNLlMWQsBGqTKjiECl1COtsjX9IAIGSI9VTRZJgcSbnP/6xIREbVCTOy8gK5o8ucfvIEFvusQLVyfS1cihmNRfRbGZzzSuosmExERtQJM7LxEuuxHjPBbBbHJ2thIoRJr/FZBkPUBwHltRERE3oyLJ7zBtS28BIhGb6gM19ahcgsvIiIir8fEzhtwCy8iIiICEzvvwC28iIiICJxj5xC1RpTGXrHcwouIiIjAxM5ueQWlyM4tNNjxISosAAszFO7bk1VHt4WXqhQwubGYoD3PLbyIiIi8WosYit2yZQu6d++Om266CW+99Zanw0FeQSlmbDhgtI1XmbIWMzYcQF5BqXsD4hZeREREhBaQ2DU0NGD27Nn49ttvceDAASxbtgyVlW7a89QEtUZEdm6hyX4x3bHs3EKoNaZauBC38CIiImr1JD8Um5+fj549eyImJgYAMGrUKGzduhWTJk0yaltXV4e6ujr9Y5VK5fx4iiqNeuoaEwGUKmuRX1SJAV3aO/31LeIWXkRERK2a5BO7kpISfVIHALGxsSguLjbZdunSpcjOznZpPOVV5pM6e9o5HbfwIiIiarUkPxQrisZDmoJgeuXpvHnzoFQq9V9nz551ejwRIQFObUdERETkLJLvsYuJiTHooTt37hxuvfVWk239/f3h7+/v0nhSE8IRFRaAMmWtufWniAzTlj4hIiIicifJ99ilpqaioKAAxcXFqKqqwpdffokRI0Z4LB65TMDCDAUAs+tPsTBD4Zl6dkRERNSqST6x8/HxwfLly3HHHXegV69eeOqpp9C+vZsXJTSRnhiFNVN6IzLMcLg1MiwAa6b0dn8dOyIiIiIAgmhqEpuXUKlUCAsLg1KpRGhoqNOvL5mdJ4iIiMhr2ZLPSH6OnZTJZYL7S5oQERERmSH5oVgiIiIisg4TOyIiIiIvwcSOiIiIyEswsSMiIiLyEkzsiIiIiLwEEzsiIiIiL8HEjoiIiMhLMLEjIiIi8hJM7IiIiIi8BBM7IiIiIi/h1VuK6bbBValUHo6EiIiIyD66PEaX11ji1YldVVUVACAuLs7DkRARERE5pqqqCmFhYRbbCKI16V8LpdFoUFJSgpCQEAiC4OlwPE6lUiEuLg5nz55FaGiop8PxCrynrsH76hq8r87He+oavK+GRFFEVVUVoqOjIZNZnkXn1T12MpkMsbGxng5DckJDQ/kfxcl4T12D99U1eF+dj/fUNXhfr2uup06HiyeIiIiIvAQTOyIiIiIvwcSuFfH398fChQvh7+/v6VC8Bu+pa/C+ugbvq/PxnroG76v9vHrxBBEREVFrwh47IiIiIi/BxI6IiIjISzCxIyIiIvISTOyIiIiIvAQTOy82YcIEtGvXDnfffbf+WH5+Pnr27ImuXbti0aJFHoyuZTp79iwGDx4MhUKB5ORkbNy4EQDvq6OqqqrQr18/pKSkICkpCW+++SYA3ldnuHz5MuLj4zFnzhwAvKfO4OPjg5SUFKSkpOCBBx4AwPvqqKKiItxxxx1QKBRISkpCTU0N76m9RPJa3377rbh582bxrrvu0h/r27ev+Ouvv4r19fVi3759xcOHD3swwpanpKRE/OWXX0RRFMXz58+LMTExYnV1Ne+rgxoaGsSamhpRFEWxpqZGTEhIEC9cuMD76gTPPPOM+Oc//1l88sknRVHkZ4AztG/f3ugY76tjBg0aJO7atUsURVGsqKjQ30feU9uxx86L3XHHHQgJCdE/LikpQUNDA5KTk+Hj44PJkycjNzfXgxG2PFFRUUhJSQEAREREIDw8HBcuXOB9dZBcLkdQUBAAoLa2Fmq1GjU1NbyvDjp+/DiOHTuGUaNGAeBngKvwvjrmyJEj8PX1xW233QYACA8PR3l5Oe+pnZjYtSIlJSWIiYnRP46NjUVxcbEHI2rZfvrpJ2g0Gvzxxx+8r05w6dIl3HLLLYiNjcXTTz+N8vJy3lcHzZkzB0uXLtU/5meAc6hUKvTp0wcDBw7Ezp07eV8ddPz4cQQHB2Ps2LHo3bs3lixZwnvqAB9PB0DuI5qoRS0IggciafkqKiqQlZWFt956i/fVSdq2bYtff/0V58+fx8SJE9G3b1+jNryv1vviiy/QrVs3dOvWDXv37gXAzwBnOXXqFKKjo1FQUIDRo0dj3bp1Rm14X61XX1+P3bt34+DBg4iIiEB6ejp8fX2N2vGeWoeJXSsSExNj8BvPuXPnEBUV5cGIWqa6ujpMmDAB8+bNQ1paGkpKSnhfnahjx45ITk7GsWPHeF8dsH//fnz44YfYuHEjqqurUV9fj9DQUN5TJ4iOjgYAJCYmQqFQQBAE3lcHxMbGol+/foiLiwMAjBo1CpcvX+Y9tROHYluR6OhoyOVyHDp0CA0NDcjJyUFGRoanw2pRRFHE1KlTMWTIEGRmZgLgfXWG8+fPQ6VSAdAOc+3atQu9evXifXXA0qVLcfbsWZw6dQqvvPIKHnzwQSxYsID31EEXL15EXV0dAG2yUVhYiMTERN5XB/Tr1w/nz5/HxYsXodFosGvXLvTp04f31E7ssfNiI0aMwIEDB1BTU4PY2Fhs2rQJq1evxqRJk1BbW4vMzEwkJSV5OswW5fvvv8dHH32E5ORkfP755wCA9evX87466Ny5c5g+fTpEUYQoinjssceQnJzM++oCvKeOOXr0KB5++GHIZDIIgoBVq1YhPDyc99UBPj4+WLJkCQYNGgRRFDF8+HCMGTMGHTp04D21gyCamnRBRERERC0Oh2KJiIiIvAQTOyIiIiIvwcSOiIiIyEswsSMiIiLyEkzsiIiIiLwEEzsiIiIiL8HEjoiIiMhLMLEjIiIi8hJM7IiIWpjBgwdj1qxZng6DiCSIiR0ReY2pU6dCEASjr/T0dI/EwwSMiNyNe8USkVdJT0/Hu+++a3DM39/fQ9EQEbkXe+yIyKv4+/sjMjLS4Ktdu3Y2XycvLw8DBw5E27Zt0b59e4wZMwYnT540aKPRaLBs2TJ07doV/v7+6NSpExYvXgxA23u4c+dOrFq1St9zeOrUKXTu3BkrV640uE5KSgqee+45m16biMgUJnZERCbU1NRg9uzZ+PHHH/HNN99AJpNhwoQJ0Gg0+jbz5s3DsmXLMH/+fBQWFuKDDz5Ax44dAQCrVq3CgAED8OCDD6K0tBSlpaWIi4tz2msTEZnCoVgi8ipbtmxBcHCwwbG5c+di/vz5mDBhAnbs2IE777wTn3zyicXr3HXXXQaP3377bURERKCwsBCJiYmoqqrCqlWrsHr1atx3330AgC5dumDgwIEAgLCwMPj5+SEoKAiRkZE2fQ/NvTYRkTnssSMir3LHHXfg4MGDBl8zZ84EAPztb3/DunXrrLrOyZMnMXnyZNx4440IDQ1FQkICAODMmTMAgKNHj6Kurg533nmn07+H5l6biMgc9tgRkVdp06YNunbtavLcHXfcgR07dlh1nYyMDMTFxeHNN99EdHQ0NBoNEhMTcfXqVQBAYGCgXfHJZDKIomhwrL6+3qbXJiIyhz12RERNVFRU4OjRo/jnP/+JO++8EzfffDMuXrxo0Oamm25CYGAgvvnmG7PX8fPzg1qtNjh2ww03oLS0VP9YpVKhqKjIptcmIjKHPXZE5FXq6upQVlZmcMzHxwcdOnSw+hrt2rVD+/btsXbtWkRFReHMmTP4xz/+YdAmICAAc+fOxdNPPw0/Pz/86U9/wh9//IEjR45g+vTpAIDOnTvjhx9+wKlTpxAcHIzw8HAMGTIE7733HjIyMtCuXTvMnz8fcrncptcmIjKHiR0ReZW8vDxERUUZHOvevTuOHTtm9TVkMhk+/PBD/O1vf0NiYiK6d++O1157DYMHDzZoN3/+fPj4+GDBggUoKSlBVFQUHnnkEf35OXPm4L777oNCocCVK1dQVFSEefPm4X//+x/GjBmDsLAwPP/88wY9dta+NhGRKYLYdLIHEZEX27FjB1avXt3sqlgiopaIiR0RtRojRozAgQMHUFNTg/DwcGzatAn9+vXzdFhERE7DxI6IiIjIS3BVLBEREZGXYGJHRERE5CWY2BERERF5CSZ2RERERF6CiR0RERGRl2BiR0REROQlmNgREREReQkmdkRERERegokdERERkZdgYkdERETkJZjYEREREXmJ/wdq+kejC0bsnQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_predictions(train_pred, train_actual, val_pred, val_actual, index, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    r2_train = pearsonr(train_actual[:,index], train_pred[:,index])[0]**2\n",
    "    r2_val = pearsonr(val_actual[:,index], val_pred[:,index])[0]**2\n",
    "    \n",
    "    ax.scatter(train_actual[:,index],train_pred[:,index],label='Train')\n",
    "    ax.scatter(val_actual[:,index],val_pred[:,index],label='Validation')\n",
    "    ax.plot(train_actual[:,index],train_actual[:,index],c='k')\n",
    "    \n",
    "    plt.text(0.02, 0.98, 'r$^2_{train}$ = %.4f\\nr$^2_{val}$ = %.4f' % (r2_train,r2_val),\n",
    "     horizontalalignment='left',\n",
    "     verticalalignment='top',\n",
    "     transform = ax.transAxes)\n",
    "\n",
    "    ax.legend(loc='upper center')\n",
    "        \n",
    "    ax.set_xlabel('{} actual'.format(title))\n",
    "    ax.set_ylabel('{} predicted'.format(title))\n",
    "    ax.tick_params(axis='both')\n",
    "    \n",
    "    return ax\n",
    "\n",
    "labels = ['P', 'E$_1$', 'E$_2$']\n",
    "atten = [1,1,1]\n",
    "\n",
    "for i,label in enumerate(labels):\n",
    "    ax = plot_predictions(best_train_predictions/atten[i],best_train_actuals/atten[i],\n",
    "                     best_val_predictions/atten[i], best_val_actuals/atten[i],i,label)\n",
    "    ax.tick_params(axis='both', labelsize=7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b109b1",
   "metadata": {},
   "source": [
    "# Train for growth kinetics using the ICCD features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8eb17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 127\n",
      "Number of training samples: 88\n",
      "Number of validation samples: 39\n"
     ]
    }
   ],
   "source": [
    "datafile = 'PLD data.json'\n",
    "\n",
    "# set the target to anomaly to train for P, E1, and E2.\n",
    "# set the target to 'growth' to train for s0, s1, and J\n",
    "target_params = 'growth'\n",
    "\n",
    "BATCH_SIZE = 88\n",
    "\n",
    "#############################\n",
    "if target_params == 'anomaly':\n",
    "    normalize_PTE1E2 = False\n",
    "else:\n",
    "    normalize_PTE1E2 = True\n",
    "\n",
    "train_data, val_data = load_data(datafile, target_params, normalize_PTE1E2=normalize_PTE1E2, train_percent=70)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a7eee86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU.\n",
      "2023-11-08 13:34:45.583533 Epoch 1, Training loss 24.344568252563477\n",
      "R2 values 0.1083, 0.0026, 0.1880; mean R2=0.0996\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 43.061535 \n",
      "\n",
      "2023-11-08 13:34:46.095809 Epoch 2, Training loss 47.08574676513672\n",
      "R2 values 0.2031, 0.0042, 0.2020; mean R2=0.1364\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 13.236775 \n",
      "\n",
      "2023-11-08 13:34:46.642671 Epoch 3, Training loss 12.725981712341309\n",
      "R2 values 0.0000, 0.0001, 0.2369; mean R2=0.0790\n",
      "Validation Error: Avg loss: 21.428040 \n",
      "\n",
      "2023-11-08 13:34:47.129696 Epoch 4, Training loss 18.384174346923828\n",
      "R2 values 0.0059, 0.0203, 0.2561; mean R2=0.0941\n",
      "Validation Error: Avg loss: 17.586103 \n",
      "\n",
      "2023-11-08 13:34:47.611378 Epoch 5, Training loss 15.569114685058594\n",
      "R2 values 0.2098, 0.0156, 0.2401; mean R2=0.1552\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 13.073273 \n",
      "\n",
      "2023-11-08 13:34:48.113381 Epoch 6, Training loss 11.873319625854492\n",
      "R2 values 0.1538, 0.0558, 0.3000; mean R2=0.1699\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 11.327225 \n",
      "\n",
      "2023-11-08 13:34:48.603699 Epoch 7, Training loss 11.426997184753418\n",
      "R2 values 0.1708, 0.0359, 0.2293; mean R2=0.1454\n",
      "Validation Error: Avg loss: 11.832385 \n",
      "\n",
      "2023-11-08 13:34:49.097604 Epoch 8, Training loss 12.2225341796875\n",
      "R2 values 0.3402, 0.1342, 0.3270; mean R2=0.2672\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 10.559813 \n",
      "\n",
      "2023-11-08 13:34:49.599467 Epoch 9, Training loss 11.165897369384766\n",
      "R2 values 0.4183, 0.0895, 0.2776; mean R2=0.2618\n",
      "Validation Error: Avg loss: 10.982585 \n",
      "\n",
      "2023-11-08 13:34:50.091419 Epoch 10, Training loss 10.146716117858887\n",
      "R2 values 0.2041, 0.2104, 0.2640; mean R2=0.2262\n",
      "Validation Error: Avg loss: 11.091432 \n",
      "\n",
      "2023-11-08 13:34:50.571509 Epoch 11, Training loss 10.129859924316406\n",
      "R2 values 0.2823, 0.3348, 0.4234; mean R2=0.3468\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 9.622623 \n",
      "\n",
      "2023-11-08 13:34:51.084115 Epoch 12, Training loss 9.667405128479004\n",
      "R2 values 0.1776, 0.2920, 0.4139; mean R2=0.2945\n",
      "Validation Error: Avg loss: 9.804486 \n",
      "\n",
      "2023-11-08 13:34:51.605253 Epoch 13, Training loss 10.400045394897461\n",
      "R2 values 0.1634, 0.4851, 0.3270; mean R2=0.3252\n",
      "Validation Error: Avg loss: 9.171444 \n",
      "\n",
      "2023-11-08 13:34:52.086140 Epoch 14, Training loss 9.156015396118164\n",
      "R2 values 0.3582, 0.3432, 0.2544; mean R2=0.3186\n",
      "Validation Error: Avg loss: 9.035711 \n",
      "\n",
      "2023-11-08 13:34:52.559778 Epoch 15, Training loss 9.401095390319824\n",
      "R2 values 0.3268, 0.3259, 0.3781; mean R2=0.3436\n",
      "Validation Error: Avg loss: 8.500882 \n",
      "\n",
      "2023-11-08 13:34:53.037078 Epoch 16, Training loss 8.77153491973877\n",
      "R2 values 0.3726, 0.3022, 0.3429; mean R2=0.3392\n",
      "Validation Error: Avg loss: 8.826108 \n",
      "\n",
      "2023-11-08 13:34:53.512701 Epoch 17, Training loss 8.835878372192383\n",
      "R2 values 0.3371, 0.2719, 0.5168; mean R2=0.3752\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 8.740929 \n",
      "\n",
      "2023-11-08 13:34:54.024611 Epoch 18, Training loss 8.64570426940918\n",
      "R2 values 0.3457, 0.3623, 0.4621; mean R2=0.3900\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 8.680202 \n",
      "\n",
      "2023-11-08 13:34:54.524293 Epoch 19, Training loss 9.224825859069824\n",
      "R2 values 0.4882, 0.4963, 0.5807; mean R2=0.5217\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 7.617747 \n",
      "\n",
      "2023-11-08 13:34:55.050461 Epoch 20, Training loss 8.408079147338867\n",
      "R2 values 0.3862, 0.2900, 0.3953; mean R2=0.3572\n",
      "Validation Error: Avg loss: 8.838235 \n",
      "\n",
      "2023-11-08 13:34:55.534774 Epoch 21, Training loss 6.599790096282959\n",
      "R2 values 0.3787, 0.4320, 0.5073; mean R2=0.4393\n",
      "Validation Error: Avg loss: 7.353501 \n",
      "\n",
      "2023-11-08 13:34:56.017209 Epoch 22, Training loss 8.925326347351074\n",
      "R2 values 0.4756, 0.3788, 0.5179; mean R2=0.4574\n",
      "Validation Error: Avg loss: 7.543962 \n",
      "\n",
      "2023-11-08 13:34:56.558069 Epoch 23, Training loss 7.7616424560546875\n",
      "R2 values 0.2747, 0.3197, 0.3651; mean R2=0.3198\n",
      "Validation Error: Avg loss: 8.783022 \n",
      "\n",
      "2023-11-08 13:34:57.031003 Epoch 24, Training loss 7.115075588226318\n",
      "R2 values 0.4931, 0.2494, 0.4215; mean R2=0.3880\n",
      "Validation Error: Avg loss: 9.292260 \n",
      "\n",
      "2023-11-08 13:34:57.499885 Epoch 25, Training loss 7.937657356262207\n",
      "R2 values 0.4018, 0.3615, 0.4975; mean R2=0.4203\n",
      "Validation Error: Avg loss: 8.284312 \n",
      "\n",
      "2023-11-08 13:34:57.970061 Epoch 26, Training loss 6.966095924377441\n",
      "R2 values 0.5417, 0.3477, 0.6100; mean R2=0.4998\n",
      "Validation Error: Avg loss: 7.666087 \n",
      "\n",
      "2023-11-08 13:34:58.447499 Epoch 27, Training loss 7.792206764221191\n",
      "R2 values 0.4313, 0.3573, 0.5248; mean R2=0.4378\n",
      "Validation Error: Avg loss: 7.801729 \n",
      "\n",
      "2023-11-08 13:34:58.925380 Epoch 28, Training loss 6.835053443908691\n",
      "R2 values 0.7316, 0.4858, 0.6499; mean R2=0.6224\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 6.139560 \n",
      "\n",
      "2023-11-08 13:34:59.441227 Epoch 29, Training loss 5.442687034606934\n",
      "R2 values 0.6051, 0.4066, 0.5691; mean R2=0.5270\n",
      "Validation Error: Avg loss: 6.994583 \n",
      "\n",
      "2023-11-08 13:34:59.919767 Epoch 30, Training loss 5.606645107269287\n",
      "R2 values 0.5710, 0.5068, 0.7156; mean R2=0.5978\n",
      "Validation Error: Avg loss: 5.981935 \n",
      "\n",
      "2023-11-08 13:35:00.589120 Epoch 31, Training loss 5.0041728019714355\n",
      "R2 values 0.6602, 0.5569, 0.7293; mean R2=0.6488\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 5.669918 \n",
      "\n",
      "2023-11-08 13:35:01.243125 Epoch 32, Training loss 5.081576824188232\n",
      "R2 values 0.6029, 0.4217, 0.6045; mean R2=0.5430\n",
      "Validation Error: Avg loss: 6.993461 \n",
      "\n",
      "2023-11-08 13:35:01.993261 Epoch 33, Training loss 6.456027984619141\n",
      "R2 values 0.6891, 0.4294, 0.6208; mean R2=0.5798\n",
      "Validation Error: Avg loss: 6.752917 \n",
      "\n",
      "2023-11-08 13:35:02.628440 Epoch 34, Training loss 5.163031578063965\n",
      "R2 values 0.6406, 0.3711, 0.6848; mean R2=0.5655\n",
      "Validation Error: Avg loss: 7.183185 \n",
      "\n",
      "2023-11-08 13:35:03.137612 Epoch 35, Training loss 5.706850051879883\n",
      "R2 values 0.5565, 0.3094, 0.5494; mean R2=0.4718\n",
      "Validation Error: Avg loss: 8.069921 \n",
      "\n",
      "2023-11-08 13:35:03.611843 Epoch 36, Training loss 5.343509674072266\n",
      "R2 values 0.7394, 0.5616, 0.7101; mean R2=0.6704\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 6.146015 \n",
      "\n",
      "2023-11-08 13:35:04.149159 Epoch 37, Training loss 5.725817680358887\n",
      "R2 values 0.5691, 0.5484, 0.6110; mean R2=0.5762\n",
      "Validation Error: Avg loss: 6.000600 \n",
      "\n",
      "2023-11-08 13:35:04.625600 Epoch 38, Training loss 5.075385570526123\n",
      "R2 values 0.7675, 0.5552, 0.7097; mean R2=0.6775\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 5.753409 \n",
      "\n",
      "2023-11-08 13:35:05.137025 Epoch 39, Training loss 4.953506946563721\n",
      "R2 values 0.5963, 0.4697, 0.5878; mean R2=0.5513\n",
      "Validation Error: Avg loss: 6.585763 \n",
      "\n",
      "2023-11-08 13:35:05.599378 Epoch 40, Training loss 5.359005451202393\n",
      "R2 values 0.5238, 0.4198, 0.4102; mean R2=0.4513\n",
      "Validation Error: Avg loss: 8.285494 \n",
      "\n",
      "2023-11-08 13:35:06.070471 Epoch 41, Training loss 5.332724571228027\n",
      "R2 values 0.5288, 0.4955, 0.5522; mean R2=0.5255\n",
      "Validation Error: Avg loss: 7.074742 \n",
      "\n",
      "2023-11-08 13:35:06.542648 Epoch 42, Training loss 5.150727272033691\n",
      "R2 values 0.5755, 0.4566, 0.5841; mean R2=0.5387\n",
      "Validation Error: Avg loss: 7.155076 \n",
      "\n",
      "2023-11-08 13:35:07.007758 Epoch 43, Training loss 4.876748085021973\n",
      "R2 values 0.6516, 0.4667, 0.5948; mean R2=0.5710\n",
      "Validation Error: Avg loss: 6.577013 \n",
      "\n",
      "2023-11-08 13:35:07.501027 Epoch 44, Training loss 4.698849201202393\n",
      "R2 values 0.7120, 0.5154, 0.6763; mean R2=0.6346\n",
      "Validation Error: Avg loss: 5.775258 \n",
      "\n",
      "2023-11-08 13:35:08.026361 Epoch 45, Training loss 4.755005836486816\n",
      "R2 values 0.6833, 0.4283, 0.5993; mean R2=0.5703\n",
      "Validation Error: Avg loss: 6.693362 \n",
      "\n",
      "2023-11-08 13:35:08.493350 Epoch 46, Training loss 5.183874130249023\n",
      "R2 values 0.5829, 0.4005, 0.5125; mean R2=0.4986\n",
      "Validation Error: Avg loss: 8.582025 \n",
      "\n",
      "2023-11-08 13:35:08.968801 Epoch 47, Training loss 5.104474067687988\n",
      "R2 values 0.5924, 0.4858, 0.6280; mean R2=0.5688\n",
      "Validation Error: Avg loss: 6.537000 \n",
      "\n",
      "2023-11-08 13:35:09.513621 Epoch 48, Training loss 4.225737571716309\n",
      "R2 values 0.4911, 0.4896, 0.6416; mean R2=0.5408\n",
      "Validation Error: Avg loss: 6.592818 \n",
      "\n",
      "2023-11-08 13:35:09.981485 Epoch 49, Training loss 4.636036396026611\n",
      "R2 values 0.6472, 0.4363, 0.6043; mean R2=0.5626\n",
      "Validation Error: Avg loss: 6.789832 \n",
      "\n",
      "2023-11-08 13:35:10.442224 Epoch 50, Training loss 4.054281234741211\n",
      "R2 values 0.7028, 0.4441, 0.6556; mean R2=0.6009\n",
      "Validation Error: Avg loss: 6.559524 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:35:10.930942 Epoch 51, Training loss 3.9138128757476807\n",
      "R2 values 0.6474, 0.3556, 0.5397; mean R2=0.5142\n",
      "Validation Error: Avg loss: 8.070448 \n",
      "\n",
      "2023-11-08 13:35:11.437107 Epoch 52, Training loss 4.363337516784668\n",
      "R2 values 0.6588, 0.4119, 0.5220; mean R2=0.5309\n",
      "Validation Error: Avg loss: 7.630685 \n",
      "\n",
      "2023-11-08 13:35:11.913730 Epoch 53, Training loss 4.886879920959473\n",
      "R2 values 0.6842, 0.6986, 0.7208; mean R2=0.7012\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 4.243939 \n",
      "\n",
      "2023-11-08 13:35:12.404784 Epoch 54, Training loss 4.451486587524414\n",
      "R2 values 0.6743, 0.4420, 0.7676; mean R2=0.6280\n",
      "Validation Error: Avg loss: 6.741308 \n",
      "\n",
      "2023-11-08 13:35:12.870531 Epoch 55, Training loss 4.855813026428223\n",
      "R2 values 0.6895, 0.5033, 0.7604; mean R2=0.6511\n",
      "Validation Error: Avg loss: 6.378070 \n",
      "\n",
      "2023-11-08 13:35:13.330191 Epoch 56, Training loss 4.705197334289551\n",
      "R2 values 0.5822, 0.6033, 0.6992; mean R2=0.6282\n",
      "Validation Error: Avg loss: 5.688840 \n",
      "\n",
      "2023-11-08 13:35:13.791103 Epoch 57, Training loss 4.7363715171813965\n",
      "R2 values 0.6152, 0.6022, 0.6567; mean R2=0.6247\n",
      "Validation Error: Avg loss: 4.990935 \n",
      "\n",
      "2023-11-08 13:35:14.262954 Epoch 58, Training loss 4.810272693634033\n",
      "R2 values 0.6320, 0.5671, 0.6680; mean R2=0.6224\n",
      "Validation Error: Avg loss: 5.451873 \n",
      "\n",
      "2023-11-08 13:35:14.732278 Epoch 59, Training loss 4.604561805725098\n",
      "R2 values 0.7032, 0.5116, 0.5945; mean R2=0.6031\n",
      "Validation Error: Avg loss: 6.579663 \n",
      "\n",
      "2023-11-08 13:35:15.195551 Epoch 60, Training loss 3.959522247314453\n",
      "R2 values 0.7076, 0.5629, 0.5655; mean R2=0.6120\n",
      "Validation Error: Avg loss: 5.767339 \n",
      "\n",
      "2023-11-08 13:35:15.659000 Epoch 61, Training loss 4.521391868591309\n",
      "R2 values 0.7123, 0.4977, 0.6198; mean R2=0.6099\n",
      "Validation Error: Avg loss: 6.997808 \n",
      "\n",
      "2023-11-08 13:35:16.120392 Epoch 62, Training loss 4.791312217712402\n",
      "R2 values 0.6383, 0.4126, 0.5459; mean R2=0.5323\n",
      "Validation Error: Avg loss: 9.778491 \n",
      "\n",
      "2023-11-08 13:35:16.586266 Epoch 63, Training loss 4.314919948577881\n",
      "R2 values 0.5367, 0.5744, 0.6211; mean R2=0.5774\n",
      "Validation Error: Avg loss: 6.471875 \n",
      "\n",
      "2023-11-08 13:35:17.041619 Epoch 64, Training loss 4.377041816711426\n",
      "R2 values 0.6250, 0.5371, 0.7387; mean R2=0.6336\n",
      "Validation Error: Avg loss: 5.605929 \n",
      "\n",
      "2023-11-08 13:35:17.508210 Epoch 65, Training loss 4.283566474914551\n",
      "R2 values 0.6441, 0.5744, 0.7082; mean R2=0.6422\n",
      "Validation Error: Avg loss: 5.427025 \n",
      "\n",
      "2023-11-08 13:35:18.029437 Epoch 66, Training loss 3.9541940689086914\n",
      "R2 values 0.7324, 0.4728, 0.7492; mean R2=0.6515\n",
      "Validation Error: Avg loss: 6.185491 \n",
      "\n",
      "2023-11-08 13:35:18.493962 Epoch 67, Training loss 4.072174549102783\n",
      "R2 values 0.6932, 0.4390, 0.5723; mean R2=0.5682\n",
      "Validation Error: Avg loss: 7.184056 \n",
      "\n",
      "2023-11-08 13:35:18.963842 Epoch 68, Training loss 3.6674575805664062\n",
      "R2 values 0.6478, 0.5934, 0.5301; mean R2=0.5904\n",
      "Validation Error: Avg loss: 5.641459 \n",
      "\n",
      "2023-11-08 13:35:19.431381 Epoch 69, Training loss 3.6799895763397217\n",
      "R2 values 0.5505, 0.5262, 0.6566; mean R2=0.5778\n",
      "Validation Error: Avg loss: 5.754711 \n",
      "\n",
      "2023-11-08 13:35:19.903130 Epoch 70, Training loss 4.31661319732666\n",
      "R2 values 0.6219, 0.5235, 0.6339; mean R2=0.5931\n",
      "Validation Error: Avg loss: 6.038811 \n",
      "\n",
      "2023-11-08 13:35:20.362010 Epoch 71, Training loss 3.869318723678589\n",
      "R2 values 0.5884, 0.5609, 0.5970; mean R2=0.5821\n",
      "Validation Error: Avg loss: 5.939718 \n",
      "\n",
      "2023-11-08 13:35:20.832811 Epoch 72, Training loss 4.274457931518555\n",
      "R2 values 0.5617, 0.5721, 0.6102; mean R2=0.5813\n",
      "Validation Error: Avg loss: 5.561056 \n",
      "\n",
      "2023-11-08 13:35:21.306296 Epoch 73, Training loss 4.323134899139404\n",
      "R2 values 0.5952, 0.5667, 0.6945; mean R2=0.6188\n",
      "Validation Error: Avg loss: 5.312857 \n",
      "\n",
      "2023-11-08 13:35:21.776184 Epoch 74, Training loss 3.7817752361297607\n",
      "R2 values 0.6366, 0.4369, 0.6205; mean R2=0.5647\n",
      "Validation Error: Avg loss: 7.277949 \n",
      "\n",
      "2023-11-08 13:35:22.247210 Epoch 75, Training loss 4.232367992401123\n",
      "R2 values 0.5879, 0.6697, 0.7645; mean R2=0.6740\n",
      "Validation Error: Avg loss: 4.047699 \n",
      "\n",
      "2023-11-08 13:35:22.710402 Epoch 76, Training loss 3.744525671005249\n",
      "R2 values 0.7618, 0.5518, 0.6363; mean R2=0.6500\n",
      "Validation Error: Avg loss: 6.086921 \n",
      "\n",
      "2023-11-08 13:35:23.177752 Epoch 77, Training loss 4.291482925415039\n",
      "R2 values 0.5953, 0.5128, 0.6355; mean R2=0.5812\n",
      "Validation Error: Avg loss: 6.612491 \n",
      "\n",
      "2023-11-08 13:35:23.634932 Epoch 78, Training loss 3.3555006980895996\n",
      "R2 values 0.7110, 0.5743, 0.6936; mean R2=0.6597\n",
      "Validation Error: Avg loss: 5.488638 \n",
      "\n",
      "2023-11-08 13:35:24.104407 Epoch 79, Training loss 3.9397149085998535\n",
      "R2 values 0.6425, 0.5281, 0.6380; mean R2=0.6029\n",
      "Validation Error: Avg loss: 6.160086 \n",
      "\n",
      "2023-11-08 13:35:24.570163 Epoch 80, Training loss 3.9260523319244385\n",
      "R2 values 0.4610, 0.5892, 0.6791; mean R2=0.5764\n",
      "Validation Error: Avg loss: 5.531326 \n",
      "\n",
      "2023-11-08 13:35:25.041436 Epoch 81, Training loss 3.6269614696502686\n",
      "R2 values 0.5816, 0.6382, 0.7480; mean R2=0.6559\n",
      "Validation Error: Avg loss: 4.433588 \n",
      "\n",
      "2023-11-08 13:35:25.508156 Epoch 82, Training loss 3.4097204208374023\n",
      "R2 values 0.7119, 0.5649, 0.6846; mean R2=0.6538\n",
      "Validation Error: Avg loss: 5.392744 \n",
      "\n",
      "2023-11-08 13:35:25.969009 Epoch 83, Training loss 3.7037863731384277\n",
      "R2 values 0.7345, 0.5340, 0.6846; mean R2=0.6510\n",
      "Validation Error: Avg loss: 5.633941 \n",
      "\n",
      "2023-11-08 13:35:26.439227 Epoch 84, Training loss 3.4918291568756104\n",
      "R2 values 0.7647, 0.4918, 0.6648; mean R2=0.6404\n",
      "Validation Error: Avg loss: 6.483596 \n",
      "\n",
      "2023-11-08 13:35:26.951342 Epoch 85, Training loss 3.4447121620178223\n",
      "R2 values 0.5913, 0.5438, 0.6106; mean R2=0.5819\n",
      "Validation Error: Avg loss: 6.825235 \n",
      "\n",
      "2023-11-08 13:35:27.413607 Epoch 86, Training loss 4.011806488037109\n",
      "R2 values 0.5398, 0.6657, 0.7488; mean R2=0.6515\n",
      "Validation Error: Avg loss: 4.874080 \n",
      "\n",
      "2023-11-08 13:35:27.879792 Epoch 87, Training loss 3.430642604827881\n",
      "R2 values 0.5964, 0.5560, 0.7240; mean R2=0.6255\n",
      "Validation Error: Avg loss: 5.482702 \n",
      "\n",
      "2023-11-08 13:35:28.355634 Epoch 88, Training loss 3.854524612426758\n",
      "R2 values 0.5542, 0.6462, 0.6877; mean R2=0.6294\n",
      "Validation Error: Avg loss: 5.079699 \n",
      "\n",
      "2023-11-08 13:35:28.826846 Epoch 89, Training loss 4.09832763671875\n",
      "R2 values 0.5307, 0.6978, 0.7520; mean R2=0.6602\n",
      "Validation Error: Avg loss: 4.033594 \n",
      "\n",
      "2023-11-08 13:35:29.302301 Epoch 90, Training loss 3.5185465812683105\n",
      "R2 values 0.5452, 0.6487, 0.6359; mean R2=0.6099\n",
      "Validation Error: Avg loss: 5.082556 \n",
      "\n",
      "2023-11-08 13:35:29.867680 Epoch 91, Training loss 4.07156229019165\n",
      "R2 values 0.6166, 0.6190, 0.6002; mean R2=0.6120\n",
      "Validation Error: Avg loss: 5.278137 \n",
      "\n",
      "2023-11-08 13:35:30.336312 Epoch 92, Training loss 3.550487518310547\n",
      "R2 values 0.7388, 0.6360, 0.7742; mean R2=0.7163\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 4.546382 \n",
      "\n",
      "2023-11-08 13:35:30.822749 Epoch 93, Training loss 4.002201080322266\n",
      "R2 values 0.7042, 0.5236, 0.6969; mean R2=0.6416\n",
      "Validation Error: Avg loss: 5.961068 \n",
      "\n",
      "2023-11-08 13:35:31.291356 Epoch 94, Training loss 2.8982582092285156\n",
      "R2 values 0.7529, 0.3984, 0.5891; mean R2=0.5801\n",
      "Validation Error: Avg loss: 7.510044 \n",
      "\n",
      "2023-11-08 13:35:31.757231 Epoch 95, Training loss 3.5790417194366455\n",
      "R2 values 0.5938, 0.5935, 0.7507; mean R2=0.6460\n",
      "Validation Error: Avg loss: 5.089408 \n",
      "\n",
      "2023-11-08 13:35:32.237423 Epoch 96, Training loss 4.085236549377441\n",
      "R2 values 0.7491, 0.5142, 0.7157; mean R2=0.6597\n",
      "Validation Error: Avg loss: 5.977842 \n",
      "\n",
      "2023-11-08 13:35:32.704083 Epoch 97, Training loss 3.2798657417297363\n",
      "R2 values 0.7404, 0.6142, 0.7297; mean R2=0.6948\n",
      "Validation Error: Avg loss: 4.771565 \n",
      "\n",
      "2023-11-08 13:35:33.161094 Epoch 98, Training loss 3.5494723320007324\n",
      "R2 values 0.6512, 0.6230, 0.7191; mean R2=0.6644\n",
      "Validation Error: Avg loss: 5.301694 \n",
      "\n",
      "2023-11-08 13:35:33.624858 Epoch 99, Training loss 3.1603262424468994\n",
      "R2 values 0.7219, 0.4908, 0.7094; mean R2=0.6407\n",
      "Validation Error: Avg loss: 7.118229 \n",
      "\n",
      "2023-11-08 13:35:34.087559 Epoch 100, Training loss 3.063140869140625\n",
      "R2 values 0.6530, 0.5732, 0.8109; mean R2=0.6790\n",
      "Validation Error: Avg loss: 4.982796 \n",
      "\n",
      "2023-11-08 13:35:34.551473 Epoch 101, Training loss 3.2402544021606445\n",
      "R2 values 0.5791, 0.5180, 0.6636; mean R2=0.5869\n",
      "Validation Error: Avg loss: 6.559751 \n",
      "\n",
      "2023-11-08 13:35:35.014785 Epoch 102, Training loss 3.6135926246643066\n",
      "R2 values 0.6521, 0.4922, 0.5812; mean R2=0.5752\n",
      "Validation Error: Avg loss: 7.680564 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:35:35.483133 Epoch 103, Training loss 3.475977659225464\n",
      "R2 values 0.6979, 0.5366, 0.6432; mean R2=0.6259\n",
      "Validation Error: Avg loss: 6.217067 \n",
      "\n",
      "2023-11-08 13:35:36.010013 Epoch 104, Training loss 3.072439193725586\n",
      "R2 values 0.6958, 0.5641, 0.7181; mean R2=0.6593\n",
      "Validation Error: Avg loss: 5.278739 \n",
      "\n",
      "2023-11-08 13:35:36.475444 Epoch 105, Training loss 3.154384136199951\n",
      "R2 values 0.6480, 0.6078, 0.6718; mean R2=0.6425\n",
      "Validation Error: Avg loss: 4.861710 \n",
      "\n",
      "2023-11-08 13:35:36.938282 Epoch 106, Training loss 3.4468741416931152\n",
      "R2 values 0.6923, 0.6354, 0.7585; mean R2=0.6954\n",
      "Validation Error: Avg loss: 4.329766 \n",
      "\n",
      "2023-11-08 13:35:37.403472 Epoch 107, Training loss 3.1716294288635254\n",
      "R2 values 0.5315, 0.7000, 0.7185; mean R2=0.6500\n",
      "Validation Error: Avg loss: 4.708929 \n",
      "\n",
      "2023-11-08 13:35:37.868273 Epoch 108, Training loss 3.402570962905884\n",
      "R2 values 0.6426, 0.6615, 0.6936; mean R2=0.6659\n",
      "Validation Error: Avg loss: 4.836097 \n",
      "\n",
      "2023-11-08 13:35:38.350893 Epoch 109, Training loss 3.424511194229126\n",
      "R2 values 0.7611, 0.6865, 0.7364; mean R2=0.7280\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 4.387780 \n",
      "\n",
      "2023-11-08 13:35:38.842444 Epoch 110, Training loss 3.312319040298462\n",
      "R2 values 0.5813, 0.6080, 0.6970; mean R2=0.6288\n",
      "Validation Error: Avg loss: 5.163407 \n",
      "\n",
      "2023-11-08 13:35:39.308409 Epoch 111, Training loss 3.356123924255371\n",
      "R2 values 0.6959, 0.5690, 0.7596; mean R2=0.6749\n",
      "Validation Error: Avg loss: 5.085198 \n",
      "\n",
      "2023-11-08 13:35:39.771526 Epoch 112, Training loss 3.2223262786865234\n",
      "R2 values 0.6956, 0.6568, 0.8046; mean R2=0.7190\n",
      "Validation Error: Avg loss: 4.113874 \n",
      "\n",
      "2023-11-08 13:35:40.237012 Epoch 113, Training loss 2.5581886768341064\n",
      "R2 values 0.6867, 0.5787, 0.6754; mean R2=0.6469\n",
      "Validation Error: Avg loss: 5.833988 \n",
      "\n",
      "2023-11-08 13:35:40.703447 Epoch 114, Training loss 2.9226417541503906\n",
      "R2 values 0.6552, 0.6572, 0.7493; mean R2=0.6872\n",
      "Validation Error: Avg loss: 4.797937 \n",
      "\n",
      "2023-11-08 13:35:41.170489 Epoch 115, Training loss 3.1850476264953613\n",
      "R2 values 0.7102, 0.5523, 0.7526; mean R2=0.6717\n",
      "Validation Error: Avg loss: 5.580851 \n",
      "\n",
      "2023-11-08 13:35:41.639146 Epoch 116, Training loss 2.9825870990753174\n",
      "R2 values 0.7011, 0.5931, 0.7067; mean R2=0.6669\n",
      "Validation Error: Avg loss: 5.357961 \n",
      "\n",
      "2023-11-08 13:35:42.118635 Epoch 117, Training loss 2.9202756881713867\n",
      "R2 values 0.7591, 0.5369, 0.7643; mean R2=0.6868\n",
      "Validation Error: Avg loss: 5.412912 \n",
      "\n",
      "2023-11-08 13:35:42.575756 Epoch 118, Training loss 2.8244457244873047\n",
      "R2 values 0.6662, 0.5651, 0.8137; mean R2=0.6817\n",
      "Validation Error: Avg loss: 5.094853 \n",
      "\n",
      "2023-11-08 13:35:43.037903 Epoch 119, Training loss 2.705841064453125\n",
      "R2 values 0.6694, 0.6373, 0.7520; mean R2=0.6862\n",
      "Validation Error: Avg loss: 5.115842 \n",
      "\n",
      "2023-11-08 13:35:43.501588 Epoch 120, Training loss 2.631352424621582\n",
      "R2 values 0.7130, 0.5882, 0.7503; mean R2=0.6838\n",
      "Validation Error: Avg loss: 5.595214 \n",
      "\n",
      "2023-11-08 13:35:43.967095 Epoch 121, Training loss 2.727024555206299\n",
      "R2 values 0.6398, 0.5938, 0.6569; mean R2=0.6302\n",
      "Validation Error: Avg loss: 5.919057 \n",
      "\n",
      "2023-11-08 13:35:44.430869 Epoch 122, Training loss 2.7687668800354004\n",
      "R2 values 0.7498, 0.6496, 0.7472; mean R2=0.7156\n",
      "Validation Error: Avg loss: 4.257860 \n",
      "\n",
      "2023-11-08 13:35:44.923973 Epoch 123, Training loss 2.9096226692199707\n",
      "R2 values 0.5889, 0.6297, 0.7114; mean R2=0.6433\n",
      "Validation Error: Avg loss: 5.325124 \n",
      "\n",
      "2023-11-08 13:35:45.384061 Epoch 124, Training loss 2.8724308013916016\n",
      "R2 values 0.6893, 0.5801, 0.7140; mean R2=0.6611\n",
      "Validation Error: Avg loss: 5.764400 \n",
      "\n",
      "2023-11-08 13:35:45.850304 Epoch 125, Training loss 2.7990198135375977\n",
      "R2 values 0.7537, 0.6160, 0.7359; mean R2=0.7019\n",
      "Validation Error: Avg loss: 5.068369 \n",
      "\n",
      "2023-11-08 13:35:46.316482 Epoch 126, Training loss 2.234104871749878\n",
      "R2 values 0.7112, 0.5570, 0.7250; mean R2=0.6644\n",
      "Validation Error: Avg loss: 5.740136 \n",
      "\n",
      "2023-11-08 13:35:46.779321 Epoch 127, Training loss 2.8020334243774414\n",
      "R2 values 0.6585, 0.6789, 0.7725; mean R2=0.7033\n",
      "Validation Error: Avg loss: 4.093454 \n",
      "\n",
      "2023-11-08 13:35:47.235272 Epoch 128, Training loss 2.7856509685516357\n",
      "R2 values 0.7004, 0.6357, 0.7591; mean R2=0.6984\n",
      "Validation Error: Avg loss: 4.643971 \n",
      "\n",
      "2023-11-08 13:35:47.706725 Epoch 129, Training loss 2.4404098987579346\n",
      "R2 values 0.7221, 0.5765, 0.6832; mean R2=0.6606\n",
      "Validation Error: Avg loss: 5.618237 \n",
      "\n",
      "2023-11-08 13:35:48.187312 Epoch 130, Training loss 2.5958404541015625\n",
      "R2 values 0.6885, 0.6595, 0.6915; mean R2=0.6799\n",
      "Validation Error: Avg loss: 4.687542 \n",
      "\n",
      "2023-11-08 13:35:48.651315 Epoch 131, Training loss 2.716952085494995\n",
      "R2 values 0.6674, 0.7310, 0.7481; mean R2=0.7155\n",
      "Validation Error: Avg loss: 3.959404 \n",
      "\n",
      "2023-11-08 13:35:49.124201 Epoch 132, Training loss 2.7944324016571045\n",
      "R2 values 0.8008, 0.6723, 0.7831; mean R2=0.7521\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 4.055295 \n",
      "\n",
      "2023-11-08 13:35:49.635577 Epoch 133, Training loss 2.6241419315338135\n",
      "R2 values 0.5735, 0.6318, 0.7611; mean R2=0.6555\n",
      "Validation Error: Avg loss: 5.054096 \n",
      "\n",
      "2023-11-08 13:35:50.109943 Epoch 134, Training loss 2.2979116439819336\n",
      "R2 values 0.7724, 0.5244, 0.7065; mean R2=0.6678\n",
      "Validation Error: Avg loss: 6.275908 \n",
      "\n",
      "2023-11-08 13:35:50.580973 Epoch 135, Training loss 2.4747276306152344\n",
      "R2 values 0.6415, 0.6661, 0.7824; mean R2=0.6966\n",
      "Validation Error: Avg loss: 4.557331 \n",
      "\n",
      "2023-11-08 13:35:51.047331 Epoch 136, Training loss 2.4146957397460938\n",
      "R2 values 0.6999, 0.6488, 0.8140; mean R2=0.7209\n",
      "Validation Error: Avg loss: 4.315916 \n",
      "\n",
      "2023-11-08 13:35:51.516521 Epoch 137, Training loss 2.7846500873565674\n",
      "R2 values 0.6350, 0.5832, 0.7502; mean R2=0.6561\n",
      "Validation Error: Avg loss: 5.150108 \n",
      "\n",
      "2023-11-08 13:35:51.987624 Epoch 138, Training loss 2.907254695892334\n",
      "R2 values 0.7906, 0.6164, 0.7477; mean R2=0.7182\n",
      "Validation Error: Avg loss: 5.256663 \n",
      "\n",
      "2023-11-08 13:35:52.457075 Epoch 139, Training loss 2.626344919204712\n",
      "R2 values 0.7975, 0.6335, 0.7317; mean R2=0.7209\n",
      "Validation Error: Avg loss: 5.394997 \n",
      "\n",
      "2023-11-08 13:35:52.918629 Epoch 140, Training loss 2.3713583946228027\n",
      "R2 values 0.6275, 0.6791, 0.7356; mean R2=0.6807\n",
      "Validation Error: Avg loss: 4.605094 \n",
      "\n",
      "2023-11-08 13:35:53.385542 Epoch 141, Training loss 2.489638328552246\n",
      "R2 values 0.7596, 0.6641, 0.7840; mean R2=0.7359\n",
      "Validation Error: Avg loss: 4.644627 \n",
      "\n",
      "2023-11-08 13:35:53.861792 Epoch 142, Training loss 2.367462635040283\n",
      "R2 values 0.7681, 0.6901, 0.7519; mean R2=0.7367\n",
      "Validation Error: Avg loss: 4.550335 \n",
      "\n",
      "2023-11-08 13:35:54.350777 Epoch 143, Training loss 2.307135581970215\n",
      "R2 values 0.6631, 0.6825, 0.7751; mean R2=0.7069\n",
      "Validation Error: Avg loss: 4.451098 \n",
      "\n",
      "2023-11-08 13:35:54.819653 Epoch 144, Training loss 2.4307901859283447\n",
      "R2 values 0.7420, 0.6495, 0.7733; mean R2=0.7216\n",
      "Validation Error: Avg loss: 4.572185 \n",
      "\n",
      "2023-11-08 13:35:55.297939 Epoch 145, Training loss 2.254361867904663\n",
      "R2 values 0.7780, 0.6766, 0.7891; mean R2=0.7479\n",
      "Validation Error: Avg loss: 4.071074 \n",
      "\n",
      "2023-11-08 13:35:55.773798 Epoch 146, Training loss 2.4086499214172363\n",
      "R2 values 0.7791, 0.6282, 0.7331; mean R2=0.7135\n",
      "Validation Error: Avg loss: 4.702658 \n",
      "\n",
      "2023-11-08 13:35:56.247455 Epoch 147, Training loss 1.9336174726486206\n",
      "R2 values 0.7677, 0.7013, 0.8413; mean R2=0.7701\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 3.714759 \n",
      "\n",
      "2023-11-08 13:35:56.748376 Epoch 148, Training loss 2.4220190048217773\n",
      "R2 values 0.6973, 0.6636, 0.6986; mean R2=0.6865\n",
      "Validation Error: Avg loss: 5.058253 \n",
      "\n",
      "2023-11-08 13:35:57.224484 Epoch 149, Training loss 2.4227232933044434\n",
      "R2 values 0.7527, 0.6144, 0.7506; mean R2=0.7059\n",
      "Validation Error: Avg loss: 5.303720 \n",
      "\n",
      "2023-11-08 13:35:57.711290 Epoch 150, Training loss 2.428609609603882\n",
      "R2 values 0.6850, 0.7143, 0.7728; mean R2=0.7240\n",
      "Validation Error: Avg loss: 3.654000 \n",
      "\n",
      "2023-11-08 13:35:58.208376 Epoch 151, Training loss 2.458174705505371\n",
      "R2 values 0.6293, 0.6342, 0.7414; mean R2=0.6683\n",
      "Validation Error: Avg loss: 4.987852 \n",
      "\n",
      "2023-11-08 13:35:58.695643 Epoch 152, Training loss 2.073122024536133\n",
      "R2 values 0.7678, 0.6641, 0.7855; mean R2=0.7391\n",
      "Validation Error: Avg loss: 4.181459 \n",
      "\n",
      "2023-11-08 13:35:59.181508 Epoch 153, Training loss 2.0988667011260986\n",
      "R2 values 0.6084, 0.6798, 0.7525; mean R2=0.6803\n",
      "Validation Error: Avg loss: 4.656553 \n",
      "\n",
      "2023-11-08 13:35:59.665951 Epoch 154, Training loss 1.9825005531311035\n",
      "R2 values 0.6358, 0.6458, 0.7487; mean R2=0.6768\n",
      "Validation Error: Avg loss: 4.749452 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:36:00.144057 Epoch 155, Training loss 2.4238638877868652\n",
      "R2 values 0.5613, 0.6497, 0.7663; mean R2=0.6591\n",
      "Validation Error: Avg loss: 4.937950 \n",
      "\n",
      "2023-11-08 13:36:00.626407 Epoch 156, Training loss 1.9919743537902832\n",
      "R2 values 0.6649, 0.6870, 0.7588; mean R2=0.7035\n",
      "Validation Error: Avg loss: 4.431592 \n",
      "\n",
      "2023-11-08 13:36:01.103148 Epoch 157, Training loss 2.1399717330932617\n",
      "R2 values 0.6081, 0.7097, 0.7971; mean R2=0.7050\n",
      "Validation Error: Avg loss: 4.045684 \n",
      "\n",
      "2023-11-08 13:36:01.578123 Epoch 158, Training loss 2.10984468460083\n",
      "R2 values 0.6500, 0.6466, 0.7548; mean R2=0.6838\n",
      "Validation Error: Avg loss: 4.891511 \n",
      "\n",
      "2023-11-08 13:36:02.054834 Epoch 159, Training loss 2.302056074142456\n",
      "R2 values 0.7190, 0.6430, 0.7765; mean R2=0.7129\n",
      "Validation Error: Avg loss: 4.778341 \n",
      "\n",
      "2023-11-08 13:36:02.534179 Epoch 160, Training loss 2.1480228900909424\n",
      "R2 values 0.6878, 0.6979, 0.7747; mean R2=0.7202\n",
      "Validation Error: Avg loss: 4.022400 \n",
      "\n",
      "2023-11-08 13:36:03.009680 Epoch 161, Training loss 2.253810167312622\n",
      "R2 values 0.6652, 0.6472, 0.8380; mean R2=0.7168\n",
      "Validation Error: Avg loss: 4.376017 \n",
      "\n",
      "2023-11-08 13:36:03.488684 Epoch 162, Training loss 2.071545362472534\n",
      "R2 values 0.7541, 0.6632, 0.7998; mean R2=0.7390\n",
      "Validation Error: Avg loss: 4.077305 \n",
      "\n",
      "2023-11-08 13:36:03.965808 Epoch 163, Training loss 2.228583812713623\n",
      "R2 values 0.6849, 0.7363, 0.7896; mean R2=0.7369\n",
      "Validation Error: Avg loss: 3.784627 \n",
      "\n",
      "2023-11-08 13:36:04.454017 Epoch 164, Training loss 1.7961628437042236\n",
      "R2 values 0.5938, 0.7687, 0.7902; mean R2=0.7176\n",
      "Validation Error: Avg loss: 3.574502 \n",
      "\n",
      "2023-11-08 13:36:04.935893 Epoch 165, Training loss 2.0504069328308105\n",
      "R2 values 0.6275, 0.6429, 0.7405; mean R2=0.6703\n",
      "Validation Error: Avg loss: 5.103847 \n",
      "\n",
      "2023-11-08 13:36:05.426207 Epoch 166, Training loss 2.1200780868530273\n",
      "R2 values 0.6352, 0.7497, 0.7844; mean R2=0.7231\n",
      "Validation Error: Avg loss: 3.952508 \n",
      "\n",
      "2023-11-08 13:36:05.897698 Epoch 167, Training loss 1.8506481647491455\n",
      "R2 values 0.7330, 0.6960, 0.7789; mean R2=0.7360\n",
      "Validation Error: Avg loss: 4.373016 \n",
      "\n",
      "2023-11-08 13:36:06.363856 Epoch 168, Training loss 2.336581230163574\n",
      "R2 values 0.6155, 0.6929, 0.8401; mean R2=0.7162\n",
      "Validation Error: Avg loss: 3.894912 \n",
      "\n",
      "2023-11-08 13:36:06.842643 Epoch 169, Training loss 1.9897812604904175\n",
      "R2 values 0.4946, 0.6667, 0.8187; mean R2=0.6600\n",
      "Validation Error: Avg loss: 4.387444 \n",
      "\n",
      "2023-11-08 13:36:07.331439 Epoch 170, Training loss 2.133641242980957\n",
      "R2 values 0.6941, 0.6845, 0.7823; mean R2=0.7203\n",
      "Validation Error: Avg loss: 4.217577 \n",
      "\n",
      "2023-11-08 13:36:07.873973 Epoch 171, Training loss 2.1358249187469482\n",
      "R2 values 0.7043, 0.6299, 0.7574; mean R2=0.6972\n",
      "Validation Error: Avg loss: 5.026887 \n",
      "\n",
      "2023-11-08 13:36:08.351139 Epoch 172, Training loss 1.7673321962356567\n",
      "R2 values 0.6798, 0.5986, 0.7822; mean R2=0.6869\n",
      "Validation Error: Avg loss: 5.420227 \n",
      "\n",
      "2023-11-08 13:36:08.827421 Epoch 173, Training loss 2.106718063354492\n",
      "R2 values 0.7003, 0.7235, 0.7975; mean R2=0.7404\n",
      "Validation Error: Avg loss: 3.870448 \n",
      "\n",
      "2023-11-08 13:36:09.306922 Epoch 174, Training loss 1.7301044464111328\n",
      "R2 values 0.7613, 0.7261, 0.7782; mean R2=0.7552\n",
      "Validation Error: Avg loss: 3.641236 \n",
      "\n",
      "2023-11-08 13:36:09.784904 Epoch 175, Training loss 1.810978651046753\n",
      "R2 values 0.7294, 0.7010, 0.8082; mean R2=0.7462\n",
      "Validation Error: Avg loss: 3.930463 \n",
      "\n",
      "2023-11-08 13:36:10.272247 Epoch 176, Training loss 1.7685576677322388\n",
      "R2 values 0.7155, 0.7320, 0.7515; mean R2=0.7330\n",
      "Validation Error: Avg loss: 4.216591 \n",
      "\n",
      "2023-11-08 13:36:10.751909 Epoch 177, Training loss 1.543974757194519\n",
      "R2 values 0.6816, 0.7092, 0.7621; mean R2=0.7176\n",
      "Validation Error: Avg loss: 4.252146 \n",
      "\n",
      "2023-11-08 13:36:11.228598 Epoch 178, Training loss 1.9039443731307983\n",
      "R2 values 0.6662, 0.6693, 0.7778; mean R2=0.7044\n",
      "Validation Error: Avg loss: 5.170796 \n",
      "\n",
      "2023-11-08 13:36:11.700915 Epoch 179, Training loss 1.5945497751235962\n",
      "R2 values 0.6252, 0.7391, 0.7925; mean R2=0.7190\n",
      "Validation Error: Avg loss: 3.900458 \n",
      "\n",
      "2023-11-08 13:36:12.194542 Epoch 180, Training loss 1.819595217704773\n",
      "R2 values 0.6868, 0.7036, 0.8531; mean R2=0.7478\n",
      "Validation Error: Avg loss: 4.032425 \n",
      "\n",
      "2023-11-08 13:36:12.672410 Epoch 181, Training loss 1.9691717624664307\n",
      "R2 values 0.7630, 0.7030, 0.8832; mean R2=0.7831\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 4.032789 \n",
      "\n",
      "2023-11-08 13:36:13.174591 Epoch 182, Training loss 2.175849199295044\n",
      "R2 values 0.6199, 0.6988, 0.8004; mean R2=0.7064\n",
      "Validation Error: Avg loss: 4.059914 \n",
      "\n",
      "2023-11-08 13:36:13.654545 Epoch 183, Training loss 1.8615795373916626\n",
      "R2 values 0.5995, 0.6901, 0.8349; mean R2=0.7082\n",
      "Validation Error: Avg loss: 4.142327 \n",
      "\n",
      "2023-11-08 13:36:14.124937 Epoch 184, Training loss 1.6206297874450684\n",
      "R2 values 0.7137, 0.7287, 0.7860; mean R2=0.7428\n",
      "Validation Error: Avg loss: 4.082629 \n",
      "\n",
      "2023-11-08 13:36:14.601704 Epoch 185, Training loss 1.9042109251022339\n",
      "R2 values 0.6667, 0.7010, 0.7537; mean R2=0.7071\n",
      "Validation Error: Avg loss: 4.564271 \n",
      "\n",
      "2023-11-08 13:36:15.073954 Epoch 186, Training loss 1.704837679862976\n",
      "R2 values 0.7095, 0.7023, 0.7729; mean R2=0.7282\n",
      "Validation Error: Avg loss: 4.337474 \n",
      "\n",
      "2023-11-08 13:36:15.564011 Epoch 187, Training loss 1.7164796590805054\n",
      "R2 values 0.7816, 0.6500, 0.7713; mean R2=0.7343\n",
      "Validation Error: Avg loss: 4.816196 \n",
      "\n",
      "2023-11-08 13:36:16.044288 Epoch 188, Training loss 1.7070878744125366\n",
      "R2 values 0.7455, 0.6623, 0.8258; mean R2=0.7445\n",
      "Validation Error: Avg loss: 4.756021 \n",
      "\n",
      "2023-11-08 13:36:16.524009 Epoch 189, Training loss 1.6825459003448486\n",
      "R2 values 0.6871, 0.7271, 0.7614; mean R2=0.7252\n",
      "Validation Error: Avg loss: 4.594492 \n",
      "\n",
      "2023-11-08 13:36:17.002777 Epoch 190, Training loss 1.4351392984390259\n",
      "R2 values 0.7566, 0.6790, 0.8286; mean R2=0.7547\n",
      "Validation Error: Avg loss: 4.150811 \n",
      "\n",
      "2023-11-08 13:36:17.481483 Epoch 191, Training loss 2.2927520275115967\n",
      "R2 values 0.7178, 0.7256, 0.7818; mean R2=0.7418\n",
      "Validation Error: Avg loss: 3.916400 \n",
      "\n",
      "2023-11-08 13:36:17.956705 Epoch 192, Training loss 1.4514403343200684\n",
      "R2 values 0.7124, 0.7301, 0.7982; mean R2=0.7469\n",
      "Validation Error: Avg loss: 4.285779 \n",
      "\n",
      "2023-11-08 13:36:18.445741 Epoch 193, Training loss 1.5799463987350464\n",
      "R2 values 0.6132, 0.7110, 0.7502; mean R2=0.6915\n",
      "Validation Error: Avg loss: 4.553816 \n",
      "\n",
      "2023-11-08 13:36:18.930925 Epoch 194, Training loss 1.776188611984253\n",
      "R2 values 0.5724, 0.6785, 0.7824; mean R2=0.6778\n",
      "Validation Error: Avg loss: 4.437363 \n",
      "\n",
      "2023-11-08 13:36:19.395579 Epoch 195, Training loss 1.70372474193573\n",
      "R2 values 0.5313, 0.7451, 0.7861; mean R2=0.6875\n",
      "Validation Error: Avg loss: 3.818590 \n",
      "\n",
      "2023-11-08 13:36:19.869718 Epoch 196, Training loss 2.0725836753845215\n",
      "R2 values 0.6362, 0.6282, 0.8062; mean R2=0.6902\n",
      "Validation Error: Avg loss: 5.164854 \n",
      "\n",
      "2023-11-08 13:36:20.345725 Epoch 197, Training loss 1.674545407295227\n",
      "R2 values 0.7440, 0.7031, 0.7499; mean R2=0.7323\n",
      "Validation Error: Avg loss: 4.273665 \n",
      "\n",
      "2023-11-08 13:36:20.817897 Epoch 198, Training loss 1.4233431816101074\n",
      "R2 values 0.8240, 0.7136, 0.8040; mean R2=0.7805\n",
      "Validation Error: Avg loss: 3.977988 \n",
      "\n",
      "2023-11-08 13:36:21.298725 Epoch 199, Training loss 1.365867018699646\n",
      "R2 values 0.7207, 0.6759, 0.7418; mean R2=0.7128\n",
      "Validation Error: Avg loss: 4.476039 \n",
      "\n",
      "2023-11-08 13:36:21.780913 Epoch 200, Training loss 1.7649766206741333\n",
      "R2 values 0.6806, 0.7229, 0.7871; mean R2=0.7302\n",
      "Validation Error: Avg loss: 3.929587 \n",
      "\n",
      "2023-11-08 13:36:22.397878 Epoch 201, Training loss 1.662355899810791\n",
      "R2 values 0.7037, 0.7331, 0.7948; mean R2=0.7439\n",
      "Validation Error: Avg loss: 3.951676 \n",
      "\n",
      "2023-11-08 13:36:22.864176 Epoch 202, Training loss 1.4668604135513306\n",
      "R2 values 0.7896, 0.6531, 0.7788; mean R2=0.7405\n",
      "Validation Error: Avg loss: 4.916785 \n",
      "\n",
      "2023-11-08 13:36:23.338334 Epoch 203, Training loss 1.5843698978424072\n",
      "R2 values 0.6943, 0.7281, 0.8568; mean R2=0.7597\n",
      "Validation Error: Avg loss: 3.908460 \n",
      "\n",
      "2023-11-08 13:36:23.803723 Epoch 204, Training loss 1.561435341835022\n",
      "R2 values 0.6603, 0.7393, 0.8472; mean R2=0.7489\n",
      "Validation Error: Avg loss: 3.538301 \n",
      "\n",
      "2023-11-08 13:36:24.268203 Epoch 205, Training loss 1.5414248704910278\n",
      "R2 values 0.7760, 0.7325, 0.8816; mean R2=0.7967\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 3.610072 \n",
      "\n",
      "2023-11-08 13:36:24.759439 Epoch 206, Training loss 1.6716232299804688\n",
      "R2 values 0.6870, 0.7255, 0.8689; mean R2=0.7605\n",
      "Validation Error: Avg loss: 3.901363 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:36:25.253321 Epoch 207, Training loss 1.4346694946289062\n",
      "R2 values 0.7253, 0.7234, 0.8764; mean R2=0.7750\n",
      "Validation Error: Avg loss: 3.908185 \n",
      "\n",
      "2023-11-08 13:36:25.736013 Epoch 208, Training loss 1.2818689346313477\n",
      "R2 values 0.7262, 0.8192, 0.8486; mean R2=0.7980\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2.698155 \n",
      "\n",
      "2023-11-08 13:36:26.227587 Epoch 209, Training loss 1.7516050338745117\n",
      "R2 values 0.7833, 0.7286, 0.8460; mean R2=0.7860\n",
      "Validation Error: Avg loss: 3.548857 \n",
      "\n",
      "2023-11-08 13:36:26.691761 Epoch 210, Training loss 1.3023381233215332\n",
      "R2 values 0.7146, 0.7432, 0.8052; mean R2=0.7543\n",
      "Validation Error: Avg loss: 3.698842 \n",
      "\n",
      "2023-11-08 13:36:27.151983 Epoch 211, Training loss 1.7034510374069214\n",
      "R2 values 0.6883, 0.8023, 0.8488; mean R2=0.7798\n",
      "Validation Error: Avg loss: 2.705579 \n",
      "\n",
      "2023-11-08 13:36:27.614704 Epoch 212, Training loss 1.641249179840088\n",
      "R2 values 0.6833, 0.7370, 0.8649; mean R2=0.7617\n",
      "Validation Error: Avg loss: 3.333556 \n",
      "\n",
      "2023-11-08 13:36:28.069695 Epoch 213, Training loss 1.4684765338897705\n",
      "R2 values 0.6598, 0.7155, 0.7800; mean R2=0.7185\n",
      "Validation Error: Avg loss: 4.687264 \n",
      "\n",
      "2023-11-08 13:36:28.539317 Epoch 214, Training loss 1.3801137208938599\n",
      "R2 values 0.7744, 0.7092, 0.7670; mean R2=0.7502\n",
      "Validation Error: Avg loss: 4.912557 \n",
      "\n",
      "2023-11-08 13:36:29.003863 Epoch 215, Training loss 1.3445838689804077\n",
      "R2 values 0.6309, 0.7196, 0.8136; mean R2=0.7214\n",
      "Validation Error: Avg loss: 4.350999 \n",
      "\n",
      "2023-11-08 13:36:29.460713 Epoch 216, Training loss 1.2648513317108154\n",
      "R2 values 0.7852, 0.7364, 0.8754; mean R2=0.7990\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 3.304648 \n",
      "\n",
      "2023-11-08 13:36:29.941160 Epoch 217, Training loss 1.2437541484832764\n",
      "R2 values 0.7740, 0.6342, 0.8187; mean R2=0.7423\n",
      "Validation Error: Avg loss: 5.060932 \n",
      "\n",
      "2023-11-08 13:36:30.429897 Epoch 218, Training loss 1.0674339532852173\n",
      "R2 values 0.6570, 0.6147, 0.8425; mean R2=0.7047\n",
      "Validation Error: Avg loss: 5.668471 \n",
      "\n",
      "2023-11-08 13:36:30.892803 Epoch 219, Training loss 1.4281482696533203\n",
      "R2 values 0.7069, 0.7062, 0.8334; mean R2=0.7488\n",
      "Validation Error: Avg loss: 4.424847 \n",
      "\n",
      "2023-11-08 13:36:31.575069 Epoch 220, Training loss 1.5777537822723389\n",
      "R2 values 0.6927, 0.7130, 0.8860; mean R2=0.7639\n",
      "Validation Error: Avg loss: 3.609465 \n",
      "\n",
      "2023-11-08 13:36:32.113388 Epoch 221, Training loss 1.7263970375061035\n",
      "R2 values 0.6855, 0.7543, 0.7864; mean R2=0.7420\n",
      "Validation Error: Avg loss: 3.477557 \n",
      "\n",
      "2023-11-08 13:36:32.586203 Epoch 222, Training loss 1.2856026887893677\n",
      "R2 values 0.7210, 0.7557, 0.8173; mean R2=0.7647\n",
      "Validation Error: Avg loss: 3.624074 \n",
      "\n",
      "2023-11-08 13:36:33.043677 Epoch 223, Training loss 1.214693307876587\n",
      "R2 values 0.6278, 0.6684, 0.7390; mean R2=0.6784\n",
      "Validation Error: Avg loss: 5.166219 \n",
      "\n",
      "2023-11-08 13:36:33.504303 Epoch 224, Training loss 1.5801268815994263\n",
      "R2 values 0.7306, 0.7665, 0.8183; mean R2=0.7718\n",
      "Validation Error: Avg loss: 3.381187 \n",
      "\n",
      "2023-11-08 13:36:33.965197 Epoch 225, Training loss 1.1494097709655762\n",
      "R2 values 0.7950, 0.7107, 0.8685; mean R2=0.7914\n",
      "Validation Error: Avg loss: 3.799940 \n",
      "\n",
      "2023-11-08 13:36:34.464799 Epoch 226, Training loss 1.3820372819900513\n",
      "R2 values 0.7596, 0.7539, 0.8383; mean R2=0.7840\n",
      "Validation Error: Avg loss: 3.498351 \n",
      "\n",
      "2023-11-08 13:36:34.950232 Epoch 227, Training loss 1.1458616256713867\n",
      "R2 values 0.6951, 0.6825, 0.8443; mean R2=0.7406\n",
      "Validation Error: Avg loss: 4.212657 \n",
      "\n",
      "2023-11-08 13:36:35.415985 Epoch 228, Training loss 1.1852699518203735\n",
      "R2 values 0.7573, 0.6621, 0.8217; mean R2=0.7470\n",
      "Validation Error: Avg loss: 4.815505 \n",
      "\n",
      "2023-11-08 13:36:35.882777 Epoch 229, Training loss 1.2552189826965332\n",
      "R2 values 0.7391, 0.7072, 0.8360; mean R2=0.7608\n",
      "Validation Error: Avg loss: 3.925014 \n",
      "\n",
      "2023-11-08 13:36:36.340607 Epoch 230, Training loss 1.3069819211959839\n",
      "R2 values 0.7390, 0.7463, 0.8616; mean R2=0.7823\n",
      "Validation Error: Avg loss: 3.279105 \n",
      "\n",
      "2023-11-08 13:36:36.808180 Epoch 231, Training loss 1.4982540607452393\n",
      "R2 values 0.7172, 0.7127, 0.8545; mean R2=0.7615\n",
      "Validation Error: Avg loss: 3.980105 \n",
      "\n",
      "2023-11-08 13:36:37.263319 Epoch 232, Training loss 1.0951417684555054\n",
      "R2 values 0.8142, 0.8237, 0.8183; mean R2=0.8187\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2.835626 \n",
      "\n",
      "2023-11-08 13:36:37.757616 Epoch 233, Training loss 1.1174825429916382\n",
      "R2 values 0.6753, 0.7217, 0.8380; mean R2=0.7450\n",
      "Validation Error: Avg loss: 4.341218 \n",
      "\n",
      "2023-11-08 13:36:38.235167 Epoch 234, Training loss 1.3266855478286743\n",
      "R2 values 0.7138, 0.7154, 0.8110; mean R2=0.7468\n",
      "Validation Error: Avg loss: 4.022079 \n",
      "\n",
      "2023-11-08 13:36:38.720648 Epoch 235, Training loss 1.1787041425704956\n",
      "R2 values 0.5974, 0.7769, 0.8394; mean R2=0.7379\n",
      "Validation Error: Avg loss: 3.364190 \n",
      "\n",
      "2023-11-08 13:36:39.195318 Epoch 236, Training loss 1.4662113189697266\n",
      "R2 values 0.7382, 0.7158, 0.8245; mean R2=0.7595\n",
      "Validation Error: Avg loss: 3.835264 \n",
      "\n",
      "2023-11-08 13:36:39.668696 Epoch 237, Training loss 1.0567201375961304\n",
      "R2 values 0.7970, 0.6359, 0.8264; mean R2=0.7531\n",
      "Validation Error: Avg loss: 5.052470 \n",
      "\n",
      "2023-11-08 13:36:40.139181 Epoch 238, Training loss 1.3592184782028198\n",
      "R2 values 0.6966, 0.7457, 0.7962; mean R2=0.7462\n",
      "Validation Error: Avg loss: 3.909871 \n",
      "\n",
      "2023-11-08 13:36:40.652653 Epoch 239, Training loss 1.1630412340164185\n",
      "R2 values 0.6991, 0.7080, 0.8713; mean R2=0.7595\n",
      "Validation Error: Avg loss: 3.706560 \n",
      "\n",
      "2023-11-08 13:36:41.123060 Epoch 240, Training loss 1.1043176651000977\n",
      "R2 values 0.6412, 0.7454, 0.8571; mean R2=0.7479\n",
      "Validation Error: Avg loss: 3.280965 \n",
      "\n",
      "2023-11-08 13:36:41.594981 Epoch 241, Training loss 1.333478569984436\n",
      "R2 values 0.6894, 0.7347, 0.8170; mean R2=0.7470\n",
      "Validation Error: Avg loss: 4.128597 \n",
      "\n",
      "2023-11-08 13:36:42.069921 Epoch 242, Training loss 1.087899923324585\n",
      "R2 values 0.7003, 0.7154, 0.8300; mean R2=0.7486\n",
      "Validation Error: Avg loss: 4.052867 \n",
      "\n",
      "2023-11-08 13:36:42.552396 Epoch 243, Training loss 1.4697299003601074\n",
      "R2 values 0.6693, 0.6970, 0.7827; mean R2=0.7163\n",
      "Validation Error: Avg loss: 4.654856 \n",
      "\n",
      "2023-11-08 13:36:43.034731 Epoch 244, Training loss 1.2861716747283936\n",
      "R2 values 0.6519, 0.6326, 0.8439; mean R2=0.7095\n",
      "Validation Error: Avg loss: 4.992481 \n",
      "\n",
      "2023-11-08 13:36:43.508971 Epoch 245, Training loss 1.2844552993774414\n",
      "R2 values 0.7260, 0.7283, 0.8915; mean R2=0.7819\n",
      "Validation Error: Avg loss: 3.366622 \n",
      "\n",
      "2023-11-08 13:36:43.994643 Epoch 246, Training loss 1.243711233139038\n",
      "R2 values 0.6362, 0.6629, 0.8422; mean R2=0.7138\n",
      "Validation Error: Avg loss: 4.628923 \n",
      "\n",
      "2023-11-08 13:36:44.636922 Epoch 247, Training loss 1.1058534383773804\n",
      "R2 values 0.6401, 0.7630, 0.8064; mean R2=0.7365\n",
      "Validation Error: Avg loss: 3.587718 \n",
      "\n",
      "2023-11-08 13:36:45.110555 Epoch 248, Training loss 1.110203742980957\n",
      "R2 values 0.6732, 0.7299, 0.8066; mean R2=0.7366\n",
      "Validation Error: Avg loss: 4.055770 \n",
      "\n",
      "2023-11-08 13:36:45.577853 Epoch 249, Training loss 1.2327405214309692\n",
      "R2 values 0.8100, 0.7545, 0.7884; mean R2=0.7843\n",
      "Validation Error: Avg loss: 3.575299 \n",
      "\n",
      "2023-11-08 13:36:46.038633 Epoch 250, Training loss 1.018527865409851\n",
      "R2 values 0.6985, 0.7074, 0.8178; mean R2=0.7412\n",
      "Validation Error: Avg loss: 3.984669 \n",
      "\n",
      "2023-11-08 13:36:46.505923 Epoch 251, Training loss 1.0046511888504028\n",
      "R2 values 0.6752, 0.8184, 0.8569; mean R2=0.7835\n",
      "Validation Error: Avg loss: 2.725978 \n",
      "\n",
      "2023-11-08 13:36:46.970940 Epoch 252, Training loss 1.0494664907455444\n",
      "R2 values 0.6906, 0.7647, 0.8830; mean R2=0.7794\n",
      "Validation Error: Avg loss: 3.215532 \n",
      "\n",
      "2023-11-08 13:36:47.462582 Epoch 253, Training loss 1.1701042652130127\n",
      "R2 values 0.6930, 0.7260, 0.8326; mean R2=0.7505\n",
      "Validation Error: Avg loss: 3.984087 \n",
      "\n",
      "2023-11-08 13:36:47.994978 Epoch 254, Training loss 1.1384576559066772\n",
      "R2 values 0.7629, 0.7644, 0.8214; mean R2=0.7829\n",
      "Validation Error: Avg loss: 3.244530 \n",
      "\n",
      "2023-11-08 13:36:48.457450 Epoch 255, Training loss 1.1042190790176392\n",
      "R2 values 0.6922, 0.7355, 0.8070; mean R2=0.7449\n",
      "Validation Error: Avg loss: 3.651473 \n",
      "\n",
      "2023-11-08 13:36:48.922972 Epoch 256, Training loss 1.1302982568740845\n",
      "R2 values 0.7323, 0.6726, 0.7665; mean R2=0.7238\n",
      "Validation Error: Avg loss: 4.526097 \n",
      "\n",
      "2023-11-08 13:36:49.382540 Epoch 257, Training loss 1.069145679473877\n",
      "R2 values 0.7334, 0.6714, 0.8304; mean R2=0.7451\n",
      "Validation Error: Avg loss: 4.545102 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:36:49.849119 Epoch 258, Training loss 1.1001044511795044\n",
      "R2 values 0.7732, 0.6655, 0.8565; mean R2=0.7651\n",
      "Validation Error: Avg loss: 4.480665 \n",
      "\n",
      "2023-11-08 13:36:50.310699 Epoch 259, Training loss 1.0241484642028809\n",
      "R2 values 0.6761, 0.6642, 0.8455; mean R2=0.7286\n",
      "Validation Error: Avg loss: 5.131372 \n",
      "\n",
      "2023-11-08 13:36:50.786286 Epoch 260, Training loss 1.3042484521865845\n",
      "R2 values 0.7547, 0.7397, 0.8313; mean R2=0.7752\n",
      "Validation Error: Avg loss: 4.043232 \n",
      "\n",
      "2023-11-08 13:36:51.253940 Epoch 261, Training loss 0.9709551334381104\n",
      "R2 values 0.7112, 0.7161, 0.8217; mean R2=0.7497\n",
      "Validation Error: Avg loss: 4.375911 \n",
      "\n",
      "2023-11-08 13:36:51.720364 Epoch 262, Training loss 0.9047942161560059\n",
      "R2 values 0.7116, 0.6754, 0.8157; mean R2=0.7342\n",
      "Validation Error: Avg loss: 4.508945 \n",
      "\n",
      "2023-11-08 13:36:52.180968 Epoch 263, Training loss 0.9266862869262695\n",
      "R2 values 0.7464, 0.7621, 0.8895; mean R2=0.7993\n",
      "Validation Error: Avg loss: 2.942619 \n",
      "\n",
      "2023-11-08 13:36:52.652235 Epoch 264, Training loss 0.8298876285552979\n",
      "R2 values 0.7426, 0.6570, 0.8031; mean R2=0.7342\n",
      "Validation Error: Avg loss: 4.840472 \n",
      "\n",
      "2023-11-08 13:36:53.112981 Epoch 265, Training loss 1.0893293619155884\n",
      "R2 values 0.7382, 0.7067, 0.8391; mean R2=0.7613\n",
      "Validation Error: Avg loss: 4.084259 \n",
      "\n",
      "2023-11-08 13:36:53.593591 Epoch 266, Training loss 1.1118203401565552\n",
      "R2 values 0.7218, 0.8200, 0.8698; mean R2=0.8039\n",
      "Validation Error: Avg loss: 2.948008 \n",
      "\n",
      "2023-11-08 13:36:54.111579 Epoch 267, Training loss 1.0986982583999634\n",
      "R2 values 0.7149, 0.7317, 0.8199; mean R2=0.7555\n",
      "Validation Error: Avg loss: 4.093333 \n",
      "\n",
      "2023-11-08 13:36:54.568560 Epoch 268, Training loss 1.1930720806121826\n",
      "R2 values 0.7050, 0.7204, 0.8514; mean R2=0.7589\n",
      "Validation Error: Avg loss: 4.109084 \n",
      "\n",
      "2023-11-08 13:36:55.035732 Epoch 269, Training loss 1.0214208364486694\n",
      "R2 values 0.7140, 0.7737, 0.8750; mean R2=0.7876\n",
      "Validation Error: Avg loss: 3.061127 \n",
      "\n",
      "2023-11-08 13:36:55.502401 Epoch 270, Training loss 1.0339559316635132\n",
      "R2 values 0.7487, 0.6839, 0.8124; mean R2=0.7483\n",
      "Validation Error: Avg loss: 4.124428 \n",
      "\n",
      "2023-11-08 13:36:55.981349 Epoch 271, Training loss 1.1155179738998413\n",
      "R2 values 0.7928, 0.7620, 0.8104; mean R2=0.7884\n",
      "Validation Error: Avg loss: 3.621895 \n",
      "\n",
      "2023-11-08 13:36:56.447476 Epoch 272, Training loss 1.0711804628372192\n",
      "R2 values 0.7827, 0.7637, 0.8194; mean R2=0.7886\n",
      "Validation Error: Avg loss: 3.631442 \n",
      "\n",
      "2023-11-08 13:36:56.942830 Epoch 273, Training loss 1.204042673110962\n",
      "R2 values 0.7197, 0.6448, 0.8421; mean R2=0.7355\n",
      "Validation Error: Avg loss: 4.910226 \n",
      "\n",
      "2023-11-08 13:36:57.412019 Epoch 274, Training loss 0.9679790139198303\n",
      "R2 values 0.7774, 0.7088, 0.8536; mean R2=0.7799\n",
      "Validation Error: Avg loss: 3.715211 \n",
      "\n",
      "2023-11-08 13:36:57.874744 Epoch 275, Training loss 1.0743532180786133\n",
      "R2 values 0.7122, 0.7906, 0.8701; mean R2=0.7910\n",
      "Validation Error: Avg loss: 3.067565 \n",
      "\n",
      "2023-11-08 13:36:58.336913 Epoch 276, Training loss 0.9769865274429321\n",
      "R2 values 0.7734, 0.7096, 0.8014; mean R2=0.7615\n",
      "Validation Error: Avg loss: 4.112017 \n",
      "\n",
      "2023-11-08 13:36:58.807546 Epoch 277, Training loss 1.0748554468154907\n",
      "R2 values 0.7308, 0.6969, 0.7912; mean R2=0.7397\n",
      "Validation Error: Avg loss: 4.414707 \n",
      "\n",
      "2023-11-08 13:36:59.285128 Epoch 278, Training loss 0.8736311197280884\n",
      "R2 values 0.7158, 0.7420, 0.8901; mean R2=0.7826\n",
      "Validation Error: Avg loss: 3.747361 \n",
      "\n",
      "2023-11-08 13:36:59.740412 Epoch 279, Training loss 0.9885603189468384\n",
      "R2 values 0.6309, 0.6966, 0.8294; mean R2=0.7190\n",
      "Validation Error: Avg loss: 4.483473 \n",
      "\n",
      "2023-11-08 13:37:00.193651 Epoch 280, Training loss 1.0252635478973389\n",
      "R2 values 0.6752, 0.7110, 0.9131; mean R2=0.7664\n",
      "Validation Error: Avg loss: 3.921884 \n",
      "\n",
      "2023-11-08 13:37:00.658933 Epoch 281, Training loss 0.9586588144302368\n",
      "R2 values 0.6732, 0.6811, 0.8515; mean R2=0.7352\n",
      "Validation Error: Avg loss: 4.321833 \n",
      "\n",
      "2023-11-08 13:37:01.114135 Epoch 282, Training loss 0.9303270578384399\n",
      "R2 values 0.7104, 0.6405, 0.8387; mean R2=0.7299\n",
      "Validation Error: Avg loss: 4.804254 \n",
      "\n",
      "2023-11-08 13:37:01.637985 Epoch 283, Training loss 0.9686815738677979\n",
      "R2 values 0.6573, 0.7280, 0.8092; mean R2=0.7315\n",
      "Validation Error: Avg loss: 3.898200 \n",
      "\n",
      "2023-11-08 13:37:02.095090 Epoch 284, Training loss 0.972186267375946\n",
      "R2 values 0.8088, 0.7225, 0.7906; mean R2=0.7740\n",
      "Validation Error: Avg loss: 3.833596 \n",
      "\n",
      "2023-11-08 13:37:02.570406 Epoch 285, Training loss 1.0331615209579468\n",
      "R2 values 0.6942, 0.7189, 0.7812; mean R2=0.7314\n",
      "Validation Error: Avg loss: 4.206471 \n",
      "\n",
      "2023-11-08 13:37:03.034452 Epoch 286, Training loss 1.108825445175171\n",
      "R2 values 0.6989, 0.6923, 0.8514; mean R2=0.7475\n",
      "Validation Error: Avg loss: 4.249764 \n",
      "\n",
      "2023-11-08 13:37:03.497227 Epoch 287, Training loss 1.0137672424316406\n",
      "R2 values 0.6872, 0.7581, 0.8334; mean R2=0.7595\n",
      "Validation Error: Avg loss: 3.378302 \n",
      "\n",
      "2023-11-08 13:37:03.959285 Epoch 288, Training loss 0.8687024116516113\n",
      "R2 values 0.6962, 0.7611, 0.8025; mean R2=0.7533\n",
      "Validation Error: Avg loss: 3.531430 \n",
      "\n",
      "2023-11-08 13:37:04.493209 Epoch 289, Training loss 0.9654396772384644\n",
      "R2 values 0.6596, 0.7862, 0.7832; mean R2=0.7430\n",
      "Validation Error: Avg loss: 3.665634 \n",
      "\n",
      "2023-11-08 13:37:04.969717 Epoch 290, Training loss 1.0013515949249268\n",
      "R2 values 0.6530, 0.7575, 0.8350; mean R2=0.7485\n",
      "Validation Error: Avg loss: 3.923592 \n",
      "\n",
      "2023-11-08 13:37:05.434367 Epoch 291, Training loss 1.129186749458313\n",
      "R2 values 0.6356, 0.7566, 0.8043; mean R2=0.7322\n",
      "Validation Error: Avg loss: 3.674087 \n",
      "\n",
      "2023-11-08 13:37:05.910193 Epoch 292, Training loss 0.8509560823440552\n",
      "R2 values 0.6734, 0.7418, 0.8516; mean R2=0.7556\n",
      "Validation Error: Avg loss: 3.637309 \n",
      "\n",
      "2023-11-08 13:37:06.369168 Epoch 293, Training loss 0.9387272000312805\n",
      "R2 values 0.6920, 0.7187, 0.7641; mean R2=0.7250\n",
      "Validation Error: Avg loss: 4.104073 \n",
      "\n",
      "2023-11-08 13:37:06.828809 Epoch 294, Training loss 0.8523826599121094\n",
      "R2 values 0.7237, 0.6944, 0.8312; mean R2=0.7498\n",
      "Validation Error: Avg loss: 4.426882 \n",
      "\n",
      "2023-11-08 13:37:07.284291 Epoch 295, Training loss 0.7988923788070679\n",
      "R2 values 0.7285, 0.7103, 0.8281; mean R2=0.7556\n",
      "Validation Error: Avg loss: 4.068710 \n",
      "\n",
      "2023-11-08 13:37:07.751627 Epoch 296, Training loss 0.9683627486228943\n",
      "R2 values 0.7225, 0.6969, 0.9028; mean R2=0.7741\n",
      "Validation Error: Avg loss: 4.113086 \n",
      "\n",
      "2023-11-08 13:37:08.206180 Epoch 297, Training loss 0.822543203830719\n",
      "R2 values 0.7235, 0.7368, 0.8437; mean R2=0.7680\n",
      "Validation Error: Avg loss: 3.679398 \n",
      "\n",
      "2023-11-08 13:37:08.664309 Epoch 298, Training loss 0.8005475997924805\n",
      "R2 values 0.7340, 0.7068, 0.8618; mean R2=0.7675\n",
      "Validation Error: Avg loss: 3.884149 \n",
      "\n",
      "2023-11-08 13:37:09.126215 Epoch 299, Training loss 0.7810485363006592\n",
      "R2 values 0.6679, 0.6916, 0.8379; mean R2=0.7325\n",
      "Validation Error: Avg loss: 4.250826 \n",
      "\n",
      "2023-11-08 13:37:09.587441 Epoch 300, Training loss 0.8121284246444702\n",
      "R2 values 0.6838, 0.7627, 0.8414; mean R2=0.7626\n",
      "Validation Error: Avg loss: 3.363493 \n",
      "\n",
      "2023-11-08 13:37:10.049658 Epoch 301, Training loss 0.8870675563812256\n",
      "R2 values 0.6807, 0.7517, 0.8558; mean R2=0.7627\n",
      "Validation Error: Avg loss: 3.467474 \n",
      "\n",
      "2023-11-08 13:37:10.512761 Epoch 302, Training loss 0.8793843388557434\n",
      "R2 values 0.7055, 0.6868, 0.8162; mean R2=0.7362\n",
      "Validation Error: Avg loss: 4.269866 \n",
      "\n",
      "2023-11-08 13:37:11.216582 Epoch 303, Training loss 0.8207588195800781\n",
      "R2 values 0.7738, 0.7419, 0.8032; mean R2=0.7729\n",
      "Validation Error: Avg loss: 3.917999 \n",
      "\n",
      "2023-11-08 13:37:11.736633 Epoch 304, Training loss 0.7540884613990784\n",
      "R2 values 0.5783, 0.6695, 0.8545; mean R2=0.7008\n",
      "Validation Error: Avg loss: 4.750552 \n",
      "\n",
      "2023-11-08 13:37:12.209328 Epoch 305, Training loss 0.6281715035438538\n",
      "R2 values 0.5942, 0.7040, 0.8502; mean R2=0.7161\n",
      "Validation Error: Avg loss: 4.195554 \n",
      "\n",
      "2023-11-08 13:37:12.688585 Epoch 306, Training loss 0.8768661022186279\n",
      "R2 values 0.7015, 0.7295, 0.8421; mean R2=0.7577\n",
      "Validation Error: Avg loss: 4.037868 \n",
      "\n",
      "2023-11-08 13:37:13.148942 Epoch 307, Training loss 0.8378337621688843\n",
      "R2 values 0.6949, 0.7271, 0.8408; mean R2=0.7542\n",
      "Validation Error: Avg loss: 3.771893 \n",
      "\n",
      "2023-11-08 13:37:13.608358 Epoch 308, Training loss 0.9906395673751831\n",
      "R2 values 0.6578, 0.6926, 0.7612; mean R2=0.7039\n",
      "Validation Error: Avg loss: 4.928425 \n",
      "\n",
      "2023-11-08 13:37:14.073330 Epoch 309, Training loss 0.8125901818275452\n",
      "R2 values 0.6315, 0.7036, 0.8661; mean R2=0.7337\n",
      "Validation Error: Avg loss: 4.064744 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:37:14.534164 Epoch 310, Training loss 0.6880312561988831\n",
      "R2 values 0.7219, 0.7305, 0.8477; mean R2=0.7667\n",
      "Validation Error: Avg loss: 3.744431 \n",
      "\n",
      "2023-11-08 13:37:15.008072 Epoch 311, Training loss 0.6909816861152649\n",
      "R2 values 0.7503, 0.7130, 0.8118; mean R2=0.7584\n",
      "Validation Error: Avg loss: 4.069803 \n",
      "\n",
      "2023-11-08 13:37:15.464294 Epoch 312, Training loss 0.8235350847244263\n",
      "R2 values 0.6572, 0.7237, 0.8266; mean R2=0.7358\n",
      "Validation Error: Avg loss: 3.792835 \n",
      "\n",
      "2023-11-08 13:37:15.925431 Epoch 313, Training loss 0.8130718469619751\n",
      "R2 values 0.6063, 0.7408, 0.8937; mean R2=0.7469\n",
      "Validation Error: Avg loss: 3.524168 \n",
      "\n",
      "2023-11-08 13:37:16.380579 Epoch 314, Training loss 0.90235835313797\n",
      "R2 values 0.6019, 0.6921, 0.8000; mean R2=0.6980\n",
      "Validation Error: Avg loss: 4.632468 \n",
      "\n",
      "2023-11-08 13:37:16.836675 Epoch 315, Training loss 0.8447617292404175\n",
      "R2 values 0.6524, 0.7369, 0.8298; mean R2=0.7397\n",
      "Validation Error: Avg loss: 4.420962 \n",
      "\n",
      "2023-11-08 13:37:17.291724 Epoch 316, Training loss 0.9371798038482666\n",
      "R2 values 0.5642, 0.7201, 0.8142; mean R2=0.6995\n",
      "Validation Error: Avg loss: 4.531096 \n",
      "\n",
      "2023-11-08 13:37:17.846620 Epoch 317, Training loss 1.0009841918945312\n",
      "R2 values 0.6540, 0.7391, 0.8913; mean R2=0.7615\n",
      "Validation Error: Avg loss: 3.375424 \n",
      "\n",
      "2023-11-08 13:37:18.325449 Epoch 318, Training loss 0.892478883266449\n",
      "R2 values 0.6465, 0.7855, 0.8915; mean R2=0.7745\n",
      "Validation Error: Avg loss: 2.715416 \n",
      "\n",
      "2023-11-08 13:37:18.790782 Epoch 319, Training loss 1.1791123151779175\n",
      "R2 values 0.7292, 0.6532, 0.8309; mean R2=0.7378\n",
      "Validation Error: Avg loss: 4.797581 \n",
      "\n",
      "2023-11-08 13:37:19.377724 Epoch 320, Training loss 0.8006471395492554\n",
      "R2 values 0.7433, 0.6982, 0.8373; mean R2=0.7596\n",
      "Validation Error: Avg loss: 4.490115 \n",
      "\n",
      "2023-11-08 13:37:19.880783 Epoch 321, Training loss 0.9715276956558228\n",
      "R2 values 0.7017, 0.7205, 0.8347; mean R2=0.7523\n",
      "Validation Error: Avg loss: 4.094988 \n",
      "\n",
      "2023-11-08 13:37:20.347030 Epoch 322, Training loss 0.8906248807907104\n",
      "R2 values 0.6893, 0.6888, 0.8367; mean R2=0.7383\n",
      "Validation Error: Avg loss: 4.116245 \n",
      "\n",
      "2023-11-08 13:37:20.805918 Epoch 323, Training loss 0.9691959023475647\n",
      "R2 values 0.6774, 0.6632, 0.7995; mean R2=0.7133\n",
      "Validation Error: Avg loss: 4.847082 \n",
      "\n",
      "2023-11-08 13:37:21.268894 Epoch 324, Training loss 0.7389358878135681\n",
      "R2 values 0.7455, 0.7298, 0.8179; mean R2=0.7644\n",
      "Validation Error: Avg loss: 4.019723 \n",
      "\n",
      "2023-11-08 13:37:21.729658 Epoch 325, Training loss 0.7010549306869507\n",
      "R2 values 0.6136, 0.7097, 0.8098; mean R2=0.7110\n",
      "Validation Error: Avg loss: 4.382657 \n",
      "\n",
      "2023-11-08 13:37:22.185667 Epoch 326, Training loss 0.9159607887268066\n",
      "R2 values 0.7243, 0.7104, 0.8271; mean R2=0.7540\n",
      "Validation Error: Avg loss: 3.864394 \n",
      "\n",
      "2023-11-08 13:37:22.701601 Epoch 327, Training loss 0.6816010475158691\n",
      "R2 values 0.7828, 0.7384, 0.8312; mean R2=0.7842\n",
      "Validation Error: Avg loss: 3.339041 \n",
      "\n",
      "2023-11-08 13:37:23.182044 Epoch 328, Training loss 1.133167028427124\n",
      "R2 values 0.6563, 0.7179, 0.8570; mean R2=0.7437\n",
      "Validation Error: Avg loss: 3.818475 \n",
      "\n",
      "2023-11-08 13:37:23.639898 Epoch 329, Training loss 0.7559932470321655\n",
      "R2 values 0.6369, 0.7188, 0.8157; mean R2=0.7238\n",
      "Validation Error: Avg loss: 4.535266 \n",
      "\n",
      "2023-11-08 13:37:24.098132 Epoch 330, Training loss 0.9858162999153137\n",
      "R2 values 0.6190, 0.6614, 0.8616; mean R2=0.7140\n",
      "Validation Error: Avg loss: 4.939487 \n",
      "\n",
      "2023-11-08 13:37:24.556657 Epoch 331, Training loss 0.8630210757255554\n",
      "R2 values 0.6707, 0.7064, 0.8577; mean R2=0.7449\n",
      "Validation Error: Avg loss: 4.064561 \n",
      "\n",
      "2023-11-08 13:37:25.021982 Epoch 332, Training loss 0.7871376276016235\n",
      "R2 values 0.6214, 0.7689, 0.8486; mean R2=0.7463\n",
      "Validation Error: Avg loss: 3.198183 \n",
      "\n",
      "2023-11-08 13:37:25.476547 Epoch 333, Training loss 0.9420512318611145\n",
      "R2 values 0.7085, 0.6725, 0.8290; mean R2=0.7366\n",
      "Validation Error: Avg loss: 4.762517 \n",
      "\n",
      "2023-11-08 13:37:25.949364 Epoch 334, Training loss 0.8148595094680786\n",
      "R2 values 0.6816, 0.6618, 0.8188; mean R2=0.7208\n",
      "Validation Error: Avg loss: 4.750854 \n",
      "\n",
      "2023-11-08 13:37:26.473069 Epoch 335, Training loss 0.8804817199707031\n",
      "R2 values 0.7074, 0.7511, 0.8540; mean R2=0.7708\n",
      "Validation Error: Avg loss: 3.499314 \n",
      "\n",
      "2023-11-08 13:37:26.933791 Epoch 336, Training loss 0.8290973901748657\n",
      "R2 values 0.6124, 0.7142, 0.7833; mean R2=0.7033\n",
      "Validation Error: Avg loss: 4.229184 \n",
      "\n",
      "2023-11-08 13:37:27.402460 Epoch 337, Training loss 0.787947952747345\n",
      "R2 values 0.6447, 0.7523, 0.7866; mean R2=0.7279\n",
      "Validation Error: Avg loss: 3.889790 \n",
      "\n",
      "2023-11-08 13:37:27.863717 Epoch 338, Training loss 0.8601097464561462\n",
      "R2 values 0.6794, 0.7317, 0.8332; mean R2=0.7481\n",
      "Validation Error: Avg loss: 3.883097 \n",
      "\n",
      "2023-11-08 13:37:28.325896 Epoch 339, Training loss 0.7386227250099182\n",
      "R2 values 0.6855, 0.6960, 0.8319; mean R2=0.7378\n",
      "Validation Error: Avg loss: 4.418314 \n",
      "\n",
      "2023-11-08 13:37:28.973708 Epoch 340, Training loss 0.8344330191612244\n",
      "R2 values 0.7210, 0.6786, 0.8385; mean R2=0.7461\n",
      "Validation Error: Avg loss: 4.346778 \n",
      "\n",
      "2023-11-08 13:37:29.442478 Epoch 341, Training loss 0.552001953125\n",
      "R2 values 0.7607, 0.7004, 0.8366; mean R2=0.7659\n",
      "Validation Error: Avg loss: 4.122918 \n",
      "\n",
      "2023-11-08 13:37:29.911495 Epoch 342, Training loss 0.7854899168014526\n",
      "R2 values 0.6370, 0.6877, 0.8622; mean R2=0.7290\n",
      "Validation Error: Avg loss: 4.499143 \n",
      "\n",
      "2023-11-08 13:37:30.380355 Epoch 343, Training loss 0.7855309247970581\n",
      "R2 values 0.7025, 0.7129, 0.8296; mean R2=0.7483\n",
      "Validation Error: Avg loss: 4.185817 \n",
      "\n",
      "2023-11-08 13:37:30.885435 Epoch 344, Training loss 0.7521997094154358\n",
      "R2 values 0.6046, 0.6839, 0.7844; mean R2=0.6910\n",
      "Validation Error: Avg loss: 4.703459 \n",
      "\n",
      "2023-11-08 13:37:31.358451 Epoch 345, Training loss 0.7532062530517578\n",
      "R2 values 0.6561, 0.7036, 0.8325; mean R2=0.7307\n",
      "Validation Error: Avg loss: 4.020356 \n",
      "\n",
      "2023-11-08 13:37:31.825019 Epoch 346, Training loss 0.787810742855072\n",
      "R2 values 0.6785, 0.7394, 0.8523; mean R2=0.7567\n",
      "Validation Error: Avg loss: 3.622385 \n",
      "\n",
      "2023-11-08 13:37:32.287394 Epoch 347, Training loss 0.693984866142273\n",
      "R2 values 0.6599, 0.7580, 0.8714; mean R2=0.7631\n",
      "Validation Error: Avg loss: 3.319714 \n",
      "\n",
      "2023-11-08 13:37:32.773774 Epoch 348, Training loss 0.8564636707305908\n",
      "R2 values 0.6220, 0.7320, 0.8353; mean R2=0.7298\n",
      "Validation Error: Avg loss: 4.029900 \n",
      "\n",
      "2023-11-08 13:37:33.236452 Epoch 349, Training loss 0.6406710743904114\n",
      "R2 values 0.7779, 0.7349, 0.8446; mean R2=0.7858\n",
      "Validation Error: Avg loss: 4.097929 \n",
      "\n",
      "2023-11-08 13:37:33.697098 Epoch 350, Training loss 0.701571524143219\n",
      "R2 values 0.6178, 0.7168, 0.7995; mean R2=0.7114\n",
      "Validation Error: Avg loss: 4.628512 \n",
      "\n",
      "2023-11-08 13:37:34.176305 Epoch 351, Training loss 0.6954688429832458\n",
      "R2 values 0.6372, 0.6911, 0.8084; mean R2=0.7122\n",
      "Validation Error: Avg loss: 4.756579 \n",
      "\n",
      "2023-11-08 13:37:34.661676 Epoch 352, Training loss 0.6077996492385864\n",
      "R2 values 0.6425, 0.6738, 0.8092; mean R2=0.7085\n",
      "Validation Error: Avg loss: 4.945427 \n",
      "\n",
      "2023-11-08 13:37:35.137854 Epoch 353, Training loss 0.6803092956542969\n",
      "R2 values 0.6334, 0.6575, 0.8153; mean R2=0.7021\n",
      "Validation Error: Avg loss: 4.869855 \n",
      "\n",
      "2023-11-08 13:37:35.903412 Epoch 354, Training loss 0.8187795877456665\n",
      "R2 values 0.6189, 0.6956, 0.8521; mean R2=0.7222\n",
      "Validation Error: Avg loss: 4.393321 \n",
      "\n",
      "2023-11-08 13:37:36.399650 Epoch 355, Training loss 0.9749868512153625\n",
      "R2 values 0.6887, 0.6947, 0.8359; mean R2=0.7398\n",
      "Validation Error: Avg loss: 4.446449 \n",
      "\n",
      "2023-11-08 13:37:36.882132 Epoch 356, Training loss 0.7479163408279419\n",
      "R2 values 0.6960, 0.7419, 0.8482; mean R2=0.7620\n",
      "Validation Error: Avg loss: 3.701706 \n",
      "\n",
      "2023-11-08 13:37:37.362138 Epoch 357, Training loss 0.6159601211547852\n",
      "R2 values 0.6867, 0.7245, 0.8677; mean R2=0.7596\n",
      "Validation Error: Avg loss: 3.793411 \n",
      "\n",
      "2023-11-08 13:37:37.835618 Epoch 358, Training loss 0.8138827085494995\n",
      "R2 values 0.6531, 0.7345, 0.7962; mean R2=0.7279\n",
      "Validation Error: Avg loss: 3.987200 \n",
      "\n",
      "2023-11-08 13:37:38.313782 Epoch 359, Training loss 0.7075065970420837\n",
      "R2 values 0.6960, 0.7599, 0.8107; mean R2=0.7556\n",
      "Validation Error: Avg loss: 3.869658 \n",
      "\n",
      "2023-11-08 13:37:38.804285 Epoch 360, Training loss 0.8532498478889465\n",
      "R2 values 0.6821, 0.7792, 0.8549; mean R2=0.7721\n",
      "Validation Error: Avg loss: 3.314763 \n",
      "\n",
      "2023-11-08 13:37:39.313481 Epoch 361, Training loss 0.6707637906074524\n",
      "R2 values 0.6597, 0.7638, 0.8065; mean R2=0.7433\n",
      "Validation Error: Avg loss: 3.260839 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:37:39.800158 Epoch 362, Training loss 0.719400942325592\n",
      "R2 values 0.6583, 0.7772, 0.8001; mean R2=0.7452\n",
      "Validation Error: Avg loss: 3.375315 \n",
      "\n",
      "2023-11-08 13:37:40.278482 Epoch 363, Training loss 0.6506016254425049\n",
      "R2 values 0.6811, 0.7102, 0.8247; mean R2=0.7387\n",
      "Validation Error: Avg loss: 4.030061 \n",
      "\n",
      "2023-11-08 13:37:40.754994 Epoch 364, Training loss 0.6671470999717712\n",
      "R2 values 0.6536, 0.7483, 0.8424; mean R2=0.7481\n",
      "Validation Error: Avg loss: 3.774207 \n",
      "\n",
      "2023-11-08 13:37:41.248624 Epoch 365, Training loss 0.738582193851471\n",
      "R2 values 0.6641, 0.6282, 0.8235; mean R2=0.7053\n",
      "Validation Error: Avg loss: 5.308769 \n",
      "\n",
      "2023-11-08 13:37:41.725338 Epoch 366, Training loss 0.541790246963501\n",
      "R2 values 0.6430, 0.6958, 0.8200; mean R2=0.7196\n",
      "Validation Error: Avg loss: 4.647261 \n",
      "\n",
      "2023-11-08 13:37:42.211605 Epoch 367, Training loss 0.6966496109962463\n",
      "R2 values 0.6538, 0.6872, 0.8403; mean R2=0.7271\n",
      "Validation Error: Avg loss: 4.491335 \n",
      "\n",
      "2023-11-08 13:37:42.714685 Epoch 368, Training loss 0.6182777285575867\n",
      "R2 values 0.7201, 0.7372, 0.8017; mean R2=0.7530\n",
      "Validation Error: Avg loss: 3.995408 \n",
      "\n",
      "2023-11-08 13:37:43.208782 Epoch 369, Training loss 0.5390360951423645\n",
      "R2 values 0.7171, 0.6695, 0.8424; mean R2=0.7430\n",
      "Validation Error: Avg loss: 4.332641 \n",
      "\n",
      "2023-11-08 13:37:43.692760 Epoch 370, Training loss 0.6533264517784119\n",
      "R2 values 0.5875, 0.7247, 0.8435; mean R2=0.7186\n",
      "Validation Error: Avg loss: 3.728257 \n",
      "\n",
      "2023-11-08 13:37:44.172725 Epoch 371, Training loss 0.5584243535995483\n",
      "R2 values 0.6864, 0.7098, 0.8696; mean R2=0.7552\n",
      "Validation Error: Avg loss: 3.851143 \n",
      "\n",
      "2023-11-08 13:37:44.647842 Epoch 372, Training loss 0.6095234155654907\n",
      "R2 values 0.6750, 0.7178, 0.8363; mean R2=0.7430\n",
      "Validation Error: Avg loss: 3.828675 \n",
      "\n",
      "2023-11-08 13:37:45.123901 Epoch 373, Training loss 0.6317383050918579\n",
      "R2 values 0.7086, 0.7353, 0.7847; mean R2=0.7429\n",
      "Validation Error: Avg loss: 3.946121 \n",
      "\n",
      "2023-11-08 13:37:45.606594 Epoch 374, Training loss 0.6116149425506592\n",
      "R2 values 0.5786, 0.7227, 0.7881; mean R2=0.6965\n",
      "Validation Error: Avg loss: 4.483740 \n",
      "\n",
      "2023-11-08 13:37:46.102124 Epoch 375, Training loss 0.5756984949111938\n",
      "R2 values 0.6823, 0.7626, 0.8309; mean R2=0.7586\n",
      "Validation Error: Avg loss: 3.544611 \n",
      "\n",
      "2023-11-08 13:37:46.582813 Epoch 376, Training loss 0.6710892915725708\n",
      "R2 values 0.7122, 0.6792, 0.8304; mean R2=0.7406\n",
      "Validation Error: Avg loss: 4.428102 \n",
      "\n",
      "2023-11-08 13:37:47.063344 Epoch 377, Training loss 0.5547298192977905\n",
      "R2 values 0.6865, 0.6681, 0.8809; mean R2=0.7452\n",
      "Validation Error: Avg loss: 4.550451 \n",
      "\n",
      "2023-11-08 13:37:47.543653 Epoch 378, Training loss 0.8262237310409546\n",
      "R2 values 0.7356, 0.7118, 0.8461; mean R2=0.7645\n",
      "Validation Error: Avg loss: 4.054330 \n",
      "\n",
      "2023-11-08 13:37:48.020366 Epoch 379, Training loss 0.6073282957077026\n",
      "R2 values 0.6504, 0.7212, 0.8719; mean R2=0.7478\n",
      "Validation Error: Avg loss: 4.139802 \n",
      "\n",
      "2023-11-08 13:37:48.596440 Epoch 380, Training loss 0.5713769197463989\n",
      "R2 values 0.7662, 0.7217, 0.7539; mean R2=0.7473\n",
      "Validation Error: Avg loss: 4.141421 \n",
      "\n",
      "2023-11-08 13:37:49.095492 Epoch 381, Training loss 0.5546748042106628\n",
      "R2 values 0.5641, 0.7304, 0.8127; mean R2=0.7024\n",
      "Validation Error: Avg loss: 4.112237 \n",
      "\n",
      "2023-11-08 13:37:49.583386 Epoch 382, Training loss 0.573465883731842\n",
      "R2 values 0.6312, 0.7156, 0.7868; mean R2=0.7112\n",
      "Validation Error: Avg loss: 4.181869 \n",
      "\n",
      "2023-11-08 13:37:50.060351 Epoch 383, Training loss 0.7070698738098145\n",
      "R2 values 0.6459, 0.7143, 0.7922; mean R2=0.7175\n",
      "Validation Error: Avg loss: 4.077958 \n",
      "\n",
      "2023-11-08 13:37:50.544299 Epoch 384, Training loss 0.5730419754981995\n",
      "R2 values 0.5154, 0.7454, 0.8480; mean R2=0.7029\n",
      "Validation Error: Avg loss: 3.579876 \n",
      "\n",
      "2023-11-08 13:37:51.032833 Epoch 385, Training loss 0.6717097163200378\n",
      "R2 values 0.6507, 0.7069, 0.8626; mean R2=0.7401\n",
      "Validation Error: Avg loss: 4.183512 \n",
      "\n",
      "2023-11-08 13:37:51.517378 Epoch 386, Training loss 0.6072810888290405\n",
      "R2 values 0.6093, 0.7028, 0.8405; mean R2=0.7175\n",
      "Validation Error: Avg loss: 4.589791 \n",
      "\n",
      "2023-11-08 13:37:52.028815 Epoch 387, Training loss 0.5695151090621948\n",
      "R2 values 0.7432, 0.7387, 0.8072; mean R2=0.7630\n",
      "Validation Error: Avg loss: 3.879449 \n",
      "\n",
      "2023-11-08 13:37:52.519952 Epoch 388, Training loss 0.5447981953620911\n",
      "R2 values 0.7240, 0.7249, 0.8291; mean R2=0.7593\n",
      "Validation Error: Avg loss: 4.471325 \n",
      "\n",
      "2023-11-08 13:37:53.038644 Epoch 389, Training loss 0.6727501153945923\n",
      "R2 values 0.7838, 0.7366, 0.8104; mean R2=0.7770\n",
      "Validation Error: Avg loss: 3.910741 \n",
      "\n",
      "2023-11-08 13:37:53.528873 Epoch 390, Training loss 0.5519349575042725\n",
      "R2 values 0.7936, 0.7003, 0.8069; mean R2=0.7669\n",
      "Validation Error: Avg loss: 4.476483 \n",
      "\n",
      "2023-11-08 13:37:54.020298 Epoch 391, Training loss 0.4871918857097626\n",
      "R2 values 0.6785, 0.7407, 0.8013; mean R2=0.7402\n",
      "Validation Error: Avg loss: 4.347662 \n",
      "\n",
      "2023-11-08 13:37:54.518072 Epoch 392, Training loss 0.5837273001670837\n",
      "R2 values 0.7029, 0.7433, 0.8629; mean R2=0.7697\n",
      "Validation Error: Avg loss: 3.771969 \n",
      "\n",
      "2023-11-08 13:37:55.005962 Epoch 393, Training loss 0.5470110774040222\n",
      "R2 values 0.6354, 0.7715, 0.8338; mean R2=0.7469\n",
      "Validation Error: Avg loss: 3.337736 \n",
      "\n",
      "2023-11-08 13:37:55.495038 Epoch 394, Training loss 0.8668156862258911\n",
      "R2 values 0.5730, 0.7310, 0.8029; mean R2=0.7023\n",
      "Validation Error: Avg loss: 3.986124 \n",
      "\n",
      "2023-11-08 13:37:55.970368 Epoch 395, Training loss 0.4637259840965271\n",
      "R2 values 0.6660, 0.6996, 0.8332; mean R2=0.7329\n",
      "Validation Error: Avg loss: 4.248280 \n",
      "\n",
      "2023-11-08 13:37:56.457220 Epoch 396, Training loss 0.6728514432907104\n",
      "R2 values 0.7638, 0.7273, 0.8261; mean R2=0.7724\n",
      "Validation Error: Avg loss: 3.710778 \n",
      "\n",
      "2023-11-08 13:37:56.942922 Epoch 397, Training loss 0.5565156936645508\n",
      "R2 values 0.6888, 0.7356, 0.8595; mean R2=0.7613\n",
      "Validation Error: Avg loss: 3.576821 \n",
      "\n",
      "2023-11-08 13:37:57.431219 Epoch 398, Training loss 0.5461480021476746\n",
      "R2 values 0.6799, 0.7339, 0.8091; mean R2=0.7410\n",
      "Validation Error: Avg loss: 3.907361 \n",
      "\n",
      "2023-11-08 13:37:57.921129 Epoch 399, Training loss 0.5280085802078247\n",
      "R2 values 0.6869, 0.7532, 0.8104; mean R2=0.7502\n",
      "Validation Error: Avg loss: 3.876170 \n",
      "\n",
      "2023-11-08 13:37:58.403755 Epoch 400, Training loss 0.5475801825523376\n",
      "R2 values 0.6208, 0.7759, 0.8114; mean R2=0.7360\n",
      "Validation Error: Avg loss: 3.666859 \n",
      "\n",
      "2023-11-08 13:37:58.900370 Epoch 401, Training loss 0.5917576551437378\n",
      "R2 values 0.5789, 0.7539, 0.8257; mean R2=0.7195\n",
      "Validation Error: Avg loss: 4.067272 \n",
      "\n",
      "2023-11-08 13:37:59.487784 Epoch 402, Training loss 0.5371066331863403\n",
      "R2 values 0.6306, 0.7037, 0.8300; mean R2=0.7214\n",
      "Validation Error: Avg loss: 3.980566 \n",
      "\n",
      "2023-11-08 13:38:00.316131 Epoch 403, Training loss 0.540160596370697\n",
      "R2 values 0.6683, 0.7153, 0.7897; mean R2=0.7244\n",
      "Validation Error: Avg loss: 3.928682 \n",
      "\n",
      "2023-11-08 13:38:00.989700 Epoch 404, Training loss 0.5220192074775696\n",
      "R2 values 0.7220, 0.7435, 0.8567; mean R2=0.7741\n",
      "Validation Error: Avg loss: 3.391868 \n",
      "\n",
      "2023-11-08 13:38:01.673157 Epoch 405, Training loss 0.5925791263580322\n",
      "R2 values 0.6876, 0.7447, 0.7901; mean R2=0.7408\n",
      "Validation Error: Avg loss: 4.194482 \n",
      "\n",
      "2023-11-08 13:38:02.365419 Epoch 406, Training loss 0.5868824124336243\n",
      "R2 values 0.6488, 0.7023, 0.7714; mean R2=0.7075\n",
      "Validation Error: Avg loss: 4.803053 \n",
      "\n",
      "2023-11-08 13:38:03.063191 Epoch 407, Training loss 0.5657997131347656\n",
      "R2 values 0.6852, 0.7543, 0.8753; mean R2=0.7716\n",
      "Validation Error: Avg loss: 3.280407 \n",
      "\n",
      "2023-11-08 13:38:03.767167 Epoch 408, Training loss 0.579399585723877\n",
      "R2 values 0.6819, 0.6725, 0.8035; mean R2=0.7193\n",
      "Validation Error: Avg loss: 4.588933 \n",
      "\n",
      "2023-11-08 13:38:04.440395 Epoch 409, Training loss 0.4868050217628479\n",
      "R2 values 0.6632, 0.6620, 0.8449; mean R2=0.7234\n",
      "Validation Error: Avg loss: 4.563453 \n",
      "\n",
      "2023-11-08 13:38:04.965780 Epoch 410, Training loss 0.5221160650253296\n",
      "R2 values 0.5952, 0.7009, 0.8056; mean R2=0.7006\n",
      "Validation Error: Avg loss: 4.491975 \n",
      "\n",
      "2023-11-08 13:38:05.439607 Epoch 411, Training loss 0.524654746055603\n",
      "R2 values 0.6137, 0.6867, 0.8090; mean R2=0.7032\n",
      "Validation Error: Avg loss: 4.482517 \n",
      "\n",
      "2023-11-08 13:38:05.958674 Epoch 412, Training loss 0.7378904223442078\n",
      "R2 values 0.6637, 0.7449, 0.8301; mean R2=0.7463\n",
      "Validation Error: Avg loss: 3.550634 \n",
      "\n",
      "2023-11-08 13:38:06.427195 Epoch 413, Training loss 0.44621631503105164\n",
      "R2 values 0.6189, 0.7004, 0.7652; mean R2=0.6948\n",
      "Validation Error: Avg loss: 4.722313 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:38:06.892161 Epoch 414, Training loss 0.5101767778396606\n",
      "R2 values 0.6698, 0.7266, 0.8033; mean R2=0.7332\n",
      "Validation Error: Avg loss: 4.265692 \n",
      "\n",
      "2023-11-08 13:38:07.350614 Epoch 415, Training loss 0.5933660268783569\n",
      "R2 values 0.7240, 0.7564, 0.8405; mean R2=0.7736\n",
      "Validation Error: Avg loss: 3.449598 \n",
      "\n",
      "2023-11-08 13:38:08.050233 Epoch 416, Training loss 0.6223923563957214\n",
      "R2 values 0.7081, 0.7566, 0.8547; mean R2=0.7732\n",
      "Validation Error: Avg loss: 3.379491 \n",
      "\n",
      "2023-11-08 13:38:08.570597 Epoch 417, Training loss 0.7527015805244446\n",
      "R2 values 0.6512, 0.7114, 0.8224; mean R2=0.7283\n",
      "Validation Error: Avg loss: 4.252278 \n",
      "\n",
      "2023-11-08 13:38:09.038823 Epoch 418, Training loss 0.5541091561317444\n",
      "R2 values 0.6483, 0.7484, 0.7880; mean R2=0.7283\n",
      "Validation Error: Avg loss: 3.952856 \n",
      "\n",
      "2023-11-08 13:38:09.502362 Epoch 419, Training loss 0.6021345853805542\n",
      "R2 values 0.5651, 0.7181, 0.8112; mean R2=0.6981\n",
      "Validation Error: Avg loss: 4.123975 \n",
      "\n",
      "2023-11-08 13:38:09.968456 Epoch 420, Training loss 0.4969027638435364\n",
      "R2 values 0.6761, 0.7543, 0.8056; mean R2=0.7453\n",
      "Validation Error: Avg loss: 3.411365 \n",
      "\n",
      "2023-11-08 13:38:10.425832 Epoch 421, Training loss 0.5643280744552612\n",
      "R2 values 0.6681, 0.7535, 0.8376; mean R2=0.7531\n",
      "Validation Error: Avg loss: 3.361623 \n",
      "\n",
      "2023-11-08 13:38:10.902466 Epoch 422, Training loss 0.5447304844856262\n",
      "R2 values 0.6607, 0.7008, 0.8347; mean R2=0.7321\n",
      "Validation Error: Avg loss: 3.949585 \n",
      "\n",
      "2023-11-08 13:38:11.389063 Epoch 423, Training loss 0.4291202127933502\n",
      "R2 values 0.5730, 0.7416, 0.8513; mean R2=0.7220\n",
      "Validation Error: Avg loss: 3.784294 \n",
      "\n",
      "2023-11-08 13:38:11.864322 Epoch 424, Training loss 0.4857339859008789\n",
      "R2 values 0.5845, 0.7233, 0.8456; mean R2=0.7178\n",
      "Validation Error: Avg loss: 4.077773 \n",
      "\n",
      "2023-11-08 13:38:12.336475 Epoch 425, Training loss 0.5238379240036011\n",
      "R2 values 0.6059, 0.7428, 0.8388; mean R2=0.7292\n",
      "Validation Error: Avg loss: 3.703140 \n",
      "\n",
      "2023-11-08 13:38:12.807767 Epoch 426, Training loss 0.5196011662483215\n",
      "R2 values 0.6490, 0.7112, 0.8282; mean R2=0.7295\n",
      "Validation Error: Avg loss: 4.020107 \n",
      "\n",
      "2023-11-08 13:38:13.280304 Epoch 427, Training loss 0.48093581199645996\n",
      "R2 values 0.6882, 0.7319, 0.8378; mean R2=0.7526\n",
      "Validation Error: Avg loss: 3.786317 \n",
      "\n",
      "2023-11-08 13:38:13.752673 Epoch 428, Training loss 0.4370025098323822\n",
      "R2 values 0.6546, 0.7884, 0.8042; mean R2=0.7491\n",
      "Validation Error: Avg loss: 3.365360 \n",
      "\n",
      "2023-11-08 13:38:14.218682 Epoch 429, Training loss 0.5299153327941895\n",
      "R2 values 0.7329, 0.7071, 0.8147; mean R2=0.7516\n",
      "Validation Error: Avg loss: 4.342175 \n",
      "\n",
      "2023-11-08 13:38:14.695434 Epoch 430, Training loss 0.5879994034767151\n",
      "R2 values 0.7185, 0.7417, 0.8508; mean R2=0.7703\n",
      "Validation Error: Avg loss: 3.465659 \n",
      "\n",
      "2023-11-08 13:38:15.170922 Epoch 431, Training loss 0.4603787064552307\n",
      "R2 values 0.6177, 0.7358, 0.8395; mean R2=0.7310\n",
      "Validation Error: Avg loss: 3.738142 \n",
      "\n",
      "2023-11-08 13:38:15.641310 Epoch 432, Training loss 0.5296314358711243\n",
      "R2 values 0.5431, 0.7366, 0.8421; mean R2=0.7073\n",
      "Validation Error: Avg loss: 3.918164 \n",
      "\n",
      "2023-11-08 13:38:16.110948 Epoch 433, Training loss 0.42679619789123535\n",
      "R2 values 0.6136, 0.7485, 0.7944; mean R2=0.7188\n",
      "Validation Error: Avg loss: 3.859689 \n",
      "\n",
      "2023-11-08 13:38:16.582860 Epoch 434, Training loss 0.5113255977630615\n",
      "R2 values 0.6911, 0.7472, 0.8256; mean R2=0.7546\n",
      "Validation Error: Avg loss: 3.623957 \n",
      "\n",
      "2023-11-08 13:38:17.053597 Epoch 435, Training loss 0.5686562061309814\n",
      "R2 values 0.7351, 0.7569, 0.8605; mean R2=0.7841\n",
      "Validation Error: Avg loss: 3.210632 \n",
      "\n",
      "2023-11-08 13:38:17.529386 Epoch 436, Training loss 0.5216963887214661\n",
      "R2 values 0.7104, 0.7597, 0.8482; mean R2=0.7728\n",
      "Validation Error: Avg loss: 3.466739 \n",
      "\n",
      "2023-11-08 13:38:17.993848 Epoch 437, Training loss 0.4617035686969757\n",
      "R2 values 0.5127, 0.6897, 0.8328; mean R2=0.6784\n",
      "Validation Error: Avg loss: 4.802090 \n",
      "\n",
      "2023-11-08 13:38:18.463330 Epoch 438, Training loss 0.5787438154220581\n",
      "R2 values 0.4559, 0.7672, 0.8339; mean R2=0.6857\n",
      "Validation Error: Avg loss: 3.816087 \n",
      "\n",
      "2023-11-08 13:38:18.952699 Epoch 439, Training loss 0.4465956687927246\n",
      "R2 values 0.6353, 0.7505, 0.8241; mean R2=0.7366\n",
      "Validation Error: Avg loss: 3.712344 \n",
      "\n",
      "2023-11-08 13:38:19.480546 Epoch 440, Training loss 0.789746105670929\n",
      "R2 values 0.5854, 0.7416, 0.8201; mean R2=0.7157\n",
      "Validation Error: Avg loss: 4.082125 \n",
      "\n",
      "2023-11-08 13:38:19.954359 Epoch 441, Training loss 0.4685167372226715\n",
      "R2 values 0.5738, 0.7493, 0.8439; mean R2=0.7224\n",
      "Validation Error: Avg loss: 4.118508 \n",
      "\n",
      "2023-11-08 13:38:20.430787 Epoch 442, Training loss 0.5174139738082886\n",
      "R2 values 0.6756, 0.7518, 0.8692; mean R2=0.7655\n",
      "Validation Error: Avg loss: 3.320454 \n",
      "\n",
      "2023-11-08 13:38:20.906876 Epoch 443, Training loss 0.37424203753471375\n",
      "R2 values 0.6413, 0.7874, 0.8496; mean R2=0.7594\n",
      "Validation Error: Avg loss: 2.892954 \n",
      "\n",
      "2023-11-08 13:38:21.387302 Epoch 444, Training loss 0.5567612051963806\n",
      "R2 values 0.6864, 0.7534, 0.7863; mean R2=0.7420\n",
      "Validation Error: Avg loss: 3.545041 \n",
      "\n",
      "2023-11-08 13:38:21.861050 Epoch 445, Training loss 0.5284983515739441\n",
      "R2 values 0.6828, 0.7580, 0.8172; mean R2=0.7527\n",
      "Validation Error: Avg loss: 3.749187 \n",
      "\n",
      "2023-11-08 13:38:22.338570 Epoch 446, Training loss 0.513552188873291\n",
      "R2 values 0.6089, 0.7493, 0.8067; mean R2=0.7216\n",
      "Validation Error: Avg loss: 4.048760 \n",
      "\n",
      "2023-11-08 13:38:22.814702 Epoch 447, Training loss 0.597150444984436\n",
      "R2 values 0.6238, 0.7599, 0.8283; mean R2=0.7373\n",
      "Validation Error: Avg loss: 3.541646 \n",
      "\n",
      "2023-11-08 13:38:23.302620 Epoch 448, Training loss 0.4751119017601013\n",
      "R2 values 0.6460, 0.7716, 0.8689; mean R2=0.7621\n",
      "Validation Error: Avg loss: 3.191315 \n",
      "\n",
      "2023-11-08 13:38:23.773055 Epoch 449, Training loss 0.513663113117218\n",
      "R2 values 0.6397, 0.6936, 0.8447; mean R2=0.7260\n",
      "Validation Error: Avg loss: 4.352436 \n",
      "\n",
      "2023-11-08 13:38:24.262390 Epoch 450, Training loss 0.4669168293476105\n",
      "R2 values 0.7126, 0.7395, 0.8071; mean R2=0.7530\n",
      "Validation Error: Avg loss: 3.880993 \n",
      "\n",
      "2023-11-08 13:38:24.731382 Epoch 451, Training loss 0.5045698881149292\n",
      "R2 values 0.6725, 0.7176, 0.7617; mean R2=0.7173\n",
      "Validation Error: Avg loss: 4.542282 \n",
      "\n",
      "2023-11-08 13:38:25.201908 Epoch 452, Training loss 0.571994960308075\n",
      "R2 values 0.5920, 0.7190, 0.8253; mean R2=0.7121\n",
      "Validation Error: Avg loss: 4.023571 \n",
      "\n",
      "2023-11-08 13:38:25.671060 Epoch 453, Training loss 0.5166047811508179\n",
      "R2 values 0.7066, 0.7827, 0.8102; mean R2=0.7665\n",
      "Validation Error: Avg loss: 3.127679 \n",
      "\n",
      "2023-11-08 13:38:26.137396 Epoch 454, Training loss 0.5547064542770386\n",
      "R2 values 0.6643, 0.7320, 0.8287; mean R2=0.7417\n",
      "Validation Error: Avg loss: 3.911946 \n",
      "\n",
      "2023-11-08 13:38:26.673457 Epoch 455, Training loss 0.4893871247768402\n",
      "R2 values 0.6280, 0.7064, 0.7797; mean R2=0.7047\n",
      "Validation Error: Avg loss: 4.220198 \n",
      "\n",
      "2023-11-08 13:38:27.130025 Epoch 456, Training loss 0.5538407564163208\n",
      "R2 values 0.6629, 0.7497, 0.7966; mean R2=0.7364\n",
      "Validation Error: Avg loss: 3.514048 \n",
      "\n",
      "2023-11-08 13:38:27.594782 Epoch 457, Training loss 0.4264987111091614\n",
      "R2 values 0.6883, 0.7626, 0.8091; mean R2=0.7534\n",
      "Validation Error: Avg loss: 3.537817 \n",
      "\n",
      "2023-11-08 13:38:28.064393 Epoch 458, Training loss 0.4670281410217285\n",
      "R2 values 0.6702, 0.7602, 0.8194; mean R2=0.7499\n",
      "Validation Error: Avg loss: 3.495479 \n",
      "\n",
      "2023-11-08 13:38:28.542634 Epoch 459, Training loss 0.4737745523452759\n",
      "R2 values 0.6170, 0.7277, 0.8375; mean R2=0.7274\n",
      "Validation Error: Avg loss: 4.059099 \n",
      "\n",
      "2023-11-08 13:38:29.027383 Epoch 460, Training loss 0.4221950173377991\n",
      "R2 values 0.6781, 0.7495, 0.8126; mean R2=0.7468\n",
      "Validation Error: Avg loss: 3.800070 \n",
      "\n",
      "2023-11-08 13:38:29.495517 Epoch 461, Training loss 0.4266318678855896\n",
      "R2 values 0.7169, 0.7448, 0.8467; mean R2=0.7694\n",
      "Validation Error: Avg loss: 3.552553 \n",
      "\n",
      "2023-11-08 13:38:29.981300 Epoch 462, Training loss 0.43570783734321594\n",
      "R2 values 0.6367, 0.7598, 0.8778; mean R2=0.7581\n",
      "Validation Error: Avg loss: 3.666506 \n",
      "\n",
      "2023-11-08 13:38:30.479766 Epoch 463, Training loss 0.5528364181518555\n",
      "R2 values 0.6850, 0.7170, 0.8797; mean R2=0.7605\n",
      "Validation Error: Avg loss: 3.701974 \n",
      "\n",
      "2023-11-08 13:38:30.957232 Epoch 464, Training loss 0.4067807197570801\n",
      "R2 values 0.6126, 0.7224, 0.8419; mean R2=0.7256\n",
      "Validation Error: Avg loss: 4.201524 \n",
      "\n",
      "2023-11-08 13:38:31.467038 Epoch 465, Training loss 0.42652031779289246\n",
      "R2 values 0.6629, 0.7012, 0.7389; mean R2=0.7010\n",
      "Validation Error: Avg loss: 4.897482 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:38:31.990613 Epoch 466, Training loss 0.6479848623275757\n",
      "R2 values 0.6409, 0.7356, 0.7875; mean R2=0.7213\n",
      "Validation Error: Avg loss: 3.946309 \n",
      "\n",
      "2023-11-08 13:38:32.466521 Epoch 467, Training loss 0.44258275628089905\n",
      "R2 values 0.6524, 0.7464, 0.8545; mean R2=0.7511\n",
      "Validation Error: Avg loss: 3.598990 \n",
      "\n",
      "2023-11-08 13:38:32.934279 Epoch 468, Training loss 0.6090632677078247\n",
      "R2 values 0.5569, 0.7420, 0.8497; mean R2=0.7162\n",
      "Validation Error: Avg loss: 3.595976 \n",
      "\n",
      "2023-11-08 13:38:33.412809 Epoch 469, Training loss 0.43486151099205017\n",
      "R2 values 0.7606, 0.7253, 0.7889; mean R2=0.7583\n",
      "Validation Error: Avg loss: 4.135739 \n",
      "\n",
      "2023-11-08 13:38:33.892322 Epoch 470, Training loss 0.6427064538002014\n",
      "R2 values 0.6224, 0.6896, 0.7727; mean R2=0.6949\n",
      "Validation Error: Avg loss: 4.609786 \n",
      "\n",
      "2023-11-08 13:38:34.367014 Epoch 471, Training loss 0.6272318363189697\n",
      "R2 values 0.6337, 0.7414, 0.8048; mean R2=0.7266\n",
      "Validation Error: Avg loss: 3.603065 \n",
      "\n",
      "2023-11-08 13:38:34.843935 Epoch 472, Training loss 0.43980085849761963\n",
      "R2 values 0.6720, 0.7319, 0.8339; mean R2=0.7459\n",
      "Validation Error: Avg loss: 3.591042 \n",
      "\n",
      "2023-11-08 13:38:35.358447 Epoch 473, Training loss 0.5963276624679565\n",
      "R2 values 0.5807, 0.7507, 0.8144; mean R2=0.7153\n",
      "Validation Error: Avg loss: 3.856380 \n",
      "\n",
      "2023-11-08 13:38:35.883266 Epoch 474, Training loss 0.46292969584465027\n",
      "R2 values 0.6117, 0.7230, 0.7841; mean R2=0.7063\n",
      "Validation Error: Avg loss: 4.667977 \n",
      "\n",
      "2023-11-08 13:38:36.345750 Epoch 475, Training loss 0.531140148639679\n",
      "R2 values 0.5866, 0.7088, 0.8048; mean R2=0.7001\n",
      "Validation Error: Avg loss: 4.516849 \n",
      "\n",
      "2023-11-08 13:38:36.814619 Epoch 476, Training loss 0.738101065158844\n",
      "R2 values 0.6953, 0.7343, 0.8274; mean R2=0.7523\n",
      "Validation Error: Avg loss: 3.743140 \n",
      "\n",
      "2023-11-08 13:38:37.281881 Epoch 477, Training loss 0.40318092703819275\n",
      "R2 values 0.7664, 0.7707, 0.8311; mean R2=0.7894\n",
      "Validation Error: Avg loss: 3.026637 \n",
      "\n",
      "2023-11-08 13:38:37.755355 Epoch 478, Training loss 0.6191425323486328\n",
      "R2 values 0.7240, 0.7380, 0.8175; mean R2=0.7599\n",
      "Validation Error: Avg loss: 3.933961 \n",
      "\n",
      "2023-11-08 13:38:38.221943 Epoch 479, Training loss 0.4595981538295746\n",
      "R2 values 0.5719, 0.7045, 0.8050; mean R2=0.6938\n",
      "Validation Error: Avg loss: 4.946455 \n",
      "\n",
      "2023-11-08 13:38:38.691915 Epoch 480, Training loss 0.4769574999809265\n",
      "R2 values 0.6397, 0.6844, 0.8241; mean R2=0.7161\n",
      "Validation Error: Avg loss: 4.820208 \n",
      "\n",
      "2023-11-08 13:38:39.162927 Epoch 481, Training loss 0.6418759822845459\n",
      "R2 values 0.5984, 0.7446, 0.8104; mean R2=0.7178\n",
      "Validation Error: Avg loss: 3.859018 \n",
      "\n",
      "2023-11-08 13:38:39.634187 Epoch 482, Training loss 0.42144498229026794\n",
      "R2 values 0.6498, 0.7194, 0.8200; mean R2=0.7297\n",
      "Validation Error: Avg loss: 3.597672 \n",
      "\n",
      "2023-11-08 13:38:40.096035 Epoch 483, Training loss 0.6993907690048218\n",
      "R2 values 0.6251, 0.7339, 0.8513; mean R2=0.7367\n",
      "Validation Error: Avg loss: 3.762716 \n",
      "\n",
      "2023-11-08 13:38:40.558401 Epoch 484, Training loss 0.4248393177986145\n",
      "R2 values 0.7074, 0.7324, 0.8310; mean R2=0.7569\n",
      "Validation Error: Avg loss: 3.915702 \n",
      "\n",
      "2023-11-08 13:38:41.013564 Epoch 485, Training loss 0.4984648823738098\n",
      "R2 values 0.6168, 0.7491, 0.8216; mean R2=0.7292\n",
      "Validation Error: Avg loss: 3.546566 \n",
      "\n",
      "2023-11-08 13:38:41.600332 Epoch 486, Training loss 0.394220769405365\n",
      "R2 values 0.6304, 0.7654, 0.8425; mean R2=0.7461\n",
      "Validation Error: Avg loss: 3.302646 \n",
      "\n",
      "2023-11-08 13:38:42.066747 Epoch 487, Training loss 0.548909604549408\n",
      "R2 values 0.7561, 0.7049, 0.8020; mean R2=0.7543\n",
      "Validation Error: Avg loss: 4.233811 \n",
      "\n",
      "2023-11-08 13:38:42.562666 Epoch 488, Training loss 0.512579619884491\n",
      "R2 values 0.7047, 0.7326, 0.7903; mean R2=0.7425\n",
      "Validation Error: Avg loss: 4.025119 \n",
      "\n",
      "2023-11-08 13:38:43.054226 Epoch 489, Training loss 0.3779047727584839\n",
      "R2 values 0.6876, 0.7160, 0.8270; mean R2=0.7435\n",
      "Validation Error: Avg loss: 4.078421 \n",
      "\n",
      "2023-11-08 13:38:43.506757 Epoch 490, Training loss 0.4205578565597534\n",
      "R2 values 0.6741, 0.7284, 0.8576; mean R2=0.7534\n",
      "Validation Error: Avg loss: 3.710495 \n",
      "\n",
      "2023-11-08 13:38:43.964880 Epoch 491, Training loss 0.34580469131469727\n",
      "R2 values 0.6125, 0.7041, 0.7905; mean R2=0.7024\n",
      "Validation Error: Avg loss: 4.263971 \n",
      "\n",
      "2023-11-08 13:38:44.424134 Epoch 492, Training loss 0.4494694173336029\n",
      "R2 values 0.5462, 0.6904, 0.8361; mean R2=0.6909\n",
      "Validation Error: Avg loss: 4.278055 \n",
      "\n",
      "2023-11-08 13:38:44.887181 Epoch 493, Training loss 0.40465593338012695\n",
      "R2 values 0.6247, 0.6937, 0.8165; mean R2=0.7116\n",
      "Validation Error: Avg loss: 4.339359 \n",
      "\n",
      "2023-11-08 13:38:45.343052 Epoch 494, Training loss 0.5308051705360413\n",
      "R2 values 0.6539, 0.7166, 0.8240; mean R2=0.7315\n",
      "Validation Error: Avg loss: 4.027226 \n",
      "\n",
      "2023-11-08 13:38:45.808202 Epoch 495, Training loss 0.4099889397621155\n",
      "R2 values 0.6099, 0.7251, 0.8434; mean R2=0.7261\n",
      "Validation Error: Avg loss: 4.279233 \n",
      "\n",
      "2023-11-08 13:38:46.267489 Epoch 496, Training loss 0.3805291950702667\n",
      "R2 values 0.7029, 0.7335, 0.8513; mean R2=0.7626\n",
      "Validation Error: Avg loss: 3.702820 \n",
      "\n",
      "2023-11-08 13:38:46.731803 Epoch 497, Training loss 0.41087597608566284\n",
      "R2 values 0.5193, 0.7044, 0.8398; mean R2=0.6878\n",
      "Validation Error: Avg loss: 4.121746 \n",
      "\n",
      "2023-11-08 13:38:47.194241 Epoch 498, Training loss 0.35589373111724854\n",
      "R2 values 0.6595, 0.7407, 0.8169; mean R2=0.7390\n",
      "Validation Error: Avg loss: 3.629507 \n",
      "\n",
      "2023-11-08 13:38:47.660045 Epoch 499, Training loss 0.4374532103538513\n",
      "R2 values 0.6343, 0.7232, 0.8573; mean R2=0.7382\n",
      "Validation Error: Avg loss: 3.763016 \n",
      "\n",
      "2023-11-08 13:38:48.351879 Epoch 500, Training loss 0.4009883403778076\n",
      "R2 values 0.6414, 0.7226, 0.8346; mean R2=0.7329\n",
      "Validation Error: Avg loss: 4.171896 \n",
      "\n",
      "2023-11-08 13:38:48.866205 Epoch 501, Training loss 0.31484997272491455\n",
      "R2 values 0.6319, 0.7096, 0.8282; mean R2=0.7232\n",
      "Validation Error: Avg loss: 3.973265 \n",
      "\n",
      "2023-11-08 13:38:49.333843 Epoch 502, Training loss 0.3735734820365906\n",
      "R2 values 0.7422, 0.7199, 0.7743; mean R2=0.7455\n",
      "Validation Error: Avg loss: 4.270416 \n",
      "\n",
      "2023-11-08 13:38:49.813198 Epoch 503, Training loss 0.39371293783187866\n",
      "R2 values 0.7031, 0.6786, 0.8203; mean R2=0.7340\n",
      "Validation Error: Avg loss: 4.721271 \n",
      "\n",
      "2023-11-08 13:38:50.277842 Epoch 504, Training loss 0.4106106460094452\n",
      "R2 values 0.5954, 0.7042, 0.8102; mean R2=0.7032\n",
      "Validation Error: Avg loss: 4.109464 \n",
      "\n",
      "2023-11-08 13:38:50.742972 Epoch 505, Training loss 0.33799466490745544\n",
      "R2 values 0.6647, 0.7376, 0.8212; mean R2=0.7411\n",
      "Validation Error: Avg loss: 3.795311 \n",
      "\n",
      "2023-11-08 13:38:51.203290 Epoch 506, Training loss 0.3616429269313812\n",
      "R2 values 0.6192, 0.7281, 0.8316; mean R2=0.7263\n",
      "Validation Error: Avg loss: 3.868137 \n",
      "\n",
      "2023-11-08 13:38:51.695145 Epoch 507, Training loss 0.42230224609375\n",
      "R2 values 0.5850, 0.7045, 0.8287; mean R2=0.7061\n",
      "Validation Error: Avg loss: 4.421169 \n",
      "\n",
      "2023-11-08 13:38:52.160703 Epoch 508, Training loss 0.35594815015792847\n",
      "R2 values 0.6878, 0.7609, 0.8168; mean R2=0.7552\n",
      "Validation Error: Avg loss: 3.651313 \n",
      "\n",
      "2023-11-08 13:38:52.630232 Epoch 509, Training loss 0.38822922110557556\n",
      "R2 values 0.6890, 0.7624, 0.7855; mean R2=0.7457\n",
      "Validation Error: Avg loss: 3.641161 \n",
      "\n",
      "2023-11-08 13:38:53.096627 Epoch 510, Training loss 0.3722442388534546\n",
      "R2 values 0.6314, 0.7442, 0.8164; mean R2=0.7307\n",
      "Validation Error: Avg loss: 3.719384 \n",
      "\n",
      "2023-11-08 13:38:53.560860 Epoch 511, Training loss 0.4387669563293457\n",
      "R2 values 0.6631, 0.7485, 0.7951; mean R2=0.7356\n",
      "Validation Error: Avg loss: 3.900845 \n",
      "\n",
      "2023-11-08 13:38:54.031529 Epoch 512, Training loss 0.3394041359424591\n",
      "R2 values 0.6468, 0.7452, 0.8313; mean R2=0.7411\n",
      "Validation Error: Avg loss: 3.836436 \n",
      "\n",
      "2023-11-08 13:38:54.497827 Epoch 513, Training loss 0.35477763414382935\n",
      "R2 values 0.6045, 0.7120, 0.8308; mean R2=0.7158\n",
      "Validation Error: Avg loss: 4.157086 \n",
      "\n",
      "2023-11-08 13:38:54.961258 Epoch 514, Training loss 0.4800965487957001\n",
      "R2 values 0.6434, 0.7096, 0.8789; mean R2=0.7440\n",
      "Validation Error: Avg loss: 3.641308 \n",
      "\n",
      "2023-11-08 13:38:55.415655 Epoch 515, Training loss 0.4417809844017029\n",
      "R2 values 0.6172, 0.7167, 0.8706; mean R2=0.7348\n",
      "Validation Error: Avg loss: 3.497717 \n",
      "\n",
      "2023-11-08 13:38:55.878670 Epoch 516, Training loss 0.5095461010932922\n",
      "R2 values 0.7434, 0.7369, 0.8433; mean R2=0.7745\n",
      "Validation Error: Avg loss: 3.597562 \n",
      "\n",
      "2023-11-08 13:38:56.336345 Epoch 517, Training loss 0.31336039304733276\n",
      "R2 values 0.6343, 0.7300, 0.7602; mean R2=0.7082\n",
      "Validation Error: Avg loss: 4.400579 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:38:56.812134 Epoch 518, Training loss 0.4797182083129883\n",
      "R2 values 0.7125, 0.7071, 0.8134; mean R2=0.7443\n",
      "Validation Error: Avg loss: 4.475201 \n",
      "\n",
      "2023-11-08 13:38:57.281548 Epoch 519, Training loss 0.3518483340740204\n",
      "R2 values 0.6508, 0.6983, 0.8000; mean R2=0.7164\n",
      "Validation Error: Avg loss: 4.191953 \n",
      "\n",
      "2023-11-08 13:38:57.936142 Epoch 520, Training loss 0.36095482110977173\n",
      "R2 values 0.6667, 0.7161, 0.8133; mean R2=0.7320\n",
      "Validation Error: Avg loss: 3.990355 \n",
      "\n",
      "2023-11-08 13:38:58.407498 Epoch 521, Training loss 0.3292599022388458\n",
      "R2 values 0.4835, 0.7508, 0.7995; mean R2=0.6779\n",
      "Validation Error: Avg loss: 3.991123 \n",
      "\n",
      "2023-11-08 13:38:58.877732 Epoch 522, Training loss 0.3972758948802948\n",
      "R2 values 0.5867, 0.7251, 0.7754; mean R2=0.6957\n",
      "Validation Error: Avg loss: 4.532039 \n",
      "\n",
      "2023-11-08 13:38:59.356599 Epoch 523, Training loss 0.347884863615036\n",
      "R2 values 0.5607, 0.7461, 0.8022; mean R2=0.7030\n",
      "Validation Error: Avg loss: 3.852872 \n",
      "\n",
      "2023-11-08 13:38:59.824831 Epoch 524, Training loss 0.36236149072647095\n",
      "R2 values 0.5868, 0.7730, 0.7831; mean R2=0.7143\n",
      "Validation Error: Avg loss: 3.403152 \n",
      "\n",
      "2023-11-08 13:39:00.289776 Epoch 525, Training loss 0.40048471093177795\n",
      "R2 values 0.5595, 0.7428, 0.7817; mean R2=0.6947\n",
      "Validation Error: Avg loss: 3.656331 \n",
      "\n",
      "2023-11-08 13:39:00.763321 Epoch 526, Training loss 0.47115951776504517\n",
      "R2 values 0.6102, 0.7088, 0.8337; mean R2=0.7176\n",
      "Validation Error: Avg loss: 3.884210 \n",
      "\n",
      "2023-11-08 13:39:01.222226 Epoch 527, Training loss 0.35932108759880066\n",
      "R2 values 0.5882, 0.7510, 0.8662; mean R2=0.7352\n",
      "Validation Error: Avg loss: 3.660104 \n",
      "\n",
      "2023-11-08 13:39:01.696107 Epoch 528, Training loss 0.399332731962204\n",
      "R2 values 0.5737, 0.7446, 0.8656; mean R2=0.7279\n",
      "Validation Error: Avg loss: 3.844774 \n",
      "\n",
      "2023-11-08 13:39:02.156887 Epoch 529, Training loss 0.42005664110183716\n",
      "R2 values 0.5854, 0.7505, 0.8167; mean R2=0.7175\n",
      "Validation Error: Avg loss: 3.650699 \n",
      "\n",
      "2023-11-08 13:39:02.666944 Epoch 530, Training loss 0.3308176100254059\n",
      "R2 values 0.6852, 0.7234, 0.8049; mean R2=0.7378\n",
      "Validation Error: Avg loss: 3.998591 \n",
      "\n",
      "2023-11-08 13:39:03.125280 Epoch 531, Training loss 0.411732941865921\n",
      "R2 values 0.5802, 0.7417, 0.7563; mean R2=0.6928\n",
      "Validation Error: Avg loss: 4.203547 \n",
      "\n",
      "2023-11-08 13:39:03.591700 Epoch 532, Training loss 0.29293009638786316\n",
      "R2 values 0.6845, 0.7485, 0.8172; mean R2=0.7501\n",
      "Validation Error: Avg loss: 3.888888 \n",
      "\n",
      "2023-11-08 13:39:04.094866 Epoch 533, Training loss 0.4075019657611847\n",
      "R2 values 0.6424, 0.7598, 0.8235; mean R2=0.7419\n",
      "Validation Error: Avg loss: 3.607409 \n",
      "\n",
      "2023-11-08 13:39:04.620126 Epoch 534, Training loss 0.3181499242782593\n",
      "R2 values 0.5560, 0.7810, 0.8532; mean R2=0.7301\n",
      "Validation Error: Avg loss: 3.178638 \n",
      "\n",
      "2023-11-08 13:39:05.119579 Epoch 535, Training loss 0.41802147030830383\n",
      "R2 values 0.6478, 0.7203, 0.8167; mean R2=0.7282\n",
      "Validation Error: Avg loss: 3.997835 \n",
      "\n",
      "2023-11-08 13:39:05.580628 Epoch 536, Training loss 0.3873898684978485\n",
      "R2 values 0.6657, 0.7366, 0.8031; mean R2=0.7351\n",
      "Validation Error: Avg loss: 4.054158 \n",
      "\n",
      "2023-11-08 13:39:06.054778 Epoch 537, Training loss 0.3018920421600342\n",
      "R2 values 0.6389, 0.7215, 0.8271; mean R2=0.7292\n",
      "Validation Error: Avg loss: 4.133292 \n",
      "\n",
      "2023-11-08 13:39:06.514173 Epoch 538, Training loss 0.3358139097690582\n",
      "R2 values 0.6882, 0.7554, 0.8167; mean R2=0.7534\n",
      "Validation Error: Avg loss: 3.564003 \n",
      "\n",
      "2023-11-08 13:39:07.008829 Epoch 539, Training loss 0.28386399149894714\n",
      "R2 values 0.6837, 0.7601, 0.8243; mean R2=0.7560\n",
      "Validation Error: Avg loss: 3.480759 \n",
      "\n",
      "2023-11-08 13:39:07.480528 Epoch 540, Training loss 0.4224443733692169\n",
      "R2 values 0.6855, 0.7338, 0.8120; mean R2=0.7438\n",
      "Validation Error: Avg loss: 3.975307 \n",
      "\n",
      "2023-11-08 13:39:07.960735 Epoch 541, Training loss 0.3233046233654022\n",
      "R2 values 0.6192, 0.7404, 0.8231; mean R2=0.7276\n",
      "Validation Error: Avg loss: 4.173152 \n",
      "\n",
      "2023-11-08 13:39:08.428966 Epoch 542, Training loss 0.34306272864341736\n",
      "R2 values 0.5879, 0.7267, 0.8112; mean R2=0.7086\n",
      "Validation Error: Avg loss: 4.244929 \n",
      "\n",
      "2023-11-08 13:39:08.934584 Epoch 543, Training loss 0.37208041548728943\n",
      "R2 values 0.6439, 0.7493, 0.7991; mean R2=0.7308\n",
      "Validation Error: Avg loss: 3.819236 \n",
      "\n",
      "2023-11-08 13:39:09.421739 Epoch 544, Training loss 0.41758039593696594\n",
      "R2 values 0.6897, 0.7201, 0.7792; mean R2=0.7297\n",
      "Validation Error: Avg loss: 4.152722 \n",
      "\n",
      "2023-11-08 13:39:09.908830 Epoch 545, Training loss 0.4417773187160492\n",
      "R2 values 0.6419, 0.7095, 0.7735; mean R2=0.7083\n",
      "Validation Error: Avg loss: 4.498479 \n",
      "\n",
      "2023-11-08 13:39:10.393685 Epoch 546, Training loss 0.3684554398059845\n",
      "R2 values 0.6528, 0.7630, 0.8006; mean R2=0.7388\n",
      "Validation Error: Avg loss: 3.693913 \n",
      "\n",
      "2023-11-08 13:39:10.874842 Epoch 547, Training loss 0.40101516246795654\n",
      "R2 values 0.6506, 0.7430, 0.8144; mean R2=0.7360\n",
      "Validation Error: Avg loss: 3.492156 \n",
      "\n",
      "2023-11-08 13:39:11.399045 Epoch 548, Training loss 0.38059738278388977\n",
      "R2 values 0.6480, 0.7531, 0.8223; mean R2=0.7411\n",
      "Validation Error: Avg loss: 3.552116 \n",
      "\n",
      "2023-11-08 13:39:11.924810 Epoch 549, Training loss 0.3279304504394531\n",
      "R2 values 0.5974, 0.7367, 0.8233; mean R2=0.7191\n",
      "Validation Error: Avg loss: 4.138455 \n",
      "\n",
      "2023-11-08 13:39:12.400130 Epoch 550, Training loss 0.38543790578842163\n",
      "R2 values 0.6616, 0.7423, 0.8103; mean R2=0.7381\n",
      "Validation Error: Avg loss: 4.244395 \n",
      "\n",
      "2023-11-08 13:39:12.884406 Epoch 551, Training loss 0.41531193256378174\n",
      "R2 values 0.6820, 0.7487, 0.8356; mean R2=0.7554\n",
      "Validation Error: Avg loss: 3.918157 \n",
      "\n",
      "2023-11-08 13:39:13.396982 Epoch 552, Training loss 0.34587424993515015\n",
      "R2 values 0.6598, 0.7485, 0.8657; mean R2=0.7580\n",
      "Validation Error: Avg loss: 3.515878 \n",
      "\n",
      "2023-11-08 13:39:13.871801 Epoch 553, Training loss 0.3924598693847656\n",
      "R2 values 0.5967, 0.7361, 0.8525; mean R2=0.7284\n",
      "Validation Error: Avg loss: 3.640338 \n",
      "\n",
      "2023-11-08 13:39:14.361594 Epoch 554, Training loss 0.4547941982746124\n",
      "R2 values 0.6457, 0.7441, 0.7860; mean R2=0.7253\n",
      "Validation Error: Avg loss: 4.066866 \n",
      "\n",
      "2023-11-08 13:39:14.849903 Epoch 555, Training loss 0.3973620533943176\n",
      "R2 values 0.6649, 0.7327, 0.7918; mean R2=0.7298\n",
      "Validation Error: Avg loss: 4.487402 \n",
      "\n",
      "2023-11-08 13:39:15.320999 Epoch 556, Training loss 0.5488733053207397\n",
      "R2 values 0.6968, 0.7240, 0.7999; mean R2=0.7403\n",
      "Validation Error: Avg loss: 3.861876 \n",
      "\n",
      "2023-11-08 13:39:15.795904 Epoch 557, Training loss 0.3189133107662201\n",
      "R2 values 0.6622, 0.7303, 0.8112; mean R2=0.7346\n",
      "Validation Error: Avg loss: 3.608640 \n",
      "\n",
      "2023-11-08 13:39:16.284831 Epoch 558, Training loss 0.5669389367103577\n",
      "R2 values 0.6787, 0.7674, 0.8030; mean R2=0.7497\n",
      "Validation Error: Avg loss: 3.333071 \n",
      "\n",
      "2023-11-08 13:39:16.774260 Epoch 559, Training loss 0.3871854245662689\n",
      "R2 values 0.6564, 0.7326, 0.7856; mean R2=0.7249\n",
      "Validation Error: Avg loss: 4.255420 \n",
      "\n",
      "2023-11-08 13:39:17.271515 Epoch 560, Training loss 0.4155004918575287\n",
      "R2 values 0.7062, 0.7441, 0.7968; mean R2=0.7490\n",
      "Validation Error: Avg loss: 4.145602 \n",
      "\n",
      "2023-11-08 13:39:17.747820 Epoch 561, Training loss 0.4875020980834961\n",
      "R2 values 0.6138, 0.7605, 0.8315; mean R2=0.7353\n",
      "Validation Error: Avg loss: 3.663390 \n",
      "\n",
      "2023-11-08 13:39:18.225625 Epoch 562, Training loss 0.3656638264656067\n",
      "R2 values 0.7195, 0.7530, 0.8580; mean R2=0.7769\n",
      "Validation Error: Avg loss: 3.270709 \n",
      "\n",
      "2023-11-08 13:39:18.708096 Epoch 563, Training loss 0.5491217970848083\n",
      "R2 values 0.6691, 0.7540, 0.8542; mean R2=0.7591\n",
      "Validation Error: Avg loss: 3.366366 \n",
      "\n",
      "2023-11-08 13:39:19.189270 Epoch 564, Training loss 0.36367329955101013\n",
      "R2 values 0.7159, 0.7164, 0.8059; mean R2=0.7461\n",
      "Validation Error: Avg loss: 4.166134 \n",
      "\n",
      "2023-11-08 13:39:19.662544 Epoch 565, Training loss 0.4610539674758911\n",
      "R2 values 0.6431, 0.7108, 0.7479; mean R2=0.7006\n",
      "Validation Error: Avg loss: 4.669027 \n",
      "\n",
      "2023-11-08 13:39:20.135432 Epoch 566, Training loss 0.4653984606266022\n",
      "R2 values 0.5779, 0.7227, 0.8409; mean R2=0.7138\n",
      "Validation Error: Avg loss: 3.954219 \n",
      "\n",
      "2023-11-08 13:39:20.618518 Epoch 567, Training loss 0.4223330020904541\n",
      "R2 values 0.6253, 0.7222, 0.8210; mean R2=0.7228\n",
      "Validation Error: Avg loss: 3.929387 \n",
      "\n",
      "2023-11-08 13:39:21.095275 Epoch 568, Training loss 0.38671761751174927\n",
      "R2 values 0.6085, 0.7101, 0.8562; mean R2=0.7250\n",
      "Validation Error: Avg loss: 4.018638 \n",
      "\n",
      "2023-11-08 13:39:21.574654 Epoch 569, Training loss 0.40495169162750244\n",
      "R2 values 0.6185, 0.7209, 0.8245; mean R2=0.7213\n",
      "Validation Error: Avg loss: 3.889232 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:39:22.064404 Epoch 570, Training loss 0.33717218041419983\n",
      "R2 values 0.5000, 0.7344, 0.8344; mean R2=0.6896\n",
      "Validation Error: Avg loss: 4.096163 \n",
      "\n",
      "2023-11-08 13:39:22.743922 Epoch 571, Training loss 0.4061567783355713\n",
      "R2 values 0.6174, 0.7806, 0.7942; mean R2=0.7307\n",
      "Validation Error: Avg loss: 3.622859 \n",
      "\n",
      "2023-11-08 13:39:23.252276 Epoch 572, Training loss 0.37190043926239014\n",
      "R2 values 0.6165, 0.7547, 0.7917; mean R2=0.7210\n",
      "Validation Error: Avg loss: 3.627479 \n",
      "\n",
      "2023-11-08 13:39:23.739367 Epoch 573, Training loss 0.368084192276001\n",
      "R2 values 0.6151, 0.7802, 0.8038; mean R2=0.7330\n",
      "Validation Error: Avg loss: 3.395498 \n",
      "\n",
      "2023-11-08 13:39:24.222685 Epoch 574, Training loss 0.48639583587646484\n",
      "R2 values 0.6905, 0.7726, 0.7987; mean R2=0.7539\n",
      "Validation Error: Avg loss: 3.890978 \n",
      "\n",
      "2023-11-08 13:39:24.698684 Epoch 575, Training loss 0.37920162081718445\n",
      "R2 values 0.6241, 0.7508, 0.8084; mean R2=0.7278\n",
      "Validation Error: Avg loss: 4.235399 \n",
      "\n",
      "2023-11-08 13:39:25.171408 Epoch 576, Training loss 0.5077583193778992\n",
      "R2 values 0.7028, 0.7353, 0.7596; mean R2=0.7326\n",
      "Validation Error: Avg loss: 4.202728 \n",
      "\n",
      "2023-11-08 13:39:25.642691 Epoch 577, Training loss 0.2722434401512146\n",
      "R2 values 0.7444, 0.7649, 0.8212; mean R2=0.7768\n",
      "Validation Error: Avg loss: 3.285849 \n",
      "\n",
      "2023-11-08 13:39:26.123725 Epoch 578, Training loss 0.6474202871322632\n",
      "R2 values 0.5958, 0.7144, 0.7875; mean R2=0.6992\n",
      "Validation Error: Avg loss: 4.328519 \n",
      "\n",
      "2023-11-08 13:39:26.604247 Epoch 579, Training loss 0.3853270411491394\n",
      "R2 values 0.6753, 0.7092, 0.8026; mean R2=0.7290\n",
      "Validation Error: Avg loss: 4.528887 \n",
      "\n",
      "2023-11-08 13:39:27.083878 Epoch 580, Training loss 0.44872549176216125\n",
      "R2 values 0.6892, 0.7314, 0.7960; mean R2=0.7389\n",
      "Validation Error: Avg loss: 4.357797 \n",
      "\n",
      "2023-11-08 13:39:27.610243 Epoch 581, Training loss 0.5659268498420715\n",
      "R2 values 0.7352, 0.7494, 0.8420; mean R2=0.7755\n",
      "Validation Error: Avg loss: 3.394210 \n",
      "\n",
      "2023-11-08 13:39:28.083589 Epoch 582, Training loss 0.42769449949264526\n",
      "R2 values 0.6817, 0.7464, 0.7764; mean R2=0.7348\n",
      "Validation Error: Avg loss: 3.431436 \n",
      "\n",
      "2023-11-08 13:39:28.554456 Epoch 583, Training loss 0.5240575075149536\n",
      "R2 values 0.7240, 0.7623, 0.7787; mean R2=0.7550\n",
      "Validation Error: Avg loss: 3.701517 \n",
      "\n",
      "2023-11-08 13:39:29.279966 Epoch 584, Training loss 0.34107354283332825\n",
      "R2 values 0.6759, 0.7103, 0.7468; mean R2=0.7110\n",
      "Validation Error: Avg loss: 4.684656 \n",
      "\n",
      "2023-11-08 13:39:29.763379 Epoch 585, Training loss 0.48706796765327454\n",
      "R2 values 0.6192, 0.7703, 0.7417; mean R2=0.7104\n",
      "Validation Error: Avg loss: 4.263871 \n",
      "\n",
      "2023-11-08 13:39:30.260971 Epoch 586, Training loss 0.5075767040252686\n",
      "R2 values 0.6963, 0.7727, 0.7926; mean R2=0.7539\n",
      "Validation Error: Avg loss: 3.404490 \n",
      "\n",
      "2023-11-08 13:39:30.740331 Epoch 587, Training loss 0.47562849521636963\n",
      "R2 values 0.6530, 0.7424, 0.8539; mean R2=0.7498\n",
      "Validation Error: Avg loss: 3.531004 \n",
      "\n",
      "2023-11-08 13:39:31.219520 Epoch 588, Training loss 0.5418797135353088\n",
      "R2 values 0.6135, 0.7540, 0.8549; mean R2=0.7408\n",
      "Validation Error: Avg loss: 3.702307 \n",
      "\n",
      "2023-11-08 13:39:31.702285 Epoch 589, Training loss 0.35011744499206543\n",
      "R2 values 0.6730, 0.7605, 0.8155; mean R2=0.7497\n",
      "Validation Error: Avg loss: 4.044934 \n",
      "\n",
      "2023-11-08 13:39:32.196062 Epoch 590, Training loss 0.44136789441108704\n",
      "R2 values 0.6865, 0.7173, 0.8092; mean R2=0.7376\n",
      "Validation Error: Avg loss: 4.554336 \n",
      "\n",
      "2023-11-08 13:39:32.676594 Epoch 591, Training loss 0.635135293006897\n",
      "R2 values 0.6336, 0.7324, 0.8151; mean R2=0.7270\n",
      "Validation Error: Avg loss: 3.980025 \n",
      "\n",
      "2023-11-08 13:39:33.145275 Epoch 592, Training loss 0.3662615716457367\n",
      "R2 values 0.6122, 0.7524, 0.8036; mean R2=0.7227\n",
      "Validation Error: Avg loss: 3.437596 \n",
      "\n",
      "2023-11-08 13:39:33.729290 Epoch 593, Training loss 0.5742966532707214\n",
      "R2 values 0.5671, 0.7657, 0.7735; mean R2=0.7021\n",
      "Validation Error: Avg loss: 3.614434 \n",
      "\n",
      "2023-11-08 13:39:34.202638 Epoch 594, Training loss 0.3774023950099945\n",
      "R2 values 0.6000, 0.7575, 0.8137; mean R2=0.7237\n",
      "Validation Error: Avg loss: 3.890950 \n",
      "\n",
      "2023-11-08 13:39:34.679750 Epoch 595, Training loss 0.46443456411361694\n",
      "R2 values 0.6722, 0.7423, 0.8226; mean R2=0.7457\n",
      "Validation Error: Avg loss: 4.242531 \n",
      "\n",
      "2023-11-08 13:39:35.152806 Epoch 596, Training loss 0.5027300119400024\n",
      "R2 values 0.6833, 0.7709, 0.7832; mean R2=0.7458\n",
      "Validation Error: Avg loss: 3.576306 \n",
      "\n",
      "2023-11-08 13:39:35.620488 Epoch 597, Training loss 0.3019430935382843\n",
      "R2 values 0.6194, 0.7725, 0.8052; mean R2=0.7324\n",
      "Validation Error: Avg loss: 3.388099 \n",
      "\n",
      "2023-11-08 13:39:36.239780 Epoch 598, Training loss 0.4143705368041992\n",
      "R2 values 0.7755, 0.7827, 0.8184; mean R2=0.7922\n",
      "Validation Error: Avg loss: 3.129487 \n",
      "\n",
      "2023-11-08 13:39:36.720091 Epoch 599, Training loss 0.5187284350395203\n",
      "R2 values 0.7127, 0.7273, 0.7466; mean R2=0.7289\n",
      "Validation Error: Avg loss: 4.642397 \n",
      "\n",
      "2023-11-08 13:39:37.223855 Epoch 600, Training loss 0.4763055741786957\n",
      "R2 values 0.5906, 0.7219, 0.8016; mean R2=0.7047\n",
      "Validation Error: Avg loss: 4.364926 \n",
      "\n",
      "2023-11-08 13:39:37.707599 Epoch 601, Training loss 0.3724712133407593\n",
      "R2 values 0.5779, 0.7053, 0.7978; mean R2=0.6937\n",
      "Validation Error: Avg loss: 4.250212 \n",
      "\n",
      "2023-11-08 13:39:38.321069 Epoch 602, Training loss 0.35338664054870605\n",
      "R2 values 0.6934, 0.7220, 0.7886; mean R2=0.7346\n",
      "Validation Error: Avg loss: 4.091164 \n",
      "\n",
      "2023-11-08 13:39:38.810047 Epoch 603, Training loss 0.2901695966720581\n",
      "R2 values 0.5742, 0.7643, 0.8144; mean R2=0.7176\n",
      "Validation Error: Avg loss: 3.335986 \n",
      "\n",
      "2023-11-08 13:39:39.314267 Epoch 604, Training loss 0.41555944085121155\n",
      "R2 values 0.6103, 0.7228, 0.8152; mean R2=0.7161\n",
      "Validation Error: Avg loss: 3.868983 \n",
      "\n",
      "2023-11-08 13:39:39.865123 Epoch 605, Training loss 0.4757547378540039\n",
      "R2 values 0.5681, 0.7340, 0.7978; mean R2=0.6999\n",
      "Validation Error: Avg loss: 3.787732 \n",
      "\n",
      "2023-11-08 13:39:40.339009 Epoch 606, Training loss 0.3203881084918976\n",
      "R2 values 0.6099, 0.7330, 0.7759; mean R2=0.7063\n",
      "Validation Error: Avg loss: 4.133009 \n",
      "\n",
      "2023-11-08 13:39:40.819820 Epoch 607, Training loss 0.3224312365055084\n",
      "R2 values 0.5715, 0.7463, 0.8137; mean R2=0.7105\n",
      "Validation Error: Avg loss: 3.663910 \n",
      "\n",
      "2023-11-08 13:39:41.304049 Epoch 608, Training loss 0.348402202129364\n",
      "R2 values 0.5999, 0.7498, 0.8147; mean R2=0.7214\n",
      "Validation Error: Avg loss: 3.596874 \n",
      "\n",
      "2023-11-08 13:39:41.785113 Epoch 609, Training loss 0.38191908597946167\n",
      "R2 values 0.6314, 0.7246, 0.8012; mean R2=0.7190\n",
      "Validation Error: Avg loss: 3.854326 \n",
      "\n",
      "2023-11-08 13:39:42.263979 Epoch 610, Training loss 0.4056256115436554\n",
      "R2 values 0.5046, 0.7674, 0.8266; mean R2=0.6996\n",
      "Validation Error: Avg loss: 3.746769 \n",
      "\n",
      "2023-11-08 13:39:42.748167 Epoch 611, Training loss 0.4604414105415344\n",
      "R2 values 0.5740, 0.7129, 0.8055; mean R2=0.6974\n",
      "Validation Error: Avg loss: 4.264133 \n",
      "\n",
      "2023-11-08 13:39:43.229604 Epoch 612, Training loss 0.40722620487213135\n",
      "R2 values 0.5666, 0.7276, 0.8142; mean R2=0.7028\n",
      "Validation Error: Avg loss: 4.409302 \n",
      "\n",
      "2023-11-08 13:39:43.723580 Epoch 613, Training loss 0.34610050916671753\n",
      "R2 values 0.5901, 0.6741, 0.8043; mean R2=0.6895\n",
      "Validation Error: Avg loss: 4.709106 \n",
      "\n",
      "2023-11-08 13:39:44.193589 Epoch 614, Training loss 0.408758282661438\n",
      "R2 values 0.5401, 0.7299, 0.8130; mean R2=0.6943\n",
      "Validation Error: Avg loss: 3.815721 \n",
      "\n",
      "2023-11-08 13:39:44.666633 Epoch 615, Training loss 0.4166271388530731\n",
      "R2 values 0.5159, 0.7652, 0.8147; mean R2=0.6986\n",
      "Validation Error: Avg loss: 3.702084 \n",
      "\n",
      "2023-11-08 13:39:45.144894 Epoch 616, Training loss 0.29768839478492737\n",
      "R2 values 0.5366, 0.7610, 0.7564; mean R2=0.6847\n",
      "Validation Error: Avg loss: 4.092586 \n",
      "\n",
      "2023-11-08 13:39:45.650221 Epoch 617, Training loss 0.3053872287273407\n",
      "R2 values 0.6212, 0.7102, 0.7839; mean R2=0.7051\n",
      "Validation Error: Avg loss: 4.611916 \n",
      "\n",
      "2023-11-08 13:39:46.183704 Epoch 618, Training loss 0.30408021807670593\n",
      "R2 values 0.6398, 0.7100, 0.7973; mean R2=0.7157\n",
      "Validation Error: Avg loss: 4.296185 \n",
      "\n",
      "2023-11-08 13:39:46.662129 Epoch 619, Training loss 0.29184770584106445\n",
      "R2 values 0.6195, 0.7613, 0.8327; mean R2=0.7378\n",
      "Validation Error: Avg loss: 3.394557 \n",
      "\n",
      "2023-11-08 13:39:47.150262 Epoch 620, Training loss 0.40266603231430054\n",
      "R2 values 0.6169, 0.7384, 0.7982; mean R2=0.7178\n",
      "Validation Error: Avg loss: 3.833965 \n",
      "\n",
      "2023-11-08 13:39:47.633227 Epoch 621, Training loss 0.3291436433792114\n",
      "R2 values 0.5949, 0.7416, 0.8268; mean R2=0.7211\n",
      "Validation Error: Avg loss: 4.016284 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:39:48.111541 Epoch 622, Training loss 0.3022089898586273\n",
      "R2 values 0.6237, 0.7280, 0.7757; mean R2=0.7091\n",
      "Validation Error: Avg loss: 4.485615 \n",
      "\n",
      "2023-11-08 13:39:48.595092 Epoch 623, Training loss 0.3170511722564697\n",
      "R2 values 0.5181, 0.7806, 0.7813; mean R2=0.6933\n",
      "Validation Error: Avg loss: 3.747749 \n",
      "\n",
      "2023-11-08 13:39:49.101828 Epoch 624, Training loss 0.3520831763744354\n",
      "R2 values 0.6672, 0.7350, 0.8407; mean R2=0.7476\n",
      "Validation Error: Avg loss: 3.781775 \n",
      "\n",
      "2023-11-08 13:39:49.576118 Epoch 625, Training loss 0.3670210838317871\n",
      "R2 values 0.6122, 0.7409, 0.8531; mean R2=0.7354\n",
      "Validation Error: Avg loss: 3.545597 \n",
      "\n",
      "2023-11-08 13:39:50.049557 Epoch 626, Training loss 0.341339111328125\n",
      "R2 values 0.6541, 0.7137, 0.8446; mean R2=0.7375\n",
      "Validation Error: Avg loss: 3.912567 \n",
      "\n",
      "2023-11-08 13:39:50.520721 Epoch 627, Training loss 0.31237661838531494\n",
      "R2 values 0.5899, 0.7180, 0.8207; mean R2=0.7095\n",
      "Validation Error: Avg loss: 4.105742 \n",
      "\n",
      "2023-11-08 13:39:50.990197 Epoch 628, Training loss 0.26127663254737854\n",
      "R2 values 0.5414, 0.7443, 0.8237; mean R2=0.7031\n",
      "Validation Error: Avg loss: 4.059777 \n",
      "\n",
      "2023-11-08 13:39:51.468799 Epoch 629, Training loss 0.38567981123924255\n",
      "R2 values 0.5873, 0.7523, 0.8215; mean R2=0.7204\n",
      "Validation Error: Avg loss: 3.607336 \n",
      "\n",
      "2023-11-08 13:39:51.958526 Epoch 630, Training loss 0.3085455000400543\n",
      "R2 values 0.6161, 0.7520, 0.8284; mean R2=0.7322\n",
      "Validation Error: Avg loss: 3.346698 \n",
      "\n",
      "2023-11-08 13:39:52.424980 Epoch 631, Training loss 0.4407331645488739\n",
      "R2 values 0.6829, 0.7409, 0.7613; mean R2=0.7284\n",
      "Validation Error: Avg loss: 3.915423 \n",
      "\n",
      "2023-11-08 13:39:52.896234 Epoch 632, Training loss 0.335721492767334\n",
      "R2 values 0.6676, 0.7658, 0.7911; mean R2=0.7415\n",
      "Validation Error: Avg loss: 3.785519 \n",
      "\n",
      "2023-11-08 13:39:53.375462 Epoch 633, Training loss 0.39910218119621277\n",
      "R2 values 0.6628, 0.7591, 0.7952; mean R2=0.7390\n",
      "Validation Error: Avg loss: 3.803633 \n",
      "\n",
      "2023-11-08 13:39:53.868366 Epoch 634, Training loss 0.33192571997642517\n",
      "R2 values 0.7043, 0.7422, 0.7783; mean R2=0.7416\n",
      "Validation Error: Avg loss: 4.042492 \n",
      "\n",
      "2023-11-08 13:39:54.345924 Epoch 635, Training loss 0.3089541792869568\n",
      "R2 values 0.7045, 0.7426, 0.7795; mean R2=0.7422\n",
      "Validation Error: Avg loss: 4.081063 \n",
      "\n",
      "2023-11-08 13:39:54.948446 Epoch 636, Training loss 0.39047861099243164\n",
      "R2 values 0.5467, 0.7210, 0.8353; mean R2=0.7010\n",
      "Validation Error: Avg loss: 4.254741 \n",
      "\n",
      "2023-11-08 13:39:55.593315 Epoch 637, Training loss 0.34472766518592834\n",
      "R2 values 0.6372, 0.6897, 0.7996; mean R2=0.7089\n",
      "Validation Error: Avg loss: 4.828978 \n",
      "\n",
      "2023-11-08 13:39:56.081283 Epoch 638, Training loss 0.45135122537612915\n",
      "R2 values 0.6138, 0.7175, 0.8353; mean R2=0.7222\n",
      "Validation Error: Avg loss: 4.144979 \n",
      "\n",
      "2023-11-08 13:39:56.549449 Epoch 639, Training loss 0.381376177072525\n",
      "R2 values 0.6755, 0.6882, 0.8042; mean R2=0.7226\n",
      "Validation Error: Avg loss: 4.189286 \n",
      "\n",
      "2023-11-08 13:39:57.017636 Epoch 640, Training loss 0.3594767451286316\n",
      "R2 values 0.6440, 0.7628, 0.7940; mean R2=0.7336\n",
      "Validation Error: Avg loss: 3.617466 \n",
      "\n",
      "2023-11-08 13:39:57.490947 Epoch 641, Training loss 0.48173174262046814\n",
      "R2 values 0.5806, 0.7134, 0.7770; mean R2=0.6903\n",
      "Validation Error: Avg loss: 4.371874 \n",
      "\n",
      "2023-11-08 13:39:57.964813 Epoch 642, Training loss 0.29466956853866577\n",
      "R2 values 0.5466, 0.7284, 0.7318; mean R2=0.6689\n",
      "Validation Error: Avg loss: 4.909924 \n",
      "\n",
      "2023-11-08 13:39:58.439334 Epoch 643, Training loss 0.5897831916809082\n",
      "R2 values 0.6742, 0.7656, 0.7482; mean R2=0.7293\n",
      "Validation Error: Avg loss: 4.054895 \n",
      "\n",
      "2023-11-08 13:39:58.978364 Epoch 644, Training loss 0.37686094641685486\n",
      "R2 values 0.6132, 0.7347, 0.8441; mean R2=0.7307\n",
      "Validation Error: Avg loss: 3.698583 \n",
      "\n",
      "2023-11-08 13:39:59.455707 Epoch 645, Training loss 0.2920920252799988\n",
      "R2 values 0.6811, 0.7312, 0.8554; mean R2=0.7559\n",
      "Validation Error: Avg loss: 3.564082 \n",
      "\n",
      "2023-11-08 13:39:59.932675 Epoch 646, Training loss 0.47892600297927856\n",
      "R2 values 0.6272, 0.7364, 0.7929; mean R2=0.7188\n",
      "Validation Error: Avg loss: 3.913812 \n",
      "\n",
      "2023-11-08 13:40:00.617671 Epoch 647, Training loss 0.2548731565475464\n",
      "R2 values 0.5782, 0.7430, 0.8256; mean R2=0.7156\n",
      "Validation Error: Avg loss: 4.235024 \n",
      "\n",
      "2023-11-08 13:40:01.096076 Epoch 648, Training loss 0.41271108388900757\n",
      "R2 values 0.6449, 0.7507, 0.8021; mean R2=0.7326\n",
      "Validation Error: Avg loss: 4.171760 \n",
      "\n",
      "2023-11-08 13:40:01.759188 Epoch 649, Training loss 0.3715679347515106\n",
      "R2 values 0.6526, 0.7902, 0.7984; mean R2=0.7470\n",
      "Validation Error: Avg loss: 3.566137 \n",
      "\n",
      "2023-11-08 13:40:02.862843 Epoch 650, Training loss 0.2948871850967407\n",
      "R2 values 0.7251, 0.7847, 0.8306; mean R2=0.7801\n",
      "Validation Error: Avg loss: 3.090609 \n",
      "\n",
      "2023-11-08 13:40:03.322081 Epoch 651, Training loss 0.48211970925331116\n",
      "R2 values 0.6032, 0.7947, 0.8469; mean R2=0.7483\n",
      "Validation Error: Avg loss: 3.088795 \n",
      "\n",
      "2023-11-08 13:40:03.805919 Epoch 652, Training loss 0.4041503667831421\n",
      "R2 values 0.6049, 0.7391, 0.8226; mean R2=0.7222\n",
      "Validation Error: Avg loss: 4.263404 \n",
      "\n",
      "2023-11-08 13:40:04.257936 Epoch 653, Training loss 0.30310893058776855\n",
      "R2 values 0.6159, 0.7162, 0.8025; mean R2=0.7115\n",
      "Validation Error: Avg loss: 4.297206 \n",
      "\n",
      "2023-11-08 13:40:04.724808 Epoch 654, Training loss 0.35048046708106995\n",
      "R2 values 0.5638, 0.7403, 0.8067; mean R2=0.7036\n",
      "Validation Error: Avg loss: 4.059492 \n",
      "\n",
      "2023-11-08 13:40:05.204269 Epoch 655, Training loss 0.3311900496482849\n",
      "R2 values 0.6339, 0.7195, 0.8086; mean R2=0.7207\n",
      "Validation Error: Avg loss: 3.923641 \n",
      "\n",
      "2023-11-08 13:40:05.669159 Epoch 656, Training loss 0.33398422598838806\n",
      "R2 values 0.6714, 0.7133, 0.8312; mean R2=0.7387\n",
      "Validation Error: Avg loss: 4.020520 \n",
      "\n",
      "2023-11-08 13:40:06.134504 Epoch 657, Training loss 0.33384954929351807\n",
      "R2 values 0.7192, 0.7571, 0.8239; mean R2=0.7667\n",
      "Validation Error: Avg loss: 3.446822 \n",
      "\n",
      "2023-11-08 13:40:06.595803 Epoch 658, Training loss 0.3304717540740967\n",
      "R2 values 0.6001, 0.7370, 0.8255; mean R2=0.7209\n",
      "Validation Error: Avg loss: 3.863395 \n",
      "\n",
      "2023-11-08 13:40:07.058559 Epoch 659, Training loss 0.43566951155662537\n",
      "R2 values 0.5790, 0.6896, 0.8085; mean R2=0.6924\n",
      "Validation Error: Avg loss: 4.961135 \n",
      "\n",
      "2023-11-08 13:40:07.534426 Epoch 660, Training loss 0.2976594567298889\n",
      "R2 values 0.5792, 0.7006, 0.8014; mean R2=0.6937\n",
      "Validation Error: Avg loss: 4.324506 \n",
      "\n",
      "2023-11-08 13:40:07.994923 Epoch 661, Training loss 0.2849302887916565\n",
      "R2 values 0.6487, 0.7435, 0.8208; mean R2=0.7377\n",
      "Validation Error: Avg loss: 3.827168 \n",
      "\n",
      "2023-11-08 13:40:08.456314 Epoch 662, Training loss 0.36922717094421387\n",
      "R2 values 0.6159, 0.7411, 0.8055; mean R2=0.7208\n",
      "Validation Error: Avg loss: 3.844966 \n",
      "\n",
      "2023-11-08 13:40:08.982554 Epoch 663, Training loss 0.28132715821266174\n",
      "R2 values 0.6794, 0.7142, 0.7529; mean R2=0.7155\n",
      "Validation Error: Avg loss: 4.456205 \n",
      "\n",
      "2023-11-08 13:40:09.443304 Epoch 664, Training loss 0.3538180887699127\n",
      "R2 values 0.6539, 0.7145, 0.7905; mean R2=0.7196\n",
      "Validation Error: Avg loss: 4.183834 \n",
      "\n",
      "2023-11-08 13:40:09.910294 Epoch 665, Training loss 0.2566791772842407\n",
      "R2 values 0.6296, 0.7614, 0.8320; mean R2=0.7410\n",
      "Validation Error: Avg loss: 3.476148 \n",
      "\n",
      "2023-11-08 13:40:10.368658 Epoch 666, Training loss 0.37712737917900085\n",
      "R2 values 0.5831, 0.7070, 0.8325; mean R2=0.7075\n",
      "Validation Error: Avg loss: 4.090874 \n",
      "\n",
      "2023-11-08 13:40:10.837010 Epoch 667, Training loss 0.35233446955680847\n",
      "R2 values 0.6830, 0.7291, 0.7628; mean R2=0.7250\n",
      "Validation Error: Avg loss: 3.954425 \n",
      "\n",
      "2023-11-08 13:40:11.388950 Epoch 668, Training loss 0.3283958435058594\n",
      "R2 values 0.6474, 0.7376, 0.8400; mean R2=0.7417\n",
      "Validation Error: Avg loss: 3.918400 \n",
      "\n",
      "2023-11-08 13:40:11.861661 Epoch 669, Training loss 0.35631462931632996\n",
      "R2 values 0.6071, 0.7400, 0.8313; mean R2=0.7261\n",
      "Validation Error: Avg loss: 3.823766 \n",
      "\n",
      "2023-11-08 13:40:12.333732 Epoch 670, Training loss 0.2889051139354706\n",
      "R2 values 0.6573, 0.7167, 0.8435; mean R2=0.7392\n",
      "Validation Error: Avg loss: 3.855415 \n",
      "\n",
      "2023-11-08 13:40:12.800815 Epoch 671, Training loss 0.3069084882736206\n",
      "R2 values 0.6725, 0.7361, 0.8468; mean R2=0.7518\n",
      "Validation Error: Avg loss: 3.635243 \n",
      "\n",
      "2023-11-08 13:40:13.277574 Epoch 672, Training loss 0.372500479221344\n",
      "R2 values 0.5838, 0.7283, 0.7998; mean R2=0.7040\n",
      "Validation Error: Avg loss: 4.245882 \n",
      "\n",
      "2023-11-08 13:40:13.746731 Epoch 673, Training loss 0.36007577180862427\n",
      "R2 values 0.5403, 0.7442, 0.7844; mean R2=0.6897\n",
      "Validation Error: Avg loss: 4.325521 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:40:14.231638 Epoch 674, Training loss 0.25558605790138245\n",
      "R2 values 0.6373, 0.7703, 0.7755; mean R2=0.7277\n",
      "Validation Error: Avg loss: 4.077096 \n",
      "\n",
      "2023-11-08 13:40:14.693628 Epoch 675, Training loss 0.3832356631755829\n",
      "R2 values 0.6338, 0.7976, 0.8356; mean R2=0.7556\n",
      "Validation Error: Avg loss: 3.074178 \n",
      "\n",
      "2023-11-08 13:40:15.152478 Epoch 676, Training loss 0.28640249371528625\n",
      "R2 values 0.5905, 0.7869, 0.8000; mean R2=0.7258\n",
      "Validation Error: Avg loss: 3.312356 \n",
      "\n",
      "2023-11-08 13:40:15.618549 Epoch 677, Training loss 0.30015531182289124\n",
      "R2 values 0.5802, 0.7553, 0.8036; mean R2=0.7130\n",
      "Validation Error: Avg loss: 3.770970 \n",
      "\n",
      "2023-11-08 13:40:16.082612 Epoch 678, Training loss 0.294183611869812\n",
      "R2 values 0.6011, 0.7521, 0.7925; mean R2=0.7152\n",
      "Validation Error: Avg loss: 3.749713 \n",
      "\n",
      "2023-11-08 13:40:16.548485 Epoch 679, Training loss 0.2657538056373596\n",
      "R2 values 0.6014, 0.7216, 0.8172; mean R2=0.7134\n",
      "Validation Error: Avg loss: 4.161623 \n",
      "\n",
      "2023-11-08 13:40:17.010496 Epoch 680, Training loss 0.3568486273288727\n",
      "R2 values 0.6672, 0.7094, 0.7577; mean R2=0.7114\n",
      "Validation Error: Avg loss: 4.628196 \n",
      "\n",
      "2023-11-08 13:40:17.486121 Epoch 681, Training loss 0.2722635567188263\n",
      "R2 values 0.6417, 0.7115, 0.7951; mean R2=0.7161\n",
      "Validation Error: Avg loss: 4.149621 \n",
      "\n",
      "2023-11-08 13:40:17.950238 Epoch 682, Training loss 0.2642101049423218\n",
      "R2 values 0.6393, 0.7239, 0.8183; mean R2=0.7272\n",
      "Validation Error: Avg loss: 3.914090 \n",
      "\n",
      "2023-11-08 13:40:18.466671 Epoch 683, Training loss 0.35229364037513733\n",
      "R2 values 0.6291, 0.7255, 0.7873; mean R2=0.7139\n",
      "Validation Error: Avg loss: 3.954836 \n",
      "\n",
      "2023-11-08 13:40:18.932151 Epoch 684, Training loss 0.33714231848716736\n",
      "R2 values 0.5923, 0.7187, 0.7817; mean R2=0.6976\n",
      "Validation Error: Avg loss: 4.193597 \n",
      "\n",
      "2023-11-08 13:40:19.634025 Epoch 685, Training loss 0.22290629148483276\n",
      "R2 values 0.5676, 0.7475, 0.7847; mean R2=0.6999\n",
      "Validation Error: Avg loss: 4.014637 \n",
      "\n",
      "2023-11-08 13:40:20.110535 Epoch 686, Training loss 0.28384092450141907\n",
      "R2 values 0.5760, 0.7191, 0.7701; mean R2=0.6884\n",
      "Validation Error: Avg loss: 4.259701 \n",
      "\n",
      "2023-11-08 13:40:20.573514 Epoch 687, Training loss 0.25166258215904236\n",
      "R2 values 0.6197, 0.7396, 0.8157; mean R2=0.7250\n",
      "Validation Error: Avg loss: 3.884152 \n",
      "\n",
      "2023-11-08 13:40:21.034080 Epoch 688, Training loss 0.35488268733024597\n",
      "R2 values 0.5764, 0.7191, 0.8254; mean R2=0.7070\n",
      "Validation Error: Avg loss: 3.945566 \n",
      "\n",
      "2023-11-08 13:40:21.495513 Epoch 689, Training loss 0.3358476459980011\n",
      "R2 values 0.5252, 0.7200, 0.8188; mean R2=0.6880\n",
      "Validation Error: Avg loss: 4.051127 \n",
      "\n",
      "2023-11-08 13:40:22.008818 Epoch 690, Training loss 0.28843313455581665\n",
      "R2 values 0.6078, 0.7803, 0.8107; mean R2=0.7330\n",
      "Validation Error: Avg loss: 3.490898 \n",
      "\n",
      "2023-11-08 13:40:22.480151 Epoch 691, Training loss 0.35357463359832764\n",
      "R2 values 0.6783, 0.7457, 0.7629; mean R2=0.7290\n",
      "Validation Error: Avg loss: 3.906068 \n",
      "\n",
      "2023-11-08 13:40:22.948777 Epoch 692, Training loss 0.32285118103027344\n",
      "R2 values 0.6551, 0.7129, 0.8125; mean R2=0.7268\n",
      "Validation Error: Avg loss: 4.071768 \n",
      "\n",
      "2023-11-08 13:40:23.417607 Epoch 693, Training loss 0.2748836874961853\n",
      "R2 values 0.6095, 0.7008, 0.8382; mean R2=0.7162\n",
      "Validation Error: Avg loss: 4.208675 \n",
      "\n",
      "2023-11-08 13:40:23.897338 Epoch 694, Training loss 0.29090645909309387\n",
      "R2 values 0.5659, 0.7707, 0.8237; mean R2=0.7201\n",
      "Validation Error: Avg loss: 3.484142 \n",
      "\n",
      "2023-11-08 13:40:24.361516 Epoch 695, Training loss 0.30199477076530457\n",
      "R2 values 0.5725, 0.7197, 0.8151; mean R2=0.7024\n",
      "Validation Error: Avg loss: 4.235496 \n",
      "\n",
      "2023-11-08 13:40:24.885626 Epoch 696, Training loss 0.2987005114555359\n",
      "R2 values 0.5863, 0.7341, 0.8440; mean R2=0.7215\n",
      "Validation Error: Avg loss: 4.032857 \n",
      "\n",
      "2023-11-08 13:40:25.347025 Epoch 697, Training loss 0.2703581750392914\n",
      "R2 values 0.7299, 0.7546, 0.7871; mean R2=0.7572\n",
      "Validation Error: Avg loss: 3.709018 \n",
      "\n",
      "2023-11-08 13:40:25.809549 Epoch 698, Training loss 0.2342946082353592\n",
      "R2 values 0.5887, 0.7566, 0.7903; mean R2=0.7119\n",
      "Validation Error: Avg loss: 3.674592 \n",
      "\n",
      "2023-11-08 13:40:26.272180 Epoch 699, Training loss 0.30834147334098816\n",
      "R2 values 0.4262, 0.7693, 0.7796; mean R2=0.6584\n",
      "Validation Error: Avg loss: 3.959889 \n",
      "\n",
      "2023-11-08 13:40:26.740357 Epoch 700, Training loss 0.2491977959871292\n",
      "R2 values 0.6870, 0.7766, 0.7497; mean R2=0.7378\n",
      "Validation Error: Avg loss: 3.774151 \n",
      "\n",
      "2023-11-08 13:40:27.197050 Epoch 701, Training loss 0.2798885405063629\n",
      "R2 values 0.5667, 0.7313, 0.7865; mean R2=0.6948\n",
      "Validation Error: Avg loss: 4.257906 \n",
      "\n",
      "2023-11-08 13:40:27.671703 Epoch 702, Training loss 0.3022433817386627\n",
      "R2 values 0.6328, 0.7173, 0.7697; mean R2=0.7066\n",
      "Validation Error: Avg loss: 4.223673 \n",
      "\n",
      "2023-11-08 13:40:28.226807 Epoch 703, Training loss 0.2860621213912964\n",
      "R2 values 0.5622, 0.7487, 0.8212; mean R2=0.7107\n",
      "Validation Error: Avg loss: 3.702031 \n",
      "\n",
      "2023-11-08 13:40:28.710425 Epoch 704, Training loss 0.2539611756801605\n",
      "R2 values 0.5163, 0.7067, 0.8030; mean R2=0.6753\n",
      "Validation Error: Avg loss: 4.337030 \n",
      "\n",
      "2023-11-08 13:40:29.190449 Epoch 705, Training loss 0.25213387608528137\n",
      "R2 values 0.6375, 0.6981, 0.7833; mean R2=0.7063\n",
      "Validation Error: Avg loss: 4.760123 \n",
      "\n",
      "2023-11-08 13:40:29.663065 Epoch 706, Training loss 0.38798847794532776\n",
      "R2 values 0.6601, 0.7508, 0.7440; mean R2=0.7183\n",
      "Validation Error: Avg loss: 4.177418 \n",
      "\n",
      "2023-11-08 13:40:30.219235 Epoch 707, Training loss 0.3013087809085846\n",
      "R2 values 0.6550, 0.7884, 0.7826; mean R2=0.7420\n",
      "Validation Error: Avg loss: 3.301304 \n",
      "\n",
      "2023-11-08 13:40:30.687872 Epoch 708, Training loss 0.2764035165309906\n",
      "R2 values 0.5656, 0.7437, 0.8300; mean R2=0.7131\n",
      "Validation Error: Avg loss: 3.843596 \n",
      "\n",
      "2023-11-08 13:40:31.191665 Epoch 709, Training loss 0.250606894493103\n",
      "R2 values 0.6461, 0.7533, 0.7648; mean R2=0.7214\n",
      "Validation Error: Avg loss: 3.926037 \n",
      "\n",
      "2023-11-08 13:40:31.650191 Epoch 710, Training loss 0.2814807891845703\n",
      "R2 values 0.6802, 0.7879, 0.8372; mean R2=0.7684\n",
      "Validation Error: Avg loss: 3.259338 \n",
      "\n",
      "2023-11-08 13:40:32.126777 Epoch 711, Training loss 0.2680817246437073\n",
      "R2 values 0.6496, 0.7442, 0.8417; mean R2=0.7451\n",
      "Validation Error: Avg loss: 3.681709 \n",
      "\n",
      "2023-11-08 13:40:32.588476 Epoch 712, Training loss 0.28613054752349854\n",
      "R2 values 0.5474, 0.6950, 0.8100; mean R2=0.6841\n",
      "Validation Error: Avg loss: 4.243710 \n",
      "\n",
      "2023-11-08 13:40:33.131400 Epoch 713, Training loss 0.31462475657463074\n",
      "R2 values 0.6205, 0.7341, 0.8170; mean R2=0.7239\n",
      "Validation Error: Avg loss: 3.753799 \n",
      "\n",
      "2023-11-08 13:40:33.589062 Epoch 714, Training loss 0.21532531082630157\n",
      "R2 values 0.6426, 0.7442, 0.8307; mean R2=0.7392\n",
      "Validation Error: Avg loss: 3.754403 \n",
      "\n",
      "2023-11-08 13:40:34.063858 Epoch 715, Training loss 0.262746125459671\n",
      "R2 values 0.6052, 0.6987, 0.8012; mean R2=0.7017\n",
      "Validation Error: Avg loss: 4.639045 \n",
      "\n",
      "2023-11-08 13:40:34.524733 Epoch 716, Training loss 0.27681073546409607\n",
      "R2 values 0.7342, 0.7337, 0.7639; mean R2=0.7439\n",
      "Validation Error: Avg loss: 4.143493 \n",
      "\n",
      "2023-11-08 13:40:35.022421 Epoch 717, Training loss 0.31261295080184937\n",
      "R2 values 0.6146, 0.7591, 0.7945; mean R2=0.7228\n",
      "Validation Error: Avg loss: 3.889476 \n",
      "\n",
      "2023-11-08 13:40:35.489533 Epoch 718, Training loss 0.2358955591917038\n",
      "R2 values 0.5741, 0.7282, 0.7759; mean R2=0.6927\n",
      "Validation Error: Avg loss: 4.377672 \n",
      "\n",
      "2023-11-08 13:40:35.968117 Epoch 719, Training loss 0.3954032063484192\n",
      "R2 values 0.7300, 0.7442, 0.7789; mean R2=0.7510\n",
      "Validation Error: Avg loss: 3.792611 \n",
      "\n",
      "2023-11-08 13:40:36.431673 Epoch 720, Training loss 0.2992156147956848\n",
      "R2 values 0.6079, 0.7928, 0.8157; mean R2=0.7388\n",
      "Validation Error: Avg loss: 3.299136 \n",
      "\n",
      "2023-11-08 13:40:36.893123 Epoch 721, Training loss 0.22584792971611023\n",
      "R2 values 0.6435, 0.7496, 0.7911; mean R2=0.7281\n",
      "Validation Error: Avg loss: 3.723970 \n",
      "\n",
      "2023-11-08 13:40:37.355647 Epoch 722, Training loss 0.28721192479133606\n",
      "R2 values 0.5533, 0.7199, 0.7686; mean R2=0.6806\n",
      "Validation Error: Avg loss: 4.425362 \n",
      "\n",
      "2023-11-08 13:40:37.820701 Epoch 723, Training loss 0.2630791664123535\n",
      "R2 values 0.5447, 0.7524, 0.7274; mean R2=0.6748\n",
      "Validation Error: Avg loss: 4.148911 \n",
      "\n",
      "2023-11-08 13:40:38.276358 Epoch 724, Training loss 0.31223565340042114\n",
      "R2 values 0.5173, 0.7199, 0.7928; mean R2=0.6767\n",
      "Validation Error: Avg loss: 4.442641 \n",
      "\n",
      "2023-11-08 13:40:38.734748 Epoch 725, Training loss 0.24962922930717468\n",
      "R2 values 0.5837, 0.7237, 0.7704; mean R2=0.6926\n",
      "Validation Error: Avg loss: 4.641510 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:40:39.206620 Epoch 726, Training loss 0.3052087724208832\n",
      "R2 values 0.6115, 0.7255, 0.7809; mean R2=0.7060\n",
      "Validation Error: Avg loss: 4.570869 \n",
      "\n",
      "2023-11-08 13:40:39.669096 Epoch 727, Training loss 0.3001365661621094\n",
      "R2 values 0.6229, 0.7409, 0.8084; mean R2=0.7241\n",
      "Validation Error: Avg loss: 4.303073 \n",
      "\n",
      "2023-11-08 13:40:40.140901 Epoch 728, Training loss 0.25238871574401855\n",
      "R2 values 0.6948, 0.7197, 0.8249; mean R2=0.7465\n",
      "Validation Error: Avg loss: 4.266395 \n",
      "\n",
      "2023-11-08 13:40:40.600041 Epoch 729, Training loss 0.26805219054222107\n",
      "R2 values 0.6982, 0.7738, 0.8270; mean R2=0.7663\n",
      "Validation Error: Avg loss: 3.465494 \n",
      "\n",
      "2023-11-08 13:40:41.058270 Epoch 730, Training loss 0.2969064712524414\n",
      "R2 values 0.5371, 0.7810, 0.7921; mean R2=0.7034\n",
      "Validation Error: Avg loss: 3.589346 \n",
      "\n",
      "2023-11-08 13:40:41.517574 Epoch 731, Training loss 0.3586103618144989\n",
      "R2 values 0.6451, 0.7408, 0.7679; mean R2=0.7179\n",
      "Validation Error: Avg loss: 4.182682 \n",
      "\n",
      "2023-11-08 13:40:41.976466 Epoch 732, Training loss 0.23683218657970428\n",
      "R2 values 0.6717, 0.7507, 0.7841; mean R2=0.7355\n",
      "Validation Error: Avg loss: 3.848495 \n",
      "\n",
      "2023-11-08 13:40:42.438544 Epoch 733, Training loss 0.2408411204814911\n",
      "R2 values 0.6607, 0.7385, 0.7883; mean R2=0.7292\n",
      "Validation Error: Avg loss: 3.780948 \n",
      "\n",
      "2023-11-08 13:40:42.899215 Epoch 734, Training loss 0.23484376072883606\n",
      "R2 values 0.6030, 0.7602, 0.8013; mean R2=0.7215\n",
      "Validation Error: Avg loss: 3.684825 \n",
      "\n",
      "2023-11-08 13:40:43.353484 Epoch 735, Training loss 0.26387590169906616\n",
      "R2 values 0.6426, 0.7524, 0.8194; mean R2=0.7381\n",
      "Validation Error: Avg loss: 3.652972 \n",
      "\n",
      "2023-11-08 13:40:43.814422 Epoch 736, Training loss 0.22738216817378998\n",
      "R2 values 0.6351, 0.7270, 0.8378; mean R2=0.7333\n",
      "Validation Error: Avg loss: 4.033753 \n",
      "\n",
      "2023-11-08 13:40:44.291111 Epoch 737, Training loss 0.2105967104434967\n",
      "R2 values 0.6964, 0.7498, 0.7588; mean R2=0.7350\n",
      "Validation Error: Avg loss: 3.888364 \n",
      "\n",
      "2023-11-08 13:40:44.750976 Epoch 738, Training loss 0.21726647019386292\n",
      "R2 values 0.6964, 0.7514, 0.7996; mean R2=0.7491\n",
      "Validation Error: Avg loss: 3.876378 \n",
      "\n",
      "2023-11-08 13:40:45.213858 Epoch 739, Training loss 0.3114926218986511\n",
      "R2 values 0.6666, 0.7811, 0.8025; mean R2=0.7500\n",
      "Validation Error: Avg loss: 3.553169 \n",
      "\n",
      "2023-11-08 13:40:45.740341 Epoch 740, Training loss 0.25492897629737854\n",
      "R2 values 0.6703, 0.7834, 0.8007; mean R2=0.7515\n",
      "Validation Error: Avg loss: 3.585291 \n",
      "\n",
      "2023-11-08 13:40:46.206969 Epoch 741, Training loss 0.33294910192489624\n",
      "R2 values 0.6022, 0.7726, 0.8322; mean R2=0.7357\n",
      "Validation Error: Avg loss: 3.660828 \n",
      "\n",
      "2023-11-08 13:40:46.674370 Epoch 742, Training loss 0.24684453010559082\n",
      "R2 values 0.6355, 0.7845, 0.8132; mean R2=0.7444\n",
      "Validation Error: Avg loss: 3.258507 \n",
      "\n",
      "2023-11-08 13:40:47.135962 Epoch 743, Training loss 0.30075573921203613\n",
      "R2 values 0.6206, 0.7510, 0.8079; mean R2=0.7265\n",
      "Validation Error: Avg loss: 3.634857 \n",
      "\n",
      "2023-11-08 13:40:47.599435 Epoch 744, Training loss 0.28482890129089355\n",
      "R2 values 0.6633, 0.7386, 0.7865; mean R2=0.7295\n",
      "Validation Error: Avg loss: 4.062396 \n",
      "\n",
      "2023-11-08 13:40:48.065030 Epoch 745, Training loss 0.22379857301712036\n",
      "R2 values 0.6435, 0.7138, 0.7859; mean R2=0.7144\n",
      "Validation Error: Avg loss: 4.515517 \n",
      "\n",
      "2023-11-08 13:40:48.535488 Epoch 746, Training loss 0.2887316644191742\n",
      "R2 values 0.6948, 0.7251, 0.8172; mean R2=0.7457\n",
      "Validation Error: Avg loss: 4.077332 \n",
      "\n",
      "2023-11-08 13:40:49.012406 Epoch 747, Training loss 0.3184867799282074\n",
      "R2 values 0.5702, 0.7363, 0.8397; mean R2=0.7154\n",
      "Validation Error: Avg loss: 4.094235 \n",
      "\n",
      "2023-11-08 13:40:49.476790 Epoch 748, Training loss 0.3463365435600281\n",
      "R2 values 0.6470, 0.8143, 0.8019; mean R2=0.7544\n",
      "Validation Error: Avg loss: 3.090140 \n",
      "\n",
      "2023-11-08 13:40:49.944769 Epoch 749, Training loss 0.2809959948062897\n",
      "R2 values 0.6036, 0.7209, 0.7656; mean R2=0.6967\n",
      "Validation Error: Avg loss: 4.763859 \n",
      "\n",
      "2023-11-08 13:40:50.411023 Epoch 750, Training loss 0.29383111000061035\n",
      "R2 values 0.5853, 0.7395, 0.7291; mean R2=0.6846\n",
      "Validation Error: Avg loss: 4.471869 \n",
      "\n",
      "2023-11-08 13:40:50.874916 Epoch 751, Training loss 0.32096606492996216\n",
      "R2 values 0.6342, 0.7460, 0.7507; mean R2=0.7103\n",
      "Validation Error: Avg loss: 4.105373 \n",
      "\n",
      "2023-11-08 13:40:51.329852 Epoch 752, Training loss 0.23017095029354095\n",
      "R2 values 0.5220, 0.6830, 0.8005; mean R2=0.6685\n",
      "Validation Error: Avg loss: 5.007990 \n",
      "\n",
      "2023-11-08 13:40:51.795893 Epoch 753, Training loss 0.2370508760213852\n",
      "R2 values 0.5508, 0.7436, 0.7842; mean R2=0.6928\n",
      "Validation Error: Avg loss: 4.295574 \n",
      "\n",
      "2023-11-08 13:40:52.255915 Epoch 754, Training loss 0.2613520324230194\n",
      "R2 values 0.5967, 0.7467, 0.7837; mean R2=0.7091\n",
      "Validation Error: Avg loss: 4.208920 \n",
      "\n",
      "2023-11-08 13:40:52.733245 Epoch 755, Training loss 0.23946478962898254\n",
      "R2 values 0.6081, 0.7642, 0.8067; mean R2=0.7263\n",
      "Validation Error: Avg loss: 3.688415 \n",
      "\n",
      "2023-11-08 13:40:53.204604 Epoch 756, Training loss 0.268303781747818\n",
      "R2 values 0.5268, 0.7195, 0.8103; mean R2=0.6855\n",
      "Validation Error: Avg loss: 4.324393 \n",
      "\n",
      "2023-11-08 13:40:53.666180 Epoch 757, Training loss 0.24835066497325897\n",
      "R2 values 0.5442, 0.7404, 0.7886; mean R2=0.6911\n",
      "Validation Error: Avg loss: 3.970665 \n",
      "\n",
      "2023-11-08 13:40:54.141141 Epoch 758, Training loss 0.2220178246498108\n",
      "R2 values 0.5820, 0.7452, 0.8195; mean R2=0.7156\n",
      "Validation Error: Avg loss: 3.687157 \n",
      "\n",
      "2023-11-08 13:40:54.639793 Epoch 759, Training loss 0.22627700865268707\n",
      "R2 values 0.5760, 0.7270, 0.7842; mean R2=0.6958\n",
      "Validation Error: Avg loss: 3.980211 \n",
      "\n",
      "2023-11-08 13:40:55.147828 Epoch 760, Training loss 0.22182051837444305\n",
      "R2 values 0.6038, 0.7763, 0.7755; mean R2=0.7185\n",
      "Validation Error: Avg loss: 3.466371 \n",
      "\n",
      "2023-11-08 13:40:55.608517 Epoch 761, Training loss 0.2670653760433197\n",
      "R2 values 0.5520, 0.7204, 0.7874; mean R2=0.6866\n",
      "Validation Error: Avg loss: 4.387576 \n",
      "\n",
      "2023-11-08 13:40:56.065312 Epoch 762, Training loss 0.2699875235557556\n",
      "R2 values 0.4983, 0.7233, 0.7709; mean R2=0.6642\n",
      "Validation Error: Avg loss: 4.692607 \n",
      "\n",
      "2023-11-08 13:40:56.537892 Epoch 763, Training loss 0.22059009969234467\n",
      "R2 values 0.6348, 0.7200, 0.7603; mean R2=0.7050\n",
      "Validation Error: Avg loss: 4.657134 \n",
      "\n",
      "2023-11-08 13:40:57.010942 Epoch 764, Training loss 0.23890018463134766\n",
      "R2 values 0.7054, 0.7557, 0.7924; mean R2=0.7512\n",
      "Validation Error: Avg loss: 3.830110 \n",
      "\n",
      "2023-11-08 13:40:57.478000 Epoch 765, Training loss 0.1837039440870285\n",
      "R2 values 0.6525, 0.7384, 0.7798; mean R2=0.7235\n",
      "Validation Error: Avg loss: 3.994646 \n",
      "\n",
      "2023-11-08 13:40:57.944307 Epoch 766, Training loss 0.19279839098453522\n",
      "R2 values 0.5665, 0.7241, 0.8056; mean R2=0.6988\n",
      "Validation Error: Avg loss: 4.122097 \n",
      "\n",
      "2023-11-08 13:40:58.408093 Epoch 767, Training loss 0.24140742421150208\n",
      "R2 values 0.4872, 0.7139, 0.7641; mean R2=0.6551\n",
      "Validation Error: Avg loss: 4.482046 \n",
      "\n",
      "2023-11-08 13:40:58.868105 Epoch 768, Training loss 0.188984677195549\n",
      "R2 values 0.6763, 0.7779, 0.7596; mean R2=0.7380\n",
      "Validation Error: Avg loss: 3.653603 \n",
      "\n",
      "2023-11-08 13:40:59.339887 Epoch 769, Training loss 0.20828381180763245\n",
      "R2 values 0.5321, 0.7799, 0.8011; mean R2=0.7044\n",
      "Validation Error: Avg loss: 3.683853 \n",
      "\n",
      "2023-11-08 13:40:59.800237 Epoch 770, Training loss 0.2122255116701126\n",
      "R2 values 0.6489, 0.7913, 0.7794; mean R2=0.7399\n",
      "Validation Error: Avg loss: 3.412735 \n",
      "\n",
      "2023-11-08 13:41:00.255437 Epoch 771, Training loss 0.1959681659936905\n",
      "R2 values 0.6056, 0.7463, 0.8310; mean R2=0.7276\n",
      "Validation Error: Avg loss: 3.614321 \n",
      "\n",
      "2023-11-08 13:41:00.720850 Epoch 772, Training loss 0.19858935475349426\n",
      "R2 values 0.6138, 0.7422, 0.7803; mean R2=0.7121\n",
      "Validation Error: Avg loss: 3.953843 \n",
      "\n",
      "2023-11-08 13:41:01.175487 Epoch 773, Training loss 0.22023311257362366\n",
      "R2 values 0.6103, 0.7453, 0.7957; mean R2=0.7171\n",
      "Validation Error: Avg loss: 3.994933 \n",
      "\n",
      "2023-11-08 13:41:01.637896 Epoch 774, Training loss 0.17855553328990936\n",
      "R2 values 0.5194, 0.7516, 0.8024; mean R2=0.6911\n",
      "Validation Error: Avg loss: 4.142955 \n",
      "\n",
      "2023-11-08 13:41:02.095338 Epoch 775, Training loss 0.255367636680603\n",
      "R2 values 0.4865, 0.7555, 0.7894; mean R2=0.6771\n",
      "Validation Error: Avg loss: 4.182593 \n",
      "\n",
      "2023-11-08 13:41:02.564977 Epoch 776, Training loss 0.236777663230896\n",
      "R2 values 0.5640, 0.7308, 0.7670; mean R2=0.6873\n",
      "Validation Error: Avg loss: 4.272649 \n",
      "\n",
      "2023-11-08 13:41:03.038272 Epoch 777, Training loss 0.2591502070426941\n",
      "R2 values 0.5916, 0.7252, 0.8370; mean R2=0.7179\n",
      "Validation Error: Avg loss: 3.832547 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:41:03.494940 Epoch 778, Training loss 0.21645410358905792\n",
      "R2 values 0.6190, 0.7485, 0.8253; mean R2=0.7309\n",
      "Validation Error: Avg loss: 3.700708 \n",
      "\n",
      "2023-11-08 13:41:04.202247 Epoch 779, Training loss 0.262909471988678\n",
      "R2 values 0.6480, 0.7278, 0.7944; mean R2=0.7234\n",
      "Validation Error: Avg loss: 3.984014 \n",
      "\n",
      "2023-11-08 13:41:04.664294 Epoch 780, Training loss 0.2881457805633545\n",
      "R2 values 0.5497, 0.7420, 0.7920; mean R2=0.6946\n",
      "Validation Error: Avg loss: 3.980054 \n",
      "\n",
      "2023-11-08 13:41:05.133980 Epoch 781, Training loss 0.19693268835544586\n",
      "R2 values 0.5196, 0.7496, 0.7857; mean R2=0.6849\n",
      "Validation Error: Avg loss: 3.993579 \n",
      "\n",
      "2023-11-08 13:41:05.588000 Epoch 782, Training loss 0.20167940855026245\n",
      "R2 values 0.4658, 0.7548, 0.7828; mean R2=0.6678\n",
      "Validation Error: Avg loss: 4.231750 \n",
      "\n",
      "2023-11-08 13:41:06.046923 Epoch 783, Training loss 0.22372448444366455\n",
      "R2 values 0.5118, 0.7566, 0.8008; mean R2=0.6897\n",
      "Validation Error: Avg loss: 3.892804 \n",
      "\n",
      "2023-11-08 13:41:06.513470 Epoch 784, Training loss 0.22959326207637787\n",
      "R2 values 0.6432, 0.7626, 0.8327; mean R2=0.7462\n",
      "Validation Error: Avg loss: 3.513953 \n",
      "\n",
      "2023-11-08 13:41:06.981915 Epoch 785, Training loss 0.30674999952316284\n",
      "R2 values 0.5924, 0.7360, 0.7901; mean R2=0.7061\n",
      "Validation Error: Avg loss: 4.061523 \n",
      "\n",
      "2023-11-08 13:41:07.437036 Epoch 786, Training loss 0.2973153591156006\n",
      "R2 values 0.6515, 0.7625, 0.7936; mean R2=0.7358\n",
      "Validation Error: Avg loss: 3.715795 \n",
      "\n",
      "2023-11-08 13:41:07.905036 Epoch 787, Training loss 0.2756163477897644\n",
      "R2 values 0.5418, 0.7451, 0.7906; mean R2=0.6925\n",
      "Validation Error: Avg loss: 4.051077 \n",
      "\n",
      "2023-11-08 13:41:08.362113 Epoch 788, Training loss 0.20753569900989532\n",
      "R2 values 0.5597, 0.7111, 0.7779; mean R2=0.6829\n",
      "Validation Error: Avg loss: 4.448651 \n",
      "\n",
      "2023-11-08 13:41:08.821067 Epoch 789, Training loss 0.24290911853313446\n",
      "R2 values 0.5718, 0.7303, 0.7823; mean R2=0.6948\n",
      "Validation Error: Avg loss: 4.324977 \n",
      "\n",
      "2023-11-08 13:41:09.286049 Epoch 790, Training loss 0.29136723279953003\n",
      "R2 values 0.6472, 0.7675, 0.7950; mean R2=0.7366\n",
      "Validation Error: Avg loss: 3.838964 \n",
      "\n",
      "2023-11-08 13:41:09.748938 Epoch 791, Training loss 0.2172662764787674\n",
      "R2 values 0.5446, 0.7359, 0.8113; mean R2=0.6973\n",
      "Validation Error: Avg loss: 4.387605 \n",
      "\n",
      "2023-11-08 13:41:10.211182 Epoch 792, Training loss 0.28202036023139954\n",
      "R2 values 0.5248, 0.7433, 0.8084; mean R2=0.6922\n",
      "Validation Error: Avg loss: 3.879086 \n",
      "\n",
      "2023-11-08 13:41:10.928320 Epoch 793, Training loss 0.1817283034324646\n",
      "R2 values 0.6065, 0.7380, 0.7801; mean R2=0.7082\n",
      "Validation Error: Avg loss: 3.885691 \n",
      "\n",
      "2023-11-08 13:41:11.398913 Epoch 794, Training loss 0.2931428551673889\n",
      "R2 values 0.6450, 0.7694, 0.7490; mean R2=0.7211\n",
      "Validation Error: Avg loss: 3.759625 \n",
      "\n",
      "2023-11-08 13:41:11.871497 Epoch 795, Training loss 0.19139695167541504\n",
      "R2 values 0.6324, 0.7573, 0.7980; mean R2=0.7292\n",
      "Validation Error: Avg loss: 3.912618 \n",
      "\n",
      "2023-11-08 13:41:12.328780 Epoch 796, Training loss 0.1822764277458191\n",
      "R2 values 0.6854, 0.7488, 0.7399; mean R2=0.7247\n",
      "Validation Error: Avg loss: 4.008770 \n",
      "\n",
      "2023-11-08 13:41:12.789592 Epoch 797, Training loss 0.21076293289661407\n",
      "R2 values 0.5785, 0.7406, 0.7505; mean R2=0.6899\n",
      "Validation Error: Avg loss: 4.048188 \n",
      "\n",
      "2023-11-08 13:41:13.247240 Epoch 798, Training loss 0.25802937150001526\n",
      "R2 values 0.6463, 0.7360, 0.7501; mean R2=0.7108\n",
      "Validation Error: Avg loss: 4.096453 \n",
      "\n",
      "2023-11-08 13:41:13.705267 Epoch 799, Training loss 0.2003737986087799\n",
      "R2 values 0.5925, 0.7291, 0.7868; mean R2=0.7028\n",
      "Validation Error: Avg loss: 4.236682 \n",
      "\n",
      "2023-11-08 13:41:14.159357 Epoch 800, Training loss 0.2133026272058487\n",
      "R2 values 0.5745, 0.7675, 0.7986; mean R2=0.7135\n",
      "Validation Error: Avg loss: 3.748487 \n",
      "\n",
      "2023-11-08 13:41:14.674226 Epoch 801, Training loss 0.19225212931632996\n",
      "R2 values 0.5858, 0.7121, 0.7593; mean R2=0.6857\n",
      "Validation Error: Avg loss: 4.657389 \n",
      "\n",
      "2023-11-08 13:41:15.150688 Epoch 802, Training loss 0.21449661254882812\n",
      "R2 values 0.5683, 0.7148, 0.7614; mean R2=0.6815\n",
      "Validation Error: Avg loss: 4.484571 \n",
      "\n",
      "2023-11-08 13:41:15.609280 Epoch 803, Training loss 0.23282107710838318\n",
      "R2 values 0.6042, 0.7586, 0.8388; mean R2=0.7339\n",
      "Validation Error: Avg loss: 3.428558 \n",
      "\n",
      "2023-11-08 13:41:16.068590 Epoch 804, Training loss 0.20485757291316986\n",
      "R2 values 0.6326, 0.7790, 0.7907; mean R2=0.7341\n",
      "Validation Error: Avg loss: 3.328321 \n",
      "\n",
      "2023-11-08 13:41:16.523258 Epoch 805, Training loss 0.25509902834892273\n",
      "R2 values 0.5542, 0.7362, 0.7645; mean R2=0.6849\n",
      "Validation Error: Avg loss: 4.155911 \n",
      "\n",
      "2023-11-08 13:41:17.114920 Epoch 806, Training loss 0.19023354351520538\n",
      "R2 values 0.5996, 0.7552, 0.7425; mean R2=0.6991\n",
      "Validation Error: Avg loss: 4.246043 \n",
      "\n",
      "2023-11-08 13:41:17.589772 Epoch 807, Training loss 0.31963130831718445\n",
      "R2 values 0.5681, 0.7655, 0.7615; mean R2=0.6984\n",
      "Validation Error: Avg loss: 3.737480 \n",
      "\n",
      "2023-11-08 13:41:18.098426 Epoch 808, Training loss 0.24253177642822266\n",
      "R2 values 0.6050, 0.7393, 0.7824; mean R2=0.7089\n",
      "Validation Error: Avg loss: 3.761372 \n",
      "\n",
      "2023-11-08 13:41:18.606574 Epoch 809, Training loss 0.3151822090148926\n",
      "R2 values 0.6932, 0.7912, 0.7977; mean R2=0.7607\n",
      "Validation Error: Avg loss: 3.321069 \n",
      "\n",
      "2023-11-08 13:41:19.069332 Epoch 810, Training loss 0.17644913494586945\n",
      "R2 values 0.6438, 0.7033, 0.7795; mean R2=0.7089\n",
      "Validation Error: Avg loss: 4.581544 \n",
      "\n",
      "2023-11-08 13:41:19.540587 Epoch 811, Training loss 0.24354802072048187\n",
      "R2 values 0.6176, 0.7520, 0.7819; mean R2=0.7172\n",
      "Validation Error: Avg loss: 3.942666 \n",
      "\n",
      "2023-11-08 13:41:20.047544 Epoch 812, Training loss 0.304818332195282\n",
      "R2 values 0.4714, 0.7410, 0.8150; mean R2=0.6758\n",
      "Validation Error: Avg loss: 4.024809 \n",
      "\n",
      "2023-11-08 13:41:20.512504 Epoch 813, Training loss 0.29664576053619385\n",
      "R2 values 0.5365, 0.7721, 0.8068; mean R2=0.7051\n",
      "Validation Error: Avg loss: 3.766256 \n",
      "\n",
      "2023-11-08 13:41:20.988866 Epoch 814, Training loss 0.2599894404411316\n",
      "R2 values 0.5763, 0.7513, 0.7222; mean R2=0.6833\n",
      "Validation Error: Avg loss: 4.652179 \n",
      "\n",
      "2023-11-08 13:41:21.486438 Epoch 815, Training loss 0.3347727656364441\n",
      "R2 values 0.5068, 0.7588, 0.7716; mean R2=0.6791\n",
      "Validation Error: Avg loss: 4.177377 \n",
      "\n",
      "2023-11-08 13:41:21.954867 Epoch 816, Training loss 0.22515366971492767\n",
      "R2 values 0.4890, 0.7684, 0.7955; mean R2=0.6843\n",
      "Validation Error: Avg loss: 3.707694 \n",
      "\n",
      "2023-11-08 13:41:22.415106 Epoch 817, Training loss 0.20469513535499573\n",
      "R2 values 0.5898, 0.7613, 0.8127; mean R2=0.7213\n",
      "Validation Error: Avg loss: 3.492258 \n",
      "\n",
      "2023-11-08 13:41:22.874213 Epoch 818, Training loss 0.20012611150741577\n",
      "R2 values 0.6147, 0.7709, 0.8084; mean R2=0.7313\n",
      "Validation Error: Avg loss: 3.202623 \n",
      "\n",
      "2023-11-08 13:41:23.324796 Epoch 819, Training loss 0.24618834257125854\n",
      "R2 values 0.7552, 0.7786, 0.8028; mean R2=0.7789\n",
      "Validation Error: Avg loss: 3.318631 \n",
      "\n",
      "2023-11-08 13:41:23.792938 Epoch 820, Training loss 0.23235873878002167\n",
      "R2 values 0.6095, 0.7525, 0.7955; mean R2=0.7192\n",
      "Validation Error: Avg loss: 3.932356 \n",
      "\n",
      "2023-11-08 13:41:24.272261 Epoch 821, Training loss 0.2424241155385971\n",
      "R2 values 0.5514, 0.7581, 0.7879; mean R2=0.6992\n",
      "Validation Error: Avg loss: 3.809259 \n",
      "\n",
      "2023-11-08 13:41:24.728431 Epoch 822, Training loss 0.20997780561447144\n",
      "R2 values 0.5812, 0.7476, 0.7999; mean R2=0.7096\n",
      "Validation Error: Avg loss: 3.902855 \n",
      "\n",
      "2023-11-08 13:41:25.188362 Epoch 823, Training loss 0.24243216216564178\n",
      "R2 values 0.5538, 0.7445, 0.8227; mean R2=0.7070\n",
      "Validation Error: Avg loss: 3.911009 \n",
      "\n",
      "2023-11-08 13:41:25.657482 Epoch 824, Training loss 0.2659754753112793\n",
      "R2 values 0.5058, 0.7380, 0.7699; mean R2=0.6712\n",
      "Validation Error: Avg loss: 4.538518 \n",
      "\n",
      "2023-11-08 13:41:26.356343 Epoch 825, Training loss 0.21210069954395294\n",
      "R2 values 0.6020, 0.7313, 0.7786; mean R2=0.7040\n",
      "Validation Error: Avg loss: 4.290412 \n",
      "\n",
      "2023-11-08 13:41:26.874539 Epoch 826, Training loss 0.2675597369670868\n",
      "R2 values 0.5455, 0.7410, 0.7778; mean R2=0.6881\n",
      "Validation Error: Avg loss: 4.216064 \n",
      "\n",
      "2023-11-08 13:41:27.339820 Epoch 827, Training loss 0.17089466750621796\n",
      "R2 values 0.6134, 0.7506, 0.7946; mean R2=0.7195\n",
      "Validation Error: Avg loss: 3.963107 \n",
      "\n",
      "2023-11-08 13:41:27.802180 Epoch 828, Training loss 0.2405714988708496\n",
      "R2 values 0.6216, 0.7436, 0.7781; mean R2=0.7144\n",
      "Validation Error: Avg loss: 3.979428 \n",
      "\n",
      "2023-11-08 13:41:28.267571 Epoch 829, Training loss 0.24934491515159607\n",
      "R2 values 0.6083, 0.7151, 0.7992; mean R2=0.7075\n",
      "Validation Error: Avg loss: 4.389157 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:41:28.729658 Epoch 830, Training loss 0.21737787127494812\n",
      "R2 values 0.5755, 0.7685, 0.7288; mean R2=0.6909\n",
      "Validation Error: Avg loss: 4.273525 \n",
      "\n",
      "2023-11-08 13:41:29.200050 Epoch 831, Training loss 0.2646191120147705\n",
      "R2 values 0.6615, 0.7368, 0.8025; mean R2=0.7336\n",
      "Validation Error: Avg loss: 3.910165 \n",
      "\n",
      "2023-11-08 13:41:29.666715 Epoch 832, Training loss 0.2124015837907791\n",
      "R2 values 0.6448, 0.7485, 0.8290; mean R2=0.7408\n",
      "Validation Error: Avg loss: 3.663853 \n",
      "\n",
      "2023-11-08 13:41:30.151531 Epoch 833, Training loss 0.24103963375091553\n",
      "R2 values 0.5620, 0.7594, 0.7998; mean R2=0.7070\n",
      "Validation Error: Avg loss: 3.793278 \n",
      "\n",
      "2023-11-08 13:41:30.610991 Epoch 834, Training loss 0.18534843623638153\n",
      "R2 values 0.6275, 0.7676, 0.7999; mean R2=0.7317\n",
      "Validation Error: Avg loss: 3.695471 \n",
      "\n",
      "2023-11-08 13:41:31.081591 Epoch 835, Training loss 0.27299249172210693\n",
      "R2 values 0.6492, 0.7742, 0.7752; mean R2=0.7329\n",
      "Validation Error: Avg loss: 3.577432 \n",
      "\n",
      "2023-11-08 13:41:31.548544 Epoch 836, Training loss 0.20922371745109558\n",
      "R2 values 0.5606, 0.7521, 0.7589; mean R2=0.6906\n",
      "Validation Error: Avg loss: 3.981900 \n",
      "\n",
      "2023-11-08 13:41:32.001849 Epoch 837, Training loss 0.2640475630760193\n",
      "R2 values 0.6246, 0.7278, 0.7693; mean R2=0.7072\n",
      "Validation Error: Avg loss: 4.247600 \n",
      "\n",
      "2023-11-08 13:41:32.460474 Epoch 838, Training loss 0.18229806423187256\n",
      "R2 values 0.6058, 0.7744, 0.7664; mean R2=0.7156\n",
      "Validation Error: Avg loss: 3.836569 \n",
      "\n",
      "2023-11-08 13:41:33.020873 Epoch 839, Training loss 0.17470933496952057\n",
      "R2 values 0.5019, 0.7136, 0.7451; mean R2=0.6535\n",
      "Validation Error: Avg loss: 4.771396 \n",
      "\n",
      "2023-11-08 13:41:33.480422 Epoch 840, Training loss 0.18695299327373505\n",
      "R2 values 0.5436, 0.7198, 0.7501; mean R2=0.6712\n",
      "Validation Error: Avg loss: 4.434636 \n",
      "\n",
      "2023-11-08 13:41:33.942862 Epoch 841, Training loss 0.2173265814781189\n",
      "R2 values 0.6169, 0.7089, 0.7868; mean R2=0.7042\n",
      "Validation Error: Avg loss: 4.497477 \n",
      "\n",
      "2023-11-08 13:41:34.429496 Epoch 842, Training loss 0.21627336740493774\n",
      "R2 values 0.5550, 0.7580, 0.7766; mean R2=0.6965\n",
      "Validation Error: Avg loss: 3.985969 \n",
      "\n",
      "2023-11-08 13:41:34.931176 Epoch 843, Training loss 0.21860270202159882\n",
      "R2 values 0.6333, 0.7847, 0.8010; mean R2=0.7397\n",
      "Validation Error: Avg loss: 3.386488 \n",
      "\n",
      "2023-11-08 13:41:35.391866 Epoch 844, Training loss 0.1920240968465805\n",
      "R2 values 0.5714, 0.7616, 0.8056; mean R2=0.7129\n",
      "Validation Error: Avg loss: 3.705529 \n",
      "\n",
      "2023-11-08 13:41:35.846713 Epoch 845, Training loss 0.20819254219532013\n",
      "R2 values 0.5332, 0.7486, 0.7817; mean R2=0.6878\n",
      "Validation Error: Avg loss: 4.200307 \n",
      "\n",
      "2023-11-08 13:41:36.307774 Epoch 846, Training loss 0.2039475291967392\n",
      "R2 values 0.6533, 0.7725, 0.7559; mean R2=0.7273\n",
      "Validation Error: Avg loss: 3.921874 \n",
      "\n",
      "2023-11-08 13:41:36.762772 Epoch 847, Training loss 0.2764052152633667\n",
      "R2 values 0.5681, 0.7655, 0.7769; mean R2=0.7035\n",
      "Validation Error: Avg loss: 3.938260 \n",
      "\n",
      "2023-11-08 13:41:37.219286 Epoch 848, Training loss 0.22490380704402924\n",
      "R2 values 0.5966, 0.7439, 0.7980; mean R2=0.7128\n",
      "Validation Error: Avg loss: 3.863141 \n",
      "\n",
      "2023-11-08 13:41:37.676135 Epoch 849, Training loss 0.2126665711402893\n",
      "R2 values 0.6896, 0.7672, 0.7616; mean R2=0.7395\n",
      "Validation Error: Avg loss: 3.690325 \n",
      "\n",
      "2023-11-08 13:41:38.184931 Epoch 850, Training loss 0.22540953755378723\n",
      "R2 values 0.6422, 0.7309, 0.7876; mean R2=0.7202\n",
      "Validation Error: Avg loss: 4.452703 \n",
      "\n",
      "2023-11-08 13:41:38.649201 Epoch 851, Training loss 0.22485768795013428\n",
      "R2 values 0.6078, 0.7032, 0.7791; mean R2=0.6967\n",
      "Validation Error: Avg loss: 4.705571 \n",
      "\n",
      "2023-11-08 13:41:39.122077 Epoch 852, Training loss 0.21490629017353058\n",
      "R2 values 0.6181, 0.7433, 0.7996; mean R2=0.7203\n",
      "Validation Error: Avg loss: 3.916469 \n",
      "\n",
      "2023-11-08 13:41:39.576074 Epoch 853, Training loss 0.2211768478155136\n",
      "R2 values 0.5834, 0.7543, 0.8398; mean R2=0.7258\n",
      "Validation Error: Avg loss: 3.590901 \n",
      "\n",
      "2023-11-08 13:41:40.172642 Epoch 854, Training loss 0.21718242764472961\n",
      "R2 values 0.6069, 0.7699, 0.7925; mean R2=0.7231\n",
      "Validation Error: Avg loss: 3.662133 \n",
      "\n",
      "2023-11-08 13:41:40.635064 Epoch 855, Training loss 0.21833087503910065\n",
      "R2 values 0.5676, 0.7190, 0.8170; mean R2=0.7012\n",
      "Validation Error: Avg loss: 4.185571 \n",
      "\n",
      "2023-11-08 13:41:41.090501 Epoch 856, Training loss 0.1996973156929016\n",
      "R2 values 0.5439, 0.7591, 0.7418; mean R2=0.6816\n",
      "Validation Error: Avg loss: 4.104955 \n",
      "\n",
      "2023-11-08 13:41:41.550658 Epoch 857, Training loss 0.2905738949775696\n",
      "R2 values 0.4790, 0.7576, 0.7823; mean R2=0.6730\n",
      "Validation Error: Avg loss: 3.788464 \n",
      "\n",
      "2023-11-08 13:41:42.022576 Epoch 858, Training loss 0.21030212938785553\n",
      "R2 values 0.5734, 0.7414, 0.7823; mean R2=0.6990\n",
      "Validation Error: Avg loss: 4.112951 \n",
      "\n",
      "2023-11-08 13:41:42.489406 Epoch 859, Training loss 0.24211682379245758\n",
      "R2 values 0.6007, 0.7564, 0.7484; mean R2=0.7018\n",
      "Validation Error: Avg loss: 4.071590 \n",
      "\n",
      "2023-11-08 13:41:42.945730 Epoch 860, Training loss 0.20812472701072693\n",
      "R2 values 0.5067, 0.7628, 0.7578; mean R2=0.6758\n",
      "Validation Error: Avg loss: 4.080172 \n",
      "\n",
      "2023-11-08 13:41:43.398469 Epoch 861, Training loss 0.20239247381687164\n",
      "R2 values 0.5758, 0.7330, 0.8145; mean R2=0.7078\n",
      "Validation Error: Avg loss: 4.029872 \n",
      "\n",
      "2023-11-08 13:41:43.866827 Epoch 862, Training loss 0.2626139223575592\n",
      "R2 values 0.6092, 0.7517, 0.7839; mean R2=0.7149\n",
      "Validation Error: Avg loss: 3.759545 \n",
      "\n",
      "2023-11-08 13:41:44.327831 Epoch 863, Training loss 0.22731748223304749\n",
      "R2 values 0.6103, 0.7580, 0.7722; mean R2=0.7135\n",
      "Validation Error: Avg loss: 3.723188 \n",
      "\n",
      "2023-11-08 13:41:44.793068 Epoch 864, Training loss 0.27496227622032166\n",
      "R2 values 0.5470, 0.7586, 0.7707; mean R2=0.6921\n",
      "Validation Error: Avg loss: 3.924668 \n",
      "\n",
      "2023-11-08 13:41:45.266783 Epoch 865, Training loss 0.3053884208202362\n",
      "R2 values 0.5543, 0.7660, 0.7871; mean R2=0.7025\n",
      "Validation Error: Avg loss: 3.844629 \n",
      "\n",
      "2023-11-08 13:41:45.735669 Epoch 866, Training loss 0.19004999101161957\n",
      "R2 values 0.5751, 0.7443, 0.7871; mean R2=0.7022\n",
      "Validation Error: Avg loss: 3.863085 \n",
      "\n",
      "2023-11-08 13:41:46.203169 Epoch 867, Training loss 0.21264031529426575\n",
      "R2 values 0.5828, 0.7880, 0.8305; mean R2=0.7338\n",
      "Validation Error: Avg loss: 3.392433 \n",
      "\n",
      "2023-11-08 13:41:46.661576 Epoch 868, Training loss 0.221140518784523\n",
      "R2 values 0.5690, 0.7145, 0.7843; mean R2=0.6893\n",
      "Validation Error: Avg loss: 4.663127 \n",
      "\n",
      "2023-11-08 13:41:47.123369 Epoch 869, Training loss 0.20452138781547546\n",
      "R2 values 0.5326, 0.7709, 0.7314; mean R2=0.6783\n",
      "Validation Error: Avg loss: 4.159238 \n",
      "\n",
      "2023-11-08 13:41:47.579319 Epoch 870, Training loss 0.19154396653175354\n",
      "R2 values 0.5994, 0.7384, 0.7898; mean R2=0.7092\n",
      "Validation Error: Avg loss: 4.171538 \n",
      "\n",
      "2023-11-08 13:41:48.050034 Epoch 871, Training loss 0.2661347985267639\n",
      "R2 values 0.5031, 0.7158, 0.7389; mean R2=0.6526\n",
      "Validation Error: Avg loss: 4.637772 \n",
      "\n",
      "2023-11-08 13:41:48.529946 Epoch 872, Training loss 0.18282659351825714\n",
      "R2 values 0.5221, 0.7067, 0.7484; mean R2=0.6591\n",
      "Validation Error: Avg loss: 4.724167 \n",
      "\n",
      "2023-11-08 13:41:48.998751 Epoch 873, Training loss 0.30978867411613464\n",
      "R2 values 0.5550, 0.7384, 0.7709; mean R2=0.6881\n",
      "Validation Error: Avg loss: 4.026594 \n",
      "\n",
      "2023-11-08 13:41:49.469649 Epoch 874, Training loss 0.16145886480808258\n",
      "R2 values 0.5447, 0.7508, 0.7717; mean R2=0.6890\n",
      "Validation Error: Avg loss: 3.842579 \n",
      "\n",
      "2023-11-08 13:41:49.941186 Epoch 875, Training loss 0.2795135974884033\n",
      "R2 values 0.5894, 0.7812, 0.7868; mean R2=0.7191\n",
      "Validation Error: Avg loss: 3.612145 \n",
      "\n",
      "2023-11-08 13:41:50.428705 Epoch 876, Training loss 0.19777795672416687\n",
      "R2 values 0.6091, 0.7273, 0.7629; mean R2=0.6998\n",
      "Validation Error: Avg loss: 4.520872 \n",
      "\n",
      "2023-11-08 13:41:51.020340 Epoch 877, Training loss 0.2924755811691284\n",
      "R2 values 0.6913, 0.7500, 0.7616; mean R2=0.7343\n",
      "Validation Error: Avg loss: 3.950209 \n",
      "\n",
      "2023-11-08 13:41:51.479495 Epoch 878, Training loss 0.19007030129432678\n",
      "R2 values 0.6075, 0.7415, 0.8110; mean R2=0.7200\n",
      "Validation Error: Avg loss: 3.835948 \n",
      "\n",
      "2023-11-08 13:41:51.936451 Epoch 879, Training loss 0.20090793073177338\n",
      "R2 values 0.6705, 0.7783, 0.8065; mean R2=0.7518\n",
      "Validation Error: Avg loss: 3.470813 \n",
      "\n",
      "2023-11-08 13:41:52.399729 Epoch 880, Training loss 0.23645927011966705\n",
      "R2 values 0.6254, 0.7328, 0.7790; mean R2=0.7124\n",
      "Validation Error: Avg loss: 4.305298 \n",
      "\n",
      "2023-11-08 13:41:52.994346 Epoch 881, Training loss 0.22778888046741486\n",
      "R2 values 0.6115, 0.7415, 0.7998; mean R2=0.7176\n",
      "Validation Error: Avg loss: 4.107658 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:41:53.448337 Epoch 882, Training loss 0.2564433217048645\n",
      "R2 values 0.5001, 0.7542, 0.7807; mean R2=0.6784\n",
      "Validation Error: Avg loss: 4.003906 \n",
      "\n",
      "2023-11-08 13:41:53.905728 Epoch 883, Training loss 0.15531669557094574\n",
      "R2 values 0.6148, 0.7462, 0.7915; mean R2=0.7175\n",
      "Validation Error: Avg loss: 3.724627 \n",
      "\n",
      "2023-11-08 13:41:54.356865 Epoch 884, Training loss 0.20832249522209167\n",
      "R2 values 0.5514, 0.7525, 0.7790; mean R2=0.6943\n",
      "Validation Error: Avg loss: 3.848509 \n",
      "\n",
      "2023-11-08 13:41:54.894017 Epoch 885, Training loss 0.21568965911865234\n",
      "R2 values 0.4935, 0.7291, 0.7593; mean R2=0.6607\n",
      "Validation Error: Avg loss: 4.419751 \n",
      "\n",
      "2023-11-08 13:41:55.351843 Epoch 886, Training loss 0.2744191288948059\n",
      "R2 values 0.5057, 0.7581, 0.7803; mean R2=0.6814\n",
      "Validation Error: Avg loss: 4.285518 \n",
      "\n",
      "2023-11-08 13:41:55.816133 Epoch 887, Training loss 0.17643435299396515\n",
      "R2 values 0.6106, 0.7412, 0.8021; mean R2=0.7180\n",
      "Validation Error: Avg loss: 3.999926 \n",
      "\n",
      "2023-11-08 13:41:56.278290 Epoch 888, Training loss 0.20595663785934448\n",
      "R2 values 0.6525, 0.7425, 0.7671; mean R2=0.7207\n",
      "Validation Error: Avg loss: 3.784631 \n",
      "\n",
      "2023-11-08 13:41:56.742226 Epoch 889, Training loss 0.2308851033449173\n",
      "R2 values 0.5069, 0.7150, 0.7874; mean R2=0.6698\n",
      "Validation Error: Avg loss: 4.328671 \n",
      "\n",
      "2023-11-08 13:41:57.198772 Epoch 890, Training loss 0.2402314692735672\n",
      "R2 values 0.5829, 0.7334, 0.7385; mean R2=0.6849\n",
      "Validation Error: Avg loss: 4.737913 \n",
      "\n",
      "2023-11-08 13:41:57.662829 Epoch 891, Training loss 0.22709830105304718\n",
      "R2 values 0.5568, 0.7391, 0.7862; mean R2=0.6940\n",
      "Validation Error: Avg loss: 4.555952 \n",
      "\n",
      "2023-11-08 13:41:58.136106 Epoch 892, Training loss 0.3933830261230469\n",
      "R2 values 0.6414, 0.7651, 0.7772; mean R2=0.7279\n",
      "Validation Error: Avg loss: 3.679805 \n",
      "\n",
      "2023-11-08 13:41:58.596615 Epoch 893, Training loss 0.227666437625885\n",
      "R2 values 0.6431, 0.7368, 0.8106; mean R2=0.7302\n",
      "Validation Error: Avg loss: 3.778627 \n",
      "\n",
      "2023-11-08 13:41:59.072395 Epoch 894, Training loss 0.23864029347896576\n",
      "R2 values 0.5050, 0.7054, 0.7702; mean R2=0.6602\n",
      "Validation Error: Avg loss: 4.467599 \n",
      "\n",
      "2023-11-08 13:41:59.543058 Epoch 895, Training loss 0.19520367681980133\n",
      "R2 values 0.5094, 0.7263, 0.7855; mean R2=0.6737\n",
      "Validation Error: Avg loss: 4.483997 \n",
      "\n",
      "2023-11-08 13:42:00.005024 Epoch 896, Training loss 0.2535739839076996\n",
      "R2 values 0.4022, 0.7336, 0.7675; mean R2=0.6344\n",
      "Validation Error: Avg loss: 4.598428 \n",
      "\n",
      "2023-11-08 13:42:00.463435 Epoch 897, Training loss 0.3315366208553314\n",
      "R2 values 0.5192, 0.7554, 0.7604; mean R2=0.6784\n",
      "Validation Error: Avg loss: 4.022665 \n",
      "\n",
      "2023-11-08 13:42:00.919912 Epoch 898, Training loss 0.24904823303222656\n",
      "R2 values 0.6198, 0.7796, 0.8156; mean R2=0.7383\n",
      "Validation Error: Avg loss: 3.289332 \n",
      "\n",
      "2023-11-08 13:42:01.378015 Epoch 899, Training loss 0.25573667883872986\n",
      "R2 values 0.6213, 0.7543, 0.8085; mean R2=0.7280\n",
      "Validation Error: Avg loss: 3.848028 \n",
      "\n",
      "2023-11-08 13:42:01.830224 Epoch 900, Training loss 0.21046026051044464\n",
      "R2 values 0.4997, 0.7878, 0.7657; mean R2=0.6844\n",
      "Validation Error: Avg loss: 3.910096 \n",
      "\n",
      "2023-11-08 13:42:02.290033 Epoch 901, Training loss 0.21161559224128723\n",
      "R2 values 0.7064, 0.7775, 0.7306; mean R2=0.7382\n",
      "Validation Error: Avg loss: 4.007864 \n",
      "\n",
      "2023-11-08 13:42:02.762803 Epoch 902, Training loss 0.38102099299430847\n",
      "R2 values 0.6820, 0.7458, 0.7948; mean R2=0.7409\n",
      "Validation Error: Avg loss: 3.778927 \n",
      "\n",
      "2023-11-08 13:42:03.272853 Epoch 903, Training loss 0.19441306591033936\n",
      "R2 values 0.6029, 0.7241, 0.8399; mean R2=0.7223\n",
      "Validation Error: Avg loss: 3.795333 \n",
      "\n",
      "2023-11-08 13:42:03.741560 Epoch 904, Training loss 0.3036876320838928\n",
      "R2 values 0.5267, 0.7224, 0.7940; mean R2=0.6810\n",
      "Validation Error: Avg loss: 4.244076 \n",
      "\n",
      "2023-11-08 13:42:04.272763 Epoch 905, Training loss 0.25815674662590027\n",
      "R2 values 0.6026, 0.6998, 0.7108; mean R2=0.6711\n",
      "Validation Error: Avg loss: 5.282781 \n",
      "\n",
      "2023-11-08 13:42:04.761816 Epoch 906, Training loss 0.29995015263557434\n",
      "R2 values 0.5477, 0.7274, 0.7497; mean R2=0.6750\n",
      "Validation Error: Avg loss: 4.858055 \n",
      "\n",
      "2023-11-08 13:42:05.218190 Epoch 907, Training loss 0.3323797881603241\n",
      "R2 values 0.4917, 0.7508, 0.7937; mean R2=0.6787\n",
      "Validation Error: Avg loss: 4.283500 \n",
      "\n",
      "2023-11-08 13:42:05.674225 Epoch 908, Training loss 0.19279900193214417\n",
      "R2 values 0.5422, 0.7554, 0.7904; mean R2=0.6960\n",
      "Validation Error: Avg loss: 3.622574 \n",
      "\n",
      "2023-11-08 13:42:06.133954 Epoch 909, Training loss 0.25862759351730347\n",
      "R2 values 0.5841, 0.7127, 0.7843; mean R2=0.6937\n",
      "Validation Error: Avg loss: 4.124754 \n",
      "\n",
      "2023-11-08 13:42:06.599299 Epoch 910, Training loss 0.2082778662443161\n",
      "R2 values 0.5599, 0.7661, 0.7765; mean R2=0.7008\n",
      "Validation Error: Avg loss: 3.618108 \n",
      "\n",
      "2023-11-08 13:42:07.072930 Epoch 911, Training loss 0.22762595117092133\n",
      "R2 values 0.6045, 0.7259, 0.7958; mean R2=0.7087\n",
      "Validation Error: Avg loss: 4.336844 \n",
      "\n",
      "2023-11-08 13:42:07.541687 Epoch 912, Training loss 0.23201654851436615\n",
      "R2 values 0.5880, 0.7636, 0.7695; mean R2=0.7070\n",
      "Validation Error: Avg loss: 3.974618 \n",
      "\n",
      "2023-11-08 13:42:08.014908 Epoch 913, Training loss 0.20984745025634766\n",
      "R2 values 0.5386, 0.7417, 0.7833; mean R2=0.6879\n",
      "Validation Error: Avg loss: 4.051949 \n",
      "\n",
      "2023-11-08 13:42:08.479696 Epoch 914, Training loss 0.21658673882484436\n",
      "R2 values 0.6403, 0.7344, 0.8066; mean R2=0.7271\n",
      "Validation Error: Avg loss: 3.916786 \n",
      "\n",
      "2023-11-08 13:42:08.949283 Epoch 915, Training loss 0.2713828384876251\n",
      "R2 values 0.6123, 0.7511, 0.8039; mean R2=0.7224\n",
      "Validation Error: Avg loss: 3.895489 \n",
      "\n",
      "2023-11-08 13:42:09.413914 Epoch 916, Training loss 0.1984144002199173\n",
      "R2 values 0.6396, 0.7252, 0.7701; mean R2=0.7116\n",
      "Validation Error: Avg loss: 4.472199 \n",
      "\n",
      "2023-11-08 13:42:09.869922 Epoch 917, Training loss 0.18680234253406525\n",
      "R2 values 0.6259, 0.7192, 0.7341; mean R2=0.6930\n",
      "Validation Error: Avg loss: 4.792965 \n",
      "\n",
      "2023-11-08 13:42:10.330076 Epoch 918, Training loss 0.19694025814533234\n",
      "R2 values 0.5823, 0.7362, 0.7450; mean R2=0.6878\n",
      "Validation Error: Avg loss: 4.358206 \n",
      "\n",
      "2023-11-08 13:42:10.794210 Epoch 919, Training loss 0.1849062293767929\n",
      "R2 values 0.5411, 0.7648, 0.7624; mean R2=0.6894\n",
      "Validation Error: Avg loss: 3.792366 \n",
      "\n",
      "2023-11-08 13:42:11.256867 Epoch 920, Training loss 0.28583696484565735\n",
      "R2 values 0.6559, 0.7687, 0.7800; mean R2=0.7349\n",
      "Validation Error: Avg loss: 3.784323 \n",
      "\n",
      "2023-11-08 13:42:11.722061 Epoch 921, Training loss 0.27373960614204407\n",
      "R2 values 0.6065, 0.7378, 0.7280; mean R2=0.6907\n",
      "Validation Error: Avg loss: 4.584303 \n",
      "\n",
      "2023-11-08 13:42:12.177383 Epoch 922, Training loss 0.2381836473941803\n",
      "R2 values 0.5223, 0.7327, 0.7263; mean R2=0.6604\n",
      "Validation Error: Avg loss: 4.662425 \n",
      "\n",
      "2023-11-08 13:42:12.634560 Epoch 923, Training loss 0.19724293053150177\n",
      "R2 values 0.4806, 0.7220, 0.7716; mean R2=0.6581\n",
      "Validation Error: Avg loss: 4.497617 \n",
      "\n",
      "2023-11-08 13:42:13.084838 Epoch 924, Training loss 0.19132737815380096\n",
      "R2 values 0.5610, 0.7379, 0.7852; mean R2=0.6947\n",
      "Validation Error: Avg loss: 3.976361 \n",
      "\n",
      "2023-11-08 13:42:13.625319 Epoch 925, Training loss 0.2151842564344406\n",
      "R2 values 0.5094, 0.7323, 0.8083; mean R2=0.6833\n",
      "Validation Error: Avg loss: 3.876378 \n",
      "\n",
      "2023-11-08 13:42:14.147073 Epoch 926, Training loss 0.21243277192115784\n",
      "R2 values 0.5307, 0.7336, 0.7985; mean R2=0.6876\n",
      "Validation Error: Avg loss: 4.203865 \n",
      "\n",
      "2023-11-08 13:42:14.629971 Epoch 927, Training loss 0.1704891175031662\n",
      "R2 values 0.6054, 0.7728, 0.7508; mean R2=0.7097\n",
      "Validation Error: Avg loss: 4.140236 \n",
      "\n",
      "2023-11-08 13:42:15.094547 Epoch 928, Training loss 0.2302730232477188\n",
      "R2 values 0.6213, 0.7590, 0.7757; mean R2=0.7186\n",
      "Validation Error: Avg loss: 4.160582 \n",
      "\n",
      "2023-11-08 13:42:15.573966 Epoch 929, Training loss 0.23681141436100006\n",
      "R2 values 0.5517, 0.7377, 0.8045; mean R2=0.6980\n",
      "Validation Error: Avg loss: 3.863751 \n",
      "\n",
      "2023-11-08 13:42:16.061080 Epoch 930, Training loss 0.2099306285381317\n",
      "R2 values 0.5675, 0.7711, 0.7858; mean R2=0.7081\n",
      "Validation Error: Avg loss: 3.536760 \n",
      "\n",
      "2023-11-08 13:42:16.520720 Epoch 931, Training loss 0.31955045461654663\n",
      "R2 values 0.5323, 0.7297, 0.8172; mean R2=0.6931\n",
      "Validation Error: Avg loss: 4.063599 \n",
      "\n",
      "2023-11-08 13:42:16.980684 Epoch 932, Training loss 0.19774915277957916\n",
      "R2 values 0.5986, 0.7447, 0.7799; mean R2=0.7078\n",
      "Validation Error: Avg loss: 4.277813 \n",
      "\n",
      "2023-11-08 13:42:17.436129 Epoch 933, Training loss 0.21967065334320068\n",
      "R2 values 0.6658, 0.7300, 0.7731; mean R2=0.7229\n",
      "Validation Error: Avg loss: 4.403592 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:42:17.897329 Epoch 934, Training loss 0.36015641689300537\n",
      "R2 values 0.5248, 0.7336, 0.7606; mean R2=0.6730\n",
      "Validation Error: Avg loss: 4.261337 \n",
      "\n",
      "2023-11-08 13:42:18.367972 Epoch 935, Training loss 0.21151115000247955\n",
      "R2 values 0.5831, 0.7480, 0.7815; mean R2=0.7042\n",
      "Validation Error: Avg loss: 3.948027 \n",
      "\n",
      "2023-11-08 13:42:18.841965 Epoch 936, Training loss 0.2850324809551239\n",
      "R2 values 0.5263, 0.7411, 0.7872; mean R2=0.6848\n",
      "Validation Error: Avg loss: 3.887923 \n",
      "\n",
      "2023-11-08 13:42:19.306450 Epoch 937, Training loss 0.20928239822387695\n",
      "R2 values 0.5072, 0.6912, 0.7667; mean R2=0.6550\n",
      "Validation Error: Avg loss: 4.916601 \n",
      "\n",
      "2023-11-08 13:42:19.771674 Epoch 938, Training loss 0.21710604429244995\n",
      "R2 values 0.5825, 0.7251, 0.7535; mean R2=0.6870\n",
      "Validation Error: Avg loss: 4.503099 \n",
      "\n",
      "2023-11-08 13:42:20.223760 Epoch 939, Training loss 0.2548567056655884\n",
      "R2 values 0.5704, 0.7479, 0.7657; mean R2=0.6947\n",
      "Validation Error: Avg loss: 3.955635 \n",
      "\n",
      "2023-11-08 13:42:20.684974 Epoch 940, Training loss 0.1977919191122055\n",
      "R2 values 0.5669, 0.7380, 0.7800; mean R2=0.6949\n",
      "Validation Error: Avg loss: 3.952079 \n",
      "\n",
      "2023-11-08 13:42:21.137895 Epoch 941, Training loss 0.3028704524040222\n",
      "R2 values 0.6021, 0.7547, 0.7708; mean R2=0.7092\n",
      "Validation Error: Avg loss: 3.747374 \n",
      "\n",
      "2023-11-08 13:42:21.594376 Epoch 942, Training loss 0.19490432739257812\n",
      "R2 values 0.5794, 0.7513, 0.7972; mean R2=0.7093\n",
      "Validation Error: Avg loss: 4.067938 \n",
      "\n",
      "2023-11-08 13:42:22.118864 Epoch 943, Training loss 0.2363971471786499\n",
      "R2 values 0.5548, 0.7617, 0.7592; mean R2=0.6919\n",
      "Validation Error: Avg loss: 4.070049 \n",
      "\n",
      "2023-11-08 13:42:22.580511 Epoch 944, Training loss 0.2081564962863922\n",
      "R2 values 0.5470, 0.7291, 0.8055; mean R2=0.6939\n",
      "Validation Error: Avg loss: 4.027380 \n",
      "\n",
      "2023-11-08 13:42:23.040991 Epoch 945, Training loss 0.22053538262844086\n",
      "R2 values 0.5369, 0.7554, 0.7901; mean R2=0.6941\n",
      "Validation Error: Avg loss: 3.730830 \n",
      "\n",
      "2023-11-08 13:42:23.510284 Epoch 946, Training loss 0.21468162536621094\n",
      "R2 values 0.4575, 0.7491, 0.7707; mean R2=0.6591\n",
      "Validation Error: Avg loss: 4.244913 \n",
      "\n",
      "2023-11-08 13:42:23.967611 Epoch 947, Training loss 0.18268418312072754\n",
      "R2 values 0.5598, 0.7154, 0.7459; mean R2=0.6737\n",
      "Validation Error: Avg loss: 4.657845 \n",
      "\n",
      "2023-11-08 13:42:24.421482 Epoch 948, Training loss 0.17006775736808777\n",
      "R2 values 0.5783, 0.7431, 0.7485; mean R2=0.6900\n",
      "Validation Error: Avg loss: 4.406060 \n",
      "\n",
      "2023-11-08 13:42:25.101555 Epoch 949, Training loss 0.18227601051330566\n",
      "R2 values 0.5856, 0.7249, 0.8004; mean R2=0.7036\n",
      "Validation Error: Avg loss: 4.228552 \n",
      "\n",
      "2023-11-08 13:42:25.552042 Epoch 950, Training loss 0.20493201911449432\n",
      "R2 values 0.5921, 0.7480, 0.7648; mean R2=0.7016\n",
      "Validation Error: Avg loss: 3.862201 \n",
      "\n",
      "2023-11-08 13:42:26.057984 Epoch 951, Training loss 0.24008426070213318\n",
      "R2 values 0.6053, 0.7518, 0.7706; mean R2=0.7093\n",
      "Validation Error: Avg loss: 3.997875 \n",
      "\n",
      "2023-11-08 13:42:26.510989 Epoch 952, Training loss 0.17382356524467468\n",
      "R2 values 0.5299, 0.7262, 0.7669; mean R2=0.6744\n",
      "Validation Error: Avg loss: 4.471770 \n",
      "\n",
      "2023-11-08 13:42:26.968655 Epoch 953, Training loss 0.21363456547260284\n",
      "R2 values 0.5476, 0.7482, 0.7390; mean R2=0.6783\n",
      "Validation Error: Avg loss: 4.280316 \n",
      "\n",
      "2023-11-08 13:42:27.427268 Epoch 954, Training loss 0.1871342658996582\n",
      "R2 values 0.5974, 0.7804, 0.8073; mean R2=0.7284\n",
      "Validation Error: Avg loss: 3.382694 \n",
      "\n",
      "2023-11-08 13:42:27.887648 Epoch 955, Training loss 0.13879501819610596\n",
      "R2 values 0.5206, 0.7654, 0.8203; mean R2=0.7021\n",
      "Validation Error: Avg loss: 3.421898 \n",
      "\n",
      "2023-11-08 13:42:28.341898 Epoch 956, Training loss 0.24345172941684723\n",
      "R2 values 0.6716, 0.7365, 0.8037; mean R2=0.7373\n",
      "Validation Error: Avg loss: 4.060651 \n",
      "\n",
      "2023-11-08 13:42:28.846764 Epoch 957, Training loss 0.23023425042629242\n",
      "R2 values 0.5473, 0.7327, 0.7141; mean R2=0.6647\n",
      "Validation Error: Avg loss: 4.743884 \n",
      "\n",
      "2023-11-08 13:42:29.317369 Epoch 958, Training loss 0.2105020135641098\n",
      "R2 values 0.4788, 0.7467, 0.7522; mean R2=0.6592\n",
      "Validation Error: Avg loss: 4.660399 \n",
      "\n",
      "2023-11-08 13:42:29.774832 Epoch 959, Training loss 0.18014977872371674\n",
      "R2 values 0.5582, 0.7000, 0.7455; mean R2=0.6679\n",
      "Validation Error: Avg loss: 4.656611 \n",
      "\n",
      "2023-11-08 13:42:30.235828 Epoch 960, Training loss 0.16810965538024902\n",
      "R2 values 0.5427, 0.7533, 0.7525; mean R2=0.6828\n",
      "Validation Error: Avg loss: 4.146065 \n",
      "\n",
      "2023-11-08 13:42:30.696089 Epoch 961, Training loss 0.1497478485107422\n",
      "R2 values 0.5616, 0.7224, 0.7935; mean R2=0.6925\n",
      "Validation Error: Avg loss: 4.077327 \n",
      "\n",
      "2023-11-08 13:42:31.145579 Epoch 962, Training loss 0.21586042642593384\n",
      "R2 values 0.5753, 0.7772, 0.7595; mean R2=0.7040\n",
      "Validation Error: Avg loss: 3.741606 \n",
      "\n",
      "2023-11-08 13:42:31.598893 Epoch 963, Training loss 0.16925737261772156\n",
      "R2 values 0.5314, 0.7282, 0.7591; mean R2=0.6729\n",
      "Validation Error: Avg loss: 4.470979 \n",
      "\n",
      "2023-11-08 13:42:32.065109 Epoch 964, Training loss 0.2515614926815033\n",
      "R2 values 0.6660, 0.7688, 0.8026; mean R2=0.7458\n",
      "Validation Error: Avg loss: 3.675034 \n",
      "\n",
      "2023-11-08 13:42:32.515595 Epoch 965, Training loss 0.14813578128814697\n",
      "R2 values 0.5853, 0.7380, 0.7836; mean R2=0.7023\n",
      "Validation Error: Avg loss: 3.921443 \n",
      "\n",
      "2023-11-08 13:42:32.973768 Epoch 966, Training loss 0.17265073955059052\n",
      "R2 values 0.5521, 0.7718, 0.7870; mean R2=0.7036\n",
      "Validation Error: Avg loss: 3.501226 \n",
      "\n",
      "2023-11-08 13:42:33.440550 Epoch 967, Training loss 0.1633453369140625\n",
      "R2 values 0.5875, 0.7399, 0.7771; mean R2=0.7015\n",
      "Validation Error: Avg loss: 4.005283 \n",
      "\n",
      "2023-11-08 13:42:33.894885 Epoch 968, Training loss 0.2144995778799057\n",
      "R2 values 0.5963, 0.7388, 0.7351; mean R2=0.6901\n",
      "Validation Error: Avg loss: 4.355893 \n",
      "\n",
      "2023-11-08 13:42:34.339312 Epoch 969, Training loss 0.24535082280635834\n",
      "R2 values 0.5894, 0.7498, 0.7479; mean R2=0.6957\n",
      "Validation Error: Avg loss: 4.112056 \n",
      "\n",
      "2023-11-08 13:42:34.810479 Epoch 970, Training loss 0.25208359956741333\n",
      "R2 values 0.5789, 0.7714, 0.7652; mean R2=0.7052\n",
      "Validation Error: Avg loss: 3.838909 \n",
      "\n",
      "2023-11-08 13:42:35.281467 Epoch 971, Training loss 0.2340526431798935\n",
      "R2 values 0.5433, 0.7199, 0.7380; mean R2=0.6671\n",
      "Validation Error: Avg loss: 4.303288 \n",
      "\n",
      "2023-11-08 13:42:35.809807 Epoch 972, Training loss 0.26875877380371094\n",
      "R2 values 0.6585, 0.7259, 0.7699; mean R2=0.7181\n",
      "Validation Error: Avg loss: 4.192757 \n",
      "\n",
      "2023-11-08 13:42:36.267964 Epoch 973, Training loss 0.23292599618434906\n",
      "R2 values 0.6803, 0.7320, 0.7875; mean R2=0.7333\n",
      "Validation Error: Avg loss: 4.281047 \n",
      "\n",
      "2023-11-08 13:42:36.731346 Epoch 974, Training loss 0.27232494950294495\n",
      "R2 values 0.5227, 0.7395, 0.7703; mean R2=0.6775\n",
      "Validation Error: Avg loss: 3.990506 \n",
      "\n",
      "2023-11-08 13:42:37.181925 Epoch 975, Training loss 0.2542075216770172\n",
      "R2 values 0.5546, 0.7394, 0.7764; mean R2=0.6902\n",
      "Validation Error: Avg loss: 4.042360 \n",
      "\n",
      "2023-11-08 13:42:37.638771 Epoch 976, Training loss 0.2014860212802887\n",
      "R2 values 0.6037, 0.7515, 0.7680; mean R2=0.7077\n",
      "Validation Error: Avg loss: 3.861778 \n",
      "\n",
      "2023-11-08 13:42:38.099330 Epoch 977, Training loss 0.21792201697826385\n",
      "R2 values 0.6654, 0.7910, 0.7584; mean R2=0.7383\n",
      "Validation Error: Avg loss: 3.492385 \n",
      "\n",
      "2023-11-08 13:42:38.570298 Epoch 978, Training loss 0.21828092634677887\n",
      "R2 values 0.5453, 0.7290, 0.7568; mean R2=0.6770\n",
      "Validation Error: Avg loss: 4.267185 \n",
      "\n",
      "2023-11-08 13:42:39.043913 Epoch 979, Training loss 0.21464677155017853\n",
      "R2 values 0.5995, 0.7028, 0.7780; mean R2=0.6934\n",
      "Validation Error: Avg loss: 4.537519 \n",
      "\n",
      "2023-11-08 13:42:39.512590 Epoch 980, Training loss 0.26325443387031555\n",
      "R2 values 0.5566, 0.7285, 0.7715; mean R2=0.6855\n",
      "Validation Error: Avg loss: 4.406590 \n",
      "\n",
      "2023-11-08 13:42:39.983392 Epoch 981, Training loss 0.28876617550849915\n",
      "R2 values 0.5582, 0.7522, 0.8191; mean R2=0.7098\n",
      "Validation Error: Avg loss: 3.863896 \n",
      "\n",
      "2023-11-08 13:42:40.434833 Epoch 982, Training loss 0.1596589833498001\n",
      "R2 values 0.5178, 0.7328, 0.7670; mean R2=0.6725\n",
      "Validation Error: Avg loss: 4.405200 \n",
      "\n",
      "2023-11-08 13:42:40.894627 Epoch 983, Training loss 0.18422897160053253\n",
      "R2 values 0.5460, 0.7830, 0.7621; mean R2=0.6970\n",
      "Validation Error: Avg loss: 3.800111 \n",
      "\n",
      "2023-11-08 13:42:41.353414 Epoch 984, Training loss 0.16349512338638306\n",
      "R2 values 0.4888, 0.7526, 0.7844; mean R2=0.6753\n",
      "Validation Error: Avg loss: 3.946557 \n",
      "\n",
      "2023-11-08 13:42:41.812378 Epoch 985, Training loss 0.19845321774482727\n",
      "R2 values 0.4908, 0.7759, 0.7445; mean R2=0.6704\n",
      "Validation Error: Avg loss: 3.844215 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:42:42.262354 Epoch 986, Training loss 0.14254127442836761\n",
      "R2 values 0.4855, 0.7879, 0.7491; mean R2=0.6742\n",
      "Validation Error: Avg loss: 3.939263 \n",
      "\n",
      "2023-11-08 13:42:42.720792 Epoch 987, Training loss 0.1815713346004486\n",
      "R2 values 0.5335, 0.7824, 0.7592; mean R2=0.6917\n",
      "Validation Error: Avg loss: 3.790214 \n",
      "\n",
      "2023-11-08 13:42:43.184607 Epoch 988, Training loss 0.2002732753753662\n",
      "R2 values 0.5876, 0.7502, 0.7927; mean R2=0.7102\n",
      "Validation Error: Avg loss: 3.890778 \n",
      "\n",
      "2023-11-08 13:42:43.653427 Epoch 989, Training loss 0.17785616219043732\n",
      "R2 values 0.6897, 0.7393, 0.7807; mean R2=0.7366\n",
      "Validation Error: Avg loss: 3.945875 \n",
      "\n",
      "2023-11-08 13:42:44.174101 Epoch 990, Training loss 0.20738521218299866\n",
      "R2 values 0.5658, 0.7531, 0.8091; mean R2=0.7093\n",
      "Validation Error: Avg loss: 3.518453 \n",
      "\n",
      "2023-11-08 13:42:44.672999 Epoch 991, Training loss 0.1803642362356186\n",
      "R2 values 0.6351, 0.7509, 0.8175; mean R2=0.7345\n",
      "Validation Error: Avg loss: 3.680115 \n",
      "\n",
      "2023-11-08 13:42:45.132344 Epoch 992, Training loss 0.19898943603038788\n",
      "R2 values 0.6743, 0.7877, 0.7682; mean R2=0.7434\n",
      "Validation Error: Avg loss: 3.688281 \n",
      "\n",
      "2023-11-08 13:42:45.589746 Epoch 993, Training loss 0.1658114194869995\n",
      "R2 values 0.6589, 0.7546, 0.7847; mean R2=0.7328\n",
      "Validation Error: Avg loss: 3.797711 \n",
      "\n",
      "2023-11-08 13:42:46.081975 Epoch 994, Training loss 0.1534614861011505\n",
      "R2 values 0.7002, 0.7851, 0.7733; mean R2=0.7529\n",
      "Validation Error: Avg loss: 3.313739 \n",
      "\n",
      "2023-11-08 13:42:46.536833 Epoch 995, Training loss 0.18079446256160736\n",
      "R2 values 0.6046, 0.7616, 0.7891; mean R2=0.7185\n",
      "Validation Error: Avg loss: 3.734787 \n",
      "\n",
      "2023-11-08 13:42:46.997087 Epoch 996, Training loss 0.17414535582065582\n",
      "R2 values 0.6357, 0.7286, 0.7699; mean R2=0.7114\n",
      "Validation Error: Avg loss: 4.201418 \n",
      "\n",
      "2023-11-08 13:42:47.481771 Epoch 997, Training loss 0.2581634521484375\n",
      "R2 values 0.5615, 0.7371, 0.7640; mean R2=0.6875\n",
      "Validation Error: Avg loss: 4.285962 \n",
      "\n",
      "2023-11-08 13:42:47.945239 Epoch 998, Training loss 0.16136716306209564\n",
      "R2 values 0.5595, 0.7697, 0.7545; mean R2=0.6946\n",
      "Validation Error: Avg loss: 3.770373 \n",
      "\n",
      "2023-11-08 13:42:48.409429 Epoch 999, Training loss 0.14740456640720367\n",
      "R2 values 0.5579, 0.7606, 0.7847; mean R2=0.7011\n",
      "Validation Error: Avg loss: 3.845776 \n",
      "\n",
      "2023-11-08 13:42:48.880364 Epoch 1000, Training loss 0.2139769196510315\n",
      "R2 values 0.6610, 0.7603, 0.7321; mean R2=0.7178\n",
      "Validation Error: Avg loss: 3.955053 \n",
      "\n",
      "2023-11-08 13:42:49.351074 Epoch 1001, Training loss 0.16768097877502441\n",
      "R2 values 0.5718, 0.7527, 0.7653; mean R2=0.6966\n",
      "Validation Error: Avg loss: 3.918025 \n",
      "\n",
      "2023-11-08 13:42:49.817644 Epoch 1002, Training loss 0.15228357911109924\n",
      "R2 values 0.6293, 0.7763, 0.7944; mean R2=0.7333\n",
      "Validation Error: Avg loss: 3.438022 \n",
      "\n",
      "2023-11-08 13:42:50.270316 Epoch 1003, Training loss 0.18338562548160553\n",
      "R2 values 0.6282, 0.7808, 0.8248; mean R2=0.7446\n",
      "Validation Error: Avg loss: 3.189968 \n",
      "\n",
      "2023-11-08 13:42:50.725147 Epoch 1004, Training loss 0.25167420506477356\n",
      "R2 values 0.6238, 0.7736, 0.7761; mean R2=0.7245\n",
      "Validation Error: Avg loss: 3.487753 \n",
      "\n",
      "2023-11-08 13:42:51.186856 Epoch 1005, Training loss 0.17780838906764984\n",
      "R2 values 0.6151, 0.7621, 0.7458; mean R2=0.7076\n",
      "Validation Error: Avg loss: 4.086451 \n",
      "\n",
      "2023-11-08 13:42:51.638053 Epoch 1006, Training loss 0.1474834531545639\n",
      "R2 values 0.5826, 0.7520, 0.7454; mean R2=0.6933\n",
      "Validation Error: Avg loss: 4.437588 \n",
      "\n",
      "2023-11-08 13:42:52.101964 Epoch 1007, Training loss 0.15400582551956177\n",
      "R2 values 0.6022, 0.7101, 0.7622; mean R2=0.6915\n",
      "Validation Error: Avg loss: 4.707965 \n",
      "\n",
      "2023-11-08 13:42:52.556389 Epoch 1008, Training loss 0.15940432250499725\n",
      "R2 values 0.5357, 0.7498, 0.7699; mean R2=0.6851\n",
      "Validation Error: Avg loss: 4.269868 \n",
      "\n",
      "2023-11-08 13:42:53.020898 Epoch 1009, Training loss 0.14796480536460876\n",
      "R2 values 0.5695, 0.7307, 0.7521; mean R2=0.6841\n",
      "Validation Error: Avg loss: 4.463367 \n",
      "\n",
      "2023-11-08 13:42:53.480632 Epoch 1010, Training loss 0.15577660501003265\n",
      "R2 values 0.5315, 0.7609, 0.7643; mean R2=0.6856\n",
      "Validation Error: Avg loss: 3.948468 \n",
      "\n",
      "2023-11-08 13:42:53.950181 Epoch 1011, Training loss 0.20042888820171356\n",
      "R2 values 0.5794, 0.7374, 0.8049; mean R2=0.7072\n",
      "Validation Error: Avg loss: 4.140640 \n",
      "\n",
      "2023-11-08 13:42:54.408011 Epoch 1012, Training loss 0.1503864973783493\n",
      "R2 values 0.5702, 0.7621, 0.7674; mean R2=0.6999\n",
      "Validation Error: Avg loss: 3.903613 \n",
      "\n",
      "2023-11-08 13:42:54.889319 Epoch 1013, Training loss 0.13534505665302277\n",
      "R2 values 0.5937, 0.7380, 0.7437; mean R2=0.6918\n",
      "Validation Error: Avg loss: 4.490733 \n",
      "\n",
      "2023-11-08 13:42:55.418494 Epoch 1014, Training loss 0.1980670690536499\n",
      "R2 values 0.6687, 0.7708, 0.7179; mean R2=0.7192\n",
      "Validation Error: Avg loss: 3.837642 \n",
      "\n",
      "2023-11-08 13:42:55.883782 Epoch 1015, Training loss 0.19050335884094238\n",
      "R2 values 0.5735, 0.7685, 0.8119; mean R2=0.7180\n",
      "Validation Error: Avg loss: 3.488463 \n",
      "\n",
      "2023-11-08 13:42:56.347883 Epoch 1016, Training loss 0.16697277128696442\n",
      "R2 values 0.5623, 0.7712, 0.7898; mean R2=0.7078\n",
      "Validation Error: Avg loss: 3.560709 \n",
      "\n",
      "2023-11-08 13:42:56.808663 Epoch 1017, Training loss 0.271467000246048\n",
      "R2 values 0.5429, 0.7776, 0.7972; mean R2=0.7059\n",
      "Validation Error: Avg loss: 3.813769 \n",
      "\n",
      "2023-11-08 13:42:57.326790 Epoch 1018, Training loss 0.19546113908290863\n",
      "R2 values 0.5493, 0.7559, 0.7747; mean R2=0.6933\n",
      "Validation Error: Avg loss: 3.965533 \n",
      "\n",
      "2023-11-08 13:42:57.786709 Epoch 1019, Training loss 0.15360300242900848\n",
      "R2 values 0.5282, 0.7587, 0.8040; mean R2=0.6970\n",
      "Validation Error: Avg loss: 3.932492 \n",
      "\n",
      "2023-11-08 13:42:58.246397 Epoch 1020, Training loss 0.16441677510738373\n",
      "R2 values 0.5876, 0.7937, 0.7947; mean R2=0.7253\n",
      "Validation Error: Avg loss: 3.207087 \n",
      "\n",
      "2023-11-08 13:42:58.724157 Epoch 1021, Training loss 0.15771901607513428\n",
      "R2 values 0.5862, 0.8034, 0.7935; mean R2=0.7277\n",
      "Validation Error: Avg loss: 3.336594 \n",
      "\n",
      "2023-11-08 13:42:59.207170 Epoch 1022, Training loss 0.19217218458652496\n",
      "R2 values 0.5299, 0.8083, 0.7764; mean R2=0.7049\n",
      "Validation Error: Avg loss: 3.440691 \n",
      "\n",
      "2023-11-08 13:42:59.678496 Epoch 1023, Training loss 0.20026274025440216\n",
      "R2 values 0.5594, 0.7929, 0.7488; mean R2=0.7004\n",
      "Validation Error: Avg loss: 3.891385 \n",
      "\n",
      "2023-11-08 13:43:00.200208 Epoch 1024, Training loss 0.22601893544197083\n",
      "R2 values 0.5418, 0.7442, 0.7264; mean R2=0.6708\n",
      "Validation Error: Avg loss: 4.425095 \n",
      "\n",
      "2023-11-08 13:43:00.674994 Epoch 1025, Training loss 0.1495354324579239\n",
      "R2 values 0.6105, 0.7425, 0.7928; mean R2=0.7152\n",
      "Validation Error: Avg loss: 3.743106 \n",
      "\n",
      "2023-11-08 13:43:01.156048 Epoch 1026, Training loss 0.2945978045463562\n",
      "R2 values 0.5545, 0.7484, 0.7814; mean R2=0.6948\n",
      "Validation Error: Avg loss: 3.869184 \n",
      "\n",
      "2023-11-08 13:43:01.621085 Epoch 1027, Training loss 0.17939090728759766\n",
      "R2 values 0.5504, 0.7690, 0.7710; mean R2=0.6968\n",
      "Validation Error: Avg loss: 4.039505 \n",
      "\n",
      "2023-11-08 13:43:02.085974 Epoch 1028, Training loss 0.16316655278205872\n",
      "R2 values 0.5986, 0.7488, 0.7924; mean R2=0.7133\n",
      "Validation Error: Avg loss: 4.268444 \n",
      "\n",
      "2023-11-08 13:43:02.542247 Epoch 1029, Training loss 0.2651420831680298\n",
      "R2 values 0.5608, 0.7484, 0.8090; mean R2=0.7061\n",
      "Validation Error: Avg loss: 3.913415 \n",
      "\n",
      "2023-11-08 13:43:02.998839 Epoch 1030, Training loss 0.18460653722286224\n",
      "R2 values 0.5478, 0.7743, 0.8226; mean R2=0.7149\n",
      "Validation Error: Avg loss: 3.505195 \n",
      "\n",
      "2023-11-08 13:43:03.457637 Epoch 1031, Training loss 0.20829440653324127\n",
      "R2 values 0.5588, 0.7720, 0.7531; mean R2=0.6946\n",
      "Validation Error: Avg loss: 3.846567 \n",
      "\n",
      "2023-11-08 13:43:03.925726 Epoch 1032, Training loss 0.17314110696315765\n",
      "R2 values 0.5078, 0.7247, 0.7548; mean R2=0.6624\n",
      "Validation Error: Avg loss: 4.518731 \n",
      "\n",
      "2023-11-08 13:43:04.581206 Epoch 1033, Training loss 0.19477985799312592\n",
      "R2 values 0.5374, 0.7734, 0.7874; mean R2=0.6994\n",
      "Validation Error: Avg loss: 3.846630 \n",
      "\n",
      "2023-11-08 13:43:05.112589 Epoch 1034, Training loss 0.2071220725774765\n",
      "R2 values 0.5481, 0.7441, 0.7806; mean R2=0.6909\n",
      "Validation Error: Avg loss: 4.169656 \n",
      "\n",
      "2023-11-08 13:43:05.566672 Epoch 1035, Training loss 0.16658514738082886\n",
      "R2 values 0.5506, 0.7716, 0.7899; mean R2=0.7040\n",
      "Validation Error: Avg loss: 3.575318 \n",
      "\n",
      "2023-11-08 13:43:06.025356 Epoch 1036, Training loss 0.20319058001041412\n",
      "R2 values 0.5154, 0.7434, 0.7743; mean R2=0.6777\n",
      "Validation Error: Avg loss: 4.091197 \n",
      "\n",
      "2023-11-08 13:43:06.479661 Epoch 1037, Training loss 0.1978188455104828\n",
      "R2 values 0.5475, 0.7378, 0.7595; mean R2=0.6816\n",
      "Validation Error: Avg loss: 4.426254 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:43:06.943762 Epoch 1038, Training loss 0.14555245637893677\n",
      "R2 values 0.4961, 0.7497, 0.7827; mean R2=0.6762\n",
      "Validation Error: Avg loss: 4.376618 \n",
      "\n",
      "2023-11-08 13:43:07.402952 Epoch 1039, Training loss 0.2031460702419281\n",
      "R2 values 0.5317, 0.7465, 0.7375; mean R2=0.6719\n",
      "Validation Error: Avg loss: 4.403844 \n",
      "\n",
      "2023-11-08 13:43:07.864672 Epoch 1040, Training loss 0.15286806225776672\n",
      "R2 values 0.4843, 0.7623, 0.7728; mean R2=0.6731\n",
      "Validation Error: Avg loss: 3.807130 \n",
      "\n",
      "2023-11-08 13:43:08.359870 Epoch 1041, Training loss 0.18858319520950317\n",
      "R2 values 0.5384, 0.7719, 0.7768; mean R2=0.6957\n",
      "Validation Error: Avg loss: 3.775079 \n",
      "\n",
      "2023-11-08 13:43:08.816158 Epoch 1042, Training loss 0.15390922129154205\n",
      "R2 values 0.5853, 0.7822, 0.7822; mean R2=0.7166\n",
      "Validation Error: Avg loss: 3.536963 \n",
      "\n",
      "2023-11-08 13:43:09.278207 Epoch 1043, Training loss 0.15868374705314636\n",
      "R2 values 0.5914, 0.7627, 0.7147; mean R2=0.6896\n",
      "Validation Error: Avg loss: 4.325881 \n",
      "\n",
      "2023-11-08 13:43:09.741735 Epoch 1044, Training loss 0.18180981278419495\n",
      "R2 values 0.5562, 0.7468, 0.7810; mean R2=0.6947\n",
      "Validation Error: Avg loss: 4.189654 \n",
      "\n",
      "2023-11-08 13:43:10.203281 Epoch 1045, Training loss 0.23564310371875763\n",
      "R2 values 0.5923, 0.7712, 0.7678; mean R2=0.7104\n",
      "Validation Error: Avg loss: 3.588705 \n",
      "\n",
      "2023-11-08 13:43:10.662639 Epoch 1046, Training loss 0.1476830542087555\n",
      "R2 values 0.5610, 0.7511, 0.7725; mean R2=0.6949\n",
      "Validation Error: Avg loss: 3.760988 \n",
      "\n",
      "2023-11-08 13:43:11.123646 Epoch 1047, Training loss 0.2986869215965271\n",
      "R2 values 0.6562, 0.7365, 0.7354; mean R2=0.7094\n",
      "Validation Error: Avg loss: 4.121872 \n",
      "\n",
      "2023-11-08 13:43:11.577179 Epoch 1048, Training loss 0.16200444102287292\n",
      "R2 values 0.5011, 0.7531, 0.7707; mean R2=0.6750\n",
      "Validation Error: Avg loss: 4.361931 \n",
      "\n",
      "2023-11-08 13:43:12.036031 Epoch 1049, Training loss 0.18520444631576538\n",
      "R2 values 0.6316, 0.7605, 0.7445; mean R2=0.7122\n",
      "Validation Error: Avg loss: 4.251099 \n",
      "\n",
      "2023-11-08 13:43:12.486781 Epoch 1050, Training loss 0.16642621159553528\n",
      "R2 values 0.4906, 0.6960, 0.7715; mean R2=0.6527\n",
      "Validation Error: Avg loss: 4.920193 \n",
      "\n",
      "2023-11-08 13:43:12.944838 Epoch 1051, Training loss 0.18557360768318176\n",
      "R2 values 0.5702, 0.7201, 0.7946; mean R2=0.6950\n",
      "Validation Error: Avg loss: 4.133829 \n",
      "\n",
      "2023-11-08 13:43:13.465853 Epoch 1052, Training loss 0.2354980707168579\n",
      "R2 values 0.5393, 0.7327, 0.7720; mean R2=0.6813\n",
      "Validation Error: Avg loss: 4.299436 \n",
      "\n",
      "2023-11-08 13:43:13.937663 Epoch 1053, Training loss 0.17265355587005615\n",
      "R2 values 0.5381, 0.7504, 0.7898; mean R2=0.6927\n",
      "Validation Error: Avg loss: 4.126952 \n",
      "\n",
      "2023-11-08 13:43:14.399807 Epoch 1054, Training loss 0.18748097121715546\n",
      "R2 values 0.4169, 0.7397, 0.7378; mean R2=0.6315\n",
      "Validation Error: Avg loss: 4.399481 \n",
      "\n",
      "2023-11-08 13:43:14.857319 Epoch 1055, Training loss 0.14068810641765594\n",
      "R2 values 0.5567, 0.7753, 0.7638; mean R2=0.6986\n",
      "Validation Error: Avg loss: 3.738789 \n",
      "\n",
      "2023-11-08 13:43:15.309219 Epoch 1056, Training loss 0.14224930107593536\n",
      "R2 values 0.4945, 0.7596, 0.7606; mean R2=0.6715\n",
      "Validation Error: Avg loss: 4.063241 \n",
      "\n",
      "2023-11-08 13:43:15.843541 Epoch 1057, Training loss 0.21057868003845215\n",
      "R2 values 0.5330, 0.7479, 0.8096; mean R2=0.6968\n",
      "Validation Error: Avg loss: 3.987277 \n",
      "\n",
      "2023-11-08 13:43:16.301159 Epoch 1058, Training loss 0.2082667052745819\n",
      "R2 values 0.6602, 0.7624, 0.7608; mean R2=0.7278\n",
      "Validation Error: Avg loss: 4.265447 \n",
      "\n",
      "2023-11-08 13:43:16.761646 Epoch 1059, Training loss 0.18734192848205566\n",
      "R2 values 0.5206, 0.7214, 0.7619; mean R2=0.6680\n",
      "Validation Error: Avg loss: 4.874591 \n",
      "\n",
      "2023-11-08 13:43:17.236736 Epoch 1060, Training loss 0.16690382361412048\n",
      "R2 values 0.5045, 0.7387, 0.7608; mean R2=0.6680\n",
      "Validation Error: Avg loss: 4.358363 \n",
      "\n",
      "2023-11-08 13:43:17.695545 Epoch 1061, Training loss 0.1626865267753601\n",
      "R2 values 0.6340, 0.7427, 0.7772; mean R2=0.7179\n",
      "Validation Error: Avg loss: 3.908531 \n",
      "\n",
      "2023-11-08 13:43:18.155402 Epoch 1062, Training loss 0.17294132709503174\n",
      "R2 values 0.5924, 0.7110, 0.7630; mean R2=0.6888\n",
      "Validation Error: Avg loss: 4.467001 \n",
      "\n",
      "2023-11-08 13:43:18.614209 Epoch 1063, Training loss 0.17760726809501648\n",
      "R2 values 0.6132, 0.7500, 0.7456; mean R2=0.7029\n",
      "Validation Error: Avg loss: 4.103839 \n",
      "\n",
      "2023-11-08 13:43:19.104153 Epoch 1064, Training loss 0.15950360894203186\n",
      "R2 values 0.5934, 0.7670, 0.7379; mean R2=0.6994\n",
      "Validation Error: Avg loss: 3.887167 \n",
      "\n",
      "2023-11-08 13:43:19.566530 Epoch 1065, Training loss 0.18904747068881989\n",
      "R2 values 0.5475, 0.7493, 0.7437; mean R2=0.6802\n",
      "Validation Error: Avg loss: 4.385630 \n",
      "\n",
      "2023-11-08 13:43:20.021672 Epoch 1066, Training loss 0.17678652703762054\n",
      "R2 values 0.5831, 0.7372, 0.7797; mean R2=0.7000\n",
      "Validation Error: Avg loss: 4.344594 \n",
      "\n",
      "2023-11-08 13:43:20.488430 Epoch 1067, Training loss 0.17785604298114777\n",
      "R2 values 0.6061, 0.7496, 0.7754; mean R2=0.7104\n",
      "Validation Error: Avg loss: 3.921477 \n",
      "\n",
      "2023-11-08 13:43:20.952564 Epoch 1068, Training loss 0.2232014685869217\n",
      "R2 values 0.4289, 0.7417, 0.7739; mean R2=0.6482\n",
      "Validation Error: Avg loss: 4.059881 \n",
      "\n",
      "2023-11-08 13:43:21.648444 Epoch 1069, Training loss 0.15799860656261444\n",
      "R2 values 0.5405, 0.7640, 0.7487; mean R2=0.6844\n",
      "Validation Error: Avg loss: 3.946088 \n",
      "\n",
      "2023-11-08 13:43:22.162433 Epoch 1070, Training loss 0.14691010117530823\n",
      "R2 values 0.4594, 0.7610, 0.7506; mean R2=0.6570\n",
      "Validation Error: Avg loss: 4.235645 \n",
      "\n",
      "2023-11-08 13:43:22.620272 Epoch 1071, Training loss 0.1817065179347992\n",
      "R2 values 0.5967, 0.7368, 0.7537; mean R2=0.6957\n",
      "Validation Error: Avg loss: 4.279100 \n",
      "\n",
      "2023-11-08 13:43:23.082661 Epoch 1072, Training loss 0.14213937520980835\n",
      "R2 values 0.5875, 0.7404, 0.7490; mean R2=0.6923\n",
      "Validation Error: Avg loss: 4.432873 \n",
      "\n",
      "2023-11-08 13:43:23.550515 Epoch 1073, Training loss 0.16811878979206085\n",
      "R2 values 0.5665, 0.7428, 0.7920; mean R2=0.7004\n",
      "Validation Error: Avg loss: 4.022580 \n",
      "\n",
      "2023-11-08 13:43:24.045596 Epoch 1074, Training loss 0.16835926473140717\n",
      "R2 values 0.5304, 0.7199, 0.7915; mean R2=0.6806\n",
      "Validation Error: Avg loss: 4.325955 \n",
      "\n",
      "2023-11-08 13:43:24.502903 Epoch 1075, Training loss 0.15277497470378876\n",
      "R2 values 0.5522, 0.7534, 0.8108; mean R2=0.7055\n",
      "Validation Error: Avg loss: 3.850784 \n",
      "\n",
      "2023-11-08 13:43:24.973156 Epoch 1076, Training loss 0.1676333248615265\n",
      "R2 values 0.5917, 0.7488, 0.7637; mean R2=0.7014\n",
      "Validation Error: Avg loss: 3.982647 \n",
      "\n",
      "2023-11-08 13:43:25.438227 Epoch 1077, Training loss 0.15366065502166748\n",
      "R2 values 0.6028, 0.7332, 0.7248; mean R2=0.6869\n",
      "Validation Error: Avg loss: 4.422674 \n",
      "\n",
      "2023-11-08 13:43:25.903262 Epoch 1078, Training loss 0.17147482931613922\n",
      "R2 values 0.5872, 0.7356, 0.7754; mean R2=0.6994\n",
      "Validation Error: Avg loss: 4.077026 \n",
      "\n",
      "2023-11-08 13:43:26.362521 Epoch 1079, Training loss 0.1309615671634674\n",
      "R2 values 0.5885, 0.7707, 0.7776; mean R2=0.7123\n",
      "Validation Error: Avg loss: 3.852452 \n",
      "\n",
      "2023-11-08 13:43:26.823147 Epoch 1080, Training loss 0.1561221033334732\n",
      "R2 values 0.5813, 0.7728, 0.8175; mean R2=0.7238\n",
      "Validation Error: Avg loss: 3.520186 \n",
      "\n",
      "2023-11-08 13:43:27.283284 Epoch 1081, Training loss 0.1369723379611969\n",
      "R2 values 0.6152, 0.7547, 0.7791; mean R2=0.7164\n",
      "Validation Error: Avg loss: 3.826828 \n",
      "\n",
      "2023-11-08 13:43:27.744475 Epoch 1082, Training loss 0.13226720690727234\n",
      "R2 values 0.5291, 0.7366, 0.7809; mean R2=0.6822\n",
      "Validation Error: Avg loss: 4.109852 \n",
      "\n",
      "2023-11-08 13:43:28.206190 Epoch 1083, Training loss 0.12093119323253632\n",
      "R2 values 0.5549, 0.7649, 0.7839; mean R2=0.7012\n",
      "Validation Error: Avg loss: 3.853198 \n",
      "\n",
      "2023-11-08 13:43:28.670642 Epoch 1084, Training loss 0.1622237116098404\n",
      "R2 values 0.5682, 0.7635, 0.7851; mean R2=0.7056\n",
      "Validation Error: Avg loss: 3.798232 \n",
      "\n",
      "2023-11-08 13:43:29.163677 Epoch 1085, Training loss 0.1991986632347107\n",
      "R2 values 0.6595, 0.7694, 0.7623; mean R2=0.7304\n",
      "Validation Error: Avg loss: 3.754614 \n",
      "\n",
      "2023-11-08 13:43:29.636659 Epoch 1086, Training loss 0.18098768591880798\n",
      "R2 values 0.6885, 0.7986, 0.7763; mean R2=0.7545\n",
      "Validation Error: Avg loss: 3.192116 \n",
      "\n",
      "2023-11-08 13:43:30.102138 Epoch 1087, Training loss 0.1682022511959076\n",
      "R2 values 0.6594, 0.7965, 0.7780; mean R2=0.7446\n",
      "Validation Error: Avg loss: 3.296376 \n",
      "\n",
      "2023-11-08 13:43:30.566369 Epoch 1088, Training loss 0.16266793012619019\n",
      "R2 values 0.5756, 0.7648, 0.7393; mean R2=0.6932\n",
      "Validation Error: Avg loss: 4.055437 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:43:31.031549 Epoch 1089, Training loss 0.1715170443058014\n",
      "R2 values 0.5702, 0.7335, 0.7529; mean R2=0.6855\n",
      "Validation Error: Avg loss: 4.518481 \n",
      "\n",
      "2023-11-08 13:43:31.494158 Epoch 1090, Training loss 0.25841593742370605\n",
      "R2 values 0.6293, 0.7632, 0.7793; mean R2=0.7239\n",
      "Validation Error: Avg loss: 3.967117 \n",
      "\n",
      "2023-11-08 13:43:31.963188 Epoch 1091, Training loss 0.13316921889781952\n",
      "R2 values 0.6522, 0.7231, 0.7874; mean R2=0.7209\n",
      "Validation Error: Avg loss: 4.164433 \n",
      "\n",
      "2023-11-08 13:43:32.429424 Epoch 1092, Training loss 0.1688658893108368\n",
      "R2 values 0.6171, 0.7116, 0.7878; mean R2=0.7055\n",
      "Validation Error: Avg loss: 4.456089 \n",
      "\n",
      "2023-11-08 13:43:32.951187 Epoch 1093, Training loss 0.15599851310253143\n",
      "R2 values 0.5395, 0.7436, 0.7566; mean R2=0.6799\n",
      "Validation Error: Avg loss: 4.097792 \n",
      "\n",
      "2023-11-08 13:43:33.414317 Epoch 1094, Training loss 0.16645249724388123\n",
      "R2 values 0.4862, 0.7471, 0.7681; mean R2=0.6672\n",
      "Validation Error: Avg loss: 4.116887 \n",
      "\n",
      "2023-11-08 13:43:33.877044 Epoch 1095, Training loss 0.15288573503494263\n",
      "R2 values 0.5261, 0.7519, 0.7571; mean R2=0.6783\n",
      "Validation Error: Avg loss: 3.975947 \n",
      "\n",
      "2023-11-08 13:43:34.335516 Epoch 1096, Training loss 0.23282025754451752\n",
      "R2 values 0.5574, 0.7471, 0.7785; mean R2=0.6943\n",
      "Validation Error: Avg loss: 4.053227 \n",
      "\n",
      "2023-11-08 13:43:34.804109 Epoch 1097, Training loss 0.1677839756011963\n",
      "R2 values 0.5977, 0.7619, 0.7406; mean R2=0.7001\n",
      "Validation Error: Avg loss: 3.993765 \n",
      "\n",
      "2023-11-08 13:43:35.276855 Epoch 1098, Training loss 0.19830010831356049\n",
      "R2 values 0.5249, 0.7490, 0.7124; mean R2=0.6621\n",
      "Validation Error: Avg loss: 4.192393 \n",
      "\n",
      "2023-11-08 13:43:35.741741 Epoch 1099, Training loss 0.15549010038375854\n",
      "R2 values 0.5834, 0.7421, 0.7347; mean R2=0.6867\n",
      "Validation Error: Avg loss: 4.173659 \n",
      "\n",
      "2023-11-08 13:43:36.192219 Epoch 1100, Training loss 0.17383268475532532\n",
      "R2 values 0.5200, 0.7431, 0.7604; mean R2=0.6745\n",
      "Validation Error: Avg loss: 4.104652 \n",
      "\n",
      "2023-11-08 13:43:36.649841 Epoch 1101, Training loss 0.19231872260570526\n",
      "R2 values 0.5667, 0.7645, 0.7515; mean R2=0.6942\n",
      "Validation Error: Avg loss: 3.898745 \n",
      "\n",
      "2023-11-08 13:43:37.120595 Epoch 1102, Training loss 0.14743857085704803\n",
      "R2 values 0.5489, 0.7551, 0.7857; mean R2=0.6966\n",
      "Validation Error: Avg loss: 4.086390 \n",
      "\n",
      "2023-11-08 13:43:37.574124 Epoch 1103, Training loss 0.13130544126033783\n",
      "R2 values 0.5129, 0.7435, 0.8057; mean R2=0.6874\n",
      "Validation Error: Avg loss: 4.198428 \n",
      "\n",
      "2023-11-08 13:43:38.074066 Epoch 1104, Training loss 0.1883576214313507\n",
      "R2 values 0.4730, 0.7445, 0.7526; mean R2=0.6567\n",
      "Validation Error: Avg loss: 4.228899 \n",
      "\n",
      "2023-11-08 13:43:38.530311 Epoch 1105, Training loss 0.12886841595172882\n",
      "R2 values 0.4908, 0.7562, 0.8047; mean R2=0.6839\n",
      "Validation Error: Avg loss: 3.863291 \n",
      "\n",
      "2023-11-08 13:43:38.988350 Epoch 1106, Training loss 0.15250660479068756\n",
      "R2 values 0.5879, 0.7483, 0.7471; mean R2=0.6944\n",
      "Validation Error: Avg loss: 4.295584 \n",
      "\n",
      "2023-11-08 13:43:39.458484 Epoch 1107, Training loss 0.15754610300064087\n",
      "R2 values 0.5114, 0.7786, 0.7539; mean R2=0.6813\n",
      "Validation Error: Avg loss: 3.874872 \n",
      "\n",
      "2023-11-08 13:43:39.920210 Epoch 1108, Training loss 0.15155653655529022\n",
      "R2 values 0.5871, 0.7780, 0.7529; mean R2=0.7060\n",
      "Validation Error: Avg loss: 3.806876 \n",
      "\n",
      "2023-11-08 13:43:40.375428 Epoch 1109, Training loss 0.1680397242307663\n",
      "R2 values 0.5810, 0.7525, 0.7819; mean R2=0.7052\n",
      "Validation Error: Avg loss: 3.766626 \n",
      "\n",
      "2023-11-08 13:43:40.839764 Epoch 1110, Training loss 0.1872248500585556\n",
      "R2 values 0.5438, 0.7627, 0.7441; mean R2=0.6835\n",
      "Validation Error: Avg loss: 3.816915 \n",
      "\n",
      "2023-11-08 13:43:41.299557 Epoch 1111, Training loss 0.16444340348243713\n",
      "R2 values 0.5896, 0.7424, 0.7447; mean R2=0.6923\n",
      "Validation Error: Avg loss: 4.093304 \n",
      "\n",
      "2023-11-08 13:43:41.754387 Epoch 1112, Training loss 0.14684996008872986\n",
      "R2 values 0.6458, 0.7581, 0.7441; mean R2=0.7160\n",
      "Validation Error: Avg loss: 4.105328 \n",
      "\n",
      "2023-11-08 13:43:42.206989 Epoch 1113, Training loss 0.1380733698606491\n",
      "R2 values 0.6740, 0.7716, 0.7410; mean R2=0.7289\n",
      "Validation Error: Avg loss: 3.855186 \n",
      "\n",
      "2023-11-08 13:43:42.664077 Epoch 1114, Training loss 0.162509024143219\n",
      "R2 values 0.6858, 0.7749, 0.7384; mean R2=0.7330\n",
      "Validation Error: Avg loss: 3.647798 \n",
      "\n",
      "2023-11-08 13:43:43.295615 Epoch 1115, Training loss 0.14830508828163147\n",
      "R2 values 0.6693, 0.7692, 0.7781; mean R2=0.7388\n",
      "Validation Error: Avg loss: 3.653334 \n",
      "\n",
      "2023-11-08 13:43:43.860535 Epoch 1116, Training loss 0.15280649065971375\n",
      "R2 values 0.5972, 0.7807, 0.7756; mean R2=0.7178\n",
      "Validation Error: Avg loss: 3.628418 \n",
      "\n",
      "2023-11-08 13:43:44.345164 Epoch 1117, Training loss 0.15143652260303497\n",
      "R2 values 0.5382, 0.7674, 0.7622; mean R2=0.6893\n",
      "Validation Error: Avg loss: 3.891187 \n",
      "\n",
      "2023-11-08 13:43:44.825933 Epoch 1118, Training loss 0.13838078081607819\n",
      "R2 values 0.4688, 0.7693, 0.7479; mean R2=0.6620\n",
      "Validation Error: Avg loss: 4.072525 \n",
      "\n",
      "2023-11-08 13:43:45.340644 Epoch 1119, Training loss 0.1562509983778\n",
      "R2 values 0.5032, 0.7526, 0.7411; mean R2=0.6656\n",
      "Validation Error: Avg loss: 4.472854 \n",
      "\n",
      "2023-11-08 13:43:45.809155 Epoch 1120, Training loss 0.17714367806911469\n",
      "R2 values 0.5444, 0.7644, 0.8100; mean R2=0.7063\n",
      "Validation Error: Avg loss: 3.789443 \n",
      "\n",
      "2023-11-08 13:43:46.271197 Epoch 1121, Training loss 0.17193864285945892\n",
      "R2 values 0.5673, 0.7670, 0.7733; mean R2=0.7025\n",
      "Validation Error: Avg loss: 3.722508 \n",
      "\n",
      "2023-11-08 13:43:46.753316 Epoch 1122, Training loss 0.16838383674621582\n",
      "R2 values 0.5643, 0.7641, 0.7691; mean R2=0.6992\n",
      "Validation Error: Avg loss: 3.779812 \n",
      "\n",
      "2023-11-08 13:43:47.226921 Epoch 1123, Training loss 0.1270769089460373\n",
      "R2 values 0.4933, 0.7367, 0.7642; mean R2=0.6647\n",
      "Validation Error: Avg loss: 4.189631 \n",
      "\n",
      "2023-11-08 13:43:47.684793 Epoch 1124, Training loss 0.15976117551326752\n",
      "R2 values 0.5472, 0.7583, 0.7823; mean R2=0.6960\n",
      "Validation Error: Avg loss: 3.879554 \n",
      "\n",
      "2023-11-08 13:43:48.147565 Epoch 1125, Training loss 0.1821308135986328\n",
      "R2 values 0.6159, 0.7473, 0.7852; mean R2=0.7161\n",
      "Validation Error: Avg loss: 4.051383 \n",
      "\n",
      "2023-11-08 13:43:48.604123 Epoch 1126, Training loss 0.1760701686143875\n",
      "R2 values 0.6250, 0.7604, 0.8054; mean R2=0.7303\n",
      "Validation Error: Avg loss: 3.572513 \n",
      "\n",
      "2023-11-08 13:43:49.080849 Epoch 1127, Training loss 0.16495820879936218\n",
      "R2 values 0.5815, 0.7494, 0.7531; mean R2=0.6947\n",
      "Validation Error: Avg loss: 4.392406 \n",
      "\n",
      "2023-11-08 13:43:49.546178 Epoch 1128, Training loss 0.2776529788970947\n",
      "R2 values 0.5381, 0.7816, 0.7409; mean R2=0.6869\n",
      "Validation Error: Avg loss: 3.908019 \n",
      "\n",
      "2023-11-08 13:43:50.003637 Epoch 1129, Training loss 0.19976946711540222\n",
      "R2 values 0.5986, 0.7626, 0.7343; mean R2=0.6985\n",
      "Validation Error: Avg loss: 4.417420 \n",
      "\n",
      "2023-11-08 13:43:50.464978 Epoch 1130, Training loss 0.23832321166992188\n",
      "R2 values 0.4881, 0.7263, 0.7620; mean R2=0.6588\n",
      "Validation Error: Avg loss: 4.571756 \n",
      "\n",
      "2023-11-08 13:43:50.931285 Epoch 1131, Training loss 0.16972415149211884\n",
      "R2 values 0.5627, 0.7713, 0.7961; mean R2=0.7100\n",
      "Validation Error: Avg loss: 3.548685 \n",
      "\n",
      "2023-11-08 13:43:51.392295 Epoch 1132, Training loss 0.2768843472003937\n",
      "R2 values 0.5564, 0.7445, 0.7601; mean R2=0.6870\n",
      "Validation Error: Avg loss: 3.880416 \n",
      "\n",
      "2023-11-08 13:43:51.846365 Epoch 1133, Training loss 0.22546005249023438\n",
      "R2 values 0.5438, 0.7633, 0.7180; mean R2=0.6750\n",
      "Validation Error: Avg loss: 4.262053 \n",
      "\n",
      "2023-11-08 13:43:52.301067 Epoch 1134, Training loss 0.16707926988601685\n",
      "R2 values 0.6081, 0.7235, 0.7195; mean R2=0.6837\n",
      "Validation Error: Avg loss: 4.953039 \n",
      "\n",
      "2023-11-08 13:43:52.794954 Epoch 1135, Training loss 0.24518221616744995\n",
      "R2 values 0.5792, 0.7664, 0.7632; mean R2=0.7029\n",
      "Validation Error: Avg loss: 3.861149 \n",
      "\n",
      "2023-11-08 13:43:53.321601 Epoch 1136, Training loss 0.17385093867778778\n",
      "R2 values 0.6871, 0.7844, 0.7863; mean R2=0.7526\n",
      "Validation Error: Avg loss: 3.368222 \n",
      "\n",
      "2023-11-08 13:43:53.790998 Epoch 1137, Training loss 0.1872977763414383\n",
      "R2 values 0.5502, 0.7592, 0.7164; mean R2=0.6753\n",
      "Validation Error: Avg loss: 4.056024 \n",
      "\n",
      "2023-11-08 13:43:54.258171 Epoch 1138, Training loss 0.12525208294391632\n",
      "R2 values 0.4630, 0.7609, 0.7541; mean R2=0.6593\n",
      "Validation Error: Avg loss: 4.144454 \n",
      "\n",
      "2023-11-08 13:43:54.782994 Epoch 1139, Training loss 0.1536789834499359\n",
      "R2 values 0.5521, 0.7592, 0.7914; mean R2=0.7009\n",
      "Validation Error: Avg loss: 3.841319 \n",
      "\n",
      "2023-11-08 13:43:55.253165 Epoch 1140, Training loss 0.18157537281513214\n",
      "R2 values 0.5570, 0.7564, 0.7385; mean R2=0.6840\n",
      "Validation Error: Avg loss: 4.039983 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:43:55.713814 Epoch 1141, Training loss 0.16728998720645905\n",
      "R2 values 0.5627, 0.7550, 0.7439; mean R2=0.6872\n",
      "Validation Error: Avg loss: 3.985206 \n",
      "\n",
      "2023-11-08 13:43:56.219295 Epoch 1142, Training loss 0.18317168951034546\n",
      "R2 values 0.5846, 0.7700, 0.7597; mean R2=0.7047\n",
      "Validation Error: Avg loss: 3.770105 \n",
      "\n",
      "2023-11-08 13:43:56.681290 Epoch 1143, Training loss 0.1594333052635193\n",
      "R2 values 0.5218, 0.7424, 0.7785; mean R2=0.6809\n",
      "Validation Error: Avg loss: 4.184744 \n",
      "\n",
      "2023-11-08 13:43:57.159051 Epoch 1144, Training loss 0.1735260784626007\n",
      "R2 values 0.6284, 0.7770, 0.7660; mean R2=0.7238\n",
      "Validation Error: Avg loss: 4.048157 \n",
      "\n",
      "2023-11-08 13:43:57.619142 Epoch 1145, Training loss 0.20507080852985382\n",
      "R2 values 0.6751, 0.7580, 0.7526; mean R2=0.7285\n",
      "Validation Error: Avg loss: 4.198335 \n",
      "\n",
      "2023-11-08 13:43:58.102115 Epoch 1146, Training loss 0.20320867002010345\n",
      "R2 values 0.5844, 0.7397, 0.7790; mean R2=0.7010\n",
      "Validation Error: Avg loss: 4.235257 \n",
      "\n",
      "2023-11-08 13:43:58.567297 Epoch 1147, Training loss 0.171633780002594\n",
      "R2 values 0.6469, 0.7824, 0.7797; mean R2=0.7363\n",
      "Validation Error: Avg loss: 3.413636 \n",
      "\n",
      "2023-11-08 13:43:59.047242 Epoch 1148, Training loss 0.180490180850029\n",
      "R2 values 0.5499, 0.7814, 0.7756; mean R2=0.7023\n",
      "Validation Error: Avg loss: 3.466537 \n",
      "\n",
      "2023-11-08 13:43:59.508157 Epoch 1149, Training loss 0.2145666778087616\n",
      "R2 values 0.5032, 0.7517, 0.7368; mean R2=0.6639\n",
      "Validation Error: Avg loss: 4.106704 \n",
      "\n",
      "2023-11-08 13:43:59.972918 Epoch 1150, Training loss 0.17158988118171692\n",
      "R2 values 0.6133, 0.7902, 0.6871; mean R2=0.6969\n",
      "Validation Error: Avg loss: 4.153613 \n",
      "\n",
      "2023-11-08 13:44:00.439405 Epoch 1151, Training loss 0.2767883837223053\n",
      "R2 values 0.5638, 0.7627, 0.7538; mean R2=0.6934\n",
      "Validation Error: Avg loss: 4.122034 \n",
      "\n",
      "2023-11-08 13:44:00.907361 Epoch 1152, Training loss 0.16271305084228516\n",
      "R2 values 0.6475, 0.7549, 0.7864; mean R2=0.7296\n",
      "Validation Error: Avg loss: 3.691093 \n",
      "\n",
      "2023-11-08 13:44:01.375526 Epoch 1153, Training loss 0.21279476583003998\n",
      "R2 values 0.6125, 0.7676, 0.8413; mean R2=0.7405\n",
      "Validation Error: Avg loss: 3.444938 \n",
      "\n",
      "2023-11-08 13:44:01.834680 Epoch 1154, Training loss 0.278851717710495\n",
      "R2 values 0.5466, 0.7363, 0.7684; mean R2=0.6837\n",
      "Validation Error: Avg loss: 4.208138 \n",
      "\n",
      "2023-11-08 13:44:02.449389 Epoch 1155, Training loss 0.14149290323257446\n",
      "R2 values 0.5622, 0.7271, 0.7400; mean R2=0.6764\n",
      "Validation Error: Avg loss: 4.703372 \n",
      "\n",
      "2023-11-08 13:44:02.991748 Epoch 1156, Training loss 0.1679028868675232\n",
      "R2 values 0.5439, 0.7587, 0.7272; mean R2=0.6766\n",
      "Validation Error: Avg loss: 4.280037 \n",
      "\n",
      "2023-11-08 13:44:03.455498 Epoch 1157, Training loss 0.17003311216831207\n",
      "R2 values 0.6139, 0.7495, 0.7442; mean R2=0.7025\n",
      "Validation Error: Avg loss: 4.167683 \n",
      "\n",
      "2023-11-08 13:44:03.924326 Epoch 1158, Training loss 0.1837293803691864\n",
      "R2 values 0.5883, 0.7683, 0.7409; mean R2=0.6992\n",
      "Validation Error: Avg loss: 3.910618 \n",
      "\n",
      "2023-11-08 13:44:04.396125 Epoch 1159, Training loss 0.19895219802856445\n",
      "R2 values 0.4706, 0.7595, 0.7371; mean R2=0.6557\n",
      "Validation Error: Avg loss: 4.039196 \n",
      "\n",
      "2023-11-08 13:44:04.865366 Epoch 1160, Training loss 0.15760253369808197\n",
      "R2 values 0.5159, 0.7631, 0.7445; mean R2=0.6745\n",
      "Validation Error: Avg loss: 4.137414 \n",
      "\n",
      "2023-11-08 13:44:05.344871 Epoch 1161, Training loss 0.18319888412952423\n",
      "R2 values 0.5760, 0.7472, 0.7283; mean R2=0.6838\n",
      "Validation Error: Avg loss: 4.303000 \n",
      "\n",
      "2023-11-08 13:44:05.807257 Epoch 1162, Training loss 0.1835702657699585\n",
      "R2 values 0.5562, 0.7665, 0.7710; mean R2=0.6979\n",
      "Validation Error: Avg loss: 4.077293 \n",
      "\n",
      "2023-11-08 13:44:06.300721 Epoch 1163, Training loss 0.1585788130760193\n",
      "R2 values 0.5832, 0.7663, 0.6973; mean R2=0.6823\n",
      "Validation Error: Avg loss: 4.275970 \n",
      "\n",
      "2023-11-08 13:44:06.770871 Epoch 1164, Training loss 0.129374161362648\n",
      "R2 values 0.6470, 0.7709, 0.7630; mean R2=0.7270\n",
      "Validation Error: Avg loss: 3.837509 \n",
      "\n",
      "2023-11-08 13:44:07.243577 Epoch 1165, Training loss 0.23679761588573456\n",
      "R2 values 0.5483, 0.7519, 0.7572; mean R2=0.6858\n",
      "Validation Error: Avg loss: 4.064434 \n",
      "\n",
      "2023-11-08 13:44:07.709395 Epoch 1166, Training loss 0.14490991830825806\n",
      "R2 values 0.5604, 0.7920, 0.7862; mean R2=0.7129\n",
      "Validation Error: Avg loss: 3.547033 \n",
      "\n",
      "2023-11-08 13:44:08.174112 Epoch 1167, Training loss 0.13926410675048828\n",
      "R2 values 0.4680, 0.7305, 0.7340; mean R2=0.6442\n",
      "Validation Error: Avg loss: 4.495442 \n",
      "\n",
      "2023-11-08 13:44:08.753116 Epoch 1168, Training loss 0.15519559383392334\n",
      "R2 values 0.5075, 0.7626, 0.7845; mean R2=0.6849\n",
      "Validation Error: Avg loss: 3.761642 \n",
      "\n",
      "2023-11-08 13:44:09.243106 Epoch 1169, Training loss 0.19708815217018127\n",
      "R2 values 0.5480, 0.7582, 0.7976; mean R2=0.7013\n",
      "Validation Error: Avg loss: 3.811210 \n",
      "\n",
      "2023-11-08 13:44:09.778708 Epoch 1170, Training loss 0.17059780657291412\n",
      "R2 values 0.5644, 0.7339, 0.7387; mean R2=0.6790\n",
      "Validation Error: Avg loss: 4.478215 \n",
      "\n",
      "2023-11-08 13:44:10.237227 Epoch 1171, Training loss 0.17169252038002014\n",
      "R2 values 0.6070, 0.7429, 0.7615; mean R2=0.7038\n",
      "Validation Error: Avg loss: 4.248947 \n",
      "\n",
      "2023-11-08 13:44:10.696633 Epoch 1172, Training loss 0.17140670120716095\n",
      "R2 values 0.5792, 0.7792, 0.7387; mean R2=0.6991\n",
      "Validation Error: Avg loss: 3.730242 \n",
      "\n",
      "2023-11-08 13:44:11.163671 Epoch 1173, Training loss 0.19252486526966095\n",
      "R2 values 0.5671, 0.7890, 0.7604; mean R2=0.7055\n",
      "Validation Error: Avg loss: 3.529005 \n",
      "\n",
      "2023-11-08 13:44:11.676160 Epoch 1174, Training loss 0.21212582290172577\n",
      "R2 values 0.5407, 0.7567, 0.7516; mean R2=0.6830\n",
      "Validation Error: Avg loss: 4.019799 \n",
      "\n",
      "2023-11-08 13:44:12.160410 Epoch 1175, Training loss 0.1534620076417923\n",
      "R2 values 0.5599, 0.7616, 0.7594; mean R2=0.6937\n",
      "Validation Error: Avg loss: 3.948263 \n",
      "\n",
      "2023-11-08 13:44:12.630426 Epoch 1176, Training loss 0.16559404134750366\n",
      "R2 values 0.5880, 0.7578, 0.7846; mean R2=0.7101\n",
      "Validation Error: Avg loss: 3.998400 \n",
      "\n",
      "2023-11-08 13:44:13.111831 Epoch 1177, Training loss 0.2019115835428238\n",
      "R2 values 0.5838, 0.7487, 0.7640; mean R2=0.6988\n",
      "Validation Error: Avg loss: 3.907887 \n",
      "\n",
      "2023-11-08 13:44:13.586958 Epoch 1178, Training loss 0.15576808154582977\n",
      "R2 values 0.5961, 0.7547, 0.7748; mean R2=0.7085\n",
      "Validation Error: Avg loss: 3.780138 \n",
      "\n",
      "2023-11-08 13:44:14.055223 Epoch 1179, Training loss 0.16963711380958557\n",
      "R2 values 0.5792, 0.7613, 0.7567; mean R2=0.6990\n",
      "Validation Error: Avg loss: 4.054232 \n",
      "\n",
      "2023-11-08 13:44:14.536391 Epoch 1180, Training loss 0.15766893327236176\n",
      "R2 values 0.5050, 0.7226, 0.7439; mean R2=0.6572\n",
      "Validation Error: Avg loss: 4.949038 \n",
      "\n",
      "2023-11-08 13:44:15.002365 Epoch 1181, Training loss 0.1946830004453659\n",
      "R2 values 0.5875, 0.7733, 0.7582; mean R2=0.7063\n",
      "Validation Error: Avg loss: 3.840543 \n",
      "\n",
      "2023-11-08 13:44:15.482138 Epoch 1182, Training loss 0.13694217801094055\n",
      "R2 values 0.5581, 0.7592, 0.7663; mean R2=0.6945\n",
      "Validation Error: Avg loss: 3.796727 \n",
      "\n",
      "2023-11-08 13:44:15.941555 Epoch 1183, Training loss 0.14011654257774353\n",
      "R2 values 0.5313, 0.7460, 0.7383; mean R2=0.6719\n",
      "Validation Error: Avg loss: 4.135996 \n",
      "\n",
      "2023-11-08 13:44:16.407497 Epoch 1184, Training loss 0.15600544214248657\n",
      "R2 values 0.5620, 0.7388, 0.7341; mean R2=0.6783\n",
      "Validation Error: Avg loss: 4.242523 \n",
      "\n",
      "2023-11-08 13:44:16.873063 Epoch 1185, Training loss 0.1640809327363968\n",
      "R2 values 0.5597, 0.7478, 0.8091; mean R2=0.7055\n",
      "Validation Error: Avg loss: 3.914305 \n",
      "\n",
      "2023-11-08 13:44:17.332656 Epoch 1186, Training loss 0.1266622692346573\n",
      "R2 values 0.5454, 0.7404, 0.7380; mean R2=0.6746\n",
      "Validation Error: Avg loss: 4.227836 \n",
      "\n",
      "2023-11-08 13:44:17.804893 Epoch 1187, Training loss 0.15830861032009125\n",
      "R2 values 0.6255, 0.7443, 0.7914; mean R2=0.7204\n",
      "Validation Error: Avg loss: 3.961676 \n",
      "\n",
      "2023-11-08 13:44:18.372774 Epoch 1188, Training loss 0.166398286819458\n",
      "R2 values 0.5314, 0.7579, 0.7645; mean R2=0.6846\n",
      "Validation Error: Avg loss: 3.995062 \n",
      "\n",
      "2023-11-08 13:44:18.902882 Epoch 1189, Training loss 0.16473771631717682\n",
      "R2 values 0.5905, 0.7389, 0.7659; mean R2=0.6984\n",
      "Validation Error: Avg loss: 4.171978 \n",
      "\n",
      "2023-11-08 13:44:19.370079 Epoch 1190, Training loss 0.1482265442609787\n",
      "R2 values 0.6092, 0.7377, 0.7615; mean R2=0.7028\n",
      "Validation Error: Avg loss: 4.400394 \n",
      "\n",
      "2023-11-08 13:44:19.846328 Epoch 1191, Training loss 0.15488506853580475\n",
      "R2 values 0.6277, 0.7398, 0.7608; mean R2=0.7094\n",
      "Validation Error: Avg loss: 4.115191 \n",
      "\n",
      "2023-11-08 13:44:20.310240 Epoch 1192, Training loss 0.13489459455013275\n",
      "R2 values 0.6152, 0.7529, 0.7541; mean R2=0.7074\n",
      "Validation Error: Avg loss: 3.956213 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:44:20.775768 Epoch 1193, Training loss 0.13081128895282745\n",
      "R2 values 0.6104, 0.7880, 0.7511; mean R2=0.7165\n",
      "Validation Error: Avg loss: 3.450310 \n",
      "\n",
      "2023-11-08 13:44:21.238687 Epoch 1194, Training loss 0.147185817360878\n",
      "R2 values 0.6889, 0.8031, 0.7193; mean R2=0.7371\n",
      "Validation Error: Avg loss: 3.259137 \n",
      "\n",
      "2023-11-08 13:44:21.701290 Epoch 1195, Training loss 0.1751117706298828\n",
      "R2 values 0.5599, 0.7608, 0.7252; mean R2=0.6820\n",
      "Validation Error: Avg loss: 4.099607 \n",
      "\n",
      "2023-11-08 13:44:22.166768 Epoch 1196, Training loss 0.16065825521945953\n",
      "R2 values 0.6663, 0.7983, 0.7883; mean R2=0.7510\n",
      "Validation Error: Avg loss: 3.420459 \n",
      "\n",
      "2023-11-08 13:44:22.630931 Epoch 1197, Training loss 0.14745765924453735\n",
      "R2 values 0.6308, 0.7733, 0.7849; mean R2=0.7297\n",
      "Validation Error: Avg loss: 3.784388 \n",
      "\n",
      "2023-11-08 13:44:23.109493 Epoch 1198, Training loss 0.15293510258197784\n",
      "R2 values 0.6212, 0.7784, 0.7904; mean R2=0.7300\n",
      "Validation Error: Avg loss: 3.586240 \n",
      "\n",
      "2023-11-08 13:44:23.576492 Epoch 1199, Training loss 0.14515845477581024\n",
      "R2 values 0.6101, 0.7522, 0.8026; mean R2=0.7216\n",
      "Validation Error: Avg loss: 3.822532 \n",
      "\n",
      "2023-11-08 13:44:24.044315 Epoch 1200, Training loss 0.21803760528564453\n",
      "R2 values 0.6257, 0.7708, 0.7647; mean R2=0.7204\n",
      "Validation Error: Avg loss: 3.785704 \n",
      "\n",
      "2023-11-08 13:44:24.523876 Epoch 1201, Training loss 0.16577093303203583\n",
      "R2 values 0.5725, 0.7481, 0.7381; mean R2=0.6862\n",
      "Validation Error: Avg loss: 4.141843 \n",
      "\n",
      "2023-11-08 13:44:24.988977 Epoch 1202, Training loss 0.15174520015716553\n",
      "R2 values 0.6373, 0.7458, 0.7613; mean R2=0.7148\n",
      "Validation Error: Avg loss: 4.167167 \n",
      "\n",
      "2023-11-08 13:44:25.447894 Epoch 1203, Training loss 0.14929115772247314\n",
      "R2 values 0.6390, 0.7531, 0.7721; mean R2=0.7214\n",
      "Validation Error: Avg loss: 3.899693 \n",
      "\n",
      "2023-11-08 13:44:26.172594 Epoch 1204, Training loss 0.167019784450531\n",
      "R2 values 0.6289, 0.8090, 0.7717; mean R2=0.7365\n",
      "Validation Error: Avg loss: 3.265418 \n",
      "\n",
      "2023-11-08 13:44:26.681478 Epoch 1205, Training loss 0.10910927504301071\n",
      "R2 values 0.6020, 0.7694, 0.7855; mean R2=0.7190\n",
      "Validation Error: Avg loss: 3.677787 \n",
      "\n",
      "2023-11-08 13:44:27.145285 Epoch 1206, Training loss 0.17469994723796844\n",
      "R2 values 0.5897, 0.7766, 0.7622; mean R2=0.7095\n",
      "Validation Error: Avg loss: 3.667032 \n",
      "\n",
      "2023-11-08 13:44:27.612625 Epoch 1207, Training loss 0.13107556104660034\n",
      "R2 values 0.6101, 0.7680, 0.7834; mean R2=0.7205\n",
      "Validation Error: Avg loss: 3.736059 \n",
      "\n",
      "2023-11-08 13:44:28.084195 Epoch 1208, Training loss 0.13465164601802826\n",
      "R2 values 0.6372, 0.7743, 0.8028; mean R2=0.7381\n",
      "Validation Error: Avg loss: 3.572086 \n",
      "\n",
      "2023-11-08 13:44:28.546598 Epoch 1209, Training loss 0.13170814514160156\n",
      "R2 values 0.6195, 0.7565, 0.7495; mean R2=0.7085\n",
      "Validation Error: Avg loss: 4.102849 \n",
      "\n",
      "2023-11-08 13:44:29.033806 Epoch 1210, Training loss 0.2187373787164688\n",
      "R2 values 0.5730, 0.7356, 0.7324; mean R2=0.6803\n",
      "Validation Error: Avg loss: 4.420011 \n",
      "\n",
      "2023-11-08 13:44:29.522618 Epoch 1211, Training loss 0.15235519409179688\n",
      "R2 values 0.5886, 0.7669, 0.7880; mean R2=0.7145\n",
      "Validation Error: Avg loss: 3.578706 \n",
      "\n",
      "2023-11-08 13:44:30.012342 Epoch 1212, Training loss 0.12907983362674713\n",
      "R2 values 0.6848, 0.7689, 0.7776; mean R2=0.7437\n",
      "Validation Error: Avg loss: 3.573620 \n",
      "\n",
      "2023-11-08 13:44:30.494448 Epoch 1213, Training loss 0.12456359714269638\n",
      "R2 values 0.5645, 0.7425, 0.7656; mean R2=0.6909\n",
      "Validation Error: Avg loss: 4.217376 \n",
      "\n",
      "2023-11-08 13:44:30.963111 Epoch 1214, Training loss 0.2259027361869812\n",
      "R2 values 0.6148, 0.7579, 0.7543; mean R2=0.7090\n",
      "Validation Error: Avg loss: 3.791723 \n",
      "\n",
      "2023-11-08 13:44:31.429637 Epoch 1215, Training loss 0.1410958617925644\n",
      "R2 values 0.6093, 0.7249, 0.7551; mean R2=0.6964\n",
      "Validation Error: Avg loss: 4.309853 \n",
      "\n",
      "2023-11-08 13:44:31.894080 Epoch 1216, Training loss 0.1561964601278305\n",
      "R2 values 0.6992, 0.7685, 0.7490; mean R2=0.7389\n",
      "Validation Error: Avg loss: 3.784466 \n",
      "\n",
      "2023-11-08 13:44:32.356702 Epoch 1217, Training loss 0.1441466361284256\n",
      "R2 values 0.5992, 0.7673, 0.7896; mean R2=0.7187\n",
      "Validation Error: Avg loss: 3.816315 \n",
      "\n",
      "2023-11-08 13:44:32.829868 Epoch 1218, Training loss 0.13251665234565735\n",
      "R2 values 0.5386, 0.7592, 0.7726; mean R2=0.6901\n",
      "Validation Error: Avg loss: 4.009128 \n",
      "\n",
      "2023-11-08 13:44:33.307472 Epoch 1219, Training loss 0.1592506766319275\n",
      "R2 values 0.5669, 0.7678, 0.7431; mean R2=0.6926\n",
      "Validation Error: Avg loss: 4.208773 \n",
      "\n",
      "2023-11-08 13:44:33.771303 Epoch 1220, Training loss 0.19937917590141296\n",
      "R2 values 0.6396, 0.7320, 0.7629; mean R2=0.7115\n",
      "Validation Error: Avg loss: 4.213544 \n",
      "\n",
      "2023-11-08 13:44:34.237105 Epoch 1221, Training loss 0.16497765481472015\n",
      "R2 values 0.6219, 0.7674, 0.7717; mean R2=0.7203\n",
      "Validation Error: Avg loss: 3.739420 \n",
      "\n",
      "2023-11-08 13:44:34.966418 Epoch 1222, Training loss 0.14622323215007782\n",
      "R2 values 0.6089, 0.7373, 0.7891; mean R2=0.7118\n",
      "Validation Error: Avg loss: 3.842388 \n",
      "\n",
      "2023-11-08 13:44:35.467506 Epoch 1223, Training loss 0.14690500497817993\n",
      "R2 values 0.5890, 0.7526, 0.7825; mean R2=0.7080\n",
      "Validation Error: Avg loss: 3.812974 \n",
      "\n",
      "2023-11-08 13:44:35.934318 Epoch 1224, Training loss 0.17161791026592255\n",
      "R2 values 0.6319, 0.7388, 0.7217; mean R2=0.6974\n",
      "Validation Error: Avg loss: 4.639529 \n",
      "\n",
      "2023-11-08 13:44:36.398403 Epoch 1225, Training loss 0.2362581044435501\n",
      "R2 values 0.6030, 0.7427, 0.7524; mean R2=0.6994\n",
      "Validation Error: Avg loss: 4.357281 \n",
      "\n",
      "2023-11-08 13:44:36.860111 Epoch 1226, Training loss 0.17078663408756256\n",
      "R2 values 0.6142, 0.7545, 0.7881; mean R2=0.7190\n",
      "Validation Error: Avg loss: 3.857436 \n",
      "\n",
      "2023-11-08 13:44:37.328377 Epoch 1227, Training loss 0.14281266927719116\n",
      "R2 values 0.6193, 0.7506, 0.7557; mean R2=0.7085\n",
      "Validation Error: Avg loss: 3.760026 \n",
      "\n",
      "2023-11-08 13:44:37.797420 Epoch 1228, Training loss 0.24950528144836426\n",
      "R2 values 0.5733, 0.7570, 0.7794; mean R2=0.7032\n",
      "Validation Error: Avg loss: 3.612248 \n",
      "\n",
      "2023-11-08 13:44:38.260532 Epoch 1229, Training loss 0.1260402649641037\n",
      "R2 values 0.6652, 0.7594, 0.7368; mean R2=0.7205\n",
      "Validation Error: Avg loss: 4.356446 \n",
      "\n",
      "2023-11-08 13:44:38.729662 Epoch 1230, Training loss 0.19552910327911377\n",
      "R2 values 0.5903, 0.7725, 0.7434; mean R2=0.7021\n",
      "Validation Error: Avg loss: 4.214787 \n",
      "\n",
      "2023-11-08 13:44:39.197817 Epoch 1231, Training loss 0.16746819019317627\n",
      "R2 values 0.5960, 0.7420, 0.7483; mean R2=0.6955\n",
      "Validation Error: Avg loss: 4.105612 \n",
      "\n",
      "2023-11-08 13:44:39.671766 Epoch 1232, Training loss 0.15640141069889069\n",
      "R2 values 0.6430, 0.7819, 0.7769; mean R2=0.7339\n",
      "Validation Error: Avg loss: 3.259327 \n",
      "\n",
      "2023-11-08 13:44:40.130059 Epoch 1233, Training loss 0.157443568110466\n",
      "R2 values 0.6322, 0.7694, 0.7313; mean R2=0.7110\n",
      "Validation Error: Avg loss: 3.678970 \n",
      "\n",
      "2023-11-08 13:44:40.587976 Epoch 1234, Training loss 0.19164782762527466\n",
      "R2 values 0.5839, 0.7502, 0.7742; mean R2=0.7028\n",
      "Validation Error: Avg loss: 4.116602 \n",
      "\n",
      "2023-11-08 13:44:41.047302 Epoch 1235, Training loss 0.10780874639749527\n",
      "R2 values 0.5807, 0.7404, 0.7734; mean R2=0.6982\n",
      "Validation Error: Avg loss: 4.086569 \n",
      "\n",
      "2023-11-08 13:44:41.586735 Epoch 1236, Training loss 0.161017507314682\n",
      "R2 values 0.5090, 0.7306, 0.7433; mean R2=0.6610\n",
      "Validation Error: Avg loss: 4.464313 \n",
      "\n",
      "2023-11-08 13:44:42.043865 Epoch 1237, Training loss 0.14032268524169922\n",
      "R2 values 0.6172, 0.7724, 0.7559; mean R2=0.7152\n",
      "Validation Error: Avg loss: 3.928698 \n",
      "\n",
      "2023-11-08 13:44:42.506251 Epoch 1238, Training loss 0.15389001369476318\n",
      "R2 values 0.6583, 0.7809, 0.7735; mean R2=0.7376\n",
      "Validation Error: Avg loss: 3.628240 \n",
      "\n",
      "2023-11-08 13:44:43.007279 Epoch 1239, Training loss 0.16642524302005768\n",
      "R2 values 0.5084, 0.7366, 0.7736; mean R2=0.6728\n",
      "Validation Error: Avg loss: 4.307873 \n",
      "\n",
      "2023-11-08 13:44:43.474739 Epoch 1240, Training loss 0.1394505351781845\n",
      "R2 values 0.5782, 0.7786, 0.7816; mean R2=0.7128\n",
      "Validation Error: Avg loss: 3.694875 \n",
      "\n",
      "2023-11-08 13:44:43.947897 Epoch 1241, Training loss 0.15587328374385834\n",
      "R2 values 0.6196, 0.7202, 0.7300; mean R2=0.6899\n",
      "Validation Error: Avg loss: 4.583775 \n",
      "\n",
      "2023-11-08 13:44:44.407078 Epoch 1242, Training loss 0.12845902144908905\n",
      "R2 values 0.6375, 0.7243, 0.7908; mean R2=0.7175\n",
      "Validation Error: Avg loss: 4.344996 \n",
      "\n",
      "2023-11-08 13:44:44.876003 Epoch 1243, Training loss 0.12734127044677734\n",
      "R2 values 0.6233, 0.7691, 0.7527; mean R2=0.7151\n",
      "Validation Error: Avg loss: 3.877444 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:44:45.343645 Epoch 1244, Training loss 0.12134099006652832\n",
      "R2 values 0.5834, 0.7281, 0.7629; mean R2=0.6915\n",
      "Validation Error: Avg loss: 4.326256 \n",
      "\n",
      "2023-11-08 13:44:45.819138 Epoch 1245, Training loss 0.15446652472019196\n",
      "R2 values 0.6514, 0.7494, 0.7483; mean R2=0.7163\n",
      "Validation Error: Avg loss: 4.000022 \n",
      "\n",
      "2023-11-08 13:44:46.280124 Epoch 1246, Training loss 0.1262892782688141\n",
      "R2 values 0.5796, 0.7878, 0.7705; mean R2=0.7126\n",
      "Validation Error: Avg loss: 3.701107 \n",
      "\n",
      "2023-11-08 13:44:46.735679 Epoch 1247, Training loss 0.15952041745185852\n",
      "R2 values 0.5958, 0.7719, 0.7659; mean R2=0.7112\n",
      "Validation Error: Avg loss: 3.804194 \n",
      "\n",
      "2023-11-08 13:44:47.200418 Epoch 1248, Training loss 0.14373861253261566\n",
      "R2 values 0.6029, 0.7649, 0.7739; mean R2=0.7139\n",
      "Validation Error: Avg loss: 3.703134 \n",
      "\n",
      "2023-11-08 13:44:47.657053 Epoch 1249, Training loss 0.14157146215438843\n",
      "R2 values 0.6541, 0.7906, 0.7991; mean R2=0.7479\n",
      "Validation Error: Avg loss: 3.367457 \n",
      "\n",
      "2023-11-08 13:44:48.125505 Epoch 1250, Training loss 0.12283526360988617\n",
      "R2 values 0.6453, 0.7875, 0.7191; mean R2=0.7173\n",
      "Validation Error: Avg loss: 3.799107 \n",
      "\n",
      "2023-11-08 13:44:48.590835 Epoch 1251, Training loss 0.15511053800582886\n",
      "R2 values 0.6040, 0.7875, 0.7850; mean R2=0.7255\n",
      "Validation Error: Avg loss: 3.516801 \n",
      "\n",
      "2023-11-08 13:44:49.051896 Epoch 1252, Training loss 0.1481619030237198\n",
      "R2 values 0.6090, 0.7564, 0.7638; mean R2=0.7097\n",
      "Validation Error: Avg loss: 3.987281 \n",
      "\n",
      "2023-11-08 13:44:49.519803 Epoch 1253, Training loss 0.12403930723667145\n",
      "R2 values 0.6686, 0.7508, 0.7568; mean R2=0.7254\n",
      "Validation Error: Avg loss: 4.054809 \n",
      "\n",
      "2023-11-08 13:44:50.011843 Epoch 1254, Training loss 0.15336133539676666\n",
      "R2 values 0.6582, 0.7528, 0.7975; mean R2=0.7362\n",
      "Validation Error: Avg loss: 3.843854 \n",
      "\n",
      "2023-11-08 13:44:50.480470 Epoch 1255, Training loss 0.097825787961483\n",
      "R2 values 0.5954, 0.7772, 0.7772; mean R2=0.7166\n",
      "Validation Error: Avg loss: 3.783686 \n",
      "\n",
      "2023-11-08 13:44:50.948397 Epoch 1256, Training loss 0.13370396196842194\n",
      "R2 values 0.5664, 0.7691, 0.7578; mean R2=0.6978\n",
      "Validation Error: Avg loss: 4.036602 \n",
      "\n",
      "2023-11-08 13:44:51.410989 Epoch 1257, Training loss 0.09055133908987045\n",
      "R2 values 0.5896, 0.7437, 0.7470; mean R2=0.6934\n",
      "Validation Error: Avg loss: 4.402201 \n",
      "\n",
      "2023-11-08 13:44:51.897579 Epoch 1258, Training loss 0.14618921279907227\n",
      "R2 values 0.5900, 0.7878, 0.7740; mean R2=0.7173\n",
      "Validation Error: Avg loss: 3.470295 \n",
      "\n",
      "2023-11-08 13:44:52.357592 Epoch 1259, Training loss 0.14585845172405243\n",
      "R2 values 0.5325, 0.7763, 0.7275; mean R2=0.6788\n",
      "Validation Error: Avg loss: 3.885150 \n",
      "\n",
      "2023-11-08 13:44:52.863441 Epoch 1260, Training loss 0.13032101094722748\n",
      "R2 values 0.6024, 0.7450, 0.7258; mean R2=0.6910\n",
      "Validation Error: Avg loss: 4.244548 \n",
      "\n",
      "2023-11-08 13:44:53.321514 Epoch 1261, Training loss 0.13405002653598785\n",
      "R2 values 0.5963, 0.7726, 0.7597; mean R2=0.7095\n",
      "Validation Error: Avg loss: 3.976441 \n",
      "\n",
      "2023-11-08 13:44:53.793289 Epoch 1262, Training loss 0.1293662190437317\n",
      "R2 values 0.5854, 0.7750, 0.7575; mean R2=0.7060\n",
      "Validation Error: Avg loss: 3.660939 \n",
      "\n",
      "2023-11-08 13:44:54.266002 Epoch 1263, Training loss 0.13785992562770844\n",
      "R2 values 0.6440, 0.7917, 0.7961; mean R2=0.7439\n",
      "Validation Error: Avg loss: 3.254430 \n",
      "\n",
      "2023-11-08 13:44:54.744460 Epoch 1264, Training loss 0.12900234758853912\n",
      "R2 values 0.6740, 0.7709, 0.7774; mean R2=0.7408\n",
      "Validation Error: Avg loss: 3.780832 \n",
      "\n",
      "2023-11-08 13:44:55.217296 Epoch 1265, Training loss 0.1683831512928009\n",
      "R2 values 0.5924, 0.7500, 0.7614; mean R2=0.7012\n",
      "Validation Error: Avg loss: 4.103971 \n",
      "\n",
      "2023-11-08 13:44:55.680349 Epoch 1266, Training loss 0.12197454273700714\n",
      "R2 values 0.6615, 0.7561, 0.7893; mean R2=0.7356\n",
      "Validation Error: Avg loss: 3.735419 \n",
      "\n",
      "2023-11-08 13:44:56.140425 Epoch 1267, Training loss 0.1154279038310051\n",
      "R2 values 0.5847, 0.7353, 0.7723; mean R2=0.6974\n",
      "Validation Error: Avg loss: 4.098194 \n",
      "\n",
      "2023-11-08 13:44:56.605182 Epoch 1268, Training loss 0.15717002749443054\n",
      "R2 values 0.5891, 0.7588, 0.7672; mean R2=0.7051\n",
      "Validation Error: Avg loss: 4.044219 \n",
      "\n",
      "2023-11-08 13:44:57.056996 Epoch 1269, Training loss 0.11435197293758392\n",
      "R2 values 0.5924, 0.7456, 0.7512; mean R2=0.6964\n",
      "Validation Error: Avg loss: 4.437577 \n",
      "\n",
      "2023-11-08 13:44:57.526694 Epoch 1270, Training loss 0.16937515139579773\n",
      "R2 values 0.5667, 0.7566, 0.7107; mean R2=0.6780\n",
      "Validation Error: Avg loss: 4.152138 \n",
      "\n",
      "2023-11-08 13:44:57.998384 Epoch 1271, Training loss 0.13324806094169617\n",
      "R2 values 0.6933, 0.7679, 0.7696; mean R2=0.7436\n",
      "Validation Error: Avg loss: 3.531732 \n",
      "\n",
      "2023-11-08 13:44:58.465512 Epoch 1272, Training loss 0.1668073534965515\n",
      "R2 values 0.6464, 0.7851, 0.7792; mean R2=0.7369\n",
      "Validation Error: Avg loss: 3.344573 \n",
      "\n",
      "2023-11-08 13:44:59.214510 Epoch 1273, Training loss 0.15543918311595917\n",
      "R2 values 0.6046, 0.7657, 0.7297; mean R2=0.7000\n",
      "Validation Error: Avg loss: 3.788795 \n",
      "\n",
      "2023-11-08 13:44:59.697381 Epoch 1274, Training loss 0.12557628750801086\n",
      "R2 values 0.5520, 0.7656, 0.7319; mean R2=0.6832\n",
      "Validation Error: Avg loss: 4.076043 \n",
      "\n",
      "2023-11-08 13:45:00.159213 Epoch 1275, Training loss 0.12972010672092438\n",
      "R2 values 0.6622, 0.7745, 0.7475; mean R2=0.7281\n",
      "Validation Error: Avg loss: 3.857891 \n",
      "\n",
      "2023-11-08 13:45:00.762508 Epoch 1276, Training loss 0.16601955890655518\n",
      "R2 values 0.6682, 0.7613, 0.8057; mean R2=0.7451\n",
      "Validation Error: Avg loss: 3.787695 \n",
      "\n",
      "2023-11-08 13:45:01.227341 Epoch 1277, Training loss 0.12217976897954941\n",
      "R2 values 0.6123, 0.7306, 0.8177; mean R2=0.7202\n",
      "Validation Error: Avg loss: 3.891184 \n",
      "\n",
      "2023-11-08 13:45:01.696687 Epoch 1278, Training loss 0.12005080282688141\n",
      "R2 values 0.6523, 0.7739, 0.7955; mean R2=0.7406\n",
      "Validation Error: Avg loss: 3.579416 \n",
      "\n",
      "2023-11-08 13:45:02.216078 Epoch 1279, Training loss 0.11533121019601822\n",
      "R2 values 0.5611, 0.7434, 0.7656; mean R2=0.6900\n",
      "Validation Error: Avg loss: 4.094437 \n",
      "\n",
      "2023-11-08 13:45:02.686376 Epoch 1280, Training loss 0.1207754909992218\n",
      "R2 values 0.6007, 0.7633, 0.7808; mean R2=0.7149\n",
      "Validation Error: Avg loss: 3.842319 \n",
      "\n",
      "2023-11-08 13:45:03.164682 Epoch 1281, Training loss 0.1595647782087326\n",
      "R2 values 0.6089, 0.7609, 0.7829; mean R2=0.7176\n",
      "Validation Error: Avg loss: 3.808737 \n",
      "\n",
      "2023-11-08 13:45:03.631519 Epoch 1282, Training loss 0.12242723256349564\n",
      "R2 values 0.6379, 0.7389, 0.7533; mean R2=0.7100\n",
      "Validation Error: Avg loss: 4.091100 \n",
      "\n",
      "2023-11-08 13:45:04.095972 Epoch 1283, Training loss 0.12476802617311478\n",
      "R2 values 0.6143, 0.7860, 0.7732; mean R2=0.7245\n",
      "Validation Error: Avg loss: 3.467283 \n",
      "\n",
      "2023-11-08 13:45:04.569999 Epoch 1284, Training loss 0.12913517653942108\n",
      "R2 values 0.5602, 0.7300, 0.7437; mean R2=0.6780\n",
      "Validation Error: Avg loss: 4.563548 \n",
      "\n",
      "2023-11-08 13:45:05.046729 Epoch 1285, Training loss 0.1695365309715271\n",
      "R2 values 0.5997, 0.7399, 0.7720; mean R2=0.7039\n",
      "Validation Error: Avg loss: 4.145000 \n",
      "\n",
      "2023-11-08 13:45:05.499134 Epoch 1286, Training loss 0.13550899922847748\n",
      "R2 values 0.6061, 0.7654, 0.7769; mean R2=0.7161\n",
      "Validation Error: Avg loss: 3.791216 \n",
      "\n",
      "2023-11-08 13:45:05.980036 Epoch 1287, Training loss 0.14154836535453796\n",
      "R2 values 0.6405, 0.7451, 0.7601; mean R2=0.7152\n",
      "Validation Error: Avg loss: 3.967723 \n",
      "\n",
      "2023-11-08 13:45:06.436148 Epoch 1288, Training loss 0.1510351002216339\n",
      "R2 values 0.5799, 0.7514, 0.7246; mean R2=0.6853\n",
      "Validation Error: Avg loss: 4.241156 \n",
      "\n",
      "2023-11-08 13:45:06.899737 Epoch 1289, Training loss 0.11721057444810867\n",
      "R2 values 0.6060, 0.7664, 0.7183; mean R2=0.6969\n",
      "Validation Error: Avg loss: 4.234492 \n",
      "\n",
      "2023-11-08 13:45:07.349140 Epoch 1290, Training loss 0.10766548663377762\n",
      "R2 values 0.6018, 0.7496, 0.7498; mean R2=0.7004\n",
      "Validation Error: Avg loss: 4.142232 \n",
      "\n",
      "2023-11-08 13:45:07.813268 Epoch 1291, Training loss 0.11541516333818436\n",
      "R2 values 0.5459, 0.7368, 0.7303; mean R2=0.6710\n",
      "Validation Error: Avg loss: 4.405050 \n",
      "\n",
      "2023-11-08 13:45:08.539494 Epoch 1292, Training loss 0.14323197305202484\n",
      "R2 values 0.6467, 0.7831, 0.7835; mean R2=0.7377\n",
      "Validation Error: Avg loss: 3.488190 \n",
      "\n",
      "2023-11-08 13:45:09.065540 Epoch 1293, Training loss 0.11573491990566254\n",
      "R2 values 0.6780, 0.7970, 0.7645; mean R2=0.7465\n",
      "Validation Error: Avg loss: 3.539255 \n",
      "\n",
      "2023-11-08 13:45:09.540499 Epoch 1294, Training loss 0.13112938404083252\n",
      "R2 values 0.5964, 0.7579, 0.7699; mean R2=0.7081\n",
      "Validation Error: Avg loss: 4.160002 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:45:10.025632 Epoch 1295, Training loss 0.12901535630226135\n",
      "R2 values 0.6764, 0.7702, 0.7791; mean R2=0.7419\n",
      "Validation Error: Avg loss: 3.703660 \n",
      "\n",
      "2023-11-08 13:45:10.488110 Epoch 1296, Training loss 0.11953943222761154\n",
      "R2 values 0.5307, 0.7559, 0.7753; mean R2=0.6873\n",
      "Validation Error: Avg loss: 3.658353 \n",
      "\n",
      "2023-11-08 13:45:10.955090 Epoch 1297, Training loss 0.17317014932632446\n",
      "R2 values 0.6744, 0.7859, 0.7989; mean R2=0.7531\n",
      "Validation Error: Avg loss: 3.075037 \n",
      "\n",
      "2023-11-08 13:45:11.422405 Epoch 1298, Training loss 0.2237754613161087\n",
      "R2 values 0.5862, 0.7610, 0.7390; mean R2=0.6954\n",
      "Validation Error: Avg loss: 4.124863 \n",
      "\n",
      "2023-11-08 13:45:11.914089 Epoch 1299, Training loss 0.10651132464408875\n",
      "R2 values 0.6143, 0.7335, 0.7080; mean R2=0.6853\n",
      "Validation Error: Avg loss: 5.051113 \n",
      "\n",
      "2023-11-08 13:45:12.382012 Epoch 1300, Training loss 0.3677128553390503\n",
      "R2 values 0.6114, 0.7419, 0.7640; mean R2=0.7058\n",
      "Validation Error: Avg loss: 4.218805 \n",
      "\n",
      "2023-11-08 13:45:12.847152 Epoch 1301, Training loss 0.1454344540834427\n",
      "R2 values 0.5747, 0.7668, 0.7727; mean R2=0.7047\n",
      "Validation Error: Avg loss: 3.639218 \n",
      "\n",
      "2023-11-08 13:45:13.311153 Epoch 1302, Training loss 0.24797093868255615\n",
      "R2 values 0.5831, 0.7501, 0.7669; mean R2=0.7000\n",
      "Validation Error: Avg loss: 3.701040 \n",
      "\n",
      "2023-11-08 13:45:13.779524 Epoch 1303, Training loss 0.2571403384208679\n",
      "R2 values 0.6534, 0.7309, 0.7494; mean R2=0.7112\n",
      "Validation Error: Avg loss: 4.453126 \n",
      "\n",
      "2023-11-08 13:45:14.252465 Epoch 1304, Training loss 0.13907484710216522\n",
      "R2 values 0.6411, 0.7706, 0.7576; mean R2=0.7231\n",
      "Validation Error: Avg loss: 4.151061 \n",
      "\n",
      "2023-11-08 13:45:14.722229 Epoch 1305, Training loss 0.35029351711273193\n",
      "R2 values 0.6164, 0.7707, 0.7778; mean R2=0.7216\n",
      "Validation Error: Avg loss: 3.706562 \n",
      "\n",
      "2023-11-08 13:45:15.249394 Epoch 1306, Training loss 0.11936799436807632\n",
      "R2 values 0.5996, 0.7427, 0.7621; mean R2=0.7015\n",
      "Validation Error: Avg loss: 3.925678 \n",
      "\n",
      "2023-11-08 13:45:15.715910 Epoch 1307, Training loss 0.25518742203712463\n",
      "R2 values 0.5923, 0.7699, 0.7563; mean R2=0.7062\n",
      "Validation Error: Avg loss: 3.569145 \n",
      "\n",
      "2023-11-08 13:45:16.185436 Epoch 1308, Training loss 0.28614604473114014\n",
      "R2 values 0.6179, 0.7344, 0.7124; mean R2=0.6882\n",
      "Validation Error: Avg loss: 4.653724 \n",
      "\n",
      "2023-11-08 13:45:16.652599 Epoch 1309, Training loss 0.30342167615890503\n",
      "R2 values 0.6271, 0.7545, 0.7599; mean R2=0.7138\n",
      "Validation Error: Avg loss: 4.225999 \n",
      "\n",
      "2023-11-08 13:45:17.122257 Epoch 1310, Training loss 0.2901817262172699\n",
      "R2 values 0.6823, 0.7517, 0.7901; mean R2=0.7414\n",
      "Validation Error: Avg loss: 3.786556 \n",
      "\n",
      "2023-11-08 13:45:17.786582 Epoch 1311, Training loss 0.16872239112854004\n",
      "R2 values 0.6115, 0.7399, 0.8335; mean R2=0.7283\n",
      "Validation Error: Avg loss: 3.701672 \n",
      "\n",
      "2023-11-08 13:45:18.285843 Epoch 1312, Training loss 0.2727189362049103\n",
      "R2 values 0.5251, 0.7529, 0.7587; mean R2=0.6789\n",
      "Validation Error: Avg loss: 4.112529 \n",
      "\n",
      "2023-11-08 13:45:18.758863 Epoch 1313, Training loss 0.1583966314792633\n",
      "R2 values 0.6320, 0.7428, 0.7405; mean R2=0.7051\n",
      "Validation Error: Avg loss: 4.378472 \n",
      "\n",
      "2023-11-08 13:45:19.240712 Epoch 1314, Training loss 0.26677778363227844\n",
      "R2 values 0.6388, 0.7326, 0.7517; mean R2=0.7077\n",
      "Validation Error: Avg loss: 4.309597 \n",
      "\n",
      "2023-11-08 13:45:19.709094 Epoch 1315, Training loss 0.20039908587932587\n",
      "R2 values 0.6322, 0.7320, 0.8027; mean R2=0.7223\n",
      "Validation Error: Avg loss: 3.994579 \n",
      "\n",
      "2023-11-08 13:45:20.187938 Epoch 1316, Training loss 0.16668789088726044\n",
      "R2 values 0.6777, 0.7934, 0.8293; mean R2=0.7668\n",
      "Validation Error: Avg loss: 2.978360 \n",
      "\n",
      "2023-11-08 13:45:20.658179 Epoch 1317, Training loss 0.1603626012802124\n",
      "R2 values 0.6225, 0.7746, 0.8055; mean R2=0.7342\n",
      "Validation Error: Avg loss: 3.567491 \n",
      "\n",
      "2023-11-08 13:45:21.128044 Epoch 1318, Training loss 0.18291479349136353\n",
      "R2 values 0.5893, 0.7726, 0.7846; mean R2=0.7155\n",
      "Validation Error: Avg loss: 3.804142 \n",
      "\n",
      "2023-11-08 13:45:21.594355 Epoch 1319, Training loss 0.15025876462459564\n",
      "R2 values 0.6562, 0.7602, 0.7926; mean R2=0.7363\n",
      "Validation Error: Avg loss: 3.877089 \n",
      "\n",
      "2023-11-08 13:45:22.062052 Epoch 1320, Training loss 0.17688892781734467\n",
      "R2 values 0.6403, 0.7365, 0.7740; mean R2=0.7169\n",
      "Validation Error: Avg loss: 3.880004 \n",
      "\n",
      "2023-11-08 13:45:22.522760 Epoch 1321, Training loss 0.13810451328754425\n",
      "R2 values 0.6788, 0.7745, 0.7858; mean R2=0.7464\n",
      "Validation Error: Avg loss: 3.522626 \n",
      "\n",
      "2023-11-08 13:45:23.056531 Epoch 1322, Training loss 0.18680566549301147\n",
      "R2 values 0.5664, 0.7925, 0.7143; mean R2=0.6911\n",
      "Validation Error: Avg loss: 3.636191 \n",
      "\n",
      "2023-11-08 13:45:23.521194 Epoch 1323, Training loss 0.1625155508518219\n",
      "R2 values 0.5488, 0.7703, 0.7413; mean R2=0.6868\n",
      "Validation Error: Avg loss: 4.249698 \n",
      "\n",
      "2023-11-08 13:45:23.986810 Epoch 1324, Training loss 0.21468240022659302\n",
      "R2 values 0.5696, 0.7640, 0.7133; mean R2=0.6823\n",
      "Validation Error: Avg loss: 4.627274 \n",
      "\n",
      "2023-11-08 13:45:24.446866 Epoch 1325, Training loss 0.21096934378147125\n",
      "R2 values 0.6183, 0.7673, 0.8106; mean R2=0.7320\n",
      "Validation Error: Avg loss: 3.610479 \n",
      "\n",
      "2023-11-08 13:45:25.060890 Epoch 1326, Training loss 0.18338674306869507\n",
      "R2 values 0.6520, 0.7697, 0.7781; mean R2=0.7332\n",
      "Validation Error: Avg loss: 3.628654 \n",
      "\n",
      "2023-11-08 13:45:25.527378 Epoch 1327, Training loss 0.16279195249080658\n",
      "R2 values 0.6643, 0.7420, 0.7336; mean R2=0.7133\n",
      "Validation Error: Avg loss: 4.108180 \n",
      "\n",
      "2023-11-08 13:45:26.015127 Epoch 1328, Training loss 0.16667181253433228\n",
      "R2 values 0.7003, 0.7521, 0.7597; mean R2=0.7374\n",
      "Validation Error: Avg loss: 3.922121 \n",
      "\n",
      "2023-11-08 13:45:26.488550 Epoch 1329, Training loss 0.14741675555706024\n",
      "R2 values 0.6007, 0.7483, 0.7428; mean R2=0.6972\n",
      "Validation Error: Avg loss: 4.326591 \n",
      "\n",
      "2023-11-08 13:45:26.954602 Epoch 1330, Training loss 0.17509683966636658\n",
      "R2 values 0.6699, 0.7783, 0.7088; mean R2=0.7190\n",
      "Validation Error: Avg loss: 3.649140 \n",
      "\n",
      "2023-11-08 13:45:27.414428 Epoch 1331, Training loss 0.15048743784427643\n",
      "R2 values 0.6237, 0.7495, 0.7648; mean R2=0.7127\n",
      "Validation Error: Avg loss: 4.036344 \n",
      "\n",
      "2023-11-08 13:45:27.884425 Epoch 1332, Training loss 0.14972157776355743\n",
      "R2 values 0.5746, 0.7680, 0.7629; mean R2=0.7018\n",
      "Validation Error: Avg loss: 3.874636 \n",
      "\n",
      "2023-11-08 13:45:28.343387 Epoch 1333, Training loss 0.14941313862800598\n",
      "R2 values 0.6298, 0.7480, 0.7372; mean R2=0.7050\n",
      "Validation Error: Avg loss: 4.310258 \n",
      "\n",
      "2023-11-08 13:45:28.811772 Epoch 1334, Training loss 0.13277354836463928\n",
      "R2 values 0.5920, 0.7600, 0.7639; mean R2=0.7053\n",
      "Validation Error: Avg loss: 3.905898 \n",
      "\n",
      "2023-11-08 13:45:29.286260 Epoch 1335, Training loss 0.10969127714633942\n",
      "R2 values 0.5758, 0.7539, 0.7806; mean R2=0.7034\n",
      "Validation Error: Avg loss: 4.028903 \n",
      "\n",
      "2023-11-08 13:45:29.757618 Epoch 1336, Training loss 0.15540854632854462\n",
      "R2 values 0.5779, 0.7431, 0.7600; mean R2=0.6936\n",
      "Validation Error: Avg loss: 3.963821 \n",
      "\n",
      "2023-11-08 13:45:30.314477 Epoch 1337, Training loss 0.18057465553283691\n",
      "R2 values 0.6129, 0.7808, 0.7771; mean R2=0.7236\n",
      "Validation Error: Avg loss: 3.537349 \n",
      "\n",
      "2023-11-08 13:45:30.770708 Epoch 1338, Training loss 0.1024819165468216\n",
      "R2 values 0.6079, 0.7863, 0.7166; mean R2=0.7036\n",
      "Validation Error: Avg loss: 3.617269 \n",
      "\n",
      "2023-11-08 13:45:31.233014 Epoch 1339, Training loss 0.13750264048576355\n",
      "R2 values 0.5931, 0.7735, 0.7476; mean R2=0.7047\n",
      "Validation Error: Avg loss: 3.798033 \n",
      "\n",
      "2023-11-08 13:45:31.752174 Epoch 1340, Training loss 0.1459023654460907\n",
      "R2 values 0.6640, 0.7704, 0.7336; mean R2=0.7226\n",
      "Validation Error: Avg loss: 3.937098 \n",
      "\n",
      "2023-11-08 13:45:32.212796 Epoch 1341, Training loss 0.1290934681892395\n",
      "R2 values 0.6081, 0.7535, 0.7512; mean R2=0.7043\n",
      "Validation Error: Avg loss: 4.106915 \n",
      "\n",
      "2023-11-08 13:45:32.674140 Epoch 1342, Training loss 0.134375661611557\n",
      "R2 values 0.6499, 0.7506, 0.8256; mean R2=0.7420\n",
      "Validation Error: Avg loss: 3.702588 \n",
      "\n",
      "2023-11-08 13:45:33.129525 Epoch 1343, Training loss 0.15851876139640808\n",
      "R2 values 0.5938, 0.7662, 0.7662; mean R2=0.7087\n",
      "Validation Error: Avg loss: 3.698730 \n",
      "\n",
      "2023-11-08 13:45:33.691364 Epoch 1344, Training loss 0.15868684649467468\n",
      "R2 values 0.5547, 0.7795, 0.7540; mean R2=0.6961\n",
      "Validation Error: Avg loss: 3.676150 \n",
      "\n",
      "2023-11-08 13:45:34.163342 Epoch 1345, Training loss 0.1266736090183258\n",
      "R2 values 0.6065, 0.7374, 0.7311; mean R2=0.6917\n",
      "Validation Error: Avg loss: 4.414654 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:45:34.616590 Epoch 1346, Training loss 0.11407215893268585\n",
      "R2 values 0.6419, 0.7634, 0.7255; mean R2=0.7103\n",
      "Validation Error: Avg loss: 4.143174 \n",
      "\n",
      "2023-11-08 13:45:35.086063 Epoch 1347, Training loss 0.23508138954639435\n",
      "R2 values 0.5885, 0.7871, 0.7581; mean R2=0.7112\n",
      "Validation Error: Avg loss: 3.541055 \n",
      "\n",
      "2023-11-08 13:45:35.554509 Epoch 1348, Training loss 0.18640394508838654\n",
      "R2 values 0.6025, 0.7630, 0.7304; mean R2=0.6986\n",
      "Validation Error: Avg loss: 3.951435 \n",
      "\n",
      "2023-11-08 13:45:36.053449 Epoch 1349, Training loss 0.16678844392299652\n",
      "R2 values 0.6232, 0.7534, 0.7409; mean R2=0.7059\n",
      "Validation Error: Avg loss: 4.215844 \n",
      "\n",
      "2023-11-08 13:45:36.527168 Epoch 1350, Training loss 0.14978577196598053\n",
      "R2 values 0.5482, 0.7813, 0.7535; mean R2=0.6943\n",
      "Validation Error: Avg loss: 3.890303 \n",
      "\n",
      "2023-11-08 13:45:36.989230 Epoch 1351, Training loss 0.15527239441871643\n",
      "R2 values 0.6389, 0.7908, 0.7387; mean R2=0.7228\n",
      "Validation Error: Avg loss: 3.685090 \n",
      "\n",
      "2023-11-08 13:45:37.452635 Epoch 1352, Training loss 0.12964515388011932\n",
      "R2 values 0.6638, 0.7551, 0.7794; mean R2=0.7328\n",
      "Validation Error: Avg loss: 3.858780 \n",
      "\n",
      "2023-11-08 13:45:37.920404 Epoch 1353, Training loss 0.11470811069011688\n",
      "R2 values 0.7200, 0.7654, 0.7527; mean R2=0.7460\n",
      "Validation Error: Avg loss: 3.738898 \n",
      "\n",
      "2023-11-08 13:45:38.390583 Epoch 1354, Training loss 0.1154588982462883\n",
      "R2 values 0.6479, 0.7512, 0.7424; mean R2=0.7139\n",
      "Validation Error: Avg loss: 4.073673 \n",
      "\n",
      "2023-11-08 13:45:38.858903 Epoch 1355, Training loss 0.16023315489292145\n",
      "R2 values 0.6314, 0.7472, 0.7601; mean R2=0.7129\n",
      "Validation Error: Avg loss: 4.145679 \n",
      "\n",
      "2023-11-08 13:45:39.329954 Epoch 1356, Training loss 0.1565016359090805\n",
      "R2 values 0.6229, 0.7579, 0.7533; mean R2=0.7114\n",
      "Validation Error: Avg loss: 4.109710 \n",
      "\n",
      "2023-11-08 13:45:39.794542 Epoch 1357, Training loss 0.1634574830532074\n",
      "R2 values 0.5148, 0.7668, 0.7444; mean R2=0.6754\n",
      "Validation Error: Avg loss: 3.943937 \n",
      "\n",
      "2023-11-08 13:45:40.274307 Epoch 1358, Training loss 0.14378148317337036\n",
      "R2 values 0.5394, 0.7756, 0.7839; mean R2=0.6996\n",
      "Validation Error: Avg loss: 3.679821 \n",
      "\n",
      "2023-11-08 13:45:40.734333 Epoch 1359, Training loss 0.13856767117977142\n",
      "R2 values 0.5644, 0.7768, 0.7328; mean R2=0.6913\n",
      "Validation Error: Avg loss: 3.690643 \n",
      "\n",
      "2023-11-08 13:45:41.215783 Epoch 1360, Training loss 0.14799806475639343\n",
      "R2 values 0.6028, 0.7592, 0.7527; mean R2=0.7049\n",
      "Validation Error: Avg loss: 4.158415 \n",
      "\n",
      "2023-11-08 13:45:41.680132 Epoch 1361, Training loss 0.12975837290287018\n",
      "R2 values 0.5748, 0.7446, 0.7115; mean R2=0.6770\n",
      "Validation Error: Avg loss: 4.546452 \n",
      "\n",
      "2023-11-08 13:45:42.137810 Epoch 1362, Training loss 0.2081698179244995\n",
      "R2 values 0.5880, 0.7529, 0.7057; mean R2=0.6822\n",
      "Validation Error: Avg loss: 4.225537 \n",
      "\n",
      "2023-11-08 13:45:42.601829 Epoch 1363, Training loss 0.13637426495552063\n",
      "R2 values 0.5896, 0.7616, 0.7664; mean R2=0.7059\n",
      "Validation Error: Avg loss: 3.800482 \n",
      "\n",
      "2023-11-08 13:45:43.071451 Epoch 1364, Training loss 0.16894745826721191\n",
      "R2 values 0.5700, 0.7502, 0.7387; mean R2=0.6863\n",
      "Validation Error: Avg loss: 3.940548 \n",
      "\n",
      "2023-11-08 13:45:43.535838 Epoch 1365, Training loss 0.11281705647706985\n",
      "R2 values 0.6059, 0.7669, 0.7552; mean R2=0.7093\n",
      "Validation Error: Avg loss: 3.855203 \n",
      "\n",
      "2023-11-08 13:45:44.013394 Epoch 1366, Training loss 0.1209658607840538\n",
      "R2 values 0.6069, 0.7534, 0.7833; mean R2=0.7145\n",
      "Validation Error: Avg loss: 3.915796 \n",
      "\n",
      "2023-11-08 13:45:44.474190 Epoch 1367, Training loss 0.145839661359787\n",
      "R2 values 0.6327, 0.7546, 0.7937; mean R2=0.7270\n",
      "Validation Error: Avg loss: 3.836631 \n",
      "\n",
      "2023-11-08 13:45:44.946846 Epoch 1368, Training loss 0.10962396115064621\n",
      "R2 values 0.6179, 0.7494, 0.8035; mean R2=0.7236\n",
      "Validation Error: Avg loss: 3.707940 \n",
      "\n",
      "2023-11-08 13:45:45.419645 Epoch 1369, Training loss 0.11813640594482422\n",
      "R2 values 0.6857, 0.7525, 0.7514; mean R2=0.7298\n",
      "Validation Error: Avg loss: 3.839124 \n",
      "\n",
      "2023-11-08 13:45:45.887785 Epoch 1370, Training loss 0.1324009746313095\n",
      "R2 values 0.6006, 0.7613, 0.7458; mean R2=0.7026\n",
      "Validation Error: Avg loss: 3.855916 \n",
      "\n",
      "2023-11-08 13:45:46.371327 Epoch 1371, Training loss 0.13928227126598358\n",
      "R2 values 0.5567, 0.7403, 0.7561; mean R2=0.6844\n",
      "Validation Error: Avg loss: 4.190401 \n",
      "\n",
      "2023-11-08 13:45:46.838474 Epoch 1372, Training loss 0.14256398379802704\n",
      "R2 values 0.6514, 0.7802, 0.7616; mean R2=0.7311\n",
      "Validation Error: Avg loss: 3.825508 \n",
      "\n",
      "2023-11-08 13:45:47.299134 Epoch 1373, Training loss 0.12139440327882767\n",
      "R2 values 0.6427, 0.7565, 0.7770; mean R2=0.7254\n",
      "Validation Error: Avg loss: 3.978950 \n",
      "\n",
      "2023-11-08 13:45:47.767953 Epoch 1374, Training loss 0.154044046998024\n",
      "R2 values 0.6115, 0.7780, 0.7635; mean R2=0.7177\n",
      "Validation Error: Avg loss: 3.713942 \n",
      "\n",
      "2023-11-08 13:45:48.300338 Epoch 1375, Training loss 0.11165481805801392\n",
      "R2 values 0.6394, 0.7435, 0.7835; mean R2=0.7221\n",
      "Validation Error: Avg loss: 3.881807 \n",
      "\n",
      "2023-11-08 13:45:48.774679 Epoch 1376, Training loss 0.15636834502220154\n",
      "R2 values 0.5818, 0.7536, 0.7928; mean R2=0.7094\n",
      "Validation Error: Avg loss: 3.852525 \n",
      "\n",
      "2023-11-08 13:45:49.237389 Epoch 1377, Training loss 0.12192422896623611\n",
      "R2 values 0.6627, 0.7485, 0.7605; mean R2=0.7239\n",
      "Validation Error: Avg loss: 4.075058 \n",
      "\n",
      "2023-11-08 13:45:49.805700 Epoch 1378, Training loss 0.1024666279554367\n",
      "R2 values 0.5958, 0.7548, 0.7582; mean R2=0.7029\n",
      "Validation Error: Avg loss: 4.159916 \n",
      "\n",
      "2023-11-08 13:45:50.321667 Epoch 1379, Training loss 0.11503241956233978\n",
      "R2 values 0.6010, 0.7970, 0.7330; mean R2=0.7103\n",
      "Validation Error: Avg loss: 3.829799 \n",
      "\n",
      "2023-11-08 13:45:50.794200 Epoch 1380, Training loss 0.12928356230258942\n",
      "R2 values 0.6506, 0.7677, 0.7733; mean R2=0.7305\n",
      "Validation Error: Avg loss: 3.844944 \n",
      "\n",
      "2023-11-08 13:45:51.261289 Epoch 1381, Training loss 0.13776908814907074\n",
      "R2 values 0.5644, 0.7595, 0.7846; mean R2=0.7028\n",
      "Validation Error: Avg loss: 3.821419 \n",
      "\n",
      "2023-11-08 13:45:51.725558 Epoch 1382, Training loss 0.1300813853740692\n",
      "R2 values 0.5665, 0.7297, 0.7477; mean R2=0.6813\n",
      "Validation Error: Avg loss: 4.389086 \n",
      "\n",
      "2023-11-08 13:45:52.190978 Epoch 1383, Training loss 0.10968039929866791\n",
      "R2 values 0.6070, 0.7451, 0.7233; mean R2=0.6918\n",
      "Validation Error: Avg loss: 4.389395 \n",
      "\n",
      "2023-11-08 13:45:52.693250 Epoch 1384, Training loss 0.12435746192932129\n",
      "R2 values 0.5848, 0.7269, 0.7025; mean R2=0.6714\n",
      "Validation Error: Avg loss: 4.435216 \n",
      "\n",
      "2023-11-08 13:45:53.180361 Epoch 1385, Training loss 0.14019975066184998\n",
      "R2 values 0.5476, 0.7839, 0.7567; mean R2=0.6961\n",
      "Validation Error: Avg loss: 3.570720 \n",
      "\n",
      "2023-11-08 13:45:53.644340 Epoch 1386, Training loss 0.12407542765140533\n",
      "R2 values 0.5846, 0.7739, 0.7499; mean R2=0.7028\n",
      "Validation Error: Avg loss: 3.671202 \n",
      "\n",
      "2023-11-08 13:45:54.121255 Epoch 1387, Training loss 0.11932137608528137\n",
      "R2 values 0.6186, 0.7783, 0.7508; mean R2=0.7159\n",
      "Validation Error: Avg loss: 3.705104 \n",
      "\n",
      "2023-11-08 13:45:54.586204 Epoch 1388, Training loss 0.11696293950080872\n",
      "R2 values 0.6273, 0.7579, 0.7261; mean R2=0.7038\n",
      "Validation Error: Avg loss: 4.094876 \n",
      "\n",
      "2023-11-08 13:45:55.052873 Epoch 1389, Training loss 0.10413281619548798\n",
      "R2 values 0.6256, 0.8088, 0.7848; mean R2=0.7397\n",
      "Validation Error: Avg loss: 3.314394 \n",
      "\n",
      "2023-11-08 13:45:55.534154 Epoch 1390, Training loss 0.11974754929542542\n",
      "R2 values 0.6145, 0.7678, 0.7266; mean R2=0.7030\n",
      "Validation Error: Avg loss: 4.055065 \n",
      "\n",
      "2023-11-08 13:45:56.007443 Epoch 1391, Training loss 0.11975395679473877\n",
      "R2 values 0.6042, 0.7667, 0.7536; mean R2=0.7081\n",
      "Validation Error: Avg loss: 3.840921 \n",
      "\n",
      "2023-11-08 13:45:56.476097 Epoch 1392, Training loss 0.13035964965820312\n",
      "R2 values 0.6531, 0.7774, 0.7794; mean R2=0.7367\n",
      "Validation Error: Avg loss: 3.562090 \n",
      "\n",
      "2023-11-08 13:45:56.944919 Epoch 1393, Training loss 0.10664407163858414\n",
      "R2 values 0.5619, 0.7633, 0.7621; mean R2=0.6958\n",
      "Validation Error: Avg loss: 3.948360 \n",
      "\n",
      "2023-11-08 13:45:57.400087 Epoch 1394, Training loss 0.08502817898988724\n",
      "R2 values 0.5204, 0.7566, 0.7444; mean R2=0.6738\n",
      "Validation Error: Avg loss: 4.182593 \n",
      "\n",
      "2023-11-08 13:45:57.878412 Epoch 1395, Training loss 0.0789993405342102\n",
      "R2 values 0.6161, 0.7684, 0.7882; mean R2=0.7242\n",
      "Validation Error: Avg loss: 3.712827 \n",
      "\n",
      "2023-11-08 13:45:58.340321 Epoch 1396, Training loss 0.08146410435438156\n",
      "R2 values 0.4972, 0.7749, 0.7376; mean R2=0.6699\n",
      "Validation Error: Avg loss: 3.781775 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:45:58.847612 Epoch 1397, Training loss 0.09706484526395798\n",
      "R2 values 0.5869, 0.7572, 0.7398; mean R2=0.6946\n",
      "Validation Error: Avg loss: 4.040638 \n",
      "\n",
      "2023-11-08 13:45:59.439815 Epoch 1398, Training loss 0.12969902157783508\n",
      "R2 values 0.6526, 0.7573, 0.7474; mean R2=0.7191\n",
      "Validation Error: Avg loss: 3.923394 \n",
      "\n",
      "2023-11-08 13:45:59.909313 Epoch 1399, Training loss 0.10973122715950012\n",
      "R2 values 0.6137, 0.7586, 0.7454; mean R2=0.7059\n",
      "Validation Error: Avg loss: 3.947927 \n",
      "\n",
      "2023-11-08 13:46:00.378924 Epoch 1400, Training loss 0.09683346003293991\n",
      "R2 values 0.6079, 0.7572, 0.7512; mean R2=0.7055\n",
      "Validation Error: Avg loss: 4.069567 \n",
      "\n",
      "2023-11-08 13:46:00.842250 Epoch 1401, Training loss 0.15739527344703674\n",
      "R2 values 0.6382, 0.7568, 0.7168; mean R2=0.7039\n",
      "Validation Error: Avg loss: 3.973781 \n",
      "\n",
      "2023-11-08 13:46:01.305701 Epoch 1402, Training loss 0.1282687485218048\n",
      "R2 values 0.6815, 0.7527, 0.7539; mean R2=0.7294\n",
      "Validation Error: Avg loss: 4.054137 \n",
      "\n",
      "2023-11-08 13:46:01.782309 Epoch 1403, Training loss 0.10172409564256668\n",
      "R2 values 0.6186, 0.7630, 0.7592; mean R2=0.7136\n",
      "Validation Error: Avg loss: 4.007776 \n",
      "\n",
      "2023-11-08 13:46:02.273474 Epoch 1404, Training loss 0.09764759242534637\n",
      "R2 values 0.6127, 0.7367, 0.7555; mean R2=0.7016\n",
      "Validation Error: Avg loss: 4.377939 \n",
      "\n",
      "2023-11-08 13:46:02.740830 Epoch 1405, Training loss 0.13945871591567993\n",
      "R2 values 0.6024, 0.7689, 0.7936; mean R2=0.7216\n",
      "Validation Error: Avg loss: 3.844097 \n",
      "\n",
      "2023-11-08 13:46:03.220191 Epoch 1406, Training loss 0.12426541745662689\n",
      "R2 values 0.5355, 0.7219, 0.7601; mean R2=0.6725\n",
      "Validation Error: Avg loss: 4.019973 \n",
      "\n",
      "2023-11-08 13:46:03.680015 Epoch 1407, Training loss 0.14278559386730194\n",
      "R2 values 0.6608, 0.7745, 0.7964; mean R2=0.7439\n",
      "Validation Error: Avg loss: 3.501788 \n",
      "\n",
      "2023-11-08 13:46:04.148289 Epoch 1408, Training loss 0.13644014298915863\n",
      "R2 values 0.6074, 0.7443, 0.7233; mean R2=0.6917\n",
      "Validation Error: Avg loss: 4.034011 \n",
      "\n",
      "2023-11-08 13:46:04.608869 Epoch 1409, Training loss 0.15263724327087402\n",
      "R2 values 0.6457, 0.7520, 0.7302; mean R2=0.7093\n",
      "Validation Error: Avg loss: 4.063605 \n",
      "\n",
      "2023-11-08 13:46:05.073354 Epoch 1410, Training loss 0.10229845345020294\n",
      "R2 values 0.5860, 0.7521, 0.7571; mean R2=0.6984\n",
      "Validation Error: Avg loss: 3.936193 \n",
      "\n",
      "2023-11-08 13:46:05.548678 Epoch 1411, Training loss 0.15703603625297546\n",
      "R2 values 0.5684, 0.7603, 0.7614; mean R2=0.6967\n",
      "Validation Error: Avg loss: 3.823266 \n",
      "\n",
      "2023-11-08 13:46:06.016291 Epoch 1412, Training loss 0.13123585283756256\n",
      "R2 values 0.6304, 0.7332, 0.8045; mean R2=0.7227\n",
      "Validation Error: Avg loss: 4.075982 \n",
      "\n",
      "2023-11-08 13:46:06.492781 Epoch 1413, Training loss 0.13572260737419128\n",
      "R2 values 0.5674, 0.7398, 0.7414; mean R2=0.6829\n",
      "Validation Error: Avg loss: 4.333315 \n",
      "\n",
      "2023-11-08 13:46:06.956460 Epoch 1414, Training loss 0.1423594057559967\n",
      "R2 values 0.5952, 0.7415, 0.7715; mean R2=0.7027\n",
      "Validation Error: Avg loss: 4.114944 \n",
      "\n",
      "2023-11-08 13:46:07.419286 Epoch 1415, Training loss 0.11504500359296799\n",
      "R2 values 0.6764, 0.7642, 0.7659; mean R2=0.7355\n",
      "Validation Error: Avg loss: 3.577862 \n",
      "\n",
      "2023-11-08 13:46:08.144949 Epoch 1416, Training loss 0.10922961682081223\n",
      "R2 values 0.5429, 0.7450, 0.7298; mean R2=0.6726\n",
      "Validation Error: Avg loss: 4.252803 \n",
      "\n",
      "2023-11-08 13:46:08.670605 Epoch 1417, Training loss 0.15276989340782166\n",
      "R2 values 0.5712, 0.7720, 0.7135; mean R2=0.6856\n",
      "Validation Error: Avg loss: 3.963843 \n",
      "\n",
      "2023-11-08 13:46:09.145297 Epoch 1418, Training loss 0.15480734407901764\n",
      "R2 values 0.5947, 0.7732, 0.7553; mean R2=0.7078\n",
      "Validation Error: Avg loss: 3.937974 \n",
      "\n",
      "2023-11-08 13:46:09.611401 Epoch 1419, Training loss 0.15735827386379242\n",
      "R2 values 0.6152, 0.7531, 0.7776; mean R2=0.7153\n",
      "Validation Error: Avg loss: 3.934252 \n",
      "\n",
      "2023-11-08 13:46:10.081061 Epoch 1420, Training loss 0.11366987973451614\n",
      "R2 values 0.6241, 0.7426, 0.7768; mean R2=0.7145\n",
      "Validation Error: Avg loss: 3.952076 \n",
      "\n",
      "2023-11-08 13:46:10.545600 Epoch 1421, Training loss 0.15803262591362\n",
      "R2 values 0.6441, 0.7645, 0.7809; mean R2=0.7298\n",
      "Validation Error: Avg loss: 3.700980 \n",
      "\n",
      "2023-11-08 13:46:11.007971 Epoch 1422, Training loss 0.13436493277549744\n",
      "R2 values 0.5839, 0.7777, 0.7348; mean R2=0.6988\n",
      "Validation Error: Avg loss: 3.984134 \n",
      "\n",
      "2023-11-08 13:46:11.482679 Epoch 1423, Training loss 0.1356886476278305\n",
      "R2 values 0.5875, 0.7422, 0.7263; mean R2=0.6853\n",
      "Validation Error: Avg loss: 4.636073 \n",
      "\n",
      "2023-11-08 13:46:11.947532 Epoch 1424, Training loss 0.1785418689250946\n",
      "R2 values 0.6328, 0.7268, 0.7465; mean R2=0.7020\n",
      "Validation Error: Avg loss: 4.359476 \n",
      "\n",
      "2023-11-08 13:46:12.405874 Epoch 1425, Training loss 0.1317015290260315\n",
      "R2 values 0.6907, 0.7729, 0.8034; mean R2=0.7557\n",
      "Validation Error: Avg loss: 3.403653 \n",
      "\n",
      "2023-11-08 13:46:12.867318 Epoch 1426, Training loss 0.18690794706344604\n",
      "R2 values 0.5199, 0.7382, 0.7467; mean R2=0.6683\n",
      "Validation Error: Avg loss: 4.084522 \n",
      "\n",
      "2023-11-08 13:46:13.332469 Epoch 1427, Training loss 0.13810932636260986\n",
      "R2 values 0.5584, 0.7591, 0.7672; mean R2=0.6949\n",
      "Validation Error: Avg loss: 3.883482 \n",
      "\n",
      "2023-11-08 13:46:13.791482 Epoch 1428, Training loss 0.16834910213947296\n",
      "R2 values 0.6244, 0.7765, 0.7891; mean R2=0.7300\n",
      "Validation Error: Avg loss: 3.696157 \n",
      "\n",
      "2023-11-08 13:46:14.259860 Epoch 1429, Training loss 0.1602572798728943\n",
      "R2 values 0.6614, 0.7719, 0.7769; mean R2=0.7367\n",
      "Validation Error: Avg loss: 3.665228 \n",
      "\n",
      "2023-11-08 13:46:14.728060 Epoch 1430, Training loss 0.1382209062576294\n",
      "R2 values 0.6480, 0.7319, 0.7443; mean R2=0.7080\n",
      "Validation Error: Avg loss: 4.113377 \n",
      "\n",
      "2023-11-08 13:46:15.194973 Epoch 1431, Training loss 0.13710038363933563\n",
      "R2 values 0.6742, 0.7685, 0.7365; mean R2=0.7264\n",
      "Validation Error: Avg loss: 3.813644 \n",
      "\n",
      "2023-11-08 13:46:15.660452 Epoch 1432, Training loss 0.1607351154088974\n",
      "R2 values 0.6659, 0.7843, 0.7659; mean R2=0.7387\n",
      "Validation Error: Avg loss: 3.652140 \n",
      "\n",
      "2023-11-08 13:46:16.126486 Epoch 1433, Training loss 0.1186189204454422\n",
      "R2 values 0.6769, 0.7818, 0.7431; mean R2=0.7339\n",
      "Validation Error: Avg loss: 3.906994 \n",
      "\n",
      "2023-11-08 13:46:16.587046 Epoch 1434, Training loss 0.13091561198234558\n",
      "R2 values 0.6270, 0.8062, 0.7868; mean R2=0.7400\n",
      "Validation Error: Avg loss: 3.511245 \n",
      "\n",
      "2023-11-08 13:46:17.052062 Epoch 1435, Training loss 0.17517124116420746\n",
      "R2 values 0.5861, 0.7810, 0.7665; mean R2=0.7112\n",
      "Validation Error: Avg loss: 3.794153 \n",
      "\n",
      "2023-11-08 13:46:17.848267 Epoch 1436, Training loss 0.11016900837421417\n",
      "R2 values 0.6864, 0.7622, 0.7778; mean R2=0.7421\n",
      "Validation Error: Avg loss: 3.619261 \n",
      "\n",
      "2023-11-08 13:46:18.322416 Epoch 1437, Training loss 0.127488911151886\n",
      "R2 values 0.6016, 0.7449, 0.7688; mean R2=0.7051\n",
      "Validation Error: Avg loss: 3.926002 \n",
      "\n",
      "2023-11-08 13:46:18.793199 Epoch 1438, Training loss 0.120540551841259\n",
      "R2 values 0.5369, 0.7964, 0.7247; mean R2=0.6860\n",
      "Validation Error: Avg loss: 3.843862 \n",
      "\n",
      "2023-11-08 13:46:19.263247 Epoch 1439, Training loss 0.14747704565525055\n",
      "R2 values 0.6217, 0.7771, 0.7959; mean R2=0.7316\n",
      "Validation Error: Avg loss: 3.641578 \n",
      "\n",
      "2023-11-08 13:46:19.737912 Epoch 1440, Training loss 0.14982019364833832\n",
      "R2 values 0.6535, 0.7885, 0.7635; mean R2=0.7352\n",
      "Validation Error: Avg loss: 3.434783 \n",
      "\n",
      "2023-11-08 13:46:20.209516 Epoch 1441, Training loss 0.12084785103797913\n",
      "R2 values 0.7138, 0.7719, 0.7600; mean R2=0.7486\n",
      "Validation Error: Avg loss: 3.495511 \n",
      "\n",
      "2023-11-08 13:46:20.682915 Epoch 1442, Training loss 0.1617131233215332\n",
      "R2 values 0.7406, 0.7410, 0.7521; mean R2=0.7445\n",
      "Validation Error: Avg loss: 4.145633 \n",
      "\n",
      "2023-11-08 13:46:21.194021 Epoch 1443, Training loss 0.132801353931427\n",
      "R2 values 0.6324, 0.7297, 0.7893; mean R2=0.7171\n",
      "Validation Error: Avg loss: 4.359664 \n",
      "\n",
      "2023-11-08 13:46:21.661894 Epoch 1444, Training loss 0.17158858478069305\n",
      "R2 values 0.6712, 0.7611, 0.7462; mean R2=0.7262\n",
      "Validation Error: Avg loss: 4.128123 \n",
      "\n",
      "2023-11-08 13:46:22.148585 Epoch 1445, Training loss 0.18189051747322083\n",
      "R2 values 0.6451, 0.7613, 0.7708; mean R2=0.7257\n",
      "Validation Error: Avg loss: 3.877548 \n",
      "\n",
      "2023-11-08 13:46:22.676801 Epoch 1446, Training loss 0.13157576322555542\n",
      "R2 values 0.6129, 0.7509, 0.7538; mean R2=0.7059\n",
      "Validation Error: Avg loss: 3.968745 \n",
      "\n",
      "2023-11-08 13:46:23.145905 Epoch 1447, Training loss 0.1286933273077011\n",
      "R2 values 0.6300, 0.7711, 0.7770; mean R2=0.7261\n",
      "Validation Error: Avg loss: 3.812843 \n",
      "\n",
      "2023-11-08 13:46:23.613692 Epoch 1448, Training loss 0.10947457700967789\n",
      "R2 values 0.5601, 0.7660, 0.7458; mean R2=0.6906\n",
      "Validation Error: Avg loss: 4.188193 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:46:24.082024 Epoch 1449, Training loss 0.18641236424446106\n",
      "R2 values 0.6277, 0.7706, 0.7696; mean R2=0.7226\n",
      "Validation Error: Avg loss: 3.577619 \n",
      "\n",
      "2023-11-08 13:46:24.555907 Epoch 1450, Training loss 0.10736516118049622\n",
      "R2 values 0.6040, 0.7621, 0.7897; mean R2=0.7186\n",
      "Validation Error: Avg loss: 3.597294 \n",
      "\n",
      "2023-11-08 13:46:25.021385 Epoch 1451, Training loss 0.09889961034059525\n",
      "R2 values 0.5936, 0.7635, 0.7539; mean R2=0.7037\n",
      "Validation Error: Avg loss: 3.745691 \n",
      "\n",
      "2023-11-08 13:46:25.496052 Epoch 1452, Training loss 0.12324340641498566\n",
      "R2 values 0.5528, 0.7411, 0.7440; mean R2=0.6793\n",
      "Validation Error: Avg loss: 4.087875 \n",
      "\n",
      "2023-11-08 13:46:25.971859 Epoch 1453, Training loss 0.12911097705364227\n",
      "R2 values 0.5919, 0.7382, 0.7662; mean R2=0.6988\n",
      "Validation Error: Avg loss: 4.144750 \n",
      "\n",
      "2023-11-08 13:46:26.463828 Epoch 1454, Training loss 0.13825874030590057\n",
      "R2 values 0.6064, 0.7393, 0.7464; mean R2=0.6974\n",
      "Validation Error: Avg loss: 4.126900 \n",
      "\n",
      "2023-11-08 13:46:26.939443 Epoch 1455, Training loss 0.09292454272508621\n",
      "R2 values 0.7012, 0.7835, 0.7596; mean R2=0.7481\n",
      "Validation Error: Avg loss: 3.580387 \n",
      "\n",
      "2023-11-08 13:46:27.409981 Epoch 1456, Training loss 0.11999823153018951\n",
      "R2 values 0.7068, 0.7622, 0.7556; mean R2=0.7415\n",
      "Validation Error: Avg loss: 3.883470 \n",
      "\n",
      "2023-11-08 13:46:27.890637 Epoch 1457, Training loss 0.08944891393184662\n",
      "R2 values 0.6711, 0.7545, 0.7736; mean R2=0.7331\n",
      "Validation Error: Avg loss: 3.991746 \n",
      "\n",
      "2023-11-08 13:46:28.364538 Epoch 1458, Training loss 0.14918778836727142\n",
      "R2 values 0.7011, 0.7394, 0.7848; mean R2=0.7418\n",
      "Validation Error: Avg loss: 4.130894 \n",
      "\n",
      "2023-11-08 13:46:28.834398 Epoch 1459, Training loss 0.12172766029834747\n",
      "R2 values 0.6583, 0.7395, 0.7633; mean R2=0.7204\n",
      "Validation Error: Avg loss: 3.974829 \n",
      "\n",
      "2023-11-08 13:46:29.317608 Epoch 1460, Training loss 0.08150812983512878\n",
      "R2 values 0.5852, 0.7425, 0.7549; mean R2=0.6942\n",
      "Validation Error: Avg loss: 4.122799 \n",
      "\n",
      "2023-11-08 13:46:29.795281 Epoch 1461, Training loss 0.11952126026153564\n",
      "R2 values 0.5878, 0.7587, 0.7412; mean R2=0.6959\n",
      "Validation Error: Avg loss: 4.021891 \n",
      "\n",
      "2023-11-08 13:46:30.280019 Epoch 1462, Training loss 0.08786081522703171\n",
      "R2 values 0.6090, 0.7558, 0.7618; mean R2=0.7089\n",
      "Validation Error: Avg loss: 3.889489 \n",
      "\n",
      "2023-11-08 13:46:30.770763 Epoch 1463, Training loss 0.10183897614479065\n",
      "R2 values 0.5957, 0.7809, 0.7586; mean R2=0.7117\n",
      "Validation Error: Avg loss: 3.764816 \n",
      "\n",
      "2023-11-08 13:46:31.323628 Epoch 1464, Training loss 0.09574191272258759\n",
      "R2 values 0.6075, 0.7460, 0.7573; mean R2=0.7036\n",
      "Validation Error: Avg loss: 4.086784 \n",
      "\n",
      "2023-11-08 13:46:31.848468 Epoch 1465, Training loss 0.13136808574199677\n",
      "R2 values 0.6300, 0.7552, 0.7779; mean R2=0.7210\n",
      "Validation Error: Avg loss: 3.834665 \n",
      "\n",
      "2023-11-08 13:46:32.318673 Epoch 1466, Training loss 0.09750532358884811\n",
      "R2 values 0.6766, 0.7603, 0.7814; mean R2=0.7394\n",
      "Validation Error: Avg loss: 3.581512 \n",
      "\n",
      "2023-11-08 13:46:32.793804 Epoch 1467, Training loss 0.11480553448200226\n",
      "R2 values 0.6055, 0.7614, 0.7618; mean R2=0.7096\n",
      "Validation Error: Avg loss: 3.877143 \n",
      "\n",
      "2023-11-08 13:46:33.260678 Epoch 1468, Training loss 0.10012909024953842\n",
      "R2 values 0.5556, 0.7674, 0.7699; mean R2=0.6976\n",
      "Validation Error: Avg loss: 3.990778 \n",
      "\n",
      "2023-11-08 13:46:33.725191 Epoch 1469, Training loss 0.14644639194011688\n",
      "R2 values 0.6261, 0.7846, 0.7610; mean R2=0.7239\n",
      "Validation Error: Avg loss: 3.833194 \n",
      "\n",
      "2023-11-08 13:46:34.191788 Epoch 1470, Training loss 0.12406673282384872\n",
      "R2 values 0.6245, 0.7791, 0.7579; mean R2=0.7205\n",
      "Validation Error: Avg loss: 3.707409 \n",
      "\n",
      "2023-11-08 13:46:34.676734 Epoch 1471, Training loss 0.11881837248802185\n",
      "R2 values 0.6262, 0.7567, 0.7330; mean R2=0.7053\n",
      "Validation Error: Avg loss: 4.236511 \n",
      "\n",
      "2023-11-08 13:46:35.158881 Epoch 1472, Training loss 0.1079811230301857\n",
      "R2 values 0.6245, 0.7559, 0.7379; mean R2=0.7061\n",
      "Validation Error: Avg loss: 4.089797 \n",
      "\n",
      "2023-11-08 13:46:35.637664 Epoch 1473, Training loss 0.10940583795309067\n",
      "R2 values 0.6458, 0.7677, 0.7910; mean R2=0.7348\n",
      "Validation Error: Avg loss: 3.714679 \n",
      "\n",
      "2023-11-08 13:46:36.108781 Epoch 1474, Training loss 0.09482932835817337\n",
      "R2 values 0.5601, 0.7760, 0.7437; mean R2=0.6932\n",
      "Validation Error: Avg loss: 3.825871 \n",
      "\n",
      "2023-11-08 13:46:36.597302 Epoch 1475, Training loss 0.10134508460760117\n",
      "R2 values 0.6139, 0.7695, 0.7597; mean R2=0.7144\n",
      "Validation Error: Avg loss: 3.837659 \n",
      "\n",
      "2023-11-08 13:46:37.064255 Epoch 1476, Training loss 0.10491390526294708\n",
      "R2 values 0.5259, 0.7463, 0.7383; mean R2=0.6702\n",
      "Validation Error: Avg loss: 4.085360 \n",
      "\n",
      "2023-11-08 13:46:37.523419 Epoch 1477, Training loss 0.11700248718261719\n",
      "R2 values 0.6221, 0.7361, 0.7678; mean R2=0.7087\n",
      "Validation Error: Avg loss: 4.256832 \n",
      "\n",
      "2023-11-08 13:46:37.987590 Epoch 1478, Training loss 0.08527237176895142\n",
      "R2 values 0.6013, 0.7692, 0.7455; mean R2=0.7053\n",
      "Validation Error: Avg loss: 3.930269 \n",
      "\n",
      "2023-11-08 13:46:38.685757 Epoch 1479, Training loss 0.12355024367570877\n",
      "R2 values 0.6937, 0.7899, 0.7485; mean R2=0.7440\n",
      "Validation Error: Avg loss: 3.514316 \n",
      "\n",
      "2023-11-08 13:46:39.206192 Epoch 1480, Training loss 0.09277106821537018\n",
      "R2 values 0.7358, 0.7812, 0.7650; mean R2=0.7607\n",
      "Validation Error: Avg loss: 3.603617 \n",
      "\n",
      "2023-11-08 13:46:39.680773 Epoch 1481, Training loss 0.1146531030535698\n",
      "R2 values 0.6274, 0.7643, 0.7311; mean R2=0.7076\n",
      "Validation Error: Avg loss: 3.999470 \n",
      "\n",
      "2023-11-08 13:46:40.141238 Epoch 1482, Training loss 0.09778933972120285\n",
      "R2 values 0.5580, 0.7577, 0.6920; mean R2=0.6693\n",
      "Validation Error: Avg loss: 4.211756 \n",
      "\n",
      "2023-11-08 13:46:40.614656 Epoch 1483, Training loss 0.0957643911242485\n",
      "R2 values 0.5871, 0.7763, 0.7696; mean R2=0.7110\n",
      "Validation Error: Avg loss: 3.692537 \n",
      "\n",
      "2023-11-08 13:46:41.092025 Epoch 1484, Training loss 0.11702203005552292\n",
      "R2 values 0.5898, 0.7731, 0.7823; mean R2=0.7150\n",
      "Validation Error: Avg loss: 3.718887 \n",
      "\n",
      "2023-11-08 13:46:41.571885 Epoch 1485, Training loss 0.09063445031642914\n",
      "R2 values 0.5646, 0.7680, 0.7644; mean R2=0.6990\n",
      "Validation Error: Avg loss: 3.868736 \n",
      "\n",
      "2023-11-08 13:46:42.108109 Epoch 1486, Training loss 0.09919320046901703\n",
      "R2 values 0.5567, 0.7651, 0.7734; mean R2=0.6984\n",
      "Validation Error: Avg loss: 4.027124 \n",
      "\n",
      "2023-11-08 13:46:42.575055 Epoch 1487, Training loss 0.11346935480833054\n",
      "R2 values 0.5956, 0.7646, 0.7678; mean R2=0.7093\n",
      "Validation Error: Avg loss: 3.879633 \n",
      "\n",
      "2023-11-08 13:46:43.057680 Epoch 1488, Training loss 0.11867661774158478\n",
      "R2 values 0.6036, 0.7647, 0.7133; mean R2=0.6939\n",
      "Validation Error: Avg loss: 4.158577 \n",
      "\n",
      "2023-11-08 13:46:43.540148 Epoch 1489, Training loss 0.11782675236463547\n",
      "R2 values 0.5978, 0.7837, 0.7816; mean R2=0.7210\n",
      "Validation Error: Avg loss: 3.588317 \n",
      "\n",
      "2023-11-08 13:46:44.026924 Epoch 1490, Training loss 0.09441280364990234\n",
      "R2 values 0.6458, 0.7842, 0.7447; mean R2=0.7249\n",
      "Validation Error: Avg loss: 3.622208 \n",
      "\n",
      "2023-11-08 13:46:44.507146 Epoch 1491, Training loss 0.10475001484155655\n",
      "R2 values 0.6835, 0.7981, 0.7458; mean R2=0.7425\n",
      "Validation Error: Avg loss: 3.571618 \n",
      "\n",
      "2023-11-08 13:46:44.994316 Epoch 1492, Training loss 0.09463278204202652\n",
      "R2 values 0.5846, 0.7631, 0.7769; mean R2=0.7082\n",
      "Validation Error: Avg loss: 4.104260 \n",
      "\n",
      "2023-11-08 13:46:45.481400 Epoch 1493, Training loss 0.15284018218517303\n",
      "R2 values 0.5413, 0.7618, 0.7465; mean R2=0.6832\n",
      "Validation Error: Avg loss: 4.029374 \n",
      "\n",
      "2023-11-08 13:46:45.978449 Epoch 1494, Training loss 0.07019093632698059\n",
      "R2 values 0.6325, 0.7714, 0.7666; mean R2=0.7235\n",
      "Validation Error: Avg loss: 3.457790 \n",
      "\n",
      "2023-11-08 13:46:46.473586 Epoch 1495, Training loss 0.12370872497558594\n",
      "R2 values 0.5988, 0.7642, 0.7451; mean R2=0.7027\n",
      "Validation Error: Avg loss: 3.697913 \n",
      "\n",
      "2023-11-08 13:46:46.961481 Epoch 1496, Training loss 0.1370697170495987\n",
      "R2 values 0.6194, 0.7864, 0.7564; mean R2=0.7207\n",
      "Validation Error: Avg loss: 3.724002 \n",
      "\n",
      "2023-11-08 13:46:47.442785 Epoch 1497, Training loss 0.1382824331521988\n",
      "R2 values 0.6317, 0.7882, 0.7457; mean R2=0.7219\n",
      "Validation Error: Avg loss: 3.716056 \n",
      "\n",
      "2023-11-08 13:46:47.926651 Epoch 1498, Training loss 0.13105560839176178\n",
      "R2 values 0.6476, 0.7507, 0.7860; mean R2=0.7281\n",
      "Validation Error: Avg loss: 3.957802 \n",
      "\n",
      "2023-11-08 13:46:48.409304 Epoch 1499, Training loss 0.10162028670310974\n",
      "R2 values 0.6033, 0.7757, 0.7791; mean R2=0.7194\n",
      "Validation Error: Avg loss: 3.715257 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:46:48.894934 Epoch 1500, Training loss 0.08410762995481491\n",
      "R2 values 0.6028, 0.7773, 0.7889; mean R2=0.7230\n",
      "Validation Error: Avg loss: 3.644540 \n",
      "\n",
      "2023-11-08 13:46:49.430872 Epoch 1501, Training loss 0.1257171332836151\n",
      "R2 values 0.6226, 0.7559, 0.7438; mean R2=0.7074\n",
      "Validation Error: Avg loss: 4.258688 \n",
      "\n",
      "2023-11-08 13:46:50.009726 Epoch 1502, Training loss 0.09978841245174408\n",
      "R2 values 0.5945, 0.7631, 0.7465; mean R2=0.7013\n",
      "Validation Error: Avg loss: 4.261057 \n",
      "\n",
      "2023-11-08 13:46:50.499934 Epoch 1503, Training loss 0.107411228120327\n",
      "R2 values 0.5796, 0.7503, 0.7664; mean R2=0.6987\n",
      "Validation Error: Avg loss: 4.056611 \n",
      "\n",
      "2023-11-08 13:46:51.039298 Epoch 1504, Training loss 0.12306780368089676\n",
      "R2 values 0.5959, 0.7510, 0.7784; mean R2=0.7084\n",
      "Validation Error: Avg loss: 3.830359 \n",
      "\n",
      "2023-11-08 13:46:51.509183 Epoch 1505, Training loss 0.08130896091461182\n",
      "R2 values 0.6797, 0.8083, 0.7956; mean R2=0.7612\n",
      "Validation Error: Avg loss: 3.107898 \n",
      "\n",
      "2023-11-08 13:46:51.981970 Epoch 1506, Training loss 0.13473309576511383\n",
      "R2 values 0.6396, 0.7535, 0.7267; mean R2=0.7066\n",
      "Validation Error: Avg loss: 4.076465 \n",
      "\n",
      "2023-11-08 13:46:52.448573 Epoch 1507, Training loss 0.10036026686429977\n",
      "R2 values 0.6311, 0.7686, 0.7758; mean R2=0.7252\n",
      "Validation Error: Avg loss: 3.987181 \n",
      "\n",
      "2023-11-08 13:46:52.966301 Epoch 1508, Training loss 0.17855782806873322\n",
      "R2 values 0.6250, 0.7714, 0.7843; mean R2=0.7269\n",
      "Validation Error: Avg loss: 3.710236 \n",
      "\n",
      "2023-11-08 13:46:53.432047 Epoch 1509, Training loss 0.0896615982055664\n",
      "R2 values 0.6440, 0.7484, 0.7517; mean R2=0.7147\n",
      "Validation Error: Avg loss: 3.896236 \n",
      "\n",
      "2023-11-08 13:46:53.900223 Epoch 1510, Training loss 0.13619552552700043\n",
      "R2 values 0.6347, 0.7546, 0.7774; mean R2=0.7222\n",
      "Validation Error: Avg loss: 3.768857 \n",
      "\n",
      "2023-11-08 13:46:54.371478 Epoch 1511, Training loss 0.1248321682214737\n",
      "R2 values 0.5699, 0.7720, 0.7142; mean R2=0.6854\n",
      "Validation Error: Avg loss: 4.430403 \n",
      "\n",
      "2023-11-08 13:46:54.850267 Epoch 1512, Training loss 0.1401882767677307\n",
      "R2 values 0.5745, 0.7693, 0.7037; mean R2=0.6825\n",
      "Validation Error: Avg loss: 4.401123 \n",
      "\n",
      "2023-11-08 13:46:55.319046 Epoch 1513, Training loss 0.14447925984859467\n",
      "R2 values 0.6178, 0.7592, 0.7470; mean R2=0.7080\n",
      "Validation Error: Avg loss: 4.046813 \n",
      "\n",
      "2023-11-08 13:46:55.793960 Epoch 1514, Training loss 0.09030361473560333\n",
      "R2 values 0.6758, 0.7493, 0.7613; mean R2=0.7288\n",
      "Validation Error: Avg loss: 3.796128 \n",
      "\n",
      "2023-11-08 13:46:56.268820 Epoch 1515, Training loss 0.12894675135612488\n",
      "R2 values 0.5785, 0.7577, 0.7828; mean R2=0.7063\n",
      "Validation Error: Avg loss: 3.631647 \n",
      "\n",
      "2023-11-08 13:46:56.741263 Epoch 1516, Training loss 0.1717749983072281\n",
      "R2 values 0.6523, 0.7596, 0.7372; mean R2=0.7164\n",
      "Validation Error: Avg loss: 4.128559 \n",
      "\n",
      "2023-11-08 13:46:57.274915 Epoch 1517, Training loss 0.12587277591228485\n",
      "R2 values 0.7101, 0.7751, 0.7529; mean R2=0.7460\n",
      "Validation Error: Avg loss: 4.034288 \n",
      "\n",
      "2023-11-08 13:46:57.737123 Epoch 1518, Training loss 0.1943308711051941\n",
      "R2 values 0.6429, 0.7495, 0.7285; mean R2=0.7070\n",
      "Validation Error: Avg loss: 4.001454 \n",
      "\n",
      "2023-11-08 13:46:58.204449 Epoch 1519, Training loss 0.09188607335090637\n",
      "R2 values 0.6035, 0.7590, 0.7487; mean R2=0.7037\n",
      "Validation Error: Avg loss: 3.760165 \n",
      "\n",
      "2023-11-08 13:46:58.676244 Epoch 1520, Training loss 0.23019252717494965\n",
      "R2 values 0.6760, 0.7601, 0.7734; mean R2=0.7365\n",
      "Validation Error: Avg loss: 3.818433 \n",
      "\n",
      "2023-11-08 13:46:59.171790 Epoch 1521, Training loss 0.12586596608161926\n",
      "R2 values 0.5636, 0.7407, 0.7145; mean R2=0.6729\n",
      "Validation Error: Avg loss: 4.802694 \n",
      "\n",
      "2023-11-08 13:46:59.644018 Epoch 1522, Training loss 0.14906685054302216\n",
      "R2 values 0.5330, 0.7675, 0.7516; mean R2=0.6840\n",
      "Validation Error: Avg loss: 4.372334 \n",
      "\n",
      "2023-11-08 13:47:00.122300 Epoch 1523, Training loss 0.18320195376873016\n",
      "R2 values 0.6109, 0.7581, 0.7601; mean R2=0.7097\n",
      "Validation Error: Avg loss: 4.039237 \n",
      "\n",
      "2023-11-08 13:47:00.580650 Epoch 1524, Training loss 0.09081943333148956\n",
      "R2 values 0.6513, 0.7914, 0.7882; mean R2=0.7436\n",
      "Validation Error: Avg loss: 3.341336 \n",
      "\n",
      "2023-11-08 13:47:01.053268 Epoch 1525, Training loss 0.16416232287883759\n",
      "R2 values 0.5477, 0.7558, 0.7817; mean R2=0.6951\n",
      "Validation Error: Avg loss: 3.739652 \n",
      "\n",
      "2023-11-08 13:47:01.516827 Epoch 1526, Training loss 0.158492773771286\n",
      "R2 values 0.5945, 0.7644, 0.7423; mean R2=0.7004\n",
      "Validation Error: Avg loss: 4.066104 \n",
      "\n",
      "2023-11-08 13:47:01.998906 Epoch 1527, Training loss 0.14054614305496216\n",
      "R2 values 0.6013, 0.7725, 0.7285; mean R2=0.7007\n",
      "Validation Error: Avg loss: 4.002317 \n",
      "\n",
      "2023-11-08 13:47:02.462625 Epoch 1528, Training loss 0.13947166502475739\n",
      "R2 values 0.6124, 0.7752, 0.7765; mean R2=0.7214\n",
      "Validation Error: Avg loss: 3.728329 \n",
      "\n",
      "2023-11-08 13:47:02.926168 Epoch 1529, Training loss 0.1152559369802475\n",
      "R2 values 0.6628, 0.7713, 0.7654; mean R2=0.7332\n",
      "Validation Error: Avg loss: 3.693075 \n",
      "\n",
      "2023-11-08 13:47:03.396913 Epoch 1530, Training loss 0.1093224510550499\n",
      "R2 values 0.6387, 0.7673, 0.7570; mean R2=0.7210\n",
      "Validation Error: Avg loss: 3.730145 \n",
      "\n",
      "2023-11-08 13:47:03.865290 Epoch 1531, Training loss 0.10870765149593353\n",
      "R2 values 0.5592, 0.7504, 0.7112; mean R2=0.6736\n",
      "Validation Error: Avg loss: 4.240909 \n",
      "\n",
      "2023-11-08 13:47:04.356792 Epoch 1532, Training loss 0.10702838748693466\n",
      "R2 values 0.5597, 0.7530, 0.7748; mean R2=0.6958\n",
      "Validation Error: Avg loss: 4.044828 \n",
      "\n",
      "2023-11-08 13:47:04.828100 Epoch 1533, Training loss 0.0789235383272171\n",
      "R2 values 0.5903, 0.7264, 0.7953; mean R2=0.7040\n",
      "Validation Error: Avg loss: 4.347725 \n",
      "\n",
      "2023-11-08 13:47:05.295494 Epoch 1534, Training loss 0.10064000636339188\n",
      "R2 values 0.6155, 0.7768, 0.7643; mean R2=0.7189\n",
      "Validation Error: Avg loss: 3.612849 \n",
      "\n",
      "2023-11-08 13:47:05.761686 Epoch 1535, Training loss 0.09475625306367874\n",
      "R2 values 0.6359, 0.7602, 0.7604; mean R2=0.7188\n",
      "Validation Error: Avg loss: 3.796778 \n",
      "\n",
      "2023-11-08 13:47:06.472969 Epoch 1536, Training loss 0.0925091877579689\n",
      "R2 values 0.5944, 0.7670, 0.7402; mean R2=0.7005\n",
      "Validation Error: Avg loss: 3.976249 \n",
      "\n",
      "2023-11-08 13:47:07.002286 Epoch 1537, Training loss 0.11859747022390366\n",
      "R2 values 0.6487, 0.7593, 0.7536; mean R2=0.7205\n",
      "Validation Error: Avg loss: 4.047503 \n",
      "\n",
      "2023-11-08 13:47:07.477557 Epoch 1538, Training loss 0.1062932163476944\n",
      "R2 values 0.5704, 0.7445, 0.7498; mean R2=0.6882\n",
      "Validation Error: Avg loss: 4.226021 \n",
      "\n",
      "2023-11-08 13:47:07.948450 Epoch 1539, Training loss 0.11048824340105057\n",
      "R2 values 0.6275, 0.7693, 0.7647; mean R2=0.7205\n",
      "Validation Error: Avg loss: 3.757997 \n",
      "\n",
      "2023-11-08 13:47:08.420013 Epoch 1540, Training loss 0.11133455485105515\n",
      "R2 values 0.6171, 0.7515, 0.7551; mean R2=0.7079\n",
      "Validation Error: Avg loss: 3.863829 \n",
      "\n",
      "2023-11-08 13:47:08.902664 Epoch 1541, Training loss 0.1007455363869667\n",
      "R2 values 0.5205, 0.7444, 0.7767; mean R2=0.6805\n",
      "Validation Error: Avg loss: 4.076605 \n",
      "\n",
      "2023-11-08 13:47:09.390646 Epoch 1542, Training loss 0.11889700591564178\n",
      "R2 values 0.6015, 0.7356, 0.7807; mean R2=0.7060\n",
      "Validation Error: Avg loss: 4.084929 \n",
      "\n",
      "2023-11-08 13:47:09.851499 Epoch 1543, Training loss 0.09503442794084549\n",
      "R2 values 0.6571, 0.7649, 0.7581; mean R2=0.7267\n",
      "Validation Error: Avg loss: 3.855153 \n",
      "\n",
      "2023-11-08 13:47:10.324004 Epoch 1544, Training loss 0.10111864656209946\n",
      "R2 values 0.6521, 0.7787, 0.7498; mean R2=0.7269\n",
      "Validation Error: Avg loss: 3.850256 \n",
      "\n",
      "2023-11-08 13:47:10.787048 Epoch 1545, Training loss 0.1110924705862999\n",
      "R2 values 0.6213, 0.7845, 0.7713; mean R2=0.7257\n",
      "Validation Error: Avg loss: 3.649574 \n",
      "\n",
      "2023-11-08 13:47:11.263539 Epoch 1546, Training loss 0.09826881438493729\n",
      "R2 values 0.6294, 0.7881, 0.7629; mean R2=0.7268\n",
      "Validation Error: Avg loss: 3.659007 \n",
      "\n",
      "2023-11-08 13:47:11.729887 Epoch 1547, Training loss 0.13539008796215057\n",
      "R2 values 0.6400, 0.7855, 0.7592; mean R2=0.7282\n",
      "Validation Error: Avg loss: 3.648599 \n",
      "\n",
      "2023-11-08 13:47:12.186188 Epoch 1548, Training loss 0.08684912323951721\n",
      "R2 values 0.6536, 0.7663, 0.7193; mean R2=0.7131\n",
      "Validation Error: Avg loss: 4.144714 \n",
      "\n",
      "2023-11-08 13:47:12.650316 Epoch 1549, Training loss 0.11388413608074188\n",
      "R2 values 0.6002, 0.7357, 0.7674; mean R2=0.7011\n",
      "Validation Error: Avg loss: 4.281214 \n",
      "\n",
      "2023-11-08 13:47:13.109283 Epoch 1550, Training loss 0.11077991127967834\n",
      "R2 values 0.6025, 0.7546, 0.7466; mean R2=0.7012\n",
      "Validation Error: Avg loss: 4.026446 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:47:13.574514 Epoch 1551, Training loss 0.10631684213876724\n",
      "R2 values 0.6020, 0.7586, 0.7485; mean R2=0.7030\n",
      "Validation Error: Avg loss: 3.865958 \n",
      "\n",
      "2023-11-08 13:47:14.041752 Epoch 1552, Training loss 0.11144369840621948\n",
      "R2 values 0.6274, 0.7617, 0.7786; mean R2=0.7226\n",
      "Validation Error: Avg loss: 3.807650 \n",
      "\n",
      "2023-11-08 13:47:14.506696 Epoch 1553, Training loss 0.12269896268844604\n",
      "R2 values 0.5979, 0.7434, 0.7748; mean R2=0.7054\n",
      "Validation Error: Avg loss: 4.262043 \n",
      "\n",
      "2023-11-08 13:47:14.974827 Epoch 1554, Training loss 0.0933067724108696\n",
      "R2 values 0.6079, 0.7544, 0.7556; mean R2=0.7060\n",
      "Validation Error: Avg loss: 4.101206 \n",
      "\n",
      "2023-11-08 13:47:15.672491 Epoch 1555, Training loss 0.12275361269712448\n",
      "R2 values 0.6161, 0.7387, 0.7718; mean R2=0.7089\n",
      "Validation Error: Avg loss: 4.067160 \n",
      "\n",
      "2023-11-08 13:47:16.199362 Epoch 1556, Training loss 0.09148167073726654\n",
      "R2 values 0.6442, 0.7440, 0.7580; mean R2=0.7154\n",
      "Validation Error: Avg loss: 4.095528 \n",
      "\n",
      "2023-11-08 13:47:16.678994 Epoch 1557, Training loss 0.17326374351978302\n",
      "R2 values 0.5741, 0.7518, 0.7674; mean R2=0.6977\n",
      "Validation Error: Avg loss: 3.875806 \n",
      "\n",
      "2023-11-08 13:47:17.138266 Epoch 1558, Training loss 0.09867493808269501\n",
      "R2 values 0.6850, 0.7496, 0.7514; mean R2=0.7287\n",
      "Validation Error: Avg loss: 4.053154 \n",
      "\n",
      "2023-11-08 13:47:17.596390 Epoch 1559, Training loss 0.1156444177031517\n",
      "R2 values 0.5895, 0.7453, 0.7736; mean R2=0.7028\n",
      "Validation Error: Avg loss: 4.292101 \n",
      "\n",
      "2023-11-08 13:47:18.061954 Epoch 1560, Training loss 0.1338963806629181\n",
      "R2 values 0.6811, 0.7748, 0.7479; mean R2=0.7346\n",
      "Validation Error: Avg loss: 3.769313 \n",
      "\n",
      "2023-11-08 13:47:18.519819 Epoch 1561, Training loss 0.10132952034473419\n",
      "R2 values 0.5888, 0.7426, 0.7369; mean R2=0.6894\n",
      "Validation Error: Avg loss: 4.086073 \n",
      "\n",
      "2023-11-08 13:47:18.980037 Epoch 1562, Training loss 0.09452536702156067\n",
      "R2 values 0.5818, 0.7795, 0.7413; mean R2=0.7008\n",
      "Validation Error: Avg loss: 3.637222 \n",
      "\n",
      "2023-11-08 13:47:19.492520 Epoch 1563, Training loss 0.1529872864484787\n",
      "R2 values 0.6252, 0.7636, 0.7401; mean R2=0.7097\n",
      "Validation Error: Avg loss: 3.985022 \n",
      "\n",
      "2023-11-08 13:47:19.964599 Epoch 1564, Training loss 0.11126910150051117\n",
      "R2 values 0.5569, 0.7455, 0.7260; mean R2=0.6761\n",
      "Validation Error: Avg loss: 4.366879 \n",
      "\n",
      "2023-11-08 13:47:20.434518 Epoch 1565, Training loss 0.16221319139003754\n",
      "R2 values 0.6127, 0.7602, 0.7805; mean R2=0.7178\n",
      "Validation Error: Avg loss: 3.949622 \n",
      "\n",
      "2023-11-08 13:47:20.895758 Epoch 1566, Training loss 0.12008100748062134\n",
      "R2 values 0.6116, 0.7532, 0.7325; mean R2=0.6991\n",
      "Validation Error: Avg loss: 4.037364 \n",
      "\n",
      "2023-11-08 13:47:21.366923 Epoch 1567, Training loss 0.11118654906749725\n",
      "R2 values 0.5779, 0.7676, 0.7509; mean R2=0.6988\n",
      "Validation Error: Avg loss: 3.911218 \n",
      "\n",
      "2023-11-08 13:47:21.966085 Epoch 1568, Training loss 0.10941754281520844\n",
      "R2 values 0.6383, 0.7359, 0.7492; mean R2=0.7078\n",
      "Validation Error: Avg loss: 4.148467 \n",
      "\n",
      "2023-11-08 13:47:22.433736 Epoch 1569, Training loss 0.12948741018772125\n",
      "R2 values 0.6345, 0.7461, 0.7289; mean R2=0.7032\n",
      "Validation Error: Avg loss: 4.357823 \n",
      "\n",
      "2023-11-08 13:47:22.896784 Epoch 1570, Training loss 0.10386468470096588\n",
      "R2 values 0.5643, 0.7236, 0.7552; mean R2=0.6810\n",
      "Validation Error: Avg loss: 4.463204 \n",
      "\n",
      "2023-11-08 13:47:23.517284 Epoch 1571, Training loss 0.09499229490756989\n",
      "R2 values 0.6423, 0.7503, 0.7599; mean R2=0.7175\n",
      "Validation Error: Avg loss: 3.835878 \n",
      "\n",
      "2023-11-08 13:47:24.003207 Epoch 1572, Training loss 0.11630536615848541\n",
      "R2 values 0.6776, 0.7705, 0.7220; mean R2=0.7234\n",
      "Validation Error: Avg loss: 3.952412 \n",
      "\n",
      "2023-11-08 13:47:24.461340 Epoch 1573, Training loss 0.12950798869132996\n",
      "R2 values 0.6155, 0.7585, 0.7321; mean R2=0.7020\n",
      "Validation Error: Avg loss: 3.920791 \n",
      "\n",
      "2023-11-08 13:47:24.934177 Epoch 1574, Training loss 0.1475677490234375\n",
      "R2 values 0.5434, 0.8045, 0.7599; mean R2=0.7026\n",
      "Validation Error: Avg loss: 3.530818 \n",
      "\n",
      "2023-11-08 13:47:25.392123 Epoch 1575, Training loss 0.12723983824253082\n",
      "R2 values 0.5906, 0.7668, 0.7406; mean R2=0.6993\n",
      "Validation Error: Avg loss: 4.069538 \n",
      "\n",
      "2023-11-08 13:47:25.859635 Epoch 1576, Training loss 0.13710546493530273\n",
      "R2 values 0.5863, 0.7605, 0.7727; mean R2=0.7065\n",
      "Validation Error: Avg loss: 3.932862 \n",
      "\n",
      "2023-11-08 13:47:26.332215 Epoch 1577, Training loss 0.1358969509601593\n",
      "R2 values 0.6300, 0.7596, 0.7712; mean R2=0.7203\n",
      "Validation Error: Avg loss: 3.945524 \n",
      "\n",
      "2023-11-08 13:47:26.816688 Epoch 1578, Training loss 0.09255276620388031\n",
      "R2 values 0.5718, 0.7588, 0.7735; mean R2=0.7014\n",
      "Validation Error: Avg loss: 3.898864 \n",
      "\n",
      "2023-11-08 13:47:27.317159 Epoch 1579, Training loss 0.11377720534801483\n",
      "R2 values 0.5928, 0.7343, 0.7329; mean R2=0.6867\n",
      "Validation Error: Avg loss: 4.384833 \n",
      "\n",
      "2023-11-08 13:47:27.785491 Epoch 1580, Training loss 0.1542418897151947\n",
      "R2 values 0.5805, 0.7388, 0.7167; mean R2=0.6787\n",
      "Validation Error: Avg loss: 4.416387 \n",
      "\n",
      "2023-11-08 13:47:28.267305 Epoch 1581, Training loss 0.10496185719966888\n",
      "R2 values 0.5451, 0.7333, 0.7288; mean R2=0.6691\n",
      "Validation Error: Avg loss: 4.649447 \n",
      "\n",
      "2023-11-08 13:47:28.741405 Epoch 1582, Training loss 0.22538061439990997\n",
      "R2 values 0.6361, 0.7572, 0.7862; mean R2=0.7265\n",
      "Validation Error: Avg loss: 3.805024 \n",
      "\n",
      "2023-11-08 13:47:29.221186 Epoch 1583, Training loss 0.10998951643705368\n",
      "R2 values 0.6291, 0.7728, 0.7837; mean R2=0.7286\n",
      "Validation Error: Avg loss: 3.466539 \n",
      "\n",
      "2023-11-08 13:47:29.686289 Epoch 1584, Training loss 0.13456101715564728\n",
      "R2 values 0.6254, 0.7816, 0.7829; mean R2=0.7300\n",
      "Validation Error: Avg loss: 3.646835 \n",
      "\n",
      "2023-11-08 13:47:30.165873 Epoch 1585, Training loss 0.1586090475320816\n",
      "R2 values 0.6281, 0.7622, 0.7357; mean R2=0.7087\n",
      "Validation Error: Avg loss: 4.218000 \n",
      "\n",
      "2023-11-08 13:47:30.844233 Epoch 1586, Training loss 0.09896936267614365\n",
      "R2 values 0.6115, 0.7714, 0.7531; mean R2=0.7120\n",
      "Validation Error: Avg loss: 3.942493 \n",
      "\n",
      "2023-11-08 13:47:31.372353 Epoch 1587, Training loss 0.16960275173187256\n",
      "R2 values 0.6886, 0.7814, 0.8135; mean R2=0.7612\n",
      "Validation Error: Avg loss: 3.272918 \n",
      "\n",
      "2023-11-08 13:47:31.836472 Epoch 1588, Training loss 0.14364546537399292\n",
      "R2 values 0.5482, 0.7350, 0.7726; mean R2=0.6853\n",
      "Validation Error: Avg loss: 4.037486 \n",
      "\n",
      "2023-11-08 13:47:32.300892 Epoch 1589, Training loss 0.12665198743343353\n",
      "R2 values 0.5757, 0.7609, 0.7597; mean R2=0.6988\n",
      "Validation Error: Avg loss: 3.703138 \n",
      "\n",
      "2023-11-08 13:47:32.766846 Epoch 1590, Training loss 0.14179155230522156\n",
      "R2 values 0.5684, 0.7708, 0.7334; mean R2=0.6908\n",
      "Validation Error: Avg loss: 4.078244 \n",
      "\n",
      "2023-11-08 13:47:33.227495 Epoch 1591, Training loss 0.11813279986381531\n",
      "R2 values 0.5903, 0.7404, 0.7481; mean R2=0.6929\n",
      "Validation Error: Avg loss: 4.335576 \n",
      "\n",
      "2023-11-08 13:47:33.735782 Epoch 1592, Training loss 0.1389213353395462\n",
      "R2 values 0.5851, 0.7358, 0.7161; mean R2=0.6790\n",
      "Validation Error: Avg loss: 4.492934 \n",
      "\n",
      "2023-11-08 13:47:34.237488 Epoch 1593, Training loss 0.09971646964550018\n",
      "R2 values 0.6602, 0.7297, 0.7014; mean R2=0.6971\n",
      "Validation Error: Avg loss: 4.401106 \n",
      "\n",
      "2023-11-08 13:47:34.709264 Epoch 1594, Training loss 0.13190367817878723\n",
      "R2 values 0.5956, 0.7442, 0.7591; mean R2=0.6996\n",
      "Validation Error: Avg loss: 4.077422 \n",
      "\n",
      "2023-11-08 13:47:35.200234 Epoch 1595, Training loss 0.15506507456302643\n",
      "R2 values 0.6189, 0.7384, 0.7020; mean R2=0.6864\n",
      "Validation Error: Avg loss: 4.546403 \n",
      "\n",
      "2023-11-08 13:47:35.687561 Epoch 1596, Training loss 0.09767456352710724\n",
      "R2 values 0.5868, 0.7347, 0.7124; mean R2=0.6779\n",
      "Validation Error: Avg loss: 4.594759 \n",
      "\n",
      "2023-11-08 13:47:36.169646 Epoch 1597, Training loss 0.17777802050113678\n",
      "R2 values 0.5528, 0.7621, 0.7225; mean R2=0.6791\n",
      "Validation Error: Avg loss: 4.212664 \n",
      "\n",
      "2023-11-08 13:47:36.652101 Epoch 1598, Training loss 0.09304764121770859\n",
      "R2 values 0.6445, 0.7780, 0.7748; mean R2=0.7324\n",
      "Validation Error: Avg loss: 3.581087 \n",
      "\n",
      "2023-11-08 13:47:37.135741 Epoch 1599, Training loss 0.0920366570353508\n",
      "R2 values 0.6486, 0.7431, 0.7977; mean R2=0.7298\n",
      "Validation Error: Avg loss: 3.674248 \n",
      "\n",
      "2023-11-08 13:47:37.607777 Epoch 1600, Training loss 0.13657304644584656\n",
      "R2 values 0.5897, 0.7607, 0.7388; mean R2=0.6964\n",
      "Validation Error: Avg loss: 3.973218 \n",
      "\n",
      "2023-11-08 13:47:38.087984 Epoch 1601, Training loss 0.11015155166387558\n",
      "R2 values 0.6855, 0.7574, 0.7629; mean R2=0.7353\n",
      "Validation Error: Avg loss: 4.141511 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:47:38.555943 Epoch 1602, Training loss 0.09417091310024261\n",
      "R2 values 0.5836, 0.7608, 0.7375; mean R2=0.6940\n",
      "Validation Error: Avg loss: 4.525817 \n",
      "\n",
      "2023-11-08 13:47:39.035451 Epoch 1603, Training loss 0.15135034918785095\n",
      "R2 values 0.5873, 0.7538, 0.7408; mean R2=0.6940\n",
      "Validation Error: Avg loss: 4.122273 \n",
      "\n",
      "2023-11-08 13:47:39.572382 Epoch 1604, Training loss 0.11623219400644302\n",
      "R2 values 0.5527, 0.7680, 0.7424; mean R2=0.6877\n",
      "Validation Error: Avg loss: 3.813028 \n",
      "\n",
      "2023-11-08 13:47:40.077762 Epoch 1605, Training loss 0.1579013615846634\n",
      "R2 values 0.6366, 0.7368, 0.8017; mean R2=0.7250\n",
      "Validation Error: Avg loss: 3.930816 \n",
      "\n",
      "2023-11-08 13:47:40.539141 Epoch 1606, Training loss 0.11563999205827713\n",
      "R2 values 0.6496, 0.7675, 0.7362; mean R2=0.7178\n",
      "Validation Error: Avg loss: 3.905165 \n",
      "\n",
      "2023-11-08 13:47:41.002771 Epoch 1607, Training loss 0.09638521820306778\n",
      "R2 values 0.6073, 0.7347, 0.7408; mean R2=0.6943\n",
      "Validation Error: Avg loss: 4.532596 \n",
      "\n",
      "2023-11-08 13:47:41.476061 Epoch 1608, Training loss 0.09800183027982712\n",
      "R2 values 0.6014, 0.7346, 0.7741; mean R2=0.7034\n",
      "Validation Error: Avg loss: 4.121253 \n",
      "\n",
      "2023-11-08 13:47:42.057685 Epoch 1609, Training loss 0.10761039704084396\n",
      "R2 values 0.5970, 0.7511, 0.7295; mean R2=0.6925\n",
      "Validation Error: Avg loss: 4.058074 \n",
      "\n",
      "2023-11-08 13:47:42.525434 Epoch 1610, Training loss 0.12020527571439743\n",
      "R2 values 0.6117, 0.7587, 0.7723; mean R2=0.7143\n",
      "Validation Error: Avg loss: 3.750451 \n",
      "\n",
      "2023-11-08 13:47:43.014358 Epoch 1611, Training loss 0.08992864191532135\n",
      "R2 values 0.6226, 0.7382, 0.8227; mean R2=0.7278\n",
      "Validation Error: Avg loss: 3.941143 \n",
      "\n",
      "2023-11-08 13:47:43.483793 Epoch 1612, Training loss 0.11062636971473694\n",
      "R2 values 0.6315, 0.7653, 0.7993; mean R2=0.7320\n",
      "Validation Error: Avg loss: 4.020195 \n",
      "\n",
      "2023-11-08 13:47:43.950663 Epoch 1613, Training loss 0.1287277191877365\n",
      "R2 values 0.6042, 0.7701, 0.7345; mean R2=0.7029\n",
      "Validation Error: Avg loss: 4.060875 \n",
      "\n",
      "2023-11-08 13:47:44.413388 Epoch 1614, Training loss 0.11309938877820969\n",
      "R2 values 0.6035, 0.7352, 0.7412; mean R2=0.6933\n",
      "Validation Error: Avg loss: 4.359468 \n",
      "\n",
      "2023-11-08 13:47:44.875561 Epoch 1615, Training loss 0.09843631833791733\n",
      "R2 values 0.6038, 0.7457, 0.7784; mean R2=0.7093\n",
      "Validation Error: Avg loss: 3.965158 \n",
      "\n",
      "2023-11-08 13:47:45.335375 Epoch 1616, Training loss 0.09486114233732224\n",
      "R2 values 0.5762, 0.7760, 0.7664; mean R2=0.7062\n",
      "Validation Error: Avg loss: 3.679028 \n",
      "\n",
      "2023-11-08 13:47:45.805775 Epoch 1617, Training loss 0.10306151211261749\n",
      "R2 values 0.5465, 0.7351, 0.7994; mean R2=0.6937\n",
      "Validation Error: Avg loss: 4.037776 \n",
      "\n",
      "2023-11-08 13:47:46.270674 Epoch 1618, Training loss 0.10664431750774384\n",
      "R2 values 0.6107, 0.7409, 0.7946; mean R2=0.7154\n",
      "Validation Error: Avg loss: 4.091853 \n",
      "\n",
      "2023-11-08 13:47:46.739545 Epoch 1619, Training loss 0.11436834186315536\n",
      "R2 values 0.6085, 0.7520, 0.7650; mean R2=0.7085\n",
      "Validation Error: Avg loss: 3.884170 \n",
      "\n",
      "2023-11-08 13:47:47.206235 Epoch 1620, Training loss 0.1191757395863533\n",
      "R2 values 0.5592, 0.7199, 0.7641; mean R2=0.6811\n",
      "Validation Error: Avg loss: 4.525629 \n",
      "\n",
      "2023-11-08 13:47:47.673991 Epoch 1621, Training loss 0.09534833580255508\n",
      "R2 values 0.6338, 0.7189, 0.7876; mean R2=0.7134\n",
      "Validation Error: Avg loss: 4.165296 \n",
      "\n",
      "2023-11-08 13:47:48.135721 Epoch 1622, Training loss 0.07635318487882614\n",
      "R2 values 0.6619, 0.7295, 0.7769; mean R2=0.7227\n",
      "Validation Error: Avg loss: 3.996203 \n",
      "\n",
      "2023-11-08 13:47:48.621264 Epoch 1623, Training loss 0.1073494702577591\n",
      "R2 values 0.5460, 0.7746, 0.7666; mean R2=0.6958\n",
      "Validation Error: Avg loss: 3.674268 \n",
      "\n",
      "2023-11-08 13:47:49.083064 Epoch 1624, Training loss 0.12697644531726837\n",
      "R2 values 0.5894, 0.7532, 0.7404; mean R2=0.6943\n",
      "Validation Error: Avg loss: 4.213930 \n",
      "\n",
      "2023-11-08 13:47:49.558595 Epoch 1625, Training loss 0.08591163158416748\n",
      "R2 values 0.5491, 0.7439, 0.7583; mean R2=0.6838\n",
      "Validation Error: Avg loss: 4.355243 \n",
      "\n",
      "2023-11-08 13:47:50.253419 Epoch 1626, Training loss 0.1626722365617752\n",
      "R2 values 0.6082, 0.7381, 0.7394; mean R2=0.6952\n",
      "Validation Error: Avg loss: 4.296752 \n",
      "\n",
      "2023-11-08 13:47:50.720089 Epoch 1627, Training loss 0.07945761829614639\n",
      "R2 values 0.6050, 0.7339, 0.7394; mean R2=0.6928\n",
      "Validation Error: Avg loss: 4.191504 \n",
      "\n",
      "2023-11-08 13:47:51.195022 Epoch 1628, Training loss 0.10331422090530396\n",
      "R2 values 0.6761, 0.7426, 0.7804; mean R2=0.7331\n",
      "Validation Error: Avg loss: 3.834373 \n",
      "\n",
      "2023-11-08 13:47:51.667002 Epoch 1629, Training loss 0.11131139099597931\n",
      "R2 values 0.6217, 0.7431, 0.7308; mean R2=0.6985\n",
      "Validation Error: Avg loss: 4.142802 \n",
      "\n",
      "2023-11-08 13:47:52.124790 Epoch 1630, Training loss 0.13698528707027435\n",
      "R2 values 0.6271, 0.7193, 0.7240; mean R2=0.6902\n",
      "Validation Error: Avg loss: 4.539838 \n",
      "\n",
      "2023-11-08 13:47:52.589344 Epoch 1631, Training loss 0.10842558741569519\n",
      "R2 values 0.6481, 0.7835, 0.7553; mean R2=0.7289\n",
      "Validation Error: Avg loss: 3.748085 \n",
      "\n",
      "2023-11-08 13:47:53.059351 Epoch 1632, Training loss 0.10727735608816147\n",
      "R2 values 0.5596, 0.7817, 0.7799; mean R2=0.7071\n",
      "Validation Error: Avg loss: 3.545991 \n",
      "\n",
      "2023-11-08 13:47:53.551811 Epoch 1633, Training loss 0.11586571484804153\n",
      "R2 values 0.5765, 0.7923, 0.7786; mean R2=0.7158\n",
      "Validation Error: Avg loss: 3.458225 \n",
      "\n",
      "2023-11-08 13:47:54.033032 Epoch 1634, Training loss 0.11128271371126175\n",
      "R2 values 0.6411, 0.7398, 0.7484; mean R2=0.7098\n",
      "Validation Error: Avg loss: 4.167573 \n",
      "\n",
      "2023-11-08 13:47:54.497048 Epoch 1635, Training loss 0.09280644357204437\n",
      "R2 values 0.5582, 0.7280, 0.7472; mean R2=0.6778\n",
      "Validation Error: Avg loss: 4.557841 \n",
      "\n",
      "2023-11-08 13:47:54.964294 Epoch 1636, Training loss 0.11845051497220993\n",
      "R2 values 0.5649, 0.7707, 0.7516; mean R2=0.6957\n",
      "Validation Error: Avg loss: 4.020249 \n",
      "\n",
      "2023-11-08 13:47:55.481355 Epoch 1637, Training loss 0.10548409819602966\n",
      "R2 values 0.5879, 0.7522, 0.7849; mean R2=0.7083\n",
      "Validation Error: Avg loss: 3.802868 \n",
      "\n",
      "2023-11-08 13:47:55.940327 Epoch 1638, Training loss 0.0991593673825264\n",
      "R2 values 0.6349, 0.7299, 0.7377; mean R2=0.7008\n",
      "Validation Error: Avg loss: 4.426637 \n",
      "\n",
      "2023-11-08 13:47:56.410120 Epoch 1639, Training loss 0.08679313957691193\n",
      "R2 values 0.6165, 0.7795, 0.7609; mean R2=0.7190\n",
      "Validation Error: Avg loss: 3.700812 \n",
      "\n",
      "2023-11-08 13:47:56.883455 Epoch 1640, Training loss 0.11868884414434433\n",
      "R2 values 0.6008, 0.7573, 0.7574; mean R2=0.7052\n",
      "Validation Error: Avg loss: 3.888341 \n",
      "\n",
      "2023-11-08 13:47:57.346224 Epoch 1641, Training loss 0.11592861264944077\n",
      "R2 values 0.6374, 0.7726, 0.7446; mean R2=0.7182\n",
      "Validation Error: Avg loss: 3.727757 \n",
      "\n",
      "2023-11-08 13:47:57.812825 Epoch 1642, Training loss 0.08840195089578629\n",
      "R2 values 0.5650, 0.7574, 0.7523; mean R2=0.6916\n",
      "Validation Error: Avg loss: 3.906201 \n",
      "\n",
      "2023-11-08 13:47:58.295649 Epoch 1643, Training loss 0.09340570122003555\n",
      "R2 values 0.5204, 0.7269, 0.7315; mean R2=0.6596\n",
      "Validation Error: Avg loss: 4.479688 \n",
      "\n",
      "2023-11-08 13:47:58.761345 Epoch 1644, Training loss 0.09135250002145767\n",
      "R2 values 0.6132, 0.7696, 0.7532; mean R2=0.7120\n",
      "Validation Error: Avg loss: 3.903474 \n",
      "\n",
      "2023-11-08 13:47:59.254760 Epoch 1645, Training loss 0.10996810346841812\n",
      "R2 values 0.5897, 0.7734, 0.7354; mean R2=0.6995\n",
      "Validation Error: Avg loss: 3.848115 \n",
      "\n",
      "2023-11-08 13:47:59.715440 Epoch 1646, Training loss 0.07694420963525772\n",
      "R2 values 0.6638, 0.7831, 0.7624; mean R2=0.7364\n",
      "Validation Error: Avg loss: 3.474772 \n",
      "\n",
      "2023-11-08 13:48:00.221420 Epoch 1647, Training loss 0.12156810611486435\n",
      "R2 values 0.6980, 0.7881, 0.7545; mean R2=0.7469\n",
      "Validation Error: Avg loss: 3.556104 \n",
      "\n",
      "2023-11-08 13:48:00.725447 Epoch 1648, Training loss 0.08662824332714081\n",
      "R2 values 0.6511, 0.7711, 0.7591; mean R2=0.7271\n",
      "Validation Error: Avg loss: 3.877909 \n",
      "\n",
      "2023-11-08 13:48:01.193969 Epoch 1649, Training loss 0.11075665801763535\n",
      "R2 values 0.6640, 0.7553, 0.7554; mean R2=0.7249\n",
      "Validation Error: Avg loss: 3.927381 \n",
      "\n",
      "2023-11-08 13:48:01.668306 Epoch 1650, Training loss 0.09155133366584778\n",
      "R2 values 0.6264, 0.7371, 0.7606; mean R2=0.7080\n",
      "Validation Error: Avg loss: 4.053535 \n",
      "\n",
      "2023-11-08 13:48:02.133055 Epoch 1651, Training loss 0.10971327126026154\n",
      "R2 values 0.6498, 0.7541, 0.7759; mean R2=0.7266\n",
      "Validation Error: Avg loss: 3.900235 \n",
      "\n",
      "2023-11-08 13:48:02.590990 Epoch 1652, Training loss 0.0985964983701706\n",
      "R2 values 0.5730, 0.7322, 0.7270; mean R2=0.6774\n",
      "Validation Error: Avg loss: 4.459687 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:48:03.053359 Epoch 1653, Training loss 0.08570397645235062\n",
      "R2 values 0.6404, 0.7325, 0.7606; mean R2=0.7112\n",
      "Validation Error: Avg loss: 4.228219 \n",
      "\n",
      "2023-11-08 13:48:03.514474 Epoch 1654, Training loss 0.08384748548269272\n",
      "R2 values 0.5985, 0.7566, 0.7123; mean R2=0.6891\n",
      "Validation Error: Avg loss: 4.277629 \n",
      "\n",
      "2023-11-08 13:48:03.976673 Epoch 1655, Training loss 0.08721697330474854\n",
      "R2 values 0.5909, 0.7461, 0.7572; mean R2=0.6981\n",
      "Validation Error: Avg loss: 4.094423 \n",
      "\n",
      "2023-11-08 13:48:04.464039 Epoch 1656, Training loss 0.11523713916540146\n",
      "R2 values 0.6526, 0.7396, 0.7441; mean R2=0.7121\n",
      "Validation Error: Avg loss: 4.224612 \n",
      "\n",
      "2023-11-08 13:48:04.931059 Epoch 1657, Training loss 0.08823230117559433\n",
      "R2 values 0.6453, 0.7777, 0.7379; mean R2=0.7203\n",
      "Validation Error: Avg loss: 3.739661 \n",
      "\n",
      "2023-11-08 13:48:05.391882 Epoch 1658, Training loss 0.13486981391906738\n",
      "R2 values 0.5823, 0.7348, 0.7434; mean R2=0.6868\n",
      "Validation Error: Avg loss: 4.220501 \n",
      "\n",
      "2023-11-08 13:48:05.859414 Epoch 1659, Training loss 0.09776810556650162\n",
      "R2 values 0.6091, 0.7401, 0.7718; mean R2=0.7070\n",
      "Validation Error: Avg loss: 4.043992 \n",
      "\n",
      "2023-11-08 13:48:06.324681 Epoch 1660, Training loss 0.09076163172721863\n",
      "R2 values 0.6361, 0.7660, 0.7491; mean R2=0.7171\n",
      "Validation Error: Avg loss: 3.882754 \n",
      "\n",
      "2023-11-08 13:48:06.800865 Epoch 1661, Training loss 0.08596012741327286\n",
      "R2 values 0.6542, 0.7627, 0.7563; mean R2=0.7244\n",
      "Validation Error: Avg loss: 3.942140 \n",
      "\n",
      "2023-11-08 13:48:07.304518 Epoch 1662, Training loss 0.11647925525903702\n",
      "R2 values 0.6022, 0.7467, 0.7634; mean R2=0.7041\n",
      "Validation Error: Avg loss: 4.188391 \n",
      "\n",
      "2023-11-08 13:48:07.767907 Epoch 1663, Training loss 0.08181336522102356\n",
      "R2 values 0.6352, 0.7708, 0.8008; mean R2=0.7356\n",
      "Validation Error: Avg loss: 3.722301 \n",
      "\n",
      "2023-11-08 13:48:08.238943 Epoch 1664, Training loss 0.10434138029813766\n",
      "R2 values 0.6406, 0.7525, 0.7248; mean R2=0.7060\n",
      "Validation Error: Avg loss: 4.262590 \n",
      "\n",
      "2023-11-08 13:48:08.705493 Epoch 1665, Training loss 0.09005115926265717\n",
      "R2 values 0.6707, 0.7534, 0.7695; mean R2=0.7312\n",
      "Validation Error: Avg loss: 3.808501 \n",
      "\n",
      "2023-11-08 13:48:09.174347 Epoch 1666, Training loss 0.08368714898824692\n",
      "R2 values 0.6226, 0.7492, 0.7480; mean R2=0.7066\n",
      "Validation Error: Avg loss: 3.905447 \n",
      "\n",
      "2023-11-08 13:48:09.639547 Epoch 1667, Training loss 0.09117678552865982\n",
      "R2 values 0.5743, 0.7489, 0.6818; mean R2=0.6683\n",
      "Validation Error: Avg loss: 4.277667 \n",
      "\n",
      "2023-11-08 13:48:10.103553 Epoch 1668, Training loss 0.11789333075284958\n",
      "R2 values 0.5811, 0.7275, 0.7141; mean R2=0.6742\n",
      "Validation Error: Avg loss: 4.520706 \n",
      "\n",
      "2023-11-08 13:48:10.558630 Epoch 1669, Training loss 0.07985810190439224\n",
      "R2 values 0.6294, 0.7493, 0.7522; mean R2=0.7103\n",
      "Validation Error: Avg loss: 4.024459 \n",
      "\n",
      "2023-11-08 13:48:11.024737 Epoch 1670, Training loss 0.11753180623054504\n",
      "R2 values 0.6484, 0.7562, 0.7484; mean R2=0.7177\n",
      "Validation Error: Avg loss: 3.977768 \n",
      "\n",
      "2023-11-08 13:48:11.485467 Epoch 1671, Training loss 0.07316035032272339\n",
      "R2 values 0.5842, 0.7347, 0.7355; mean R2=0.6848\n",
      "Validation Error: Avg loss: 4.254242 \n",
      "\n",
      "2023-11-08 13:48:11.957938 Epoch 1672, Training loss 0.09366755187511444\n",
      "R2 values 0.6039, 0.7723, 0.7586; mean R2=0.7116\n",
      "Validation Error: Avg loss: 3.874488 \n",
      "\n",
      "2023-11-08 13:48:12.497148 Epoch 1673, Training loss 0.06287238746881485\n",
      "R2 values 0.5865, 0.7618, 0.7304; mean R2=0.6929\n",
      "Validation Error: Avg loss: 4.114426 \n",
      "\n",
      "2023-11-08 13:48:13.024828 Epoch 1674, Training loss 0.09829512983560562\n",
      "R2 values 0.6034, 0.7493, 0.7429; mean R2=0.6986\n",
      "Validation Error: Avg loss: 4.060029 \n",
      "\n",
      "2023-11-08 13:48:13.491374 Epoch 1675, Training loss 0.10156691074371338\n",
      "R2 values 0.6310, 0.7548, 0.7750; mean R2=0.7203\n",
      "Validation Error: Avg loss: 3.980093 \n",
      "\n",
      "2023-11-08 13:48:13.953722 Epoch 1676, Training loss 0.08565651625394821\n",
      "R2 values 0.6475, 0.7253, 0.7860; mean R2=0.7196\n",
      "Validation Error: Avg loss: 4.152490 \n",
      "\n",
      "2023-11-08 13:48:14.419883 Epoch 1677, Training loss 0.08655796945095062\n",
      "R2 values 0.5600, 0.7564, 0.7672; mean R2=0.6946\n",
      "Validation Error: Avg loss: 3.862224 \n",
      "\n",
      "2023-11-08 13:48:14.895289 Epoch 1678, Training loss 0.11287824809551239\n",
      "R2 values 0.7096, 0.8032, 0.7627; mean R2=0.7585\n",
      "Validation Error: Avg loss: 3.299547 \n",
      "\n",
      "2023-11-08 13:48:15.403177 Epoch 1679, Training loss 0.09150437265634537\n",
      "R2 values 0.6165, 0.7597, 0.7518; mean R2=0.7093\n",
      "Validation Error: Avg loss: 3.892798 \n",
      "\n",
      "2023-11-08 13:48:15.863051 Epoch 1680, Training loss 0.08726361393928528\n",
      "R2 values 0.6160, 0.7514, 0.7266; mean R2=0.6980\n",
      "Validation Error: Avg loss: 4.274345 \n",
      "\n",
      "2023-11-08 13:48:16.327667 Epoch 1681, Training loss 0.09945543110370636\n",
      "R2 values 0.6474, 0.7767, 0.7790; mean R2=0.7344\n",
      "Validation Error: Avg loss: 3.552305 \n",
      "\n",
      "2023-11-08 13:48:16.805213 Epoch 1682, Training loss 0.08423721790313721\n",
      "R2 values 0.6509, 0.7291, 0.7350; mean R2=0.7050\n",
      "Validation Error: Avg loss: 4.195857 \n",
      "\n",
      "2023-11-08 13:48:17.285552 Epoch 1683, Training loss 0.09278986603021622\n",
      "R2 values 0.5932, 0.7269, 0.7445; mean R2=0.6882\n",
      "Validation Error: Avg loss: 4.320509 \n",
      "\n",
      "2023-11-08 13:48:17.751440 Epoch 1684, Training loss 0.09062984585762024\n",
      "R2 values 0.6306, 0.7709, 0.7371; mean R2=0.7128\n",
      "Validation Error: Avg loss: 3.943531 \n",
      "\n",
      "2023-11-08 13:48:18.224196 Epoch 1685, Training loss 0.111145980656147\n",
      "R2 values 0.6169, 0.7404, 0.7538; mean R2=0.7037\n",
      "Validation Error: Avg loss: 4.242760 \n",
      "\n",
      "2023-11-08 13:48:18.688925 Epoch 1686, Training loss 0.10404371470212936\n",
      "R2 values 0.5828, 0.7436, 0.7564; mean R2=0.6943\n",
      "Validation Error: Avg loss: 4.152757 \n",
      "\n",
      "2023-11-08 13:48:19.159270 Epoch 1687, Training loss 0.07971815019845963\n",
      "R2 values 0.6701, 0.7815, 0.7973; mean R2=0.7496\n",
      "Validation Error: Avg loss: 3.388015 \n",
      "\n",
      "2023-11-08 13:48:19.625841 Epoch 1688, Training loss 0.10013605654239655\n",
      "R2 values 0.5417, 0.7448, 0.7668; mean R2=0.6844\n",
      "Validation Error: Avg loss: 4.162673 \n",
      "\n",
      "2023-11-08 13:48:20.099503 Epoch 1689, Training loss 0.12428025156259537\n",
      "R2 values 0.6561, 0.7604, 0.7713; mean R2=0.7293\n",
      "Validation Error: Avg loss: 3.914967 \n",
      "\n",
      "2023-11-08 13:48:20.562199 Epoch 1690, Training loss 0.07047725468873978\n",
      "R2 values 0.6465, 0.7646, 0.7617; mean R2=0.7243\n",
      "Validation Error: Avg loss: 3.995750 \n",
      "\n",
      "2023-11-08 13:48:21.032350 Epoch 1691, Training loss 0.09632930904626846\n",
      "R2 values 0.5981, 0.7691, 0.7402; mean R2=0.7025\n",
      "Validation Error: Avg loss: 3.980693 \n",
      "\n",
      "2023-11-08 13:48:21.503671 Epoch 1692, Training loss 0.0953604057431221\n",
      "R2 values 0.6129, 0.7372, 0.7614; mean R2=0.7038\n",
      "Validation Error: Avg loss: 4.031139 \n",
      "\n",
      "2023-11-08 13:48:22.041241 Epoch 1693, Training loss 0.06722116470336914\n",
      "R2 values 0.6329, 0.7661, 0.7494; mean R2=0.7161\n",
      "Validation Error: Avg loss: 3.802701 \n",
      "\n",
      "2023-11-08 13:48:22.501397 Epoch 1694, Training loss 0.08720973134040833\n",
      "R2 values 0.6310, 0.7860, 0.7505; mean R2=0.7225\n",
      "Validation Error: Avg loss: 3.669806 \n",
      "\n",
      "2023-11-08 13:48:22.965874 Epoch 1695, Training loss 0.08097565174102783\n",
      "R2 values 0.5466, 0.7533, 0.7218; mean R2=0.6739\n",
      "Validation Error: Avg loss: 4.424281 \n",
      "\n",
      "2023-11-08 13:48:23.432145 Epoch 1696, Training loss 0.11667639762163162\n",
      "R2 values 0.6208, 0.7500, 0.6937; mean R2=0.6881\n",
      "Validation Error: Avg loss: 4.322488 \n",
      "\n",
      "2023-11-08 13:48:23.905610 Epoch 1697, Training loss 0.08470096439123154\n",
      "R2 values 0.6062, 0.7884, 0.7753; mean R2=0.7233\n",
      "Validation Error: Avg loss: 3.458793 \n",
      "\n",
      "2023-11-08 13:48:24.371308 Epoch 1698, Training loss 0.10216610133647919\n",
      "R2 values 0.6389, 0.7660, 0.7584; mean R2=0.7211\n",
      "Validation Error: Avg loss: 3.683882 \n",
      "\n",
      "2023-11-08 13:48:24.865128 Epoch 1699, Training loss 0.08469363301992416\n",
      "R2 values 0.5938, 0.7523, 0.7297; mean R2=0.6919\n",
      "Validation Error: Avg loss: 4.157650 \n",
      "\n",
      "2023-11-08 13:48:25.328072 Epoch 1700, Training loss 0.08460433781147003\n",
      "R2 values 0.5798, 0.7391, 0.7305; mean R2=0.6831\n",
      "Validation Error: Avg loss: 4.234326 \n",
      "\n",
      "2023-11-08 13:48:25.794071 Epoch 1701, Training loss 0.09944577515125275\n",
      "R2 values 0.6680, 0.7637, 0.7590; mean R2=0.7302\n",
      "Validation Error: Avg loss: 3.864967 \n",
      "\n",
      "2023-11-08 13:48:26.262226 Epoch 1702, Training loss 0.06846311688423157\n",
      "R2 values 0.6845, 0.7510, 0.7703; mean R2=0.7353\n",
      "Validation Error: Avg loss: 3.914471 \n",
      "\n",
      "2023-11-08 13:48:26.737894 Epoch 1703, Training loss 0.09012872725725174\n",
      "R2 values 0.5883, 0.7620, 0.7421; mean R2=0.6975\n",
      "Validation Error: Avg loss: 3.894506 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:48:27.221649 Epoch 1704, Training loss 0.08414740115404129\n",
      "R2 values 0.6178, 0.7791, 0.7516; mean R2=0.7162\n",
      "Validation Error: Avg loss: 3.857451 \n",
      "\n",
      "2023-11-08 13:48:27.685797 Epoch 1705, Training loss 0.07487650215625763\n",
      "R2 values 0.6208, 0.7698, 0.7627; mean R2=0.7178\n",
      "Validation Error: Avg loss: 3.966723 \n",
      "\n",
      "2023-11-08 13:48:28.166616 Epoch 1706, Training loss 0.08988577127456665\n",
      "R2 values 0.6100, 0.7658, 0.7012; mean R2=0.6923\n",
      "Validation Error: Avg loss: 3.957202 \n",
      "\n",
      "2023-11-08 13:48:28.625119 Epoch 1707, Training loss 0.08081571012735367\n",
      "R2 values 0.6194, 0.7560, 0.7517; mean R2=0.7090\n",
      "Validation Error: Avg loss: 3.916469 \n",
      "\n",
      "2023-11-08 13:48:29.091993 Epoch 1708, Training loss 0.17293891310691833\n",
      "R2 values 0.6647, 0.7776, 0.7697; mean R2=0.7373\n",
      "Validation Error: Avg loss: 3.592319 \n",
      "\n",
      "2023-11-08 13:48:29.562379 Epoch 1709, Training loss 0.08997452259063721\n",
      "R2 values 0.6310, 0.7619, 0.7479; mean R2=0.7136\n",
      "Validation Error: Avg loss: 4.258878 \n",
      "\n",
      "2023-11-08 13:48:30.034541 Epoch 1710, Training loss 0.14744466543197632\n",
      "R2 values 0.5810, 0.7516, 0.7704; mean R2=0.7010\n",
      "Validation Error: Avg loss: 4.216855 \n",
      "\n",
      "2023-11-08 13:48:30.517129 Epoch 1711, Training loss 0.184108167886734\n",
      "R2 values 0.6134, 0.7684, 0.7808; mean R2=0.7208\n",
      "Validation Error: Avg loss: 3.731019 \n",
      "\n",
      "2023-11-08 13:48:30.994191 Epoch 1712, Training loss 0.1274271458387375\n",
      "R2 values 0.6401, 0.7339, 0.7593; mean R2=0.7111\n",
      "Validation Error: Avg loss: 4.161393 \n",
      "\n",
      "2023-11-08 13:48:31.453112 Epoch 1713, Training loss 0.14392918348312378\n",
      "R2 values 0.6234, 0.7482, 0.7057; mean R2=0.6924\n",
      "Validation Error: Avg loss: 4.432155 \n",
      "\n",
      "2023-11-08 13:48:31.923637 Epoch 1714, Training loss 0.12411420047283173\n",
      "R2 values 0.5795, 0.7500, 0.7128; mean R2=0.6807\n",
      "Validation Error: Avg loss: 4.433483 \n",
      "\n",
      "2023-11-08 13:48:32.385143 Epoch 1715, Training loss 0.1162080392241478\n",
      "R2 values 0.6332, 0.7838, 0.7438; mean R2=0.7203\n",
      "Validation Error: Avg loss: 3.826417 \n",
      "\n",
      "2023-11-08 13:48:32.843333 Epoch 1716, Training loss 0.08643800765275955\n",
      "R2 values 0.5815, 0.7691, 0.7563; mean R2=0.7023\n",
      "Validation Error: Avg loss: 3.760575 \n",
      "\n",
      "2023-11-08 13:48:33.306941 Epoch 1717, Training loss 0.10799439996480942\n",
      "R2 values 0.6084, 0.7456, 0.7705; mean R2=0.7082\n",
      "Validation Error: Avg loss: 3.855684 \n",
      "\n",
      "2023-11-08 13:48:33.813223 Epoch 1718, Training loss 0.1088523268699646\n",
      "R2 values 0.6433, 0.7583, 0.7726; mean R2=0.7247\n",
      "Validation Error: Avg loss: 3.737107 \n",
      "\n",
      "2023-11-08 13:48:34.289899 Epoch 1719, Training loss 0.12936851382255554\n",
      "R2 values 0.5336, 0.7473, 0.7083; mean R2=0.6631\n",
      "Validation Error: Avg loss: 4.306771 \n",
      "\n",
      "2023-11-08 13:48:34.753571 Epoch 1720, Training loss 0.1084349974989891\n",
      "R2 values 0.6561, 0.7574, 0.7577; mean R2=0.7237\n",
      "Validation Error: Avg loss: 4.005508 \n",
      "\n",
      "2023-11-08 13:48:35.217122 Epoch 1721, Training loss 0.12477803975343704\n",
      "R2 values 0.5929, 0.7482, 0.7141; mean R2=0.6851\n",
      "Validation Error: Avg loss: 4.256114 \n",
      "\n",
      "2023-11-08 13:48:35.854482 Epoch 1722, Training loss 0.1480323076248169\n",
      "R2 values 0.6435, 0.7440, 0.7819; mean R2=0.7232\n",
      "Validation Error: Avg loss: 3.826143 \n",
      "\n",
      "2023-11-08 13:48:36.350478 Epoch 1723, Training loss 0.1194298267364502\n",
      "R2 values 0.6748, 0.7758, 0.7837; mean R2=0.7448\n",
      "Validation Error: Avg loss: 3.690289 \n",
      "\n",
      "2023-11-08 13:48:36.816753 Epoch 1724, Training loss 0.11503753811120987\n",
      "R2 values 0.6218, 0.7732, 0.7108; mean R2=0.7019\n",
      "Validation Error: Avg loss: 4.143523 \n",
      "\n",
      "2023-11-08 13:48:37.300602 Epoch 1725, Training loss 0.10622454434633255\n",
      "R2 values 0.6421, 0.7764, 0.7548; mean R2=0.7244\n",
      "Validation Error: Avg loss: 3.899353 \n",
      "\n",
      "2023-11-08 13:48:37.767621 Epoch 1726, Training loss 0.1569875180721283\n",
      "R2 values 0.6122, 0.7767, 0.7490; mean R2=0.7126\n",
      "Validation Error: Avg loss: 3.713884 \n",
      "\n",
      "2023-11-08 13:48:38.230631 Epoch 1727, Training loss 0.16413654386997223\n",
      "R2 values 0.6495, 0.7657, 0.7584; mean R2=0.7245\n",
      "Validation Error: Avg loss: 3.674596 \n",
      "\n",
      "2023-11-08 13:48:38.695024 Epoch 1728, Training loss 0.10365056991577148\n",
      "R2 values 0.6492, 0.7310, 0.7293; mean R2=0.7031\n",
      "Validation Error: Avg loss: 4.265022 \n",
      "\n",
      "2023-11-08 13:48:39.170771 Epoch 1729, Training loss 0.1533578634262085\n",
      "R2 values 0.5484, 0.7157, 0.7551; mean R2=0.6731\n",
      "Validation Error: Avg loss: 4.576015 \n",
      "\n",
      "2023-11-08 13:48:39.642062 Epoch 1730, Training loss 0.11178866773843765\n",
      "R2 values 0.5621, 0.7233, 0.7402; mean R2=0.6752\n",
      "Validation Error: Avg loss: 4.693217 \n",
      "\n",
      "2023-11-08 13:48:40.116532 Epoch 1731, Training loss 0.1588653028011322\n",
      "R2 values 0.5794, 0.7646, 0.7568; mean R2=0.7003\n",
      "Validation Error: Avg loss: 4.060108 \n",
      "\n",
      "2023-11-08 13:48:40.574502 Epoch 1732, Training loss 0.11036722362041473\n",
      "R2 values 0.5869, 0.7458, 0.7609; mean R2=0.6979\n",
      "Validation Error: Avg loss: 3.874910 \n",
      "\n",
      "2023-11-08 13:48:41.041813 Epoch 1733, Training loss 0.0851566419005394\n",
      "R2 values 0.6248, 0.8023, 0.8074; mean R2=0.7448\n",
      "Validation Error: Avg loss: 3.077281 \n",
      "\n",
      "2023-11-08 13:48:41.505386 Epoch 1734, Training loss 0.10309971123933792\n",
      "R2 values 0.5541, 0.7804, 0.7819; mean R2=0.7054\n",
      "Validation Error: Avg loss: 3.689527 \n",
      "\n",
      "2023-11-08 13:48:41.967293 Epoch 1735, Training loss 0.15312184393405914\n",
      "R2 values 0.6079, 0.7577, 0.7198; mean R2=0.6951\n",
      "Validation Error: Avg loss: 4.330349 \n",
      "\n",
      "2023-11-08 13:48:42.427542 Epoch 1736, Training loss 0.1610926240682602\n",
      "R2 values 0.6517, 0.7670, 0.7876; mean R2=0.7354\n",
      "Validation Error: Avg loss: 3.755364 \n",
      "\n",
      "2023-11-08 13:48:42.890874 Epoch 1737, Training loss 0.1533200889825821\n",
      "R2 values 0.6522, 0.7717, 0.7667; mean R2=0.7302\n",
      "Validation Error: Avg loss: 3.572732 \n",
      "\n",
      "2023-11-08 13:48:43.357978 Epoch 1738, Training loss 0.15268473327159882\n",
      "R2 values 0.6552, 0.7431, 0.7661; mean R2=0.7215\n",
      "Validation Error: Avg loss: 3.856067 \n",
      "\n",
      "2023-11-08 13:48:43.824911 Epoch 1739, Training loss 0.11693200469017029\n",
      "R2 values 0.5831, 0.7247, 0.7370; mean R2=0.6816\n",
      "Validation Error: Avg loss: 4.514246 \n",
      "\n",
      "2023-11-08 13:48:44.288818 Epoch 1740, Training loss 0.09775453060865402\n",
      "R2 values 0.5754, 0.7457, 0.7536; mean R2=0.6916\n",
      "Validation Error: Avg loss: 4.274260 \n",
      "\n",
      "2023-11-08 13:48:44.754599 Epoch 1741, Training loss 0.116947241127491\n",
      "R2 values 0.5275, 0.7483, 0.6963; mean R2=0.6574\n",
      "Validation Error: Avg loss: 4.317477 \n",
      "\n",
      "2023-11-08 13:48:45.215520 Epoch 1742, Training loss 0.10336533933877945\n",
      "R2 values 0.6304, 0.7637, 0.7463; mean R2=0.7135\n",
      "Validation Error: Avg loss: 3.678338 \n",
      "\n",
      "2023-11-08 13:48:45.677373 Epoch 1743, Training loss 0.14016880095005035\n",
      "R2 values 0.6086, 0.7633, 0.7535; mean R2=0.7084\n",
      "Validation Error: Avg loss: 3.663422 \n",
      "\n",
      "2023-11-08 13:48:46.205301 Epoch 1744, Training loss 0.107349693775177\n",
      "R2 values 0.6017, 0.7489, 0.7543; mean R2=0.7016\n",
      "Validation Error: Avg loss: 4.095761 \n",
      "\n",
      "2023-11-08 13:48:46.668255 Epoch 1745, Training loss 0.08703624457120895\n",
      "R2 values 0.5901, 0.7687, 0.7071; mean R2=0.6886\n",
      "Validation Error: Avg loss: 4.313974 \n",
      "\n",
      "2023-11-08 13:48:47.364931 Epoch 1746, Training loss 0.14675749838352203\n",
      "R2 values 0.6004, 0.7289, 0.7357; mean R2=0.6883\n",
      "Validation Error: Avg loss: 4.425433 \n",
      "\n",
      "2023-11-08 13:48:47.845765 Epoch 1747, Training loss 0.09858053177595139\n",
      "R2 values 0.5943, 0.7392, 0.7309; mean R2=0.6882\n",
      "Validation Error: Avg loss: 4.075953 \n",
      "\n",
      "2023-11-08 13:48:48.319128 Epoch 1748, Training loss 0.14249809086322784\n",
      "R2 values 0.6594, 0.7432, 0.7620; mean R2=0.7215\n",
      "Validation Error: Avg loss: 3.945790 \n",
      "\n",
      "2023-11-08 13:48:48.786440 Epoch 1749, Training loss 0.09702031314373016\n",
      "R2 values 0.5854, 0.7512, 0.7197; mean R2=0.6854\n",
      "Validation Error: Avg loss: 4.201367 \n",
      "\n",
      "2023-11-08 13:48:49.253000 Epoch 1750, Training loss 0.12052519619464874\n",
      "R2 values 0.6152, 0.7456, 0.7298; mean R2=0.6969\n",
      "Validation Error: Avg loss: 4.356544 \n",
      "\n",
      "2023-11-08 13:48:49.717814 Epoch 1751, Training loss 0.16776110231876373\n",
      "R2 values 0.6369, 0.7708, 0.7396; mean R2=0.7158\n",
      "Validation Error: Avg loss: 3.822768 \n",
      "\n",
      "2023-11-08 13:48:50.176755 Epoch 1752, Training loss 0.1109069287776947\n",
      "R2 values 0.6175, 0.7801, 0.7741; mean R2=0.7239\n",
      "Validation Error: Avg loss: 3.552650 \n",
      "\n",
      "2023-11-08 13:48:50.637902 Epoch 1753, Training loss 0.13196849822998047\n",
      "R2 values 0.5589, 0.7566, 0.7432; mean R2=0.6862\n",
      "Validation Error: Avg loss: 4.085413 \n",
      "\n",
      "2023-11-08 13:48:51.096127 Epoch 1754, Training loss 0.1121595948934555\n",
      "R2 values 0.6138, 0.7559, 0.7727; mean R2=0.7141\n",
      "Validation Error: Avg loss: 3.943368 \n",
      "\n",
      "2023-11-08 13:48:51.555763 Epoch 1755, Training loss 0.08840005099773407\n",
      "R2 values 0.6208, 0.7401, 0.7395; mean R2=0.7001\n",
      "Validation Error: Avg loss: 4.439157 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:48:52.022006 Epoch 1756, Training loss 0.13775216042995453\n",
      "R2 values 0.6509, 0.7662, 0.7399; mean R2=0.7190\n",
      "Validation Error: Avg loss: 3.925502 \n",
      "\n",
      "2023-11-08 13:48:52.477332 Epoch 1757, Training loss 0.11277350783348083\n",
      "R2 values 0.6519, 0.7428, 0.7508; mean R2=0.7152\n",
      "Validation Error: Avg loss: 3.996311 \n",
      "\n",
      "2023-11-08 13:48:52.946203 Epoch 1758, Training loss 0.16073259711265564\n",
      "R2 values 0.6153, 0.7453, 0.7585; mean R2=0.7064\n",
      "Validation Error: Avg loss: 4.078956 \n",
      "\n",
      "2023-11-08 13:48:53.418710 Epoch 1759, Training loss 0.10851980000734329\n",
      "R2 values 0.5563, 0.7271, 0.7483; mean R2=0.6773\n",
      "Validation Error: Avg loss: 4.438289 \n",
      "\n",
      "2023-11-08 13:48:53.886303 Epoch 1760, Training loss 0.11444871127605438\n",
      "R2 values 0.5863, 0.7198, 0.7337; mean R2=0.6800\n",
      "Validation Error: Avg loss: 4.713217 \n",
      "\n",
      "2023-11-08 13:48:54.356237 Epoch 1761, Training loss 0.18759854137897491\n",
      "R2 values 0.6255, 0.7219, 0.7469; mean R2=0.6981\n",
      "Validation Error: Avg loss: 4.402857 \n",
      "\n",
      "2023-11-08 13:48:54.820174 Epoch 1762, Training loss 0.0895516648888588\n",
      "R2 values 0.6433, 0.7467, 0.7674; mean R2=0.7191\n",
      "Validation Error: Avg loss: 3.794491 \n",
      "\n",
      "2023-11-08 13:48:55.288191 Epoch 1763, Training loss 0.18052555620670319\n",
      "R2 values 0.5808, 0.7271, 0.7483; mean R2=0.6854\n",
      "Validation Error: Avg loss: 4.504364 \n",
      "\n",
      "2023-11-08 13:48:55.748635 Epoch 1764, Training loss 0.09648212790489197\n",
      "R2 values 0.5642, 0.7499, 0.7831; mean R2=0.6991\n",
      "Validation Error: Avg loss: 4.106154 \n",
      "\n",
      "2023-11-08 13:48:56.213553 Epoch 1765, Training loss 0.10618358850479126\n",
      "R2 values 0.6706, 0.7512, 0.7893; mean R2=0.7370\n",
      "Validation Error: Avg loss: 4.119076 \n",
      "\n",
      "2023-11-08 13:48:56.682756 Epoch 1766, Training loss 0.1351296752691269\n",
      "R2 values 0.6681, 0.7288, 0.7937; mean R2=0.7302\n",
      "Validation Error: Avg loss: 3.997636 \n",
      "\n",
      "2023-11-08 13:48:57.156248 Epoch 1767, Training loss 0.10136145353317261\n",
      "R2 values 0.6508, 0.7733, 0.7341; mean R2=0.7194\n",
      "Validation Error: Avg loss: 3.714576 \n",
      "\n",
      "2023-11-08 13:48:57.638502 Epoch 1768, Training loss 0.12795217335224152\n",
      "R2 values 0.5950, 0.7547, 0.7260; mean R2=0.6919\n",
      "Validation Error: Avg loss: 4.170941 \n",
      "\n",
      "2023-11-08 13:48:58.103699 Epoch 1769, Training loss 0.07786893844604492\n",
      "R2 values 0.5886, 0.7292, 0.7337; mean R2=0.6838\n",
      "Validation Error: Avg loss: 4.473344 \n",
      "\n",
      "2023-11-08 13:48:58.584939 Epoch 1770, Training loss 0.10150984674692154\n",
      "R2 values 0.6351, 0.7630, 0.7443; mean R2=0.7142\n",
      "Validation Error: Avg loss: 3.832347 \n",
      "\n",
      "2023-11-08 13:48:59.062222 Epoch 1771, Training loss 0.1019359678030014\n",
      "R2 values 0.6267, 0.7425, 0.7698; mean R2=0.7130\n",
      "Validation Error: Avg loss: 3.922829 \n",
      "\n",
      "2023-11-08 13:48:59.533701 Epoch 1772, Training loss 0.08432360738515854\n",
      "R2 values 0.5964, 0.7867, 0.7607; mean R2=0.7146\n",
      "Validation Error: Avg loss: 3.386128 \n",
      "\n",
      "2023-11-08 13:49:00.003710 Epoch 1773, Training loss 0.11940667033195496\n",
      "R2 values 0.6283, 0.7515, 0.7328; mean R2=0.7042\n",
      "Validation Error: Avg loss: 3.976447 \n",
      "\n",
      "2023-11-08 13:49:00.469253 Epoch 1774, Training loss 0.09038116037845612\n",
      "R2 values 0.6123, 0.7619, 0.7078; mean R2=0.6940\n",
      "Validation Error: Avg loss: 4.098791 \n",
      "\n",
      "2023-11-08 13:49:00.931804 Epoch 1775, Training loss 0.10864347964525223\n",
      "R2 values 0.6307, 0.7503, 0.7693; mean R2=0.7168\n",
      "Validation Error: Avg loss: 4.125019 \n",
      "\n",
      "2023-11-08 13:49:01.399637 Epoch 1776, Training loss 0.07174883037805557\n",
      "R2 values 0.5543, 0.7333, 0.7414; mean R2=0.6763\n",
      "Validation Error: Avg loss: 4.275555 \n",
      "\n",
      "2023-11-08 13:49:01.865620 Epoch 1777, Training loss 0.10734561830759048\n",
      "R2 values 0.5586, 0.7298, 0.7550; mean R2=0.6811\n",
      "Validation Error: Avg loss: 4.140577 \n",
      "\n",
      "2023-11-08 13:49:02.332929 Epoch 1778, Training loss 0.09344936162233353\n",
      "R2 values 0.6019, 0.7714, 0.7556; mean R2=0.7096\n",
      "Validation Error: Avg loss: 4.013398 \n",
      "\n",
      "2023-11-08 13:49:02.801019 Epoch 1779, Training loss 0.06815267354249954\n",
      "R2 values 0.6031, 0.7307, 0.7326; mean R2=0.6888\n",
      "Validation Error: Avg loss: 4.408850 \n",
      "\n",
      "2023-11-08 13:49:03.260154 Epoch 1780, Training loss 0.1132885068655014\n",
      "R2 values 0.4873, 0.7655, 0.7556; mean R2=0.6695\n",
      "Validation Error: Avg loss: 4.095132 \n",
      "\n",
      "2023-11-08 13:49:03.959006 Epoch 1781, Training loss 0.07801362127065659\n",
      "R2 values 0.6245, 0.7733, 0.7371; mean R2=0.7116\n",
      "Validation Error: Avg loss: 3.863719 \n",
      "\n",
      "2023-11-08 13:49:04.503111 Epoch 1782, Training loss 0.09143271297216415\n",
      "R2 values 0.5808, 0.7653, 0.7262; mean R2=0.6908\n",
      "Validation Error: Avg loss: 3.860965 \n",
      "\n",
      "2023-11-08 13:49:04.976810 Epoch 1783, Training loss 0.06639460474252701\n",
      "R2 values 0.6365, 0.7787, 0.7487; mean R2=0.7213\n",
      "Validation Error: Avg loss: 3.726636 \n",
      "\n",
      "2023-11-08 13:49:05.437962 Epoch 1784, Training loss 0.08953358978033066\n",
      "R2 values 0.5694, 0.7489, 0.7161; mean R2=0.6781\n",
      "Validation Error: Avg loss: 4.211145 \n",
      "\n",
      "2023-11-08 13:49:05.902088 Epoch 1785, Training loss 0.07454239577054977\n",
      "R2 values 0.6446, 0.7777, 0.7670; mean R2=0.7298\n",
      "Validation Error: Avg loss: 3.577432 \n",
      "\n",
      "2023-11-08 13:49:06.372566 Epoch 1786, Training loss 0.08342770487070084\n",
      "R2 values 0.6053, 0.7415, 0.7459; mean R2=0.6976\n",
      "Validation Error: Avg loss: 4.114089 \n",
      "\n",
      "2023-11-08 13:49:06.840794 Epoch 1787, Training loss 0.0848940834403038\n",
      "R2 values 0.6476, 0.7867, 0.7891; mean R2=0.7411\n",
      "Validation Error: Avg loss: 3.297851 \n",
      "\n",
      "2023-11-08 13:49:07.316761 Epoch 1788, Training loss 0.11988426744937897\n",
      "R2 values 0.5038, 0.7519, 0.7555; mean R2=0.6704\n",
      "Validation Error: Avg loss: 4.123314 \n",
      "\n",
      "2023-11-08 13:49:07.829582 Epoch 1789, Training loss 0.11336000263690948\n",
      "R2 values 0.5896, 0.7678, 0.7206; mean R2=0.6927\n",
      "Validation Error: Avg loss: 4.121272 \n",
      "\n",
      "2023-11-08 13:49:08.305078 Epoch 1790, Training loss 0.09308445453643799\n",
      "R2 values 0.5949, 0.7746, 0.7402; mean R2=0.7032\n",
      "Validation Error: Avg loss: 3.984002 \n",
      "\n",
      "2023-11-08 13:49:08.766753 Epoch 1791, Training loss 0.11058162897825241\n",
      "R2 values 0.5651, 0.7769, 0.7352; mean R2=0.6924\n",
      "Validation Error: Avg loss: 4.056306 \n",
      "\n",
      "2023-11-08 13:49:09.235120 Epoch 1792, Training loss 0.09576080739498138\n",
      "R2 values 0.6048, 0.7522, 0.7675; mean R2=0.7082\n",
      "Validation Error: Avg loss: 4.122538 \n",
      "\n",
      "2023-11-08 13:49:09.704897 Epoch 1793, Training loss 0.1064685806632042\n",
      "R2 values 0.6680, 0.7509, 0.7497; mean R2=0.7229\n",
      "Validation Error: Avg loss: 3.902236 \n",
      "\n",
      "2023-11-08 13:49:10.167969 Epoch 1794, Training loss 0.08894483000040054\n",
      "R2 values 0.6442, 0.7684, 0.7437; mean R2=0.7188\n",
      "Validation Error: Avg loss: 3.723709 \n",
      "\n",
      "2023-11-08 13:49:10.629306 Epoch 1795, Training loss 0.09037565439939499\n",
      "R2 values 0.5612, 0.7482, 0.7752; mean R2=0.6949\n",
      "Validation Error: Avg loss: 3.775578 \n",
      "\n",
      "2023-11-08 13:49:11.140772 Epoch 1796, Training loss 0.09083560109138489\n",
      "R2 values 0.5532, 0.7890, 0.7665; mean R2=0.7029\n",
      "Validation Error: Avg loss: 3.571880 \n",
      "\n",
      "2023-11-08 13:49:11.646725 Epoch 1797, Training loss 0.08934937417507172\n",
      "R2 values 0.5813, 0.7701, 0.7247; mean R2=0.6920\n",
      "Validation Error: Avg loss: 4.141954 \n",
      "\n",
      "2023-11-08 13:49:12.106336 Epoch 1798, Training loss 0.09575070440769196\n",
      "R2 values 0.6172, 0.7670, 0.7430; mean R2=0.7091\n",
      "Validation Error: Avg loss: 4.019120 \n",
      "\n",
      "2023-11-08 13:49:12.562285 Epoch 1799, Training loss 0.09544242918491364\n",
      "R2 values 0.6462, 0.7550, 0.7550; mean R2=0.7187\n",
      "Validation Error: Avg loss: 3.982523 \n",
      "\n",
      "2023-11-08 13:49:13.027124 Epoch 1800, Training loss 0.09431268274784088\n",
      "R2 values 0.6454, 0.7467, 0.7816; mean R2=0.7246\n",
      "Validation Error: Avg loss: 3.740546 \n",
      "\n",
      "2023-11-08 13:49:13.487082 Epoch 1801, Training loss 0.09373997151851654\n",
      "R2 values 0.5936, 0.7918, 0.7806; mean R2=0.7220\n",
      "Validation Error: Avg loss: 3.314305 \n",
      "\n",
      "2023-11-08 13:49:13.954488 Epoch 1802, Training loss 0.10332705825567245\n",
      "R2 values 0.6065, 0.7468, 0.7531; mean R2=0.7022\n",
      "Validation Error: Avg loss: 3.950017 \n",
      "\n",
      "2023-11-08 13:49:14.435106 Epoch 1803, Training loss 0.10663942992687225\n",
      "R2 values 0.6099, 0.7573, 0.7605; mean R2=0.7092\n",
      "Validation Error: Avg loss: 3.962219 \n",
      "\n",
      "2023-11-08 13:49:14.968834 Epoch 1804, Training loss 0.08663782477378845\n",
      "R2 values 0.5579, 0.7564, 0.7439; mean R2=0.6861\n",
      "Validation Error: Avg loss: 4.068885 \n",
      "\n",
      "2023-11-08 13:49:15.435558 Epoch 1805, Training loss 0.08416230976581573\n",
      "R2 values 0.5398, 0.7583, 0.7615; mean R2=0.6865\n",
      "Validation Error: Avg loss: 3.970761 \n",
      "\n",
      "2023-11-08 13:49:15.907215 Epoch 1806, Training loss 0.08753956109285355\n",
      "R2 values 0.6345, 0.7420, 0.7471; mean R2=0.7078\n",
      "Validation Error: Avg loss: 4.085784 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:49:16.371499 Epoch 1807, Training loss 0.096634142100811\n",
      "R2 values 0.5827, 0.7738, 0.7195; mean R2=0.6920\n",
      "Validation Error: Avg loss: 3.821954 \n",
      "\n",
      "2023-11-08 13:49:16.834476 Epoch 1808, Training loss 0.10874491184949875\n",
      "R2 values 0.6014, 0.7331, 0.7234; mean R2=0.6860\n",
      "Validation Error: Avg loss: 4.492635 \n",
      "\n",
      "2023-11-08 13:49:17.299095 Epoch 1809, Training loss 0.09635268151760101\n",
      "R2 values 0.6389, 0.7160, 0.7371; mean R2=0.6973\n",
      "Validation Error: Avg loss: 4.363132 \n",
      "\n",
      "2023-11-08 13:49:17.788639 Epoch 1810, Training loss 0.0750558078289032\n",
      "R2 values 0.5923, 0.7109, 0.7767; mean R2=0.6933\n",
      "Validation Error: Avg loss: 4.393424 \n",
      "\n",
      "2023-11-08 13:49:18.271636 Epoch 1811, Training loss 0.0972980484366417\n",
      "R2 values 0.6022, 0.7340, 0.7458; mean R2=0.6940\n",
      "Validation Error: Avg loss: 4.428088 \n",
      "\n",
      "2023-11-08 13:49:18.738791 Epoch 1812, Training loss 0.10454246401786804\n",
      "R2 values 0.6103, 0.7558, 0.7515; mean R2=0.7059\n",
      "Validation Error: Avg loss: 3.947982 \n",
      "\n",
      "2023-11-08 13:49:19.199352 Epoch 1813, Training loss 0.08060667663812637\n",
      "R2 values 0.6130, 0.7786, 0.7290; mean R2=0.7069\n",
      "Validation Error: Avg loss: 3.770515 \n",
      "\n",
      "2023-11-08 13:49:19.668636 Epoch 1814, Training loss 0.08696050196886063\n",
      "R2 values 0.5788, 0.7807, 0.7606; mean R2=0.7067\n",
      "Validation Error: Avg loss: 3.763992 \n",
      "\n",
      "2023-11-08 13:49:20.129604 Epoch 1815, Training loss 0.08384425938129425\n",
      "R2 values 0.4786, 0.7587, 0.7318; mean R2=0.6564\n",
      "Validation Error: Avg loss: 4.064086 \n",
      "\n",
      "2023-11-08 13:49:20.594812 Epoch 1816, Training loss 0.08772050589323044\n",
      "R2 values 0.6554, 0.7399, 0.7470; mean R2=0.7141\n",
      "Validation Error: Avg loss: 4.185508 \n",
      "\n",
      "2023-11-08 13:49:21.054832 Epoch 1817, Training loss 0.07765734195709229\n",
      "R2 values 0.6631, 0.7764, 0.7681; mean R2=0.7359\n",
      "Validation Error: Avg loss: 3.912062 \n",
      "\n",
      "2023-11-08 13:49:21.518371 Epoch 1818, Training loss 0.08344897627830505\n",
      "R2 values 0.5666, 0.7568, 0.7755; mean R2=0.6996\n",
      "Validation Error: Avg loss: 4.228515 \n",
      "\n",
      "2023-11-08 13:49:21.979234 Epoch 1819, Training loss 0.07649382948875427\n",
      "R2 values 0.6176, 0.7150, 0.7555; mean R2=0.6960\n",
      "Validation Error: Avg loss: 4.562935 \n",
      "\n",
      "2023-11-08 13:49:22.438163 Epoch 1820, Training loss 0.0865352526307106\n",
      "R2 values 0.5605, 0.7233, 0.7351; mean R2=0.6730\n",
      "Validation Error: Avg loss: 4.635314 \n",
      "\n",
      "2023-11-08 13:49:22.903992 Epoch 1821, Training loss 0.07947726547718048\n",
      "R2 values 0.5649, 0.7407, 0.7579; mean R2=0.6878\n",
      "Validation Error: Avg loss: 4.140119 \n",
      "\n",
      "2023-11-08 13:49:23.365703 Epoch 1822, Training loss 0.0895484909415245\n",
      "R2 values 0.6174, 0.7543, 0.7635; mean R2=0.7117\n",
      "Validation Error: Avg loss: 3.974306 \n",
      "\n",
      "2023-11-08 13:49:23.832532 Epoch 1823, Training loss 0.07658839970827103\n",
      "R2 values 0.6352, 0.7541, 0.7508; mean R2=0.7134\n",
      "Validation Error: Avg loss: 3.991349 \n",
      "\n",
      "2023-11-08 13:49:24.395400 Epoch 1824, Training loss 0.06797487288713455\n",
      "R2 values 0.5567, 0.7455, 0.7443; mean R2=0.6822\n",
      "Validation Error: Avg loss: 4.154922 \n",
      "\n",
      "2023-11-08 13:49:24.859244 Epoch 1825, Training loss 0.08235630393028259\n",
      "R2 values 0.6777, 0.7846, 0.7307; mean R2=0.7310\n",
      "Validation Error: Avg loss: 3.870497 \n",
      "\n",
      "2023-11-08 13:49:25.319380 Epoch 1826, Training loss 0.06327853351831436\n",
      "R2 values 0.6197, 0.7613, 0.7809; mean R2=0.7206\n",
      "Validation Error: Avg loss: 3.925914 \n",
      "\n",
      "2023-11-08 13:49:25.776925 Epoch 1827, Training loss 0.0797356590628624\n",
      "R2 values 0.6167, 0.7517, 0.7708; mean R2=0.7131\n",
      "Validation Error: Avg loss: 4.067538 \n",
      "\n",
      "2023-11-08 13:49:26.235101 Epoch 1828, Training loss 0.08198029547929764\n",
      "R2 values 0.6415, 0.7606, 0.7624; mean R2=0.7215\n",
      "Validation Error: Avg loss: 3.861648 \n",
      "\n",
      "2023-11-08 13:49:26.697194 Epoch 1829, Training loss 0.08035115897655487\n",
      "R2 values 0.6581, 0.7556, 0.8082; mean R2=0.7406\n",
      "Validation Error: Avg loss: 3.844295 \n",
      "\n",
      "2023-11-08 13:49:27.160228 Epoch 1830, Training loss 0.07637912780046463\n",
      "R2 values 0.6408, 0.7682, 0.7516; mean R2=0.7202\n",
      "Validation Error: Avg loss: 3.970216 \n",
      "\n",
      "2023-11-08 13:49:27.652134 Epoch 1831, Training loss 0.0837695375084877\n",
      "R2 values 0.5931, 0.7594, 0.7824; mean R2=0.7116\n",
      "Validation Error: Avg loss: 4.137620 \n",
      "\n",
      "2023-11-08 13:49:28.141807 Epoch 1832, Training loss 0.10413378477096558\n",
      "R2 values 0.6219, 0.7575, 0.7626; mean R2=0.7140\n",
      "Validation Error: Avg loss: 4.178893 \n",
      "\n",
      "2023-11-08 13:49:28.599006 Epoch 1833, Training loss 0.12112964689731598\n",
      "R2 values 0.6603, 0.7812, 0.7595; mean R2=0.7337\n",
      "Validation Error: Avg loss: 3.556170 \n",
      "\n",
      "2023-11-08 13:49:29.082705 Epoch 1834, Training loss 0.08579357713460922\n",
      "R2 values 0.6218, 0.7871, 0.7495; mean R2=0.7195\n",
      "Validation Error: Avg loss: 3.652054 \n",
      "\n",
      "2023-11-08 13:49:29.553608 Epoch 1835, Training loss 0.08863076567649841\n",
      "R2 values 0.6215, 0.7585, 0.7494; mean R2=0.7098\n",
      "Validation Error: Avg loss: 4.018355 \n",
      "\n",
      "2023-11-08 13:49:30.014553 Epoch 1836, Training loss 0.07378395646810532\n",
      "R2 values 0.6911, 0.7710, 0.7655; mean R2=0.7425\n",
      "Validation Error: Avg loss: 3.875506 \n",
      "\n",
      "2023-11-08 13:49:30.472109 Epoch 1837, Training loss 0.07725580036640167\n",
      "R2 values 0.5973, 0.7760, 0.7146; mean R2=0.6960\n",
      "Validation Error: Avg loss: 3.969268 \n",
      "\n",
      "2023-11-08 13:49:30.939374 Epoch 1838, Training loss 0.09233737736940384\n",
      "R2 values 0.6143, 0.7542, 0.7610; mean R2=0.7098\n",
      "Validation Error: Avg loss: 3.920932 \n",
      "\n",
      "2023-11-08 13:49:31.402703 Epoch 1839, Training loss 0.09075398743152618\n",
      "R2 values 0.6599, 0.7554, 0.7725; mean R2=0.7292\n",
      "Validation Error: Avg loss: 3.704623 \n",
      "\n",
      "2023-11-08 13:49:32.066508 Epoch 1840, Training loss 0.09187351912260056\n",
      "R2 values 0.6845, 0.7392, 0.7514; mean R2=0.7250\n",
      "Validation Error: Avg loss: 3.857545 \n",
      "\n",
      "2023-11-08 13:49:32.595201 Epoch 1841, Training loss 0.09600041061639786\n",
      "R2 values 0.6864, 0.7786, 0.7497; mean R2=0.7382\n",
      "Validation Error: Avg loss: 3.496617 \n",
      "\n",
      "2023-11-08 13:49:33.061881 Epoch 1842, Training loss 0.0843760222196579\n",
      "R2 values 0.6034, 0.7735, 0.7677; mean R2=0.7149\n",
      "Validation Error: Avg loss: 3.813833 \n",
      "\n",
      "2023-11-08 13:49:33.525046 Epoch 1843, Training loss 0.0950937494635582\n",
      "R2 values 0.6264, 0.7378, 0.7398; mean R2=0.7013\n",
      "Validation Error: Avg loss: 4.446841 \n",
      "\n",
      "2023-11-08 13:49:33.988439 Epoch 1844, Training loss 0.09388820081949234\n",
      "R2 values 0.6720, 0.7661, 0.7470; mean R2=0.7284\n",
      "Validation Error: Avg loss: 3.980118 \n",
      "\n",
      "2023-11-08 13:49:34.450510 Epoch 1845, Training loss 0.07919464260339737\n",
      "R2 values 0.6088, 0.7447, 0.7261; mean R2=0.6932\n",
      "Validation Error: Avg loss: 4.146581 \n",
      "\n",
      "2023-11-08 13:49:34.956596 Epoch 1846, Training loss 0.09323564171791077\n",
      "R2 values 0.5703, 0.7424, 0.7422; mean R2=0.6849\n",
      "Validation Error: Avg loss: 4.203399 \n",
      "\n",
      "2023-11-08 13:49:35.421370 Epoch 1847, Training loss 0.06322221457958221\n",
      "R2 values 0.6007, 0.7680, 0.7444; mean R2=0.7044\n",
      "Validation Error: Avg loss: 4.005182 \n",
      "\n",
      "2023-11-08 13:49:35.889967 Epoch 1848, Training loss 0.08072438836097717\n",
      "R2 values 0.5687, 0.7686, 0.7559; mean R2=0.6977\n",
      "Validation Error: Avg loss: 4.037422 \n",
      "\n",
      "2023-11-08 13:49:36.349779 Epoch 1849, Training loss 0.0972251445055008\n",
      "R2 values 0.5761, 0.7404, 0.7907; mean R2=0.7024\n",
      "Validation Error: Avg loss: 4.140629 \n",
      "\n",
      "2023-11-08 13:49:36.815064 Epoch 1850, Training loss 0.09087072312831879\n",
      "R2 values 0.6404, 0.7803, 0.7941; mean R2=0.7382\n",
      "Validation Error: Avg loss: 3.446693 \n",
      "\n",
      "2023-11-08 13:49:37.277139 Epoch 1851, Training loss 0.10247974097728729\n",
      "R2 values 0.5921, 0.7435, 0.7898; mean R2=0.7085\n",
      "Validation Error: Avg loss: 3.971037 \n",
      "\n",
      "2023-11-08 13:49:37.971250 Epoch 1852, Training loss 0.0851309522986412\n",
      "R2 values 0.6254, 0.7958, 0.7858; mean R2=0.7357\n",
      "Validation Error: Avg loss: 3.466391 \n",
      "\n",
      "2023-11-08 13:49:38.498141 Epoch 1853, Training loss 0.0944196879863739\n",
      "R2 values 0.6338, 0.7458, 0.7652; mean R2=0.7149\n",
      "Validation Error: Avg loss: 4.230765 \n",
      "\n",
      "2023-11-08 13:49:38.959644 Epoch 1854, Training loss 0.090183787047863\n",
      "R2 values 0.5855, 0.7757, 0.7554; mean R2=0.7055\n",
      "Validation Error: Avg loss: 3.709357 \n",
      "\n",
      "2023-11-08 13:49:39.475255 Epoch 1855, Training loss 0.09697878360748291\n",
      "R2 values 0.6701, 0.7279, 0.7526; mean R2=0.7169\n",
      "Validation Error: Avg loss: 4.255857 \n",
      "\n",
      "2023-11-08 13:49:39.938155 Epoch 1856, Training loss 0.09979698061943054\n",
      "R2 values 0.5908, 0.7235, 0.7814; mean R2=0.6986\n",
      "Validation Error: Avg loss: 4.255044 \n",
      "\n",
      "2023-11-08 13:49:40.396649 Epoch 1857, Training loss 0.08709469437599182\n",
      "R2 values 0.6484, 0.7583, 0.7721; mean R2=0.7262\n",
      "Validation Error: Avg loss: 3.886102 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:49:40.864348 Epoch 1858, Training loss 0.07723509520292282\n",
      "R2 values 0.5972, 0.7459, 0.7350; mean R2=0.6927\n",
      "Validation Error: Avg loss: 4.384165 \n",
      "\n",
      "2023-11-08 13:49:41.334565 Epoch 1859, Training loss 0.06483736634254456\n",
      "R2 values 0.6291, 0.7624, 0.7036; mean R2=0.6983\n",
      "Validation Error: Avg loss: 4.121188 \n",
      "\n",
      "2023-11-08 13:49:41.808118 Epoch 1860, Training loss 0.06806173175573349\n",
      "R2 values 0.5808, 0.7822, 0.7693; mean R2=0.7108\n",
      "Validation Error: Avg loss: 3.751534 \n",
      "\n",
      "2023-11-08 13:49:42.286556 Epoch 1861, Training loss 0.10682600736618042\n",
      "R2 values 0.6031, 0.7625, 0.7552; mean R2=0.7069\n",
      "Validation Error: Avg loss: 3.794095 \n",
      "\n",
      "2023-11-08 13:49:42.755394 Epoch 1862, Training loss 0.12292350828647614\n",
      "R2 values 0.6323, 0.7630, 0.7490; mean R2=0.7148\n",
      "Validation Error: Avg loss: 3.925604 \n",
      "\n",
      "2023-11-08 13:49:43.221945 Epoch 1863, Training loss 0.07779385149478912\n",
      "R2 values 0.6322, 0.7402, 0.7397; mean R2=0.7041\n",
      "Validation Error: Avg loss: 4.321516 \n",
      "\n",
      "2023-11-08 13:49:43.686496 Epoch 1864, Training loss 0.09985213726758957\n",
      "R2 values 0.6579, 0.7687, 0.7558; mean R2=0.7275\n",
      "Validation Error: Avg loss: 3.979690 \n",
      "\n",
      "2023-11-08 13:49:44.147491 Epoch 1865, Training loss 0.0898689478635788\n",
      "R2 values 0.5147, 0.7347, 0.7408; mean R2=0.6634\n",
      "Validation Error: Avg loss: 4.711095 \n",
      "\n",
      "2023-11-08 13:49:44.612092 Epoch 1866, Training loss 0.08831647783517838\n",
      "R2 values 0.6255, 0.7710, 0.7389; mean R2=0.7118\n",
      "Validation Error: Avg loss: 3.969601 \n",
      "\n",
      "2023-11-08 13:49:45.072734 Epoch 1867, Training loss 0.0843145102262497\n",
      "R2 values 0.6303, 0.7272, 0.7584; mean R2=0.7053\n",
      "Validation Error: Avg loss: 4.264593 \n",
      "\n",
      "2023-11-08 13:49:45.533055 Epoch 1868, Training loss 0.08150114119052887\n",
      "R2 values 0.6273, 0.7489, 0.7477; mean R2=0.7080\n",
      "Validation Error: Avg loss: 3.817751 \n",
      "\n",
      "2023-11-08 13:49:46.214664 Epoch 1869, Training loss 0.07442770898342133\n",
      "R2 values 0.6127, 0.7780, 0.7721; mean R2=0.7209\n",
      "Validation Error: Avg loss: 3.556919 \n",
      "\n",
      "2023-11-08 13:49:46.738238 Epoch 1870, Training loss 0.0847664624452591\n",
      "R2 values 0.6088, 0.7744, 0.7484; mean R2=0.7105\n",
      "Validation Error: Avg loss: 3.769907 \n",
      "\n",
      "2023-11-08 13:49:47.203144 Epoch 1871, Training loss 0.08945052325725555\n",
      "R2 values 0.6152, 0.7734, 0.7505; mean R2=0.7130\n",
      "Validation Error: Avg loss: 3.938000 \n",
      "\n",
      "2023-11-08 13:49:47.661858 Epoch 1872, Training loss 0.08929858356714249\n",
      "R2 values 0.5858, 0.7607, 0.7082; mean R2=0.6849\n",
      "Validation Error: Avg loss: 4.243976 \n",
      "\n",
      "2023-11-08 13:49:48.125471 Epoch 1873, Training loss 0.09643242508172989\n",
      "R2 values 0.6067, 0.7543, 0.7676; mean R2=0.7095\n",
      "Validation Error: Avg loss: 3.885090 \n",
      "\n",
      "2023-11-08 13:49:48.592017 Epoch 1874, Training loss 0.13051848113536835\n",
      "R2 values 0.5672, 0.7682, 0.7572; mean R2=0.6975\n",
      "Validation Error: Avg loss: 4.014175 \n",
      "\n",
      "2023-11-08 13:49:49.056073 Epoch 1875, Training loss 0.07792308181524277\n",
      "R2 values 0.5988, 0.7918, 0.7440; mean R2=0.7115\n",
      "Validation Error: Avg loss: 3.847233 \n",
      "\n",
      "2023-11-08 13:49:49.524217 Epoch 1876, Training loss 0.10552065074443817\n",
      "R2 values 0.6025, 0.7540, 0.7573; mean R2=0.7046\n",
      "Validation Error: Avg loss: 4.024799 \n",
      "\n",
      "2023-11-08 13:49:49.991078 Epoch 1877, Training loss 0.09405830502510071\n",
      "R2 values 0.5971, 0.7309, 0.7461; mean R2=0.6914\n",
      "Validation Error: Avg loss: 4.112784 \n",
      "\n",
      "2023-11-08 13:49:50.452668 Epoch 1878, Training loss 0.11579644680023193\n",
      "R2 values 0.5807, 0.7297, 0.7736; mean R2=0.6946\n",
      "Validation Error: Avg loss: 4.103021 \n",
      "\n",
      "2023-11-08 13:49:50.916266 Epoch 1879, Training loss 0.0961894765496254\n",
      "R2 values 0.6303, 0.7390, 0.7481; mean R2=0.7058\n",
      "Validation Error: Avg loss: 4.346632 \n",
      "\n",
      "2023-11-08 13:49:51.386013 Epoch 1880, Training loss 0.07324840873479843\n",
      "R2 values 0.6212, 0.7170, 0.7449; mean R2=0.6944\n",
      "Validation Error: Avg loss: 4.833693 \n",
      "\n",
      "2023-11-08 13:49:51.853066 Epoch 1881, Training loss 0.17077094316482544\n",
      "R2 values 0.6388, 0.7362, 0.7712; mean R2=0.7154\n",
      "Validation Error: Avg loss: 4.211775 \n",
      "\n",
      "2023-11-08 13:49:52.319102 Epoch 1882, Training loss 0.09747392684221268\n",
      "R2 values 0.6534, 0.7352, 0.7752; mean R2=0.7213\n",
      "Validation Error: Avg loss: 4.023515 \n",
      "\n",
      "2023-11-08 13:49:52.950286 Epoch 1883, Training loss 0.08769916743040085\n",
      "R2 values 0.5956, 0.7815, 0.7375; mean R2=0.7049\n",
      "Validation Error: Avg loss: 3.626139 \n",
      "\n",
      "2023-11-08 13:49:53.479007 Epoch 1884, Training loss 0.11312360316514969\n",
      "R2 values 0.6412, 0.7412, 0.7658; mean R2=0.7161\n",
      "Validation Error: Avg loss: 4.010774 \n",
      "\n",
      "2023-11-08 13:49:53.934946 Epoch 1885, Training loss 0.07155624777078629\n",
      "R2 values 0.6219, 0.7612, 0.7401; mean R2=0.7077\n",
      "Validation Error: Avg loss: 4.117598 \n",
      "\n",
      "2023-11-08 13:49:54.390323 Epoch 1886, Training loss 0.0796615332365036\n",
      "R2 values 0.6347, 0.7554, 0.7570; mean R2=0.7157\n",
      "Validation Error: Avg loss: 4.133358 \n",
      "\n",
      "2023-11-08 13:49:54.856141 Epoch 1887, Training loss 0.08344003558158875\n",
      "R2 values 0.6210, 0.7567, 0.7514; mean R2=0.7097\n",
      "Validation Error: Avg loss: 3.959014 \n",
      "\n",
      "2023-11-08 13:49:55.316570 Epoch 1888, Training loss 0.08483102172613144\n",
      "R2 values 0.5774, 0.7764, 0.7644; mean R2=0.7061\n",
      "Validation Error: Avg loss: 3.654752 \n",
      "\n",
      "2023-11-08 13:49:55.787897 Epoch 1889, Training loss 0.12443970888853073\n",
      "R2 values 0.5574, 0.7495, 0.7226; mean R2=0.6765\n",
      "Validation Error: Avg loss: 4.218100 \n",
      "\n",
      "2023-11-08 13:49:56.254077 Epoch 1890, Training loss 0.06356590986251831\n",
      "R2 values 0.5745, 0.7397, 0.7962; mean R2=0.7035\n",
      "Validation Error: Avg loss: 4.130678 \n",
      "\n",
      "2023-11-08 13:49:56.721219 Epoch 1891, Training loss 0.1119159609079361\n",
      "R2 values 0.6025, 0.7586, 0.7166; mean R2=0.6926\n",
      "Validation Error: Avg loss: 4.001563 \n",
      "\n",
      "2023-11-08 13:49:57.202219 Epoch 1892, Training loss 0.07281332463026047\n",
      "R2 values 0.6421, 0.7314, 0.7167; mean R2=0.6967\n",
      "Validation Error: Avg loss: 4.482855 \n",
      "\n",
      "2023-11-08 13:49:57.669937 Epoch 1893, Training loss 0.10241532325744629\n",
      "R2 values 0.6324, 0.7503, 0.7244; mean R2=0.7024\n",
      "Validation Error: Avg loss: 4.110956 \n",
      "\n",
      "2023-11-08 13:49:58.145286 Epoch 1894, Training loss 0.0696415901184082\n",
      "R2 values 0.6452, 0.7454, 0.7477; mean R2=0.7128\n",
      "Validation Error: Avg loss: 4.020866 \n",
      "\n",
      "2023-11-08 13:49:58.604811 Epoch 1895, Training loss 0.070742666721344\n",
      "R2 values 0.6727, 0.7541, 0.7405; mean R2=0.7224\n",
      "Validation Error: Avg loss: 4.015631 \n",
      "\n",
      "2023-11-08 13:49:59.071634 Epoch 1896, Training loss 0.07782959938049316\n",
      "R2 values 0.6360, 0.7629, 0.7446; mean R2=0.7145\n",
      "Validation Error: Avg loss: 4.071255 \n",
      "\n",
      "2023-11-08 13:49:59.531313 Epoch 1897, Training loss 0.09330140054225922\n",
      "R2 values 0.6046, 0.7516, 0.7025; mean R2=0.6862\n",
      "Validation Error: Avg loss: 4.173015 \n",
      "\n",
      "2023-11-08 13:49:59.999601 Epoch 1898, Training loss 0.09160467237234116\n",
      "R2 values 0.6354, 0.7759, 0.7818; mean R2=0.7310\n",
      "Validation Error: Avg loss: 3.625728 \n",
      "\n",
      "2023-11-08 13:50:00.695350 Epoch 1899, Training loss 0.05839180573821068\n",
      "R2 values 0.6075, 0.7547, 0.7389; mean R2=0.7004\n",
      "Validation Error: Avg loss: 3.887138 \n",
      "\n",
      "2023-11-08 13:50:01.156568 Epoch 1900, Training loss 0.08740673959255219\n",
      "R2 values 0.6165, 0.7493, 0.7462; mean R2=0.7040\n",
      "Validation Error: Avg loss: 3.999734 \n",
      "\n",
      "2023-11-08 13:50:01.619193 Epoch 1901, Training loss 0.06737194955348969\n",
      "R2 values 0.6459, 0.7401, 0.7619; mean R2=0.7160\n",
      "Validation Error: Avg loss: 4.184785 \n",
      "\n",
      "2023-11-08 13:50:02.082028 Epoch 1902, Training loss 0.10055973380804062\n",
      "R2 values 0.6535, 0.7338, 0.7385; mean R2=0.7086\n",
      "Validation Error: Avg loss: 4.386659 \n",
      "\n",
      "2023-11-08 13:50:02.984072 Epoch 1903, Training loss 0.08904480189085007\n",
      "R2 values 0.6259, 0.7753, 0.7365; mean R2=0.7126\n",
      "Validation Error: Avg loss: 3.819606 \n",
      "\n",
      "2023-11-08 13:50:03.453410 Epoch 1904, Training loss 0.07471625506877899\n",
      "R2 values 0.5883, 0.7391, 0.7867; mean R2=0.7047\n",
      "Validation Error: Avg loss: 3.988205 \n",
      "\n",
      "2023-11-08 13:50:03.947735 Epoch 1905, Training loss 0.09395455569028854\n",
      "R2 values 0.5538, 0.7598, 0.7510; mean R2=0.6882\n",
      "Validation Error: Avg loss: 3.977095 \n",
      "\n",
      "2023-11-08 13:50:04.470312 Epoch 1906, Training loss 0.09300301223993301\n",
      "R2 values 0.6412, 0.7496, 0.7449; mean R2=0.7119\n",
      "Validation Error: Avg loss: 4.375335 \n",
      "\n",
      "2023-11-08 13:50:04.933492 Epoch 1907, Training loss 0.10656039416790009\n",
      "R2 values 0.6680, 0.7581, 0.7379; mean R2=0.7213\n",
      "Validation Error: Avg loss: 3.990950 \n",
      "\n",
      "2023-11-08 13:50:05.393628 Epoch 1908, Training loss 0.0962781235575676\n",
      "R2 values 0.7221, 0.7680, 0.7324; mean R2=0.7408\n",
      "Validation Error: Avg loss: 3.703038 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:50:05.851745 Epoch 1909, Training loss 0.08044974505901337\n",
      "R2 values 0.6358, 0.7839, 0.7188; mean R2=0.7128\n",
      "Validation Error: Avg loss: 3.717775 \n",
      "\n",
      "2023-11-08 13:50:06.312422 Epoch 1910, Training loss 0.11210517585277557\n",
      "R2 values 0.5301, 0.7417, 0.7203; mean R2=0.6640\n",
      "Validation Error: Avg loss: 4.377361 \n",
      "\n",
      "2023-11-08 13:50:06.770939 Epoch 1911, Training loss 0.10462888330221176\n",
      "R2 values 0.6524, 0.7575, 0.7239; mean R2=0.7113\n",
      "Validation Error: Avg loss: 4.209615 \n",
      "\n",
      "2023-11-08 13:50:07.247733 Epoch 1912, Training loss 0.11018135398626328\n",
      "R2 values 0.6501, 0.7785, 0.7963; mean R2=0.7417\n",
      "Validation Error: Avg loss: 3.522600 \n",
      "\n",
      "2023-11-08 13:50:07.707474 Epoch 1913, Training loss 0.12353105843067169\n",
      "R2 values 0.6598, 0.7381, 0.7536; mean R2=0.7172\n",
      "Validation Error: Avg loss: 3.953569 \n",
      "\n",
      "2023-11-08 13:50:08.179032 Epoch 1914, Training loss 0.0862920954823494\n",
      "R2 values 0.6087, 0.7404, 0.7851; mean R2=0.7114\n",
      "Validation Error: Avg loss: 3.899424 \n",
      "\n",
      "2023-11-08 13:50:08.639228 Epoch 1915, Training loss 0.1385655254125595\n",
      "R2 values 0.5403, 0.7620, 0.7414; mean R2=0.6812\n",
      "Validation Error: Avg loss: 4.274372 \n",
      "\n",
      "2023-11-08 13:50:09.098669 Epoch 1916, Training loss 0.1231846958398819\n",
      "R2 values 0.5687, 0.7349, 0.7352; mean R2=0.6796\n",
      "Validation Error: Avg loss: 4.647717 \n",
      "\n",
      "2023-11-08 13:50:09.569148 Epoch 1917, Training loss 0.12722234427928925\n",
      "R2 values 0.5932, 0.7510, 0.7333; mean R2=0.6925\n",
      "Validation Error: Avg loss: 4.417988 \n",
      "\n",
      "2023-11-08 13:50:10.033913 Epoch 1918, Training loss 0.11216873675584793\n",
      "R2 values 0.6240, 0.7200, 0.7646; mean R2=0.7029\n",
      "Validation Error: Avg loss: 4.239405 \n",
      "\n",
      "2023-11-08 13:50:10.492141 Epoch 1919, Training loss 0.0833708867430687\n",
      "R2 values 0.5948, 0.7467, 0.7944; mean R2=0.7120\n",
      "Validation Error: Avg loss: 3.674037 \n",
      "\n",
      "2023-11-08 13:50:10.956842 Epoch 1920, Training loss 0.15791326761245728\n",
      "R2 values 0.6325, 0.7520, 0.7642; mean R2=0.7162\n",
      "Validation Error: Avg loss: 3.859459 \n",
      "\n",
      "2023-11-08 13:50:11.411163 Epoch 1921, Training loss 0.11026706546545029\n",
      "R2 values 0.6378, 0.7589, 0.7174; mean R2=0.7047\n",
      "Validation Error: Avg loss: 4.258394 \n",
      "\n",
      "2023-11-08 13:50:11.873796 Epoch 1922, Training loss 0.1163095012307167\n",
      "R2 values 0.5636, 0.7464, 0.7232; mean R2=0.6778\n",
      "Validation Error: Avg loss: 4.431749 \n",
      "\n",
      "2023-11-08 13:50:12.334549 Epoch 1923, Training loss 0.13163071870803833\n",
      "R2 values 0.5858, 0.7859, 0.6784; mean R2=0.6834\n",
      "Validation Error: Avg loss: 3.973013 \n",
      "\n",
      "2023-11-08 13:50:12.805293 Epoch 1924, Training loss 0.10874659568071365\n",
      "R2 values 0.6080, 0.7712, 0.7798; mean R2=0.7197\n",
      "Validation Error: Avg loss: 3.626228 \n",
      "\n",
      "2023-11-08 13:50:13.538073 Epoch 1925, Training loss 0.1615636646747589\n",
      "R2 values 0.5824, 0.7427, 0.7410; mean R2=0.6887\n",
      "Validation Error: Avg loss: 4.171505 \n",
      "\n",
      "2023-11-08 13:50:14.030839 Epoch 1926, Training loss 0.10968708992004395\n",
      "R2 values 0.6178, 0.7552, 0.7580; mean R2=0.7104\n",
      "Validation Error: Avg loss: 4.146159 \n",
      "\n",
      "2023-11-08 13:50:14.480731 Epoch 1927, Training loss 0.1596008986234665\n",
      "R2 values 0.6338, 0.7463, 0.7523; mean R2=0.7108\n",
      "Validation Error: Avg loss: 4.147616 \n",
      "\n",
      "2023-11-08 13:50:14.950088 Epoch 1928, Training loss 0.09739591181278229\n",
      "R2 values 0.6359, 0.7378, 0.7512; mean R2=0.7083\n",
      "Validation Error: Avg loss: 4.164591 \n",
      "\n",
      "2023-11-08 13:50:15.410985 Epoch 1929, Training loss 0.08582773059606552\n",
      "R2 values 0.6018, 0.7664, 0.7888; mean R2=0.7190\n",
      "Validation Error: Avg loss: 3.632560 \n",
      "\n",
      "2023-11-08 13:50:15.875924 Epoch 1930, Training loss 0.11335040628910065\n",
      "R2 values 0.5280, 0.7900, 0.7645; mean R2=0.6942\n",
      "Validation Error: Avg loss: 3.552174 \n",
      "\n",
      "2023-11-08 13:50:16.339101 Epoch 1931, Training loss 0.08418019860982895\n",
      "R2 values 0.6301, 0.7612, 0.7794; mean R2=0.7235\n",
      "Validation Error: Avg loss: 3.744182 \n",
      "\n",
      "2023-11-08 13:50:16.799798 Epoch 1932, Training loss 0.0993361547589302\n",
      "R2 values 0.6183, 0.7527, 0.7625; mean R2=0.7112\n",
      "Validation Error: Avg loss: 4.189479 \n",
      "\n",
      "2023-11-08 13:50:17.267176 Epoch 1933, Training loss 0.08852239698171616\n",
      "R2 values 0.5898, 0.7363, 0.7277; mean R2=0.6846\n",
      "Validation Error: Avg loss: 4.382775 \n",
      "\n",
      "2023-11-08 13:50:17.728776 Epoch 1934, Training loss 0.10333515703678131\n",
      "R2 values 0.6308, 0.7181, 0.7604; mean R2=0.7031\n",
      "Validation Error: Avg loss: 4.286984 \n",
      "\n",
      "2023-11-08 13:50:18.209175 Epoch 1935, Training loss 0.12512683868408203\n",
      "R2 values 0.6147, 0.7364, 0.7682; mean R2=0.7064\n",
      "Validation Error: Avg loss: 4.001418 \n",
      "\n",
      "2023-11-08 13:50:18.670127 Epoch 1936, Training loss 0.08994652330875397\n",
      "R2 values 0.6849, 0.7435, 0.7621; mean R2=0.7302\n",
      "Validation Error: Avg loss: 4.012856 \n",
      "\n",
      "2023-11-08 13:50:19.135410 Epoch 1937, Training loss 0.08084441721439362\n",
      "R2 values 0.6283, 0.7380, 0.7418; mean R2=0.7027\n",
      "Validation Error: Avg loss: 4.599828 \n",
      "\n",
      "2023-11-08 13:50:19.600871 Epoch 1938, Training loss 0.12446071207523346\n",
      "R2 values 0.6496, 0.7562, 0.7596; mean R2=0.7218\n",
      "Validation Error: Avg loss: 4.181195 \n",
      "\n",
      "2023-11-08 13:50:20.064785 Epoch 1939, Training loss 0.0940297320485115\n",
      "R2 values 0.5889, 0.7666, 0.7444; mean R2=0.7000\n",
      "Validation Error: Avg loss: 3.906694 \n",
      "\n",
      "2023-11-08 13:50:20.528687 Epoch 1940, Training loss 0.0780997946858406\n",
      "R2 values 0.6393, 0.7815, 0.7941; mean R2=0.7383\n",
      "Validation Error: Avg loss: 3.403873 \n",
      "\n",
      "2023-11-08 13:50:20.995640 Epoch 1941, Training loss 0.09327419102191925\n",
      "R2 values 0.6236, 0.7654, 0.7657; mean R2=0.7182\n",
      "Validation Error: Avg loss: 3.821003 \n",
      "\n",
      "2023-11-08 13:50:21.505531 Epoch 1942, Training loss 0.0797547698020935\n",
      "R2 values 0.5852, 0.7504, 0.7552; mean R2=0.6970\n",
      "Validation Error: Avg loss: 4.155775 \n",
      "\n",
      "2023-11-08 13:50:21.968403 Epoch 1943, Training loss 0.07205412536859512\n",
      "R2 values 0.5745, 0.7643, 0.7631; mean R2=0.7006\n",
      "Validation Error: Avg loss: 3.940603 \n",
      "\n",
      "2023-11-08 13:50:22.426348 Epoch 1944, Training loss 0.0881839245557785\n",
      "R2 values 0.5684, 0.7562, 0.7219; mean R2=0.6821\n",
      "Validation Error: Avg loss: 4.119651 \n",
      "\n",
      "2023-11-08 13:50:22.885586 Epoch 1945, Training loss 0.07428698241710663\n",
      "R2 values 0.6381, 0.7722, 0.7615; mean R2=0.7239\n",
      "Validation Error: Avg loss: 3.822560 \n",
      "\n",
      "2023-11-08 13:50:23.349975 Epoch 1946, Training loss 0.09465960413217545\n",
      "R2 values 0.6191, 0.7417, 0.7185; mean R2=0.6931\n",
      "Validation Error: Avg loss: 4.502033 \n",
      "\n",
      "2023-11-08 13:50:23.819371 Epoch 1947, Training loss 0.0803142637014389\n",
      "R2 values 0.6406, 0.7472, 0.7657; mean R2=0.7178\n",
      "Validation Error: Avg loss: 4.038167 \n",
      "\n",
      "2023-11-08 13:50:24.326933 Epoch 1948, Training loss 0.1097642332315445\n",
      "R2 values 0.5374, 0.7358, 0.7607; mean R2=0.6780\n",
      "Validation Error: Avg loss: 4.074765 \n",
      "\n",
      "2023-11-08 13:50:24.860514 Epoch 1949, Training loss 0.08815115690231323\n",
      "R2 values 0.5895, 0.7535, 0.7341; mean R2=0.6923\n",
      "Validation Error: Avg loss: 3.936158 \n",
      "\n",
      "2023-11-08 13:50:25.320252 Epoch 1950, Training loss 0.1410413682460785\n",
      "R2 values 0.5871, 0.7158, 0.7534; mean R2=0.6854\n",
      "Validation Error: Avg loss: 4.403047 \n",
      "\n",
      "2023-11-08 13:50:25.772826 Epoch 1951, Training loss 0.09430057555437088\n",
      "R2 values 0.5791, 0.7380, 0.7424; mean R2=0.6865\n",
      "Validation Error: Avg loss: 4.435905 \n",
      "\n",
      "2023-11-08 13:50:26.235266 Epoch 1952, Training loss 0.09748468548059464\n",
      "R2 values 0.6523, 0.7436, 0.7400; mean R2=0.7120\n",
      "Validation Error: Avg loss: 4.368483 \n",
      "\n",
      "2023-11-08 13:50:26.700781 Epoch 1953, Training loss 0.0769522562623024\n",
      "R2 values 0.6390, 0.7323, 0.7193; mean R2=0.6969\n",
      "Validation Error: Avg loss: 4.447802 \n",
      "\n",
      "2023-11-08 13:50:27.333663 Epoch 1954, Training loss 0.08108874410390854\n",
      "R2 values 0.6854, 0.7444, 0.7562; mean R2=0.7287\n",
      "Validation Error: Avg loss: 3.892339 \n",
      "\n",
      "2023-11-08 13:50:28.155311 Epoch 1955, Training loss 0.08413451164960861\n",
      "R2 values 0.6413, 0.7680, 0.7204; mean R2=0.7099\n",
      "Validation Error: Avg loss: 3.793003 \n",
      "\n",
      "2023-11-08 13:50:28.964459 Epoch 1956, Training loss 0.12064347416162491\n",
      "R2 values 0.6220, 0.7598, 0.7383; mean R2=0.7067\n",
      "Validation Error: Avg loss: 4.136751 \n",
      "\n",
      "2023-11-08 13:50:29.757026 Epoch 1957, Training loss 0.08659526705741882\n",
      "R2 values 0.6236, 0.7706, 0.7456; mean R2=0.7132\n",
      "Validation Error: Avg loss: 4.051293 \n",
      "\n",
      "2023-11-08 13:50:30.639240 Epoch 1958, Training loss 0.09136609733104706\n",
      "R2 values 0.5941, 0.7626, 0.7810; mean R2=0.7126\n",
      "Validation Error: Avg loss: 3.868932 \n",
      "\n",
      "2023-11-08 13:50:31.421674 Epoch 1959, Training loss 0.08116358518600464\n",
      "R2 values 0.5738, 0.7432, 0.7495; mean R2=0.6888\n",
      "Validation Error: Avg loss: 4.275313 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-08 13:50:32.228834 Epoch 1960, Training loss 0.098655104637146\n",
      "R2 values 0.5681, 0.7306, 0.7570; mean R2=0.6852\n",
      "Validation Error: Avg loss: 4.299560 \n",
      "\n",
      "2023-11-08 13:50:33.003003 Epoch 1961, Training loss 0.10976646095514297\n",
      "R2 values 0.5839, 0.7258, 0.7602; mean R2=0.6900\n",
      "Validation Error: Avg loss: 4.245517 \n",
      "\n",
      "2023-11-08 13:50:33.589433 Epoch 1962, Training loss 0.07970694452524185\n",
      "R2 values 0.5566, 0.7555, 0.7681; mean R2=0.6934\n",
      "Validation Error: Avg loss: 4.238803 \n",
      "\n",
      "2023-11-08 13:50:34.092673 Epoch 1963, Training loss 0.10090802609920502\n",
      "R2 values 0.5855, 0.7588, 0.7217; mean R2=0.6887\n",
      "Validation Error: Avg loss: 4.164483 \n",
      "\n",
      "2023-11-08 13:50:34.599374 Epoch 1964, Training loss 0.09491802006959915\n",
      "R2 values 0.5675, 0.7558, 0.7458; mean R2=0.6897\n",
      "Validation Error: Avg loss: 3.896542 \n",
      "\n",
      "2023-11-08 13:50:35.290654 Epoch 1965, Training loss 0.09072893857955933\n",
      "R2 values 0.6291, 0.7395, 0.7439; mean R2=0.7042\n",
      "Validation Error: Avg loss: 3.886031 \n",
      "\n",
      "2023-11-08 13:50:35.838776 Epoch 1966, Training loss 0.10029077529907227\n",
      "R2 values 0.6467, 0.7420, 0.7225; mean R2=0.7037\n",
      "Validation Error: Avg loss: 4.136898 \n",
      "\n",
      "2023-11-08 13:50:36.322899 Epoch 1967, Training loss 0.11955738067626953\n",
      "R2 values 0.6464, 0.7565, 0.7457; mean R2=0.7162\n",
      "Validation Error: Avg loss: 4.184808 \n",
      "\n",
      "2023-11-08 13:50:36.812090 Epoch 1968, Training loss 0.08121804147958755\n",
      "R2 values 0.6027, 0.7598, 0.7555; mean R2=0.7060\n",
      "Validation Error: Avg loss: 4.106023 \n",
      "\n",
      "2023-11-08 13:50:37.302899 Epoch 1969, Training loss 0.11586994677782059\n",
      "R2 values 0.6334, 0.7301, 0.7782; mean R2=0.7139\n",
      "Validation Error: Avg loss: 4.245961 \n",
      "\n",
      "2023-11-08 13:50:37.791792 Epoch 1970, Training loss 0.0856938511133194\n",
      "R2 values 0.5915, 0.7533, 0.8060; mean R2=0.7169\n",
      "Validation Error: Avg loss: 3.676438 \n",
      "\n",
      "2023-11-08 13:50:38.283321 Epoch 1971, Training loss 0.1490592211484909\n",
      "R2 values 0.5248, 0.7614, 0.7740; mean R2=0.6867\n",
      "Validation Error: Avg loss: 3.854826 \n",
      "\n",
      "2023-11-08 13:50:38.770678 Epoch 1972, Training loss 0.12211651355028152\n",
      "R2 values 0.5804, 0.7543, 0.7325; mean R2=0.6891\n",
      "Validation Error: Avg loss: 4.171226 \n",
      "\n",
      "2023-11-08 13:50:39.264997 Epoch 1973, Training loss 0.12218938022851944\n",
      "R2 values 0.6456, 0.7512, 0.7358; mean R2=0.7109\n",
      "Validation Error: Avg loss: 4.172875 \n",
      "\n",
      "2023-11-08 13:50:39.764608 Epoch 1974, Training loss 0.09965665638446808\n",
      "R2 values 0.6188, 0.7355, 0.6978; mean R2=0.6840\n",
      "Validation Error: Avg loss: 4.369508 \n",
      "\n",
      "2023-11-08 13:50:40.262069 Epoch 1975, Training loss 0.1165652871131897\n",
      "R2 values 0.7092, 0.7589, 0.7537; mean R2=0.7406\n",
      "Validation Error: Avg loss: 3.785575 \n",
      "\n",
      "2023-11-08 13:50:40.750648 Epoch 1976, Training loss 0.16037507355213165\n",
      "R2 values 0.6523, 0.7585, 0.7940; mean R2=0.7350\n",
      "Validation Error: Avg loss: 3.685899 \n",
      "\n",
      "2023-11-08 13:50:41.240799 Epoch 1977, Training loss 0.08979710936546326\n",
      "R2 values 0.5960, 0.7474, 0.7687; mean R2=0.7041\n",
      "Validation Error: Avg loss: 4.147749 \n",
      "\n",
      "2023-11-08 13:50:41.729232 Epoch 1978, Training loss 0.13818992674350739\n",
      "R2 values 0.6303, 0.7045, 0.7847; mean R2=0.7065\n",
      "Validation Error: Avg loss: 4.426877 \n",
      "\n",
      "2023-11-08 13:50:42.218020 Epoch 1979, Training loss 0.14970406889915466\n",
      "R2 values 0.6340, 0.7690, 0.7736; mean R2=0.7255\n",
      "Validation Error: Avg loss: 3.723706 \n",
      "\n",
      "2023-11-08 13:50:42.701340 Epoch 1980, Training loss 0.09992668777704239\n",
      "R2 values 0.6498, 0.7409, 0.7462; mean R2=0.7123\n",
      "Validation Error: Avg loss: 4.037528 \n",
      "\n",
      "2023-11-08 13:50:43.201844 Epoch 1981, Training loss 0.10075539350509644\n",
      "R2 values 0.6428, 0.7397, 0.7157; mean R2=0.6994\n",
      "Validation Error: Avg loss: 4.090411 \n",
      "\n",
      "2023-11-08 13:50:43.694355 Epoch 1982, Training loss 0.11509694904088974\n",
      "R2 values 0.5714, 0.7915, 0.7387; mean R2=0.7005\n",
      "Validation Error: Avg loss: 3.772626 \n",
      "\n",
      "2023-11-08 13:50:44.180513 Epoch 1983, Training loss 0.12349214404821396\n",
      "R2 values 0.5519, 0.7689, 0.7342; mean R2=0.6850\n",
      "Validation Error: Avg loss: 4.152824 \n",
      "\n",
      "2023-11-08 13:50:44.668158 Epoch 1984, Training loss 0.11764507740736008\n",
      "R2 values 0.5894, 0.7716, 0.7800; mean R2=0.7136\n",
      "Validation Error: Avg loss: 3.657440 \n",
      "\n",
      "2023-11-08 13:50:45.184557 Epoch 1985, Training loss 0.12998472154140472\n",
      "R2 values 0.6147, 0.7526, 0.7533; mean R2=0.7069\n",
      "Validation Error: Avg loss: 3.802346 \n",
      "\n",
      "2023-11-08 13:50:45.726632 Epoch 1986, Training loss 0.10895471274852753\n",
      "R2 values 0.6274, 0.7684, 0.7575; mean R2=0.7177\n",
      "Validation Error: Avg loss: 3.716326 \n",
      "\n",
      "2023-11-08 13:50:46.215154 Epoch 1987, Training loss 0.12799225747585297\n",
      "R2 values 0.6446, 0.7510, 0.7524; mean R2=0.7160\n",
      "Validation Error: Avg loss: 4.128742 \n",
      "\n",
      "2023-11-08 13:50:46.706225 Epoch 1988, Training loss 0.10918914526700974\n",
      "R2 values 0.6203, 0.7617, 0.7232; mean R2=0.7017\n",
      "Validation Error: Avg loss: 4.164106 \n",
      "\n",
      "2023-11-08 13:50:47.194679 Epoch 1989, Training loss 0.1293070912361145\n",
      "R2 values 0.6525, 0.7807, 0.7545; mean R2=0.7292\n",
      "Validation Error: Avg loss: 3.611800 \n",
      "\n",
      "2023-11-08 13:50:47.917655 Epoch 1990, Training loss 0.08230014890432358\n",
      "R2 values 0.6406, 0.7749, 0.7713; mean R2=0.7289\n",
      "Validation Error: Avg loss: 3.469869 \n",
      "\n",
      "2023-11-08 13:50:48.415467 Epoch 1991, Training loss 0.11769530922174454\n",
      "R2 values 0.6264, 0.7851, 0.7567; mean R2=0.7227\n",
      "Validation Error: Avg loss: 3.578971 \n",
      "\n",
      "2023-11-08 13:50:48.905268 Epoch 1992, Training loss 0.11662755906581879\n",
      "R2 values 0.6119, 0.7694, 0.7209; mean R2=0.7007\n",
      "Validation Error: Avg loss: 3.980902 \n",
      "\n",
      "2023-11-08 13:50:49.396189 Epoch 1993, Training loss 0.08807715028524399\n",
      "R2 values 0.5576, 0.7344, 0.7318; mean R2=0.6746\n",
      "Validation Error: Avg loss: 4.618628 \n",
      "\n",
      "2023-11-08 13:50:49.883686 Epoch 1994, Training loss 0.11484415084123611\n",
      "R2 values 0.6154, 0.7498, 0.7552; mean R2=0.7068\n",
      "Validation Error: Avg loss: 4.066238 \n",
      "\n",
      "2023-11-08 13:50:50.365146 Epoch 1995, Training loss 0.10062719881534576\n",
      "R2 values 0.6440, 0.7525, 0.7306; mean R2=0.7090\n",
      "Validation Error: Avg loss: 3.944393 \n",
      "\n",
      "2023-11-08 13:50:50.856503 Epoch 1996, Training loss 0.08493994176387787\n",
      "R2 values 0.6225, 0.7579, 0.7352; mean R2=0.7052\n",
      "Validation Error: Avg loss: 4.052123 \n",
      "\n",
      "2023-11-08 13:50:51.361710 Epoch 1997, Training loss 0.13615278899669647\n",
      "R2 values 0.5821, 0.7665, 0.7636; mean R2=0.7041\n",
      "Validation Error: Avg loss: 3.888540 \n",
      "\n",
      "2023-11-08 13:50:51.859992 Epoch 1998, Training loss 0.10938380658626556\n",
      "R2 values 0.5513, 0.7677, 0.7197; mean R2=0.6795\n",
      "Validation Error: Avg loss: 4.304593 \n",
      "\n",
      "2023-11-08 13:50:52.344354 Epoch 1999, Training loss 0.14669758081436157\n",
      "R2 values 0.5853, 0.7882, 0.7644; mean R2=0.7126\n",
      "Validation Error: Avg loss: 3.847763 \n",
      "\n",
      "2023-11-08 13:50:52.874161 Epoch 2000, Training loss 0.10381577908992767\n",
      "R2 values 0.5623, 0.7542, 0.7738; mean R2=0.6968\n",
      "Validation Error: Avg loss: 3.777389 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose between 'Mixed', 'ICCD', or 'Params'\n",
    "features_to_use = 'ICCD' \n",
    "\n",
    "n_epochs=2000\n",
    "learning_rate = 0.0014129147018238114\n",
    "L2 = 0.0005312227896860003\n",
    "\n",
    "checkpoint_name = 'Growth Kinetics ICCD Input Checkpoint'\n",
    "\n",
    "model = MixedICCDNet(features=features_to_use,\n",
    "                     l1=64,        # MLP nodes layer 1 for ICCD features\n",
    "                     l2=32,        # MLP nodes layer 2 for ICCD features\n",
    "                     param_l1=48,  # MLP nodes layer 1 for parameter features\n",
    "                     param_out=32, # MLP nodes layer 2 for parameter features\n",
    "                     c1=16,        # MLP nodes layer 1 for combined features\n",
    "                     c2=24,        # MLP nodes layer 1 for combined features\n",
    "                     c3=32)        # MLP nodes layer 1 for combined features\n",
    "\n",
    "# Train the model\n",
    "results = train(model,train_loader,val_loader, n_epochs, learning_rate, L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81ff67d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, val_loss_list, r2_list, best_R2, best_val_predictions,\\\n",
    "best_val_actuals,best_train_predictions, best_train_actuals = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55558029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best r2 value was: 0.8187494603962465\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('The best r2 value was:', best_R2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_loss_list, label='Train',alpha=0.8)\n",
    "ax.plot(val_loss_list,label='Test',alpha=0.8)\n",
    "\n",
    "#ax.set_ylim(0,2000)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MSE Loss')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8d0b853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r2_array = np.array(r2_list)\n",
    "labels = ['s$_0$', 's$_1$', 'J', 'mean']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(r2_array.shape[1]):\n",
    "    ax.plot(r2_array[:,i],label=labels[i],alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('r$^2$')\n",
    "ax.legend()\n",
    "ax.tick_params(axis='both')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f95a7ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_predictions(train_pred, train_actual, val_pred, val_actual, index, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    r2_train = pearsonr(train_actual[:,index], train_pred[:,index])[0]**2\n",
    "    r2_val = pearsonr(val_actual[:,index], val_pred[:,index])[0]**2\n",
    "    \n",
    "    ax.scatter(train_actual[:,index],train_pred[:,index],label='Train')\n",
    "    ax.scatter(val_actual[:,index],val_pred[:,index],label='Validation')\n",
    "    ax.plot(train_actual[:,index],train_actual[:,index],c='k')\n",
    "    \n",
    "    plt.text(0.02, 0.98, 'r$^2_{train}$ = %.4f\\nr$^2_{val}$ = %.4f' % (r2_train,r2_val),\n",
    "     horizontalalignment='left',\n",
    "     verticalalignment='top',\n",
    "     transform = ax.transAxes)\n",
    "\n",
    "    ax.legend(loc='upper center')\n",
    "        \n",
    "    ax.set_xlabel('{} actual'.format(title))\n",
    "    ax.set_ylabel('{} predicted'.format(title))\n",
    "    ax.tick_params(axis='both')\n",
    "    \n",
    "    return ax\n",
    "\n",
    "labels = ['s$_0$', 's$_1$', 'J']\n",
    "atten = [10,1,1000]\n",
    "\n",
    "for i,label in enumerate(labels):\n",
    "    ax = plot_predictions(best_train_predictions/atten[i],best_train_actuals/atten[i],\n",
    "                     best_val_predictions/atten[i], best_val_actuals/atten[i],i,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86defa76",
   "metadata": {},
   "source": [
    "# Train for growth kinetics using the growth parameter features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "522dfdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 127\n",
      "Number of training samples: 88\n",
      "Number of validation samples: 39\n"
     ]
    }
   ],
   "source": [
    "datafile = 'PLD data.json'\n",
    "\n",
    "# set the target to anomaly to train for P, E1, and E2.\n",
    "# set the target to 'growth' to train for s0, s1, and J\n",
    "target_params = 'growth'\n",
    "\n",
    "BATCH_SIZE = 88\n",
    "\n",
    "#############################\n",
    "if target_params == 'anomaly':\n",
    "    normalize_PTE1E2 = False\n",
    "else:\n",
    "    normalize_PTE1E2 = True\n",
    "\n",
    "train_data, val_data = load_data(datafile, target_params, normalize_PTE1E2=normalize_PTE1E2, train_percent=70)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02308676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU.\n",
      "in params\n",
      "2023-11-08 13:50:56.662365 Epoch 1, Training loss 24.57111930847168\n",
      "in params\n",
      "R2 values 0.1008, 0.0651, 0.0479; mean R2=0.0713\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 26.958961 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:50:56.976707 Epoch 2, Training loss 23.38414764404297\n",
      "in params\n",
      "R2 values 0.0774, 0.1816, 0.0593; mean R2=0.1061\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 25.739393 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:50:57.284095 Epoch 3, Training loss 22.430795669555664\n",
      "in params\n",
      "R2 values 0.0102, 0.1289, 0.0390; mean R2=0.0594\n",
      "Validation Error: Avg loss: 24.507336 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:50:57.573939 Epoch 4, Training loss 21.306241989135742\n",
      "in params\n",
      "R2 values 0.0001, 0.0434, 0.0454; mean R2=0.0296\n",
      "Validation Error: Avg loss: 23.073994 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:50:57.874818 Epoch 5, Training loss 20.078359603881836\n",
      "in params\n",
      "R2 values 0.0098, 0.0196, 0.0022; mean R2=0.0105\n",
      "Validation Error: Avg loss: 21.381617 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:50:58.167792 Epoch 6, Training loss 18.539583206176758\n",
      "in params\n",
      "R2 values 0.0000, 0.0014, 0.0079; mean R2=0.0031\n",
      "Validation Error: Avg loss: 19.562918 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:50:58.455062 Epoch 7, Training loss 17.180803298950195\n",
      "in params\n",
      "R2 values 0.0067, 0.0046, 0.0127; mean R2=0.0080\n",
      "Validation Error: Avg loss: 17.601004 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:50:58.745466 Epoch 8, Training loss 15.369962692260742\n",
      "in params\n",
      "R2 values 0.0021, 0.0072, 0.0081; mean R2=0.0058\n",
      "Validation Error: Avg loss: 15.635909 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:50:59.033231 Epoch 9, Training loss 13.921931266784668\n",
      "in params\n",
      "R2 values 0.0114, 0.0156, 0.0415; mean R2=0.0228\n",
      "Validation Error: Avg loss: 14.060499 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:50:59.332004 Epoch 10, Training loss 12.951374053955078\n",
      "in params\n",
      "R2 values 0.0056, 0.0026, 0.0019; mean R2=0.0034\n",
      "Validation Error: Avg loss: 13.724359 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:50:59.618424 Epoch 11, Training loss 12.212998390197754\n",
      "in params\n",
      "R2 values 0.0032, 0.0121, 0.0172; mean R2=0.0109\n",
      "Validation Error: Avg loss: 13.192195 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:50:59.907967 Epoch 12, Training loss 12.153429985046387\n",
      "in params\n",
      "R2 values 0.0035, 0.0432, 0.0521; mean R2=0.0330\n",
      "Validation Error: Avg loss: 13.051112 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:00.189526 Epoch 13, Training loss 13.21152114868164\n",
      "in params\n",
      "R2 values 0.0004, 0.0305, 0.0358; mean R2=0.0223\n",
      "Validation Error: Avg loss: 13.528584 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:00.479017 Epoch 14, Training loss 12.967065811157227\n",
      "in params\n",
      "R2 values 0.0161, 0.0502, 0.0725; mean R2=0.0462\n",
      "Validation Error: Avg loss: 13.168862 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:00.771939 Epoch 15, Training loss 12.425615310668945\n",
      "in params\n",
      "R2 values 0.0512, 0.1260, 0.1814; mean R2=0.1196\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 12.109908 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:01.077285 Epoch 16, Training loss 11.938009262084961\n",
      "in params\n",
      "R2 values 0.1106, 0.1390, 0.1655; mean R2=0.1384\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 11.729284 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:01.382976 Epoch 17, Training loss 11.426436424255371\n",
      "in params\n",
      "R2 values 0.0549, 0.1243, 0.1516; mean R2=0.1103\n",
      "Validation Error: Avg loss: 11.636295 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:01.673355 Epoch 18, Training loss 11.278727531433105\n",
      "in params\n",
      "R2 values 0.0998, 0.2090, 0.2249; mean R2=0.1779\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 11.178503 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:01.980071 Epoch 19, Training loss 10.621349334716797\n",
      "in params\n",
      "R2 values 0.2221, 0.3056, 0.3476; mean R2=0.2918\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 10.776455 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:02.284777 Epoch 20, Training loss 10.356367111206055\n",
      "in params\n",
      "R2 values 0.1471, 0.2172, 0.3205; mean R2=0.2283\n",
      "Validation Error: Avg loss: 11.384450 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:02.569633 Epoch 21, Training loss 10.099770545959473\n",
      "in params\n",
      "R2 values 0.2025, 0.3432, 0.4075; mean R2=0.3177\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 10.982911 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:02.880836 Epoch 22, Training loss 10.363683700561523\n",
      "in params\n",
      "R2 values 0.3021, 0.4725, 0.4603; mean R2=0.4116\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 10.085241 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:03.182113 Epoch 23, Training loss 10.099394798278809\n",
      "in params\n",
      "R2 values 0.2843, 0.2518, 0.3546; mean R2=0.2969\n",
      "Validation Error: Avg loss: 11.118113 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:03.469977 Epoch 24, Training loss 9.727485656738281\n",
      "in params\n",
      "R2 values 0.2664, 0.3123, 0.4202; mean R2=0.3330\n",
      "Validation Error: Avg loss: 10.799036 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:03.750257 Epoch 25, Training loss 9.415056228637695\n",
      "in params\n",
      "R2 values 0.1727, 0.2990, 0.3425; mean R2=0.2714\n",
      "Validation Error: Avg loss: 10.567136 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:04.032393 Epoch 26, Training loss 9.079118728637695\n",
      "in params\n",
      "R2 values 0.3680, 0.4140, 0.4748; mean R2=0.4190\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 9.621208 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:04.337113 Epoch 27, Training loss 9.040507316589355\n",
      "in params\n",
      "R2 values 0.4950, 0.4374, 0.5802; mean R2=0.5042\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 8.681462 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:04.644420 Epoch 28, Training loss 7.950619220733643\n",
      "in params\n",
      "R2 values 0.2451, 0.2222, 0.3402; mean R2=0.2692\n",
      "Validation Error: Avg loss: 9.966841 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:04.930412 Epoch 29, Training loss 7.830342769622803\n",
      "in params\n",
      "R2 values 0.4129, 0.3939, 0.5956; mean R2=0.4674\n",
      "Validation Error: Avg loss: 8.395145 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:05.215022 Epoch 30, Training loss 7.325324058532715\n",
      "in params\n",
      "R2 values 0.4347, 0.4053, 0.5614; mean R2=0.4672\n",
      "Validation Error: Avg loss: 7.984467 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:05.496027 Epoch 31, Training loss 7.0035810470581055\n",
      "in params\n",
      "R2 values 0.2495, 0.3721, 0.4822; mean R2=0.3679\n",
      "Validation Error: Avg loss: 8.454627 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:05.786133 Epoch 32, Training loss 7.210301876068115\n",
      "in params\n",
      "R2 values 0.3620, 0.5093, 0.5882; mean R2=0.4865\n",
      "Validation Error: Avg loss: 7.110152 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:06.069172 Epoch 33, Training loss 6.904829978942871\n",
      "in params\n",
      "R2 values 0.3640, 0.4349, 0.5592; mean R2=0.4527\n",
      "Validation Error: Avg loss: 7.683408 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:06.351197 Epoch 34, Training loss 6.688941955566406\n",
      "in params\n",
      "R2 values 0.4045, 0.5269, 0.5570; mean R2=0.4961\n",
      "Validation Error: Avg loss: 6.987527 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:06.635522 Epoch 35, Training loss 5.881657600402832\n",
      "in params\n",
      "R2 values 0.5188, 0.5691, 0.6050; mean R2=0.5643\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 6.376799 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:06.951271 Epoch 36, Training loss 6.01185941696167\n",
      "in params\n",
      "R2 values 0.4659, 0.6192, 0.6635; mean R2=0.5829\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 6.044675 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:07.253423 Epoch 37, Training loss 5.991628170013428\n",
      "in params\n",
      "R2 values 0.4017, 0.4852, 0.5489; mean R2=0.4786\n",
      "Validation Error: Avg loss: 7.274022 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:07.530923 Epoch 38, Training loss 5.444014072418213\n",
      "in params\n",
      "R2 values 0.3962, 0.4436, 0.5410; mean R2=0.4603\n",
      "Validation Error: Avg loss: 7.590002 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:07.811792 Epoch 39, Training loss 5.533229827880859\n",
      "in params\n",
      "R2 values 0.4426, 0.5243, 0.5561; mean R2=0.5076\n",
      "Validation Error: Avg loss: 6.574642 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:08.091610 Epoch 40, Training loss 5.811399459838867\n",
      "in params\n",
      "R2 values 0.4737, 0.5711, 0.6239; mean R2=0.5562\n",
      "Validation Error: Avg loss: 5.894719 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:08.395629 Epoch 41, Training loss 5.988256454467773\n",
      "in params\n",
      "R2 values 0.4531, 0.5627, 0.5913; mean R2=0.5357\n",
      "Validation Error: Avg loss: 5.910618 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:08.685344 Epoch 42, Training loss 6.156219959259033\n",
      "in params\n",
      "R2 values 0.4994, 0.4891, 0.5794; mean R2=0.5227\n",
      "Validation Error: Avg loss: 6.528188 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:08.970911 Epoch 43, Training loss 5.170178413391113\n",
      "in params\n",
      "R2 values 0.5404, 0.5895, 0.6418; mean R2=0.5906\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 5.422376 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:09.282928 Epoch 44, Training loss 5.847395420074463\n",
      "in params\n",
      "R2 values 0.4273, 0.3033, 0.4760; mean R2=0.4022\n",
      "Validation Error: Avg loss: 8.711924 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:51:09.573178 Epoch 45, Training loss 5.003548622131348\n",
      "in params\n",
      "R2 values 0.5673, 0.5165, 0.6961; mean R2=0.5933\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 5.960840 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:09.888147 Epoch 46, Training loss 5.069001197814941\n",
      "in params\n",
      "R2 values 0.5762, 0.5778, 0.6521; mean R2=0.6020\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 5.747877 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:10.191058 Epoch 47, Training loss 6.185672760009766\n",
      "in params\n",
      "R2 values 0.5285, 0.5133, 0.5942; mean R2=0.5453\n",
      "Validation Error: Avg loss: 6.294693 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:10.475571 Epoch 48, Training loss 5.321436405181885\n",
      "in params\n",
      "R2 values 0.4715, 0.5741, 0.6655; mean R2=0.5704\n",
      "Validation Error: Avg loss: 5.584956 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:10.756913 Epoch 49, Training loss 5.525704383850098\n",
      "in params\n",
      "R2 values 0.4306, 0.5120, 0.5639; mean R2=0.5022\n",
      "Validation Error: Avg loss: 6.386841 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:11.036773 Epoch 50, Training loss 5.0359697341918945\n",
      "in params\n",
      "R2 values 0.5420, 0.3198, 0.5258; mean R2=0.4625\n",
      "Validation Error: Avg loss: 8.642297 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:11.317382 Epoch 51, Training loss 4.619414329528809\n",
      "in params\n",
      "R2 values 0.3920, 0.4592, 0.5133; mean R2=0.4548\n",
      "Validation Error: Avg loss: 6.980061 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:11.600501 Epoch 52, Training loss 4.892376899719238\n",
      "in params\n",
      "R2 values 0.4880, 0.5109, 0.5717; mean R2=0.5235\n",
      "Validation Error: Avg loss: 6.341887 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:11.879977 Epoch 53, Training loss 4.955007076263428\n",
      "in params\n",
      "R2 values 0.5448, 0.5477, 0.6463; mean R2=0.5796\n",
      "Validation Error: Avg loss: 5.589786 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:12.161457 Epoch 54, Training loss 5.524542808532715\n",
      "in params\n",
      "R2 values 0.4404, 0.5686, 0.5847; mean R2=0.5312\n",
      "Validation Error: Avg loss: 5.745542 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:12.442621 Epoch 55, Training loss 4.988184452056885\n",
      "in params\n",
      "R2 values 0.4692, 0.5673, 0.5360; mean R2=0.5242\n",
      "Validation Error: Avg loss: 5.851303 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:12.727424 Epoch 56, Training loss 5.28902006149292\n",
      "in params\n",
      "R2 values 0.6186, 0.6244, 0.7042; mean R2=0.6490\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 4.722590 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:13.027565 Epoch 57, Training loss 4.755566596984863\n",
      "in params\n",
      "R2 values 0.5104, 0.5394, 0.6188; mean R2=0.5562\n",
      "Validation Error: Avg loss: 5.711228 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:13.311995 Epoch 58, Training loss 4.584047317504883\n",
      "in params\n",
      "R2 values 0.5421, 0.5565, 0.6465; mean R2=0.5817\n",
      "Validation Error: Avg loss: 5.599730 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:13.603112 Epoch 59, Training loss 4.5801520347595215\n",
      "in params\n",
      "R2 values 0.4419, 0.6039, 0.6235; mean R2=0.5564\n",
      "Validation Error: Avg loss: 5.321855 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:13.903362 Epoch 60, Training loss 5.365825653076172\n",
      "in params\n",
      "R2 values 0.5581, 0.6286, 0.6516; mean R2=0.6128\n",
      "Validation Error: Avg loss: 4.780346 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:14.187485 Epoch 61, Training loss 4.837928771972656\n",
      "in params\n",
      "R2 values 0.4987, 0.5702, 0.5861; mean R2=0.5517\n",
      "Validation Error: Avg loss: 5.532378 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:14.464743 Epoch 62, Training loss 5.178840637207031\n",
      "in params\n",
      "R2 values 0.5512, 0.5554, 0.7141; mean R2=0.6069\n",
      "Validation Error: Avg loss: 5.200597 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:14.757571 Epoch 63, Training loss 4.8513617515563965\n",
      "in params\n",
      "R2 values 0.6206, 0.4871, 0.6952; mean R2=0.6010\n",
      "Validation Error: Avg loss: 5.935565 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:15.045346 Epoch 64, Training loss 5.435253143310547\n",
      "in params\n",
      "R2 values 0.5409, 0.5288, 0.6480; mean R2=0.5725\n",
      "Validation Error: Avg loss: 5.682916 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:15.333456 Epoch 65, Training loss 5.6936116218566895\n",
      "in params\n",
      "R2 values 0.5190, 0.5720, 0.6427; mean R2=0.5779\n",
      "Validation Error: Avg loss: 5.335211 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:15.622571 Epoch 66, Training loss 4.510438919067383\n",
      "in params\n",
      "R2 values 0.5967, 0.4973, 0.5749; mean R2=0.5563\n",
      "Validation Error: Avg loss: 6.062519 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:15.910563 Epoch 67, Training loss 5.538959503173828\n",
      "in params\n",
      "R2 values 0.5385, 0.5928, 0.5744; mean R2=0.5686\n",
      "Validation Error: Avg loss: 5.380203 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:16.194509 Epoch 68, Training loss 4.930546760559082\n",
      "in params\n",
      "R2 values 0.5181, 0.6242, 0.5904; mean R2=0.5776\n",
      "Validation Error: Avg loss: 5.230893 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:16.472284 Epoch 69, Training loss 5.364913463592529\n",
      "in params\n",
      "R2 values 0.6594, 0.5546, 0.6581; mean R2=0.6241\n",
      "Validation Error: Avg loss: 5.300386 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:16.758448 Epoch 70, Training loss 5.240238189697266\n",
      "in params\n",
      "R2 values 0.4889, 0.7038, 0.5853; mean R2=0.5926\n",
      "Validation Error: Avg loss: 4.778966 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:17.045437 Epoch 71, Training loss 4.454350471496582\n",
      "in params\n",
      "R2 values 0.4212, 0.5131, 0.4939; mean R2=0.4761\n",
      "Validation Error: Avg loss: 6.443382 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:17.321098 Epoch 72, Training loss 4.942686080932617\n",
      "in params\n",
      "R2 values 0.5635, 0.5508, 0.7117; mean R2=0.6087\n",
      "Validation Error: Avg loss: 5.500269 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:17.600586 Epoch 73, Training loss 4.8610429763793945\n",
      "in params\n",
      "R2 values 0.4721, 0.3714, 0.5172; mean R2=0.4536\n",
      "Validation Error: Avg loss: 7.646461 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:17.879570 Epoch 74, Training loss 4.173209190368652\n",
      "in params\n",
      "R2 values 0.5901, 0.5959, 0.6720; mean R2=0.6193\n",
      "Validation Error: Avg loss: 5.052998 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:18.189059 Epoch 75, Training loss 5.333234786987305\n",
      "in params\n",
      "R2 values 0.5128, 0.6661, 0.5971; mean R2=0.5920\n",
      "Validation Error: Avg loss: 4.784259 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:18.480635 Epoch 76, Training loss 4.842363357543945\n",
      "in params\n",
      "R2 values 0.6277, 0.5869, 0.6650; mean R2=0.6266\n",
      "Validation Error: Avg loss: 5.045225 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:18.766393 Epoch 77, Training loss 5.129958629608154\n",
      "in params\n",
      "R2 values 0.5247, 0.5229, 0.6015; mean R2=0.5497\n",
      "Validation Error: Avg loss: 5.936416 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:19.047533 Epoch 78, Training loss 5.891263008117676\n",
      "in params\n",
      "R2 values 0.5623, 0.7500, 0.7050; mean R2=0.6724\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 3.729502 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:19.372221 Epoch 79, Training loss 5.798051834106445\n",
      "in params\n",
      "R2 values 0.5746, 0.6082, 0.6700; mean R2=0.6176\n",
      "Validation Error: Avg loss: 4.882773 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:19.660839 Epoch 80, Training loss 5.0815558433532715\n",
      "in params\n",
      "R2 values 0.4727, 0.7145, 0.7235; mean R2=0.6369\n",
      "Validation Error: Avg loss: 4.337038 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:19.949504 Epoch 81, Training loss 4.841493129730225\n",
      "in params\n",
      "R2 values 0.4487, 0.5535, 0.5504; mean R2=0.5175\n",
      "Validation Error: Avg loss: 5.929274 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:20.228776 Epoch 82, Training loss 4.590793609619141\n",
      "in params\n",
      "R2 values 0.5564, 0.5546, 0.6852; mean R2=0.5988\n",
      "Validation Error: Avg loss: 5.403327 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:20.512197 Epoch 83, Training loss 4.793297290802002\n",
      "in params\n",
      "R2 values 0.6000, 0.5894, 0.7695; mean R2=0.6530\n",
      "Validation Error: Avg loss: 4.742776 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:20.801405 Epoch 84, Training loss 5.67598819732666\n",
      "in params\n",
      "R2 values 0.5367, 0.6181, 0.6595; mean R2=0.6047\n",
      "Validation Error: Avg loss: 4.988255 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:21.081223 Epoch 85, Training loss 4.330028533935547\n",
      "in params\n",
      "R2 values 0.4531, 0.6005, 0.6252; mean R2=0.5596\n",
      "Validation Error: Avg loss: 5.588417 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:21.364075 Epoch 86, Training loss 4.271584987640381\n",
      "in params\n",
      "R2 values 0.4985, 0.7169, 0.6548; mean R2=0.6234\n",
      "Validation Error: Avg loss: 4.318139 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:21.655557 Epoch 87, Training loss 5.798844814300537\n",
      "in params\n",
      "R2 values 0.5600, 0.6525, 0.7060; mean R2=0.6395\n",
      "Validation Error: Avg loss: 4.627965 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:21.935948 Epoch 88, Training loss 5.182353973388672\n",
      "in params\n",
      "R2 values 0.4157, 0.7603, 0.6623; mean R2=0.6128\n",
      "Validation Error: Avg loss: 4.048258 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:22.221881 Epoch 89, Training loss 4.863067150115967\n",
      "in params\n",
      "R2 values 0.5633, 0.6925, 0.6396; mean R2=0.6318\n",
      "Validation Error: Avg loss: 4.271956 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:22.512847 Epoch 90, Training loss 5.133313179016113\n",
      "in params\n",
      "R2 values 0.5026, 0.5786, 0.6812; mean R2=0.5875\n",
      "Validation Error: Avg loss: 5.161678 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:51:22.804269 Epoch 91, Training loss 3.9601523876190186\n",
      "in params\n",
      "R2 values 0.5381, 0.6143, 0.6962; mean R2=0.6162\n",
      "Validation Error: Avg loss: 4.951969 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:23.091928 Epoch 92, Training loss 4.174336910247803\n",
      "in params\n",
      "R2 values 0.4762, 0.6941, 0.6070; mean R2=0.5924\n",
      "Validation Error: Avg loss: 4.954591 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:23.365156 Epoch 93, Training loss 4.7742462158203125\n",
      "in params\n",
      "R2 values 0.5657, 0.5939, 0.6048; mean R2=0.5881\n",
      "Validation Error: Avg loss: 5.801108 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:23.664293 Epoch 94, Training loss 4.49231481552124\n",
      "in params\n",
      "R2 values 0.5115, 0.4844, 0.5179; mean R2=0.5046\n",
      "Validation Error: Avg loss: 7.008097 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:23.945068 Epoch 95, Training loss 5.3067240715026855\n",
      "in params\n",
      "R2 values 0.5348, 0.7514, 0.6980; mean R2=0.6614\n",
      "Validation Error: Avg loss: 3.999837 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:24.226882 Epoch 96, Training loss 4.735767841339111\n",
      "in params\n",
      "R2 values 0.5158, 0.6897, 0.6517; mean R2=0.6191\n",
      "Validation Error: Avg loss: 4.730141 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:24.501355 Epoch 97, Training loss 5.062079429626465\n",
      "in params\n",
      "R2 values 0.5484, 0.5704, 0.5203; mean R2=0.5464\n",
      "Validation Error: Avg loss: 5.801661 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:24.790137 Epoch 98, Training loss 4.313619613647461\n",
      "in params\n",
      "R2 values 0.5748, 0.8318, 0.7046; mean R2=0.7038\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 3.132559 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:25.089782 Epoch 99, Training loss 5.087049961090088\n",
      "in params\n",
      "R2 values 0.4796, 0.7834, 0.6558; mean R2=0.6396\n",
      "Validation Error: Avg loss: 3.868375 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:25.376731 Epoch 100, Training loss 5.227550983428955\n",
      "in params\n",
      "R2 values 0.5086, 0.6445, 0.5851; mean R2=0.5794\n",
      "Validation Error: Avg loss: 5.019590 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:25.661398 Epoch 101, Training loss 6.081101894378662\n",
      "in params\n",
      "R2 values 0.6287, 0.7005, 0.7527; mean R2=0.6940\n",
      "Validation Error: Avg loss: 3.927775 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:25.948806 Epoch 102, Training loss 5.035871982574463\n",
      "in params\n",
      "R2 values 0.4990, 0.6768, 0.6166; mean R2=0.5975\n",
      "Validation Error: Avg loss: 4.774015 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:26.229273 Epoch 103, Training loss 5.826479434967041\n",
      "in params\n",
      "R2 values 0.4950, 0.6827, 0.6624; mean R2=0.6134\n",
      "Validation Error: Avg loss: 5.035936 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:26.509402 Epoch 104, Training loss 5.642493724822998\n",
      "in params\n",
      "R2 values 0.5612, 0.5505, 0.6292; mean R2=0.5803\n",
      "Validation Error: Avg loss: 6.270423 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:26.793082 Epoch 105, Training loss 5.478431701660156\n",
      "in params\n",
      "R2 values 0.6427, 0.5906, 0.7082; mean R2=0.6471\n",
      "Validation Error: Avg loss: 5.164545 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:27.074344 Epoch 106, Training loss 5.20173454284668\n",
      "in params\n",
      "R2 values 0.6780, 0.6427, 0.6270; mean R2=0.6492\n",
      "Validation Error: Avg loss: 4.747490 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:27.350340 Epoch 107, Training loss 5.112838268280029\n",
      "in params\n",
      "R2 values 0.5979, 0.6606, 0.6699; mean R2=0.6428\n",
      "Validation Error: Avg loss: 4.446591 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:27.639473 Epoch 108, Training loss 4.77325963973999\n",
      "in params\n",
      "R2 values 0.5208, 0.5498, 0.6666; mean R2=0.5791\n",
      "Validation Error: Avg loss: 5.437227 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:27.917431 Epoch 109, Training loss 4.547597408294678\n",
      "in params\n",
      "R2 values 0.5304, 0.6672, 0.6623; mean R2=0.6200\n",
      "Validation Error: Avg loss: 4.490335 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:28.213197 Epoch 110, Training loss 4.497159004211426\n",
      "in params\n",
      "R2 values 0.4443, 0.5768, 0.5908; mean R2=0.5373\n",
      "Validation Error: Avg loss: 5.636460 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:28.498472 Epoch 111, Training loss 4.694069862365723\n",
      "in params\n",
      "R2 values 0.5258, 0.6757, 0.6539; mean R2=0.6184\n",
      "Validation Error: Avg loss: 4.459997 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:28.777220 Epoch 112, Training loss 5.577736854553223\n",
      "in params\n",
      "R2 values 0.5516, 0.5383, 0.5490; mean R2=0.5463\n",
      "Validation Error: Avg loss: 5.860796 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:29.059661 Epoch 113, Training loss 5.454323768615723\n",
      "in params\n",
      "R2 values 0.5943, 0.5037, 0.5380; mean R2=0.5453\n",
      "Validation Error: Avg loss: 6.173596 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:29.348453 Epoch 114, Training loss 4.591013431549072\n",
      "in params\n",
      "R2 values 0.5653, 0.6695, 0.6354; mean R2=0.6234\n",
      "Validation Error: Avg loss: 4.462638 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:29.631509 Epoch 115, Training loss 5.379579544067383\n",
      "in params\n",
      "R2 values 0.5707, 0.5872, 0.5941; mean R2=0.5840\n",
      "Validation Error: Avg loss: 5.629190 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:29.915961 Epoch 116, Training loss 4.603792667388916\n",
      "in params\n",
      "R2 values 0.5352, 0.5262, 0.6108; mean R2=0.5574\n",
      "Validation Error: Avg loss: 6.083365 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:30.198322 Epoch 117, Training loss 4.524237155914307\n",
      "in params\n",
      "R2 values 0.6635, 0.6365, 0.6280; mean R2=0.6427\n",
      "Validation Error: Avg loss: 5.016631 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:30.488583 Epoch 118, Training loss 4.611493110656738\n",
      "in params\n",
      "R2 values 0.5367, 0.6188, 0.5903; mean R2=0.5819\n",
      "Validation Error: Avg loss: 5.402153 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:30.772063 Epoch 119, Training loss 4.361619472503662\n",
      "in params\n",
      "R2 values 0.5752, 0.7026, 0.6732; mean R2=0.6504\n",
      "Validation Error: Avg loss: 4.603683 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:31.056685 Epoch 120, Training loss 5.0526323318481445\n",
      "in params\n",
      "R2 values 0.6081, 0.6205, 0.7357; mean R2=0.6547\n",
      "Validation Error: Avg loss: 4.779895 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:31.347243 Epoch 121, Training loss 4.784149646759033\n",
      "in params\n",
      "R2 values 0.5610, 0.6386, 0.6418; mean R2=0.6138\n",
      "Validation Error: Avg loss: 4.829717 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:31.652006 Epoch 122, Training loss 5.261150360107422\n",
      "in params\n",
      "R2 values 0.4979, 0.6527, 0.6891; mean R2=0.6132\n",
      "Validation Error: Avg loss: 4.678296 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:31.935287 Epoch 123, Training loss 4.870211601257324\n",
      "in params\n",
      "R2 values 0.6240, 0.6643, 0.6307; mean R2=0.6397\n",
      "Validation Error: Avg loss: 4.599212 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:32.230734 Epoch 124, Training loss 4.936607837677002\n",
      "in params\n",
      "R2 values 0.5618, 0.8041, 0.7442; mean R2=0.7034\n",
      "Validation Error: Avg loss: 3.659404 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:32.524701 Epoch 125, Training loss 4.396890640258789\n",
      "in params\n",
      "R2 values 0.6040, 0.5730, 0.5715; mean R2=0.5828\n",
      "Validation Error: Avg loss: 5.816258 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:32.821529 Epoch 126, Training loss 5.514183521270752\n",
      "in params\n",
      "R2 values 0.5904, 0.7164, 0.7038; mean R2=0.6702\n",
      "Validation Error: Avg loss: 4.157375 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:33.107867 Epoch 127, Training loss 4.8179030418396\n",
      "in params\n",
      "R2 values 0.5280, 0.5719, 0.6549; mean R2=0.5849\n",
      "Validation Error: Avg loss: 5.407727 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:33.397118 Epoch 128, Training loss 5.190759181976318\n",
      "in params\n",
      "R2 values 0.5073, 0.7720, 0.7389; mean R2=0.6727\n",
      "Validation Error: Avg loss: 3.558380 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:33.700488 Epoch 129, Training loss 5.783294677734375\n",
      "in params\n",
      "R2 values 0.5166, 0.6549, 0.6904; mean R2=0.6206\n",
      "Validation Error: Avg loss: 4.777308 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:33.985071 Epoch 130, Training loss 4.75728702545166\n",
      "in params\n",
      "R2 values 0.3778, 0.6938, 0.5354; mean R2=0.5357\n",
      "Validation Error: Avg loss: 4.790059 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:34.271923 Epoch 131, Training loss 5.535130500793457\n",
      "in params\n",
      "R2 values 0.4115, 0.6494, 0.5802; mean R2=0.5470\n",
      "Validation Error: Avg loss: 5.137495 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:34.563694 Epoch 132, Training loss 5.036013603210449\n",
      "in params\n",
      "R2 values 0.5361, 0.8152, 0.7642; mean R2=0.7052\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 3.663051 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:34.905737 Epoch 133, Training loss 5.985596179962158\n",
      "in params\n",
      "R2 values 0.4666, 0.7362, 0.6275; mean R2=0.6101\n",
      "Validation Error: Avg loss: 5.060308 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:35.200396 Epoch 134, Training loss 4.781376361846924\n",
      "in params\n",
      "R2 values 0.4806, 0.7339, 0.7416; mean R2=0.6521\n",
      "Validation Error: Avg loss: 4.181599 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:35.499420 Epoch 135, Training loss 3.9756641387939453\n",
      "in params\n",
      "R2 values 0.5246, 0.7441, 0.6188; mean R2=0.6292\n",
      "Validation Error: Avg loss: 4.020805 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:35.792855 Epoch 136, Training loss 5.140272617340088\n",
      "in params\n",
      "R2 values 0.5448, 0.3741, 0.5148; mean R2=0.4779\n",
      "Validation Error: Avg loss: 7.554127 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:51:36.094863 Epoch 137, Training loss 5.267448425292969\n",
      "in params\n",
      "R2 values 0.5659, 0.6863, 0.5938; mean R2=0.6153\n",
      "Validation Error: Avg loss: 4.603072 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:36.388674 Epoch 138, Training loss 5.043649196624756\n",
      "in params\n",
      "R2 values 0.6003, 0.6980, 0.7066; mean R2=0.6683\n",
      "Validation Error: Avg loss: 4.163315 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:36.690568 Epoch 139, Training loss 4.621140956878662\n",
      "in params\n",
      "R2 values 0.5130, 0.6358, 0.6692; mean R2=0.6060\n",
      "Validation Error: Avg loss: 4.720412 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:36.982333 Epoch 140, Training loss 4.598975658416748\n",
      "in params\n",
      "R2 values 0.6306, 0.7041, 0.6636; mean R2=0.6661\n",
      "Validation Error: Avg loss: 3.998990 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:37.274938 Epoch 141, Training loss 5.117395401000977\n",
      "in params\n",
      "R2 values 0.6249, 0.6283, 0.6574; mean R2=0.6368\n",
      "Validation Error: Avg loss: 5.293780 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:37.566477 Epoch 142, Training loss 4.053661346435547\n",
      "in params\n",
      "R2 values 0.6128, 0.6709, 0.6569; mean R2=0.6468\n",
      "Validation Error: Avg loss: 4.448196 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:37.863808 Epoch 143, Training loss 4.911218166351318\n",
      "in params\n",
      "R2 values 0.6645, 0.7286, 0.6495; mean R2=0.6809\n",
      "Validation Error: Avg loss: 3.796413 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:38.159061 Epoch 144, Training loss 4.806911468505859\n",
      "in params\n",
      "R2 values 0.4413, 0.5759, 0.6166; mean R2=0.5446\n",
      "Validation Error: Avg loss: 5.487991 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:38.462801 Epoch 145, Training loss 4.708283424377441\n",
      "in params\n",
      "R2 values 0.5384, 0.6790, 0.6258; mean R2=0.6144\n",
      "Validation Error: Avg loss: 4.449293 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:38.767706 Epoch 146, Training loss 5.3299784660339355\n",
      "in params\n",
      "R2 values 0.5563, 0.7843, 0.7306; mean R2=0.6904\n",
      "Validation Error: Avg loss: 3.270772 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:39.062911 Epoch 147, Training loss 5.099730014801025\n",
      "in params\n",
      "R2 values 0.6871, 0.6734, 0.7005; mean R2=0.6870\n",
      "Validation Error: Avg loss: 4.211205 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:39.362854 Epoch 148, Training loss 4.754436016082764\n",
      "in params\n",
      "R2 values 0.5873, 0.6764, 0.6520; mean R2=0.6386\n",
      "Validation Error: Avg loss: 4.421730 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:39.658499 Epoch 149, Training loss 5.6508073806762695\n",
      "in params\n",
      "R2 values 0.4923, 0.7106, 0.6061; mean R2=0.6030\n",
      "Validation Error: Avg loss: 4.733061 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:39.953126 Epoch 150, Training loss 3.6005656719207764\n",
      "in params\n",
      "R2 values 0.5358, 0.7252, 0.6139; mean R2=0.6250\n",
      "Validation Error: Avg loss: 4.680838 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:40.253003 Epoch 151, Training loss 5.018976211547852\n",
      "in params\n",
      "R2 values 0.5182, 0.7193, 0.7135; mean R2=0.6503\n",
      "Validation Error: Avg loss: 4.333790 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:40.544574 Epoch 152, Training loss 5.050149917602539\n",
      "in params\n",
      "R2 values 0.5296, 0.7073, 0.7256; mean R2=0.6542\n",
      "Validation Error: Avg loss: 4.264567 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:40.840355 Epoch 153, Training loss 4.295030117034912\n",
      "in params\n",
      "R2 values 0.5474, 0.5919, 0.5671; mean R2=0.5688\n",
      "Validation Error: Avg loss: 5.498148 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:41.132866 Epoch 154, Training loss 4.8754801750183105\n",
      "in params\n",
      "R2 values 0.5242, 0.5995, 0.5349; mean R2=0.5529\n",
      "Validation Error: Avg loss: 5.480854 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:41.425713 Epoch 155, Training loss 5.395124912261963\n",
      "in params\n",
      "R2 values 0.4962, 0.7785, 0.7724; mean R2=0.6824\n",
      "Validation Error: Avg loss: 3.758599 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:41.717753 Epoch 156, Training loss 5.590443134307861\n",
      "in params\n",
      "R2 values 0.6328, 0.6095, 0.6692; mean R2=0.6372\n",
      "Validation Error: Avg loss: 4.908062 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:42.031833 Epoch 157, Training loss 4.6144514083862305\n",
      "in params\n",
      "R2 values 0.6289, 0.5767, 0.6138; mean R2=0.6064\n",
      "Validation Error: Avg loss: 5.874590 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:42.311950 Epoch 158, Training loss 5.2776360511779785\n",
      "in params\n",
      "R2 values 0.6490, 0.5334, 0.6460; mean R2=0.6095\n",
      "Validation Error: Avg loss: 6.182416 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:42.597284 Epoch 159, Training loss 5.597655296325684\n",
      "in params\n",
      "R2 values 0.4752, 0.6369, 0.6372; mean R2=0.5831\n",
      "Validation Error: Avg loss: 5.156244 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:42.886024 Epoch 160, Training loss 4.793787956237793\n",
      "in params\n",
      "R2 values 0.5735, 0.7069, 0.6697; mean R2=0.6500\n",
      "Validation Error: Avg loss: 4.302337 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:43.171102 Epoch 161, Training loss 4.71385383605957\n",
      "in params\n",
      "R2 values 0.6760, 0.5255, 0.7090; mean R2=0.6369\n",
      "Validation Error: Avg loss: 5.435640 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:43.459696 Epoch 162, Training loss 4.714432239532471\n",
      "in params\n",
      "R2 values 0.5354, 0.5290, 0.6216; mean R2=0.5620\n",
      "Validation Error: Avg loss: 5.762271 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:43.756238 Epoch 163, Training loss 4.148853778839111\n",
      "in params\n",
      "R2 values 0.5771, 0.6672, 0.6515; mean R2=0.6319\n",
      "Validation Error: Avg loss: 4.433667 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:44.042057 Epoch 164, Training loss 4.435238361358643\n",
      "in params\n",
      "R2 values 0.5926, 0.7799, 0.6412; mean R2=0.6712\n",
      "Validation Error: Avg loss: 3.496226 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:44.328661 Epoch 165, Training loss 4.697125434875488\n",
      "in params\n",
      "R2 values 0.5706, 0.6207, 0.6670; mean R2=0.6194\n",
      "Validation Error: Avg loss: 5.517734 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:44.618442 Epoch 166, Training loss 3.8565056324005127\n",
      "in params\n",
      "R2 values 0.4930, 0.6055, 0.6136; mean R2=0.5707\n",
      "Validation Error: Avg loss: 5.629297 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:44.922728 Epoch 167, Training loss 5.704899311065674\n",
      "in params\n",
      "R2 values 0.6034, 0.8209, 0.7118; mean R2=0.7120\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 3.874804 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:45.235412 Epoch 168, Training loss 4.287424087524414\n",
      "in params\n",
      "R2 values 0.5660, 0.7252, 0.6326; mean R2=0.6412\n",
      "Validation Error: Avg loss: 4.471556 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:45.521853 Epoch 169, Training loss 4.828276634216309\n",
      "in params\n",
      "R2 values 0.5484, 0.7294, 0.6088; mean R2=0.6289\n",
      "Validation Error: Avg loss: 4.453436 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:45.816269 Epoch 170, Training loss 4.445042610168457\n",
      "in params\n",
      "R2 values 0.5327, 0.7046, 0.7204; mean R2=0.6526\n",
      "Validation Error: Avg loss: 4.029819 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:46.113258 Epoch 171, Training loss 4.710994243621826\n",
      "in params\n",
      "R2 values 0.6179, 0.5819, 0.6178; mean R2=0.6059\n",
      "Validation Error: Avg loss: 5.308546 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:46.405301 Epoch 172, Training loss 4.113912105560303\n",
      "in params\n",
      "R2 values 0.6212, 0.7118, 0.6448; mean R2=0.6593\n",
      "Validation Error: Avg loss: 4.149430 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:46.688606 Epoch 173, Training loss 4.6979169845581055\n",
      "in params\n",
      "R2 values 0.5227, 0.7861, 0.7443; mean R2=0.6844\n",
      "Validation Error: Avg loss: 3.355930 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:46.977288 Epoch 174, Training loss 4.468920707702637\n",
      "in params\n",
      "R2 values 0.5289, 0.6496, 0.6458; mean R2=0.6081\n",
      "Validation Error: Avg loss: 4.783954 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:47.266030 Epoch 175, Training loss 4.31918478012085\n",
      "in params\n",
      "R2 values 0.6489, 0.6379, 0.6522; mean R2=0.6463\n",
      "Validation Error: Avg loss: 4.780406 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:47.555917 Epoch 176, Training loss 3.6659491062164307\n",
      "in params\n",
      "R2 values 0.5793, 0.8100, 0.6724; mean R2=0.6873\n",
      "Validation Error: Avg loss: 3.361372 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:47.848107 Epoch 177, Training loss 5.07290506362915\n",
      "in params\n",
      "R2 values 0.5896, 0.6270, 0.5115; mean R2=0.5760\n",
      "Validation Error: Avg loss: 5.669913 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:48.138460 Epoch 178, Training loss 5.114083766937256\n",
      "in params\n",
      "R2 values 0.5696, 0.6420, 0.6495; mean R2=0.6204\n",
      "Validation Error: Avg loss: 4.773515 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:48.431547 Epoch 179, Training loss 4.501430988311768\n",
      "in params\n",
      "R2 values 0.6303, 0.6670, 0.7120; mean R2=0.6698\n",
      "Validation Error: Avg loss: 4.329885 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:48.728532 Epoch 180, Training loss 4.204405784606934\n",
      "in params\n",
      "R2 values 0.6786, 0.5932, 0.6214; mean R2=0.6310\n",
      "Validation Error: Avg loss: 5.157499 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:49.020509 Epoch 181, Training loss 3.7697079181671143\n",
      "in params\n",
      "R2 values 0.5978, 0.5368, 0.5862; mean R2=0.5736\n",
      "Validation Error: Avg loss: 6.086230 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:49.311459 Epoch 182, Training loss 3.582007884979248\n",
      "in params\n",
      "R2 values 0.4765, 0.5996, 0.5999; mean R2=0.5587\n",
      "Validation Error: Avg loss: 6.184449 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:51:49.642789 Epoch 183, Training loss 4.113719463348389\n",
      "in params\n",
      "R2 values 0.5074, 0.7493, 0.7082; mean R2=0.6550\n",
      "Validation Error: Avg loss: 3.788254 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:49.935158 Epoch 184, Training loss 4.969729423522949\n",
      "in params\n",
      "R2 values 0.6714, 0.6857, 0.6957; mean R2=0.6843\n",
      "Validation Error: Avg loss: 4.131445 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:50.230783 Epoch 185, Training loss 4.422624111175537\n",
      "in params\n",
      "R2 values 0.5446, 0.5987, 0.5565; mean R2=0.5666\n",
      "Validation Error: Avg loss: 6.134625 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:50.846767 Epoch 186, Training loss 4.739096164703369\n",
      "in params\n",
      "R2 values 0.5075, 0.7573, 0.5862; mean R2=0.6170\n",
      "Validation Error: Avg loss: 3.969165 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:51.292401 Epoch 187, Training loss 4.866119861602783\n",
      "in params\n",
      "R2 values 0.4529, 0.7009, 0.6296; mean R2=0.5945\n",
      "Validation Error: Avg loss: 4.462955 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:51.591926 Epoch 188, Training loss 3.8660202026367188\n",
      "in params\n",
      "R2 values 0.6804, 0.7289, 0.6177; mean R2=0.6757\n",
      "Validation Error: Avg loss: 3.972689 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:51.894254 Epoch 189, Training loss 4.216549873352051\n",
      "in params\n",
      "R2 values 0.5719, 0.6903, 0.6722; mean R2=0.6448\n",
      "Validation Error: Avg loss: 4.319943 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:52.185741 Epoch 190, Training loss 5.676337718963623\n",
      "in params\n",
      "R2 values 0.6355, 0.5581, 0.6339; mean R2=0.6092\n",
      "Validation Error: Avg loss: 5.687265 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:52.478111 Epoch 191, Training loss 5.512340545654297\n",
      "in params\n",
      "R2 values 0.6668, 0.4560, 0.6223; mean R2=0.5817\n",
      "Validation Error: Avg loss: 6.427271 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:52.776058 Epoch 192, Training loss 4.7464518547058105\n",
      "in params\n",
      "R2 values 0.6377, 0.6969, 0.6909; mean R2=0.6752\n",
      "Validation Error: Avg loss: 4.930346 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:53.062638 Epoch 193, Training loss 4.430600643157959\n",
      "in params\n",
      "R2 values 0.4957, 0.5060, 0.6206; mean R2=0.5408\n",
      "Validation Error: Avg loss: 6.747605 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:53.358065 Epoch 194, Training loss 4.4290080070495605\n",
      "in params\n",
      "R2 values 0.5304, 0.6826, 0.6379; mean R2=0.6169\n",
      "Validation Error: Avg loss: 4.978195 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:53.654095 Epoch 195, Training loss 4.825481414794922\n",
      "in params\n",
      "R2 values 0.4432, 0.6592, 0.6023; mean R2=0.5682\n",
      "Validation Error: Avg loss: 4.903189 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:53.970637 Epoch 196, Training loss 4.2348527908325195\n",
      "in params\n",
      "R2 values 0.3660, 0.6172, 0.4564; mean R2=0.4799\n",
      "Validation Error: Avg loss: 5.998541 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:54.262880 Epoch 197, Training loss 4.81353235244751\n",
      "in params\n",
      "R2 values 0.4570, 0.7697, 0.5970; mean R2=0.6079\n",
      "Validation Error: Avg loss: 4.537362 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:54.564678 Epoch 198, Training loss 3.840074062347412\n",
      "in params\n",
      "R2 values 0.5169, 0.7403, 0.6297; mean R2=0.6290\n",
      "Validation Error: Avg loss: 4.283397 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:54.864464 Epoch 199, Training loss 4.235949516296387\n",
      "in params\n",
      "R2 values 0.5432, 0.6944, 0.6145; mean R2=0.6174\n",
      "Validation Error: Avg loss: 5.033793 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:55.164344 Epoch 200, Training loss 5.285312652587891\n",
      "in params\n",
      "R2 values 0.5421, 0.4864, 0.6696; mean R2=0.5660\n",
      "Validation Error: Avg loss: 6.332435 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:55.463629 Epoch 201, Training loss 4.780672073364258\n",
      "in params\n",
      "R2 values 0.5127, 0.7602, 0.6507; mean R2=0.6412\n",
      "Validation Error: Avg loss: 4.162406 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:55.762040 Epoch 202, Training loss 4.971471786499023\n",
      "in params\n",
      "R2 values 0.4349, 0.7597, 0.6221; mean R2=0.6056\n",
      "Validation Error: Avg loss: 4.233674 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:56.054711 Epoch 203, Training loss 3.568916082382202\n",
      "in params\n",
      "R2 values 0.4914, 0.7500, 0.6786; mean R2=0.6400\n",
      "Validation Error: Avg loss: 3.791514 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:56.351291 Epoch 204, Training loss 3.690687656402588\n",
      "in params\n",
      "R2 values 0.5685, 0.7421, 0.6665; mean R2=0.6590\n",
      "Validation Error: Avg loss: 3.890220 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:56.649735 Epoch 205, Training loss 4.546209335327148\n",
      "in params\n",
      "R2 values 0.6205, 0.5649, 0.6566; mean R2=0.6140\n",
      "Validation Error: Avg loss: 5.231037 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:56.942455 Epoch 206, Training loss 4.765039920806885\n",
      "in params\n",
      "R2 values 0.3981, 0.7044, 0.5727; mean R2=0.5584\n",
      "Validation Error: Avg loss: 4.722269 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:57.241783 Epoch 207, Training loss 5.544698238372803\n",
      "in params\n",
      "R2 values 0.5656, 0.7389, 0.6751; mean R2=0.6599\n",
      "Validation Error: Avg loss: 3.798924 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:57.540428 Epoch 208, Training loss 5.204865455627441\n",
      "in params\n",
      "R2 values 0.5761, 0.6357, 0.6512; mean R2=0.6210\n",
      "Validation Error: Avg loss: 4.835927 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:57.833025 Epoch 209, Training loss 4.7504096031188965\n",
      "in params\n",
      "R2 values 0.6491, 0.6724, 0.6944; mean R2=0.6720\n",
      "Validation Error: Avg loss: 4.601279 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:58.130303 Epoch 210, Training loss 4.792661666870117\n",
      "in params\n",
      "R2 values 0.6279, 0.7176, 0.6810; mean R2=0.6755\n",
      "Validation Error: Avg loss: 4.831157 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:58.429924 Epoch 211, Training loss 5.310214042663574\n",
      "in params\n",
      "R2 values 0.5451, 0.5431, 0.6155; mean R2=0.5679\n",
      "Validation Error: Avg loss: 6.352236 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:58.747138 Epoch 212, Training loss 5.082497596740723\n",
      "in params\n",
      "R2 values 0.6331, 0.8281, 0.7035; mean R2=0.7215\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 3.090980 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:59.077968 Epoch 213, Training loss 4.545956134796143\n",
      "in params\n",
      "R2 values 0.5643, 0.7660, 0.6201; mean R2=0.6501\n",
      "Validation Error: Avg loss: 3.770756 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:59.405173 Epoch 214, Training loss 4.487600803375244\n",
      "in params\n",
      "R2 values 0.5451, 0.7350, 0.5608; mean R2=0.6136\n",
      "Validation Error: Avg loss: 4.270028 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:51:59.719254 Epoch 215, Training loss 5.103005409240723\n",
      "in params\n",
      "R2 values 0.6618, 0.7588, 0.7684; mean R2=0.7297\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 3.250317 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:00.039508 Epoch 216, Training loss 4.909517765045166\n",
      "in params\n",
      "R2 values 0.6041, 0.7257, 0.6678; mean R2=0.6658\n",
      "Validation Error: Avg loss: 3.824987 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:00.339703 Epoch 217, Training loss 5.514194488525391\n",
      "in params\n",
      "R2 values 0.5600, 0.6523, 0.6269; mean R2=0.6131\n",
      "Validation Error: Avg loss: 4.780383 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:00.629162 Epoch 218, Training loss 5.153702735900879\n",
      "in params\n",
      "R2 values 0.5786, 0.7660, 0.6212; mean R2=0.6553\n",
      "Validation Error: Avg loss: 5.088151 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:00.922828 Epoch 219, Training loss 3.9280285835266113\n",
      "in params\n",
      "R2 values 0.6279, 0.6758, 0.5974; mean R2=0.6337\n",
      "Validation Error: Avg loss: 5.840603 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:01.222244 Epoch 220, Training loss 3.552838087081909\n",
      "in params\n",
      "R2 values 0.5622, 0.7710, 0.6559; mean R2=0.6630\n",
      "Validation Error: Avg loss: 4.043506 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:01.516616 Epoch 221, Training loss 4.471373558044434\n",
      "in params\n",
      "R2 values 0.5665, 0.7341, 0.5760; mean R2=0.6255\n",
      "Validation Error: Avg loss: 4.795670 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:01.815667 Epoch 222, Training loss 3.921755790710449\n",
      "in params\n",
      "R2 values 0.6311, 0.7104, 0.6949; mean R2=0.6788\n",
      "Validation Error: Avg loss: 4.392973 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:02.116981 Epoch 223, Training loss 3.9129834175109863\n",
      "in params\n",
      "R2 values 0.3992, 0.6923, 0.5741; mean R2=0.5552\n",
      "Validation Error: Avg loss: 4.732601 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:02.409523 Epoch 224, Training loss 5.298954010009766\n",
      "in params\n",
      "R2 values 0.4793, 0.6605, 0.6820; mean R2=0.6073\n",
      "Validation Error: Avg loss: 4.511639 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:02.712901 Epoch 225, Training loss 4.693490028381348\n",
      "in params\n",
      "R2 values 0.5622, 0.7201, 0.6055; mean R2=0.6293\n",
      "Validation Error: Avg loss: 4.287086 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:03.027252 Epoch 226, Training loss 4.839768886566162\n",
      "in params\n",
      "R2 values 0.6075, 0.6533, 0.7064; mean R2=0.6557\n",
      "Validation Error: Avg loss: 4.443191 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:03.326283 Epoch 227, Training loss 4.663581848144531\n",
      "in params\n",
      "R2 values 0.5480, 0.6774, 0.6392; mean R2=0.6215\n",
      "Validation Error: Avg loss: 5.066189 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:03.625703 Epoch 228, Training loss 4.804421901702881\n",
      "in params\n",
      "R2 values 0.5198, 0.5225, 0.5189; mean R2=0.5204\n",
      "Validation Error: Avg loss: 6.285947 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:52:03.936254 Epoch 229, Training loss 4.283524990081787\n",
      "in params\n",
      "R2 values 0.5738, 0.6112, 0.6436; mean R2=0.6095\n",
      "Validation Error: Avg loss: 5.394372 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:04.236039 Epoch 230, Training loss 3.5227572917938232\n",
      "in params\n",
      "R2 values 0.6278, 0.5990, 0.6428; mean R2=0.6232\n",
      "Validation Error: Avg loss: 5.308608 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:04.530858 Epoch 231, Training loss 4.255596160888672\n",
      "in params\n",
      "R2 values 0.5455, 0.6445, 0.5507; mean R2=0.5802\n",
      "Validation Error: Avg loss: 5.253454 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:04.834276 Epoch 232, Training loss 3.650456428527832\n",
      "in params\n",
      "R2 values 0.6682, 0.7734, 0.6306; mean R2=0.6907\n",
      "Validation Error: Avg loss: 4.098231 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:05.124881 Epoch 233, Training loss 4.771698951721191\n",
      "in params\n",
      "R2 values 0.6998, 0.7688, 0.6799; mean R2=0.7162\n",
      "Validation Error: Avg loss: 3.511325 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:05.420070 Epoch 234, Training loss 4.497910022735596\n",
      "in params\n",
      "R2 values 0.5976, 0.5449, 0.5732; mean R2=0.5719\n",
      "Validation Error: Avg loss: 5.846767 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:05.711346 Epoch 235, Training loss 4.347285747528076\n",
      "in params\n",
      "R2 values 0.7023, 0.6756, 0.7157; mean R2=0.6979\n",
      "Validation Error: Avg loss: 4.039032 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:06.009440 Epoch 236, Training loss 5.145784378051758\n",
      "in params\n",
      "R2 values 0.5557, 0.6736, 0.5968; mean R2=0.6087\n",
      "Validation Error: Avg loss: 5.176794 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:06.308105 Epoch 237, Training loss 4.287991523742676\n",
      "in params\n",
      "R2 values 0.4567, 0.5737, 0.5638; mean R2=0.5314\n",
      "Validation Error: Avg loss: 6.042024 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:06.606631 Epoch 238, Training loss 4.796216011047363\n",
      "in params\n",
      "R2 values 0.5912, 0.6842, 0.5775; mean R2=0.6176\n",
      "Validation Error: Avg loss: 4.892910 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:06.904678 Epoch 239, Training loss 3.7699286937713623\n",
      "in params\n",
      "R2 values 0.5654, 0.5193, 0.6141; mean R2=0.5663\n",
      "Validation Error: Avg loss: 5.965539 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:07.207026 Epoch 240, Training loss 4.927576541900635\n",
      "in params\n",
      "R2 values 0.6598, 0.7122, 0.6802; mean R2=0.6841\n",
      "Validation Error: Avg loss: 4.281709 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:07.499882 Epoch 241, Training loss 4.215964317321777\n",
      "in params\n",
      "R2 values 0.4635, 0.7378, 0.6038; mean R2=0.6017\n",
      "Validation Error: Avg loss: 4.405654 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:07.807788 Epoch 242, Training loss 4.275169849395752\n",
      "in params\n",
      "R2 values 0.5484, 0.7100, 0.5610; mean R2=0.6064\n",
      "Validation Error: Avg loss: 4.659629 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:08.110000 Epoch 243, Training loss 3.7526047229766846\n",
      "in params\n",
      "R2 values 0.4800, 0.7894, 0.5220; mean R2=0.5971\n",
      "Validation Error: Avg loss: 4.095702 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:08.407012 Epoch 244, Training loss 4.7435302734375\n",
      "in params\n",
      "R2 values 0.4467, 0.6886, 0.6123; mean R2=0.5825\n",
      "Validation Error: Avg loss: 5.269972 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:08.719846 Epoch 245, Training loss 4.009190559387207\n",
      "in params\n",
      "R2 values 0.5947, 0.7059, 0.7000; mean R2=0.6669\n",
      "Validation Error: Avg loss: 4.433263 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:09.035357 Epoch 246, Training loss 4.2680840492248535\n",
      "in params\n",
      "R2 values 0.5529, 0.7325, 0.7138; mean R2=0.6664\n",
      "Validation Error: Avg loss: 4.536206 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:09.345242 Epoch 247, Training loss 4.887817859649658\n",
      "in params\n",
      "R2 values 0.5326, 0.7615, 0.6325; mean R2=0.6422\n",
      "Validation Error: Avg loss: 4.498799 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:09.651605 Epoch 248, Training loss 4.7805280685424805\n",
      "in params\n",
      "R2 values 0.6047, 0.6200, 0.5446; mean R2=0.5897\n",
      "Validation Error: Avg loss: 5.270190 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:09.946133 Epoch 249, Training loss 3.7500107288360596\n",
      "in params\n",
      "R2 values 0.4870, 0.6040, 0.6042; mean R2=0.5650\n",
      "Validation Error: Avg loss: 5.262167 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:10.241827 Epoch 250, Training loss 4.30474328994751\n",
      "in params\n",
      "R2 values 0.5305, 0.7324, 0.5806; mean R2=0.6145\n",
      "Validation Error: Avg loss: 4.269831 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:10.536452 Epoch 251, Training loss 3.5629310607910156\n",
      "in params\n",
      "R2 values 0.5063, 0.7272, 0.6514; mean R2=0.6283\n",
      "Validation Error: Avg loss: 4.590085 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:10.830396 Epoch 252, Training loss 4.299990177154541\n",
      "in params\n",
      "R2 values 0.5159, 0.7951, 0.6733; mean R2=0.6614\n",
      "Validation Error: Avg loss: 3.531533 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:11.139453 Epoch 253, Training loss 3.3311879634857178\n",
      "in params\n",
      "R2 values 0.5291, 0.5094, 0.5448; mean R2=0.5278\n",
      "Validation Error: Avg loss: 6.249630 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:11.434839 Epoch 254, Training loss 4.335061073303223\n",
      "in params\n",
      "R2 values 0.5208, 0.7591, 0.6890; mean R2=0.6563\n",
      "Validation Error: Avg loss: 4.184875 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:11.737052 Epoch 255, Training loss 3.47115159034729\n",
      "in params\n",
      "R2 values 0.5135, 0.6425, 0.5838; mean R2=0.5800\n",
      "Validation Error: Avg loss: 5.912870 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:12.031276 Epoch 256, Training loss 4.021738052368164\n",
      "in params\n",
      "R2 values 0.6286, 0.5583, 0.6236; mean R2=0.6035\n",
      "Validation Error: Avg loss: 5.608809 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:12.321768 Epoch 257, Training loss 4.316463947296143\n",
      "in params\n",
      "R2 values 0.5276, 0.5961, 0.5859; mean R2=0.5699\n",
      "Validation Error: Avg loss: 5.977737 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:12.617857 Epoch 258, Training loss 4.319283485412598\n",
      "in params\n",
      "R2 values 0.5724, 0.7115, 0.5489; mean R2=0.6110\n",
      "Validation Error: Avg loss: 4.670657 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:12.917369 Epoch 259, Training loss 5.156163215637207\n",
      "in params\n",
      "R2 values 0.6133, 0.6141, 0.6269; mean R2=0.6181\n",
      "Validation Error: Avg loss: 5.030436 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:13.210170 Epoch 260, Training loss 3.977402687072754\n",
      "in params\n",
      "R2 values 0.4184, 0.6664, 0.5618; mean R2=0.5488\n",
      "Validation Error: Avg loss: 4.951189 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:13.496870 Epoch 261, Training loss 5.464840412139893\n",
      "in params\n",
      "R2 values 0.5727, 0.5769, 0.5730; mean R2=0.5742\n",
      "Validation Error: Avg loss: 5.588478 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:13.793368 Epoch 262, Training loss 5.420546054840088\n",
      "in params\n",
      "R2 values 0.5726, 0.5624, 0.5337; mean R2=0.5562\n",
      "Validation Error: Avg loss: 5.813478 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:14.094642 Epoch 263, Training loss 5.394784450531006\n",
      "in params\n",
      "R2 values 0.6464, 0.6488, 0.6911; mean R2=0.6621\n",
      "Validation Error: Avg loss: 4.626223 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:14.387713 Epoch 264, Training loss 4.420638084411621\n",
      "in params\n",
      "R2 values 0.6169, 0.5753, 0.6524; mean R2=0.6149\n",
      "Validation Error: Avg loss: 5.872076 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:14.685081 Epoch 265, Training loss 6.060544967651367\n",
      "in params\n",
      "R2 values 0.6015, 0.7788, 0.6034; mean R2=0.6612\n",
      "Validation Error: Avg loss: 4.521125 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:14.979815 Epoch 266, Training loss 5.721678733825684\n",
      "in params\n",
      "R2 values 0.6550, 0.7490, 0.6199; mean R2=0.6746\n",
      "Validation Error: Avg loss: 4.837933 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:15.271291 Epoch 267, Training loss 4.2788615226745605\n",
      "in params\n",
      "R2 values 0.6312, 0.7647, 0.7862; mean R2=0.7274\n",
      "Validation Error: Avg loss: 4.189925 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:15.573889 Epoch 268, Training loss 3.6119117736816406\n",
      "in params\n",
      "R2 values 0.4741, 0.7279, 0.5786; mean R2=0.5936\n",
      "Validation Error: Avg loss: 4.392837 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:15.872580 Epoch 269, Training loss 3.751800298690796\n",
      "in params\n",
      "R2 values 0.5224, 0.7505, 0.5336; mean R2=0.6022\n",
      "Validation Error: Avg loss: 4.318252 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:16.184712 Epoch 270, Training loss 4.440960884094238\n",
      "in params\n",
      "R2 values 0.4790, 0.8132, 0.6561; mean R2=0.6494\n",
      "Validation Error: Avg loss: 3.453334 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:16.481108 Epoch 271, Training loss 3.623303174972534\n",
      "in params\n",
      "R2 values 0.5216, 0.7529, 0.6050; mean R2=0.6265\n",
      "Validation Error: Avg loss: 4.082051 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:16.775797 Epoch 272, Training loss 4.77352237701416\n",
      "in params\n",
      "R2 values 0.4623, 0.7222, 0.6069; mean R2=0.5971\n",
      "Validation Error: Avg loss: 4.421589 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:17.062374 Epoch 273, Training loss 2.83609676361084\n",
      "in params\n",
      "R2 values 0.6159, 0.5446, 0.6067; mean R2=0.5891\n",
      "Validation Error: Avg loss: 5.693747 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:17.348592 Epoch 274, Training loss 4.834465980529785\n",
      "in params\n",
      "R2 values 0.5009, 0.7721, 0.5640; mean R2=0.6123\n",
      "Validation Error: Avg loss: 4.381227 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:17.645065 Epoch 275, Training loss 3.944162130355835\n",
      "in params\n",
      "R2 values 0.5289, 0.8031, 0.6174; mean R2=0.6498\n",
      "Validation Error: Avg loss: 3.743146 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:52:17.934071 Epoch 276, Training loss 4.437337875366211\n",
      "in params\n",
      "R2 values 0.5992, 0.7655, 0.6904; mean R2=0.6850\n",
      "Validation Error: Avg loss: 4.053355 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:18.224573 Epoch 277, Training loss 4.227051734924316\n",
      "in params\n",
      "R2 values 0.4343, 0.6892, 0.5631; mean R2=0.5622\n",
      "Validation Error: Avg loss: 5.178154 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:18.543225 Epoch 278, Training loss 4.844029426574707\n",
      "in params\n",
      "R2 values 0.4547, 0.7425, 0.5718; mean R2=0.5896\n",
      "Validation Error: Avg loss: 5.098037 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:18.835274 Epoch 279, Training loss 3.876154899597168\n",
      "in params\n",
      "R2 values 0.5600, 0.7010, 0.6842; mean R2=0.6484\n",
      "Validation Error: Avg loss: 4.137762 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:19.149073 Epoch 280, Training loss 4.087001800537109\n",
      "in params\n",
      "R2 values 0.6128, 0.8211, 0.7486; mean R2=0.7275\n",
      "Validation Error: Avg loss: 2.828347 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:19.445006 Epoch 281, Training loss 3.96374249458313\n",
      "in params\n",
      "R2 values 0.5748, 0.6598, 0.6480; mean R2=0.6275\n",
      "Validation Error: Avg loss: 4.694807 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:19.747177 Epoch 282, Training loss 3.984269618988037\n",
      "in params\n",
      "R2 values 0.5265, 0.7853, 0.5744; mean R2=0.6287\n",
      "Validation Error: Avg loss: 3.802669 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:20.059586 Epoch 283, Training loss 4.419796943664551\n",
      "in params\n",
      "R2 values 0.4901, 0.8291, 0.5889; mean R2=0.6360\n",
      "Validation Error: Avg loss: 3.928190 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:20.353559 Epoch 284, Training loss 4.040343284606934\n",
      "in params\n",
      "R2 values 0.5916, 0.6294, 0.5660; mean R2=0.5957\n",
      "Validation Error: Avg loss: 5.163720 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:20.653926 Epoch 285, Training loss 3.8074350357055664\n",
      "in params\n",
      "R2 values 0.5602, 0.6893, 0.7405; mean R2=0.6633\n",
      "Validation Error: Avg loss: 4.269300 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:20.950464 Epoch 286, Training loss 3.3083481788635254\n",
      "in params\n",
      "R2 values 0.6251, 0.8568, 0.7813; mean R2=0.7544\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2.634913 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:21.268275 Epoch 287, Training loss 4.822643280029297\n",
      "in params\n",
      "R2 values 0.3560, 0.4826, 0.5649; mean R2=0.4678\n",
      "Validation Error: Avg loss: 6.871438 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:21.563890 Epoch 288, Training loss 4.6850504875183105\n",
      "in params\n",
      "R2 values 0.6178, 0.8242, 0.6394; mean R2=0.6938\n",
      "Validation Error: Avg loss: 3.183451 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:21.873747 Epoch 289, Training loss 3.381826400756836\n",
      "in params\n",
      "R2 values 0.5480, 0.6942, 0.6735; mean R2=0.6386\n",
      "Validation Error: Avg loss: 4.216256 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:22.171977 Epoch 290, Training loss 4.088807106018066\n",
      "in params\n",
      "R2 values 0.6306, 0.7598, 0.7421; mean R2=0.7109\n",
      "Validation Error: Avg loss: 3.530758 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:22.463861 Epoch 291, Training loss 3.856858253479004\n",
      "in params\n",
      "R2 values 0.4610, 0.5547, 0.4531; mean R2=0.4896\n",
      "Validation Error: Avg loss: 6.317134 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:22.756275 Epoch 292, Training loss 4.558929443359375\n",
      "in params\n",
      "R2 values 0.5385, 0.6266, 0.6509; mean R2=0.6053\n",
      "Validation Error: Avg loss: 4.906277 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:23.054742 Epoch 293, Training loss 4.846926689147949\n",
      "in params\n",
      "R2 values 0.5829, 0.7883, 0.6415; mean R2=0.6709\n",
      "Validation Error: Avg loss: 3.861836 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:23.354754 Epoch 294, Training loss 3.299609661102295\n",
      "in params\n",
      "R2 values 0.7002, 0.7828, 0.7386; mean R2=0.7405\n",
      "Validation Error: Avg loss: 3.259817 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:23.655760 Epoch 295, Training loss 4.517096519470215\n",
      "in params\n",
      "R2 values 0.4851, 0.6284, 0.6369; mean R2=0.5834\n",
      "Validation Error: Avg loss: 5.138248 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:23.962464 Epoch 296, Training loss 5.258651256561279\n",
      "in params\n",
      "R2 values 0.5900, 0.6265, 0.6096; mean R2=0.6087\n",
      "Validation Error: Avg loss: 5.032755 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:24.282081 Epoch 297, Training loss 4.831324100494385\n",
      "in params\n",
      "R2 values 0.6116, 0.6981, 0.6023; mean R2=0.6374\n",
      "Validation Error: Avg loss: 4.433621 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:24.581933 Epoch 298, Training loss 3.612356662750244\n",
      "in params\n",
      "R2 values 0.6567, 0.8393, 0.7003; mean R2=0.7321\n",
      "Validation Error: Avg loss: 3.648633 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:24.886219 Epoch 299, Training loss 3.85368013381958\n",
      "in params\n",
      "R2 values 0.6123, 0.8678, 0.7494; mean R2=0.7432\n",
      "Validation Error: Avg loss: 2.666169 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:25.179942 Epoch 300, Training loss 3.993474006652832\n",
      "in params\n",
      "R2 values 0.5910, 0.6765, 0.7165; mean R2=0.6614\n",
      "Validation Error: Avg loss: 4.375921 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:25.475918 Epoch 301, Training loss 4.0497870445251465\n",
      "in params\n",
      "R2 values 0.6396, 0.5545, 0.6893; mean R2=0.6278\n",
      "Validation Error: Avg loss: 5.684817 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:25.775576 Epoch 302, Training loss 4.461705207824707\n",
      "in params\n",
      "R2 values 0.5286, 0.6316, 0.6470; mean R2=0.6024\n",
      "Validation Error: Avg loss: 4.858297 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:26.064412 Epoch 303, Training loss 4.601443290710449\n",
      "in params\n",
      "R2 values 0.5333, 0.7248, 0.5869; mean R2=0.6150\n",
      "Validation Error: Avg loss: 4.508366 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:26.362864 Epoch 304, Training loss 4.5765604972839355\n",
      "in params\n",
      "R2 values 0.6316, 0.7835, 0.6111; mean R2=0.6754\n",
      "Validation Error: Avg loss: 4.334013 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:26.662213 Epoch 305, Training loss 3.6725168228149414\n",
      "in params\n",
      "R2 values 0.4756, 0.7425, 0.6748; mean R2=0.6309\n",
      "Validation Error: Avg loss: 3.977561 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:26.967805 Epoch 306, Training loss 3.1435134410858154\n",
      "in params\n",
      "R2 values 0.5394, 0.8000, 0.5396; mean R2=0.6263\n",
      "Validation Error: Avg loss: 4.536535 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:27.281693 Epoch 307, Training loss 3.870882987976074\n",
      "in params\n",
      "R2 values 0.5560, 0.7372, 0.5071; mean R2=0.6001\n",
      "Validation Error: Avg loss: 4.689884 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:27.573765 Epoch 308, Training loss 4.539005756378174\n",
      "in params\n",
      "R2 values 0.5060, 0.6290, 0.5783; mean R2=0.5711\n",
      "Validation Error: Avg loss: 5.202364 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:27.866609 Epoch 309, Training loss 4.572452068328857\n",
      "in params\n",
      "R2 values 0.4940, 0.7340, 0.5055; mean R2=0.5778\n",
      "Validation Error: Avg loss: 4.599678 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:28.159298 Epoch 310, Training loss 4.408353805541992\n",
      "in params\n",
      "R2 values 0.5909, 0.6799, 0.5606; mean R2=0.6105\n",
      "Validation Error: Avg loss: 4.638762 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:28.455342 Epoch 311, Training loss 3.590831756591797\n",
      "in params\n",
      "R2 values 0.5266, 0.7543, 0.5611; mean R2=0.6140\n",
      "Validation Error: Avg loss: 4.054030 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:28.766976 Epoch 312, Training loss 4.512771129608154\n",
      "in params\n",
      "R2 values 0.6551, 0.7750, 0.6463; mean R2=0.6922\n",
      "Validation Error: Avg loss: 3.523285 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:29.060518 Epoch 313, Training loss 3.5625455379486084\n",
      "in params\n",
      "R2 values 0.5989, 0.7422, 0.6556; mean R2=0.6656\n",
      "Validation Error: Avg loss: 3.727571 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:29.366591 Epoch 314, Training loss 5.26390266418457\n",
      "in params\n",
      "R2 values 0.6629, 0.7541, 0.6162; mean R2=0.6778\n",
      "Validation Error: Avg loss: 3.727551 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:29.663857 Epoch 315, Training loss 4.295285701751709\n",
      "in params\n",
      "R2 values 0.5899, 0.7326, 0.5540; mean R2=0.6255\n",
      "Validation Error: Avg loss: 4.238915 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:29.963856 Epoch 316, Training loss 3.572967290878296\n",
      "in params\n",
      "R2 values 0.4636, 0.5605, 0.6060; mean R2=0.5434\n",
      "Validation Error: Avg loss: 5.982645 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:30.281616 Epoch 317, Training loss 4.073044300079346\n",
      "in params\n",
      "R2 values 0.5300, 0.5901, 0.7285; mean R2=0.6162\n",
      "Validation Error: Avg loss: 4.939726 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:30.577089 Epoch 318, Training loss 3.154695510864258\n",
      "in params\n",
      "R2 values 0.5211, 0.8150, 0.5834; mean R2=0.6398\n",
      "Validation Error: Avg loss: 3.619412 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:30.881688 Epoch 319, Training loss 3.3176798820495605\n",
      "in params\n",
      "R2 values 0.5304, 0.8203, 0.6116; mean R2=0.6541\n",
      "Validation Error: Avg loss: 3.409284 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:31.174392 Epoch 320, Training loss 3.4694113731384277\n",
      "in params\n",
      "R2 values 0.5407, 0.6939, 0.6826; mean R2=0.6391\n",
      "Validation Error: Avg loss: 4.598058 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:31.466556 Epoch 321, Training loss 3.766831874847412\n",
      "in params\n",
      "R2 values 0.6573, 0.8084, 0.5679; mean R2=0.6779\n",
      "Validation Error: Avg loss: 3.715282 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:52:31.760570 Epoch 322, Training loss 4.41778564453125\n",
      "in params\n",
      "R2 values 0.5451, 0.4994, 0.6002; mean R2=0.5483\n",
      "Validation Error: Avg loss: 6.613403 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:32.085481 Epoch 323, Training loss 4.583263397216797\n",
      "in params\n",
      "R2 values 0.6155, 0.7604, 0.6802; mean R2=0.6853\n",
      "Validation Error: Avg loss: 3.808732 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:32.379665 Epoch 324, Training loss 6.1214704513549805\n",
      "in params\n",
      "R2 values 0.6065, 0.7850, 0.6495; mean R2=0.6804\n",
      "Validation Error: Avg loss: 3.892762 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:32.670744 Epoch 325, Training loss 4.8430352210998535\n",
      "in params\n",
      "R2 values 0.5746, 0.7472, 0.6130; mean R2=0.6449\n",
      "Validation Error: Avg loss: 3.958113 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:32.967692 Epoch 326, Training loss 3.9730844497680664\n",
      "in params\n",
      "R2 values 0.6089, 0.7510, 0.7077; mean R2=0.6892\n",
      "Validation Error: Avg loss: 3.679580 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:33.260336 Epoch 327, Training loss 3.3873860836029053\n",
      "in params\n",
      "R2 values 0.5295, 0.7001, 0.6445; mean R2=0.6247\n",
      "Validation Error: Avg loss: 4.266017 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:33.554111 Epoch 328, Training loss 4.172512531280518\n",
      "in params\n",
      "R2 values 0.5881, 0.8305, 0.6600; mean R2=0.6929\n",
      "Validation Error: Avg loss: 2.987406 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:33.851493 Epoch 329, Training loss 4.542455196380615\n",
      "in params\n",
      "R2 values 0.5097, 0.7867, 0.6490; mean R2=0.6485\n",
      "Validation Error: Avg loss: 3.522331 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:34.145892 Epoch 330, Training loss 4.841960430145264\n",
      "in params\n",
      "R2 values 0.5471, 0.5153, 0.5321; mean R2=0.5315\n",
      "Validation Error: Avg loss: 6.241563 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:34.446162 Epoch 331, Training loss 3.5945801734924316\n",
      "in params\n",
      "R2 values 0.5868, 0.6822, 0.6633; mean R2=0.6441\n",
      "Validation Error: Avg loss: 4.456302 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:34.746052 Epoch 332, Training loss 3.586916446685791\n",
      "in params\n",
      "R2 values 0.6048, 0.7866, 0.5909; mean R2=0.6608\n",
      "Validation Error: Avg loss: 3.658386 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:35.063638 Epoch 333, Training loss 4.1571574211120605\n",
      "in params\n",
      "R2 values 0.5620, 0.6312, 0.5914; mean R2=0.5949\n",
      "Validation Error: Avg loss: 5.432979 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:35.365895 Epoch 334, Training loss 4.575048446655273\n",
      "in params\n",
      "R2 values 0.4919, 0.7549, 0.5696; mean R2=0.6055\n",
      "Validation Error: Avg loss: 4.282894 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:35.664640 Epoch 335, Training loss 4.382421493530273\n",
      "in params\n",
      "R2 values 0.7620, 0.7908, 0.6968; mean R2=0.7499\n",
      "Validation Error: Avg loss: 3.630312 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:35.953948 Epoch 336, Training loss 3.8294641971588135\n",
      "in params\n",
      "R2 values 0.5401, 0.5881, 0.4675; mean R2=0.5319\n",
      "Validation Error: Avg loss: 5.836221 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:36.251584 Epoch 337, Training loss 4.072206497192383\n",
      "in params\n",
      "R2 values 0.6352, 0.7517, 0.6260; mean R2=0.6710\n",
      "Validation Error: Avg loss: 3.764502 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:36.544124 Epoch 338, Training loss 4.361745357513428\n",
      "in params\n",
      "R2 values 0.5740, 0.6881, 0.6039; mean R2=0.6220\n",
      "Validation Error: Avg loss: 4.442970 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:36.842431 Epoch 339, Training loss 4.941866874694824\n",
      "in params\n",
      "R2 values 0.6092, 0.4535, 0.5576; mean R2=0.5401\n",
      "Validation Error: Avg loss: 6.598524 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:37.134009 Epoch 340, Training loss 4.378820896148682\n",
      "in params\n",
      "R2 values 0.5739, 0.6475, 0.5759; mean R2=0.5991\n",
      "Validation Error: Avg loss: 5.192034 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:37.428728 Epoch 341, Training loss 4.226881980895996\n",
      "in params\n",
      "R2 values 0.5764, 0.6173, 0.5933; mean R2=0.5957\n",
      "Validation Error: Avg loss: 5.100788 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:37.724427 Epoch 342, Training loss 3.2247700691223145\n",
      "in params\n",
      "R2 values 0.6743, 0.8655, 0.7233; mean R2=0.7544\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2.552686 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:38.041639 Epoch 343, Training loss 4.103936195373535\n",
      "in params\n",
      "R2 values 0.6621, 0.7290, 0.6870; mean R2=0.6927\n",
      "Validation Error: Avg loss: 3.724437 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:38.335933 Epoch 344, Training loss 4.468506336212158\n",
      "in params\n",
      "R2 values 0.5427, 0.5539, 0.5033; mean R2=0.5333\n",
      "Validation Error: Avg loss: 6.077321 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:38.673016 Epoch 345, Training loss 4.113705158233643\n",
      "in params\n",
      "R2 values 0.5122, 0.7918, 0.6440; mean R2=0.6493\n",
      "Validation Error: Avg loss: 3.552753 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:38.967952 Epoch 346, Training loss 3.6138851642608643\n",
      "in params\n",
      "R2 values 0.5626, 0.7428, 0.6198; mean R2=0.6417\n",
      "Validation Error: Avg loss: 4.438062 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:39.283892 Epoch 347, Training loss 3.614173650741577\n",
      "in params\n",
      "R2 values 0.5523, 0.8484, 0.7315; mean R2=0.7108\n",
      "Validation Error: Avg loss: 2.745799 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:39.587772 Epoch 348, Training loss 5.414238452911377\n",
      "in params\n",
      "R2 values 0.7003, 0.6498, 0.6347; mean R2=0.6616\n",
      "Validation Error: Avg loss: 4.702127 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:39.879521 Epoch 349, Training loss 3.801468849182129\n",
      "in params\n",
      "R2 values 0.6412, 0.8134, 0.6642; mean R2=0.7063\n",
      "Validation Error: Avg loss: 3.285697 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:40.181270 Epoch 350, Training loss 3.788881540298462\n",
      "in params\n",
      "R2 values 0.6759, 0.8696, 0.6403; mean R2=0.7286\n",
      "Validation Error: Avg loss: 2.877592 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:40.499438 Epoch 351, Training loss 4.189834117889404\n",
      "in params\n",
      "R2 values 0.5869, 0.4765, 0.7222; mean R2=0.5952\n",
      "Validation Error: Avg loss: 6.397083 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:40.798519 Epoch 352, Training loss 4.004571437835693\n",
      "in params\n",
      "R2 values 0.6589, 0.7551, 0.6616; mean R2=0.6919\n",
      "Validation Error: Avg loss: 3.940395 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:41.091750 Epoch 353, Training loss 5.03823184967041\n",
      "in params\n",
      "R2 values 0.6786, 0.8123, 0.7053; mean R2=0.7321\n",
      "Validation Error: Avg loss: 2.929358 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:41.384457 Epoch 354, Training loss 3.8875131607055664\n",
      "in params\n",
      "R2 values 0.6825, 0.7047, 0.6190; mean R2=0.6687\n",
      "Validation Error: Avg loss: 4.808401 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:41.682819 Epoch 355, Training loss 3.8667094707489014\n",
      "in params\n",
      "R2 values 0.5193, 0.7184, 0.5902; mean R2=0.6093\n",
      "Validation Error: Avg loss: 4.407088 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:41.976822 Epoch 356, Training loss 4.055662631988525\n",
      "in params\n",
      "R2 values 0.6503, 0.7211, 0.6387; mean R2=0.6700\n",
      "Validation Error: Avg loss: 4.443943 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:42.284842 Epoch 357, Training loss 4.4906535148620605\n",
      "in params\n",
      "R2 values 0.5214, 0.6356, 0.5309; mean R2=0.5626\n",
      "Validation Error: Avg loss: 5.311498 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:42.575457 Epoch 358, Training loss 2.6376869678497314\n",
      "in params\n",
      "R2 values 0.6164, 0.8344, 0.5902; mean R2=0.6803\n",
      "Validation Error: Avg loss: 3.692640 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:42.890003 Epoch 359, Training loss 3.4038121700286865\n",
      "in params\n",
      "R2 values 0.5341, 0.6381, 0.6477; mean R2=0.6066\n",
      "Validation Error: Avg loss: 5.163600 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:43.188254 Epoch 360, Training loss 3.976191759109497\n",
      "in params\n",
      "R2 values 0.5993, 0.8280, 0.6828; mean R2=0.7033\n",
      "Validation Error: Avg loss: 3.232746 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:43.477923 Epoch 361, Training loss 4.649805068969727\n",
      "in params\n",
      "R2 values 0.6837, 0.7850, 0.6403; mean R2=0.7030\n",
      "Validation Error: Avg loss: 3.386677 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:43.770006 Epoch 362, Training loss 4.081663131713867\n",
      "in params\n",
      "R2 values 0.6180, 0.7635, 0.6306; mean R2=0.6707\n",
      "Validation Error: Avg loss: 3.866885 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:44.069367 Epoch 363, Training loss 3.6426949501037598\n",
      "in params\n",
      "R2 values 0.6435, 0.6473, 0.6670; mean R2=0.6526\n",
      "Validation Error: Avg loss: 4.670242 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:44.369952 Epoch 364, Training loss 3.5060412883758545\n",
      "in params\n",
      "R2 values 0.6951, 0.7498, 0.7480; mean R2=0.7310\n",
      "Validation Error: Avg loss: 3.834775 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:44.666251 Epoch 365, Training loss 4.99832010269165\n",
      "in params\n",
      "R2 values 0.4779, 0.5551, 0.5619; mean R2=0.5316\n",
      "Validation Error: Avg loss: 6.087078 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:44.965653 Epoch 366, Training loss 3.8381876945495605\n",
      "in params\n",
      "R2 values 0.5674, 0.6152, 0.5851; mean R2=0.5892\n",
      "Validation Error: Avg loss: 5.537745 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:45.263047 Epoch 367, Training loss 4.5277533531188965\n",
      "in params\n",
      "R2 values 0.6421, 0.8340, 0.6332; mean R2=0.7031\n",
      "Validation Error: Avg loss: 3.099878 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:52:45.555984 Epoch 368, Training loss 3.5151307582855225\n",
      "in params\n",
      "R2 values 0.5394, 0.6033, 0.5983; mean R2=0.5803\n",
      "Validation Error: Avg loss: 5.230744 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:45.846596 Epoch 369, Training loss 4.215605735778809\n",
      "in params\n",
      "R2 values 0.6339, 0.7582, 0.6567; mean R2=0.6829\n",
      "Validation Error: Avg loss: 3.626477 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:46.139805 Epoch 370, Training loss 4.0009684562683105\n",
      "in params\n",
      "R2 values 0.5547, 0.7840, 0.6658; mean R2=0.6682\n",
      "Validation Error: Avg loss: 3.468198 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:46.434703 Epoch 371, Training loss 4.206570625305176\n",
      "in params\n",
      "R2 values 0.7232, 0.7825, 0.7943; mean R2=0.7666\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2.937788 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:46.760533 Epoch 372, Training loss 4.783071041107178\n",
      "in params\n",
      "R2 values 0.5395, 0.7276, 0.4828; mean R2=0.5833\n",
      "Validation Error: Avg loss: 4.650009 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:47.047123 Epoch 373, Training loss 3.5403738021850586\n",
      "in params\n",
      "R2 values 0.5798, 0.8355, 0.5983; mean R2=0.6712\n",
      "Validation Error: Avg loss: 3.755943 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:47.345477 Epoch 374, Training loss 4.005507946014404\n",
      "in params\n",
      "R2 values 0.5744, 0.7920, 0.6818; mean R2=0.6827\n",
      "Validation Error: Avg loss: 4.144387 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:47.639446 Epoch 375, Training loss 5.654385089874268\n",
      "in params\n",
      "R2 values 0.5834, 0.7753, 0.5800; mean R2=0.6462\n",
      "Validation Error: Avg loss: 4.297043 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:47.931672 Epoch 376, Training loss 3.8938987255096436\n",
      "in params\n",
      "R2 values 0.6059, 0.8143, 0.6612; mean R2=0.6938\n",
      "Validation Error: Avg loss: 3.690920 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:48.221169 Epoch 377, Training loss 3.64800763130188\n",
      "in params\n",
      "R2 values 0.5747, 0.5966, 0.6966; mean R2=0.6226\n",
      "Validation Error: Avg loss: 5.202500 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:48.525558 Epoch 378, Training loss 4.771926403045654\n",
      "in params\n",
      "R2 values 0.6568, 0.7541, 0.5932; mean R2=0.6680\n",
      "Validation Error: Avg loss: 4.224975 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:48.829704 Epoch 379, Training loss 3.943497657775879\n",
      "in params\n",
      "R2 values 0.6662, 0.8237, 0.6201; mean R2=0.7033\n",
      "Validation Error: Avg loss: 3.252620 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:49.122781 Epoch 380, Training loss 5.537265777587891\n",
      "in params\n",
      "R2 values 0.6106, 0.6244, 0.6229; mean R2=0.6193\n",
      "Validation Error: Avg loss: 5.049964 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:49.430583 Epoch 381, Training loss 4.567412853240967\n",
      "in params\n",
      "R2 values 0.5611, 0.7372, 0.6393; mean R2=0.6459\n",
      "Validation Error: Avg loss: 4.360855 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:49.730570 Epoch 382, Training loss 4.498144149780273\n",
      "in params\n",
      "R2 values 0.6679, 0.8907, 0.7285; mean R2=0.7624\n",
      "Validation Error: Avg loss: 2.457372 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:50.031585 Epoch 383, Training loss 3.6581296920776367\n",
      "in params\n",
      "R2 values 0.6178, 0.6854, 0.7207; mean R2=0.6747\n",
      "Validation Error: Avg loss: 4.425103 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:50.331702 Epoch 384, Training loss 4.953559875488281\n",
      "in params\n",
      "R2 values 0.5084, 0.6220, 0.6373; mean R2=0.5892\n",
      "Validation Error: Avg loss: 5.290547 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:50.625486 Epoch 385, Training loss 3.7127363681793213\n",
      "in params\n",
      "R2 values 0.6195, 0.6786, 0.6707; mean R2=0.6563\n",
      "Validation Error: Avg loss: 4.561955 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:50.922322 Epoch 386, Training loss 4.136041164398193\n",
      "in params\n",
      "R2 values 0.7311, 0.7732, 0.6755; mean R2=0.7266\n",
      "Validation Error: Avg loss: 3.388927 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:51.215011 Epoch 387, Training loss 3.721381425857544\n",
      "in params\n",
      "R2 values 0.5810, 0.6735, 0.6199; mean R2=0.6248\n",
      "Validation Error: Avg loss: 4.471013 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:51.504425 Epoch 388, Training loss 3.6047592163085938\n",
      "in params\n",
      "R2 values 0.6397, 0.7317, 0.6162; mean R2=0.6625\n",
      "Validation Error: Avg loss: 4.185966 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:51.801067 Epoch 389, Training loss 4.287868976593018\n",
      "in params\n",
      "R2 values 0.6643, 0.8477, 0.7421; mean R2=0.7514\n",
      "Validation Error: Avg loss: 2.812701 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:52.105661 Epoch 390, Training loss 4.094212055206299\n",
      "in params\n",
      "R2 values 0.6818, 0.6172, 0.6503; mean R2=0.6498\n",
      "Validation Error: Avg loss: 6.093149 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:52.394695 Epoch 391, Training loss 4.717883110046387\n",
      "in params\n",
      "R2 values 0.6239, 0.6532, 0.5855; mean R2=0.6209\n",
      "Validation Error: Avg loss: 4.947798 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:52.691671 Epoch 392, Training loss 3.471599817276001\n",
      "in params\n",
      "R2 values 0.6006, 0.7649, 0.6322; mean R2=0.6659\n",
      "Validation Error: Avg loss: 4.562346 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:52.988634 Epoch 393, Training loss 3.8876991271972656\n",
      "in params\n",
      "R2 values 0.6700, 0.7279, 0.6973; mean R2=0.6984\n",
      "Validation Error: Avg loss: 3.729667 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:53.279442 Epoch 394, Training loss 5.093051910400391\n",
      "in params\n",
      "R2 values 0.6956, 0.8041, 0.7160; mean R2=0.7386\n",
      "Validation Error: Avg loss: 3.036062 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:53.570592 Epoch 395, Training loss 3.1093547344207764\n",
      "in params\n",
      "R2 values 0.6054, 0.6863, 0.6762; mean R2=0.6560\n",
      "Validation Error: Avg loss: 4.145397 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:53.864226 Epoch 396, Training loss 3.9399826526641846\n",
      "in params\n",
      "R2 values 0.7235, 0.7500, 0.7514; mean R2=0.7416\n",
      "Validation Error: Avg loss: 3.469688 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:54.163854 Epoch 397, Training loss 4.599371910095215\n",
      "in params\n",
      "R2 values 0.6512, 0.7147, 0.5550; mean R2=0.6403\n",
      "Validation Error: Avg loss: 4.599830 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:54.457251 Epoch 398, Training loss 3.3612334728240967\n",
      "in params\n",
      "R2 values 0.5797, 0.5421, 0.5726; mean R2=0.5648\n",
      "Validation Error: Avg loss: 5.980556 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:54.749098 Epoch 399, Training loss 4.462142467498779\n",
      "in params\n",
      "R2 values 0.6989, 0.7170, 0.7559; mean R2=0.7239\n",
      "Validation Error: Avg loss: 3.684099 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:55.043528 Epoch 400, Training loss 3.949983596801758\n",
      "in params\n",
      "R2 values 0.6858, 0.7374, 0.6121; mean R2=0.6785\n",
      "Validation Error: Avg loss: 4.031336 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:55.332554 Epoch 401, Training loss 4.005462169647217\n",
      "in params\n",
      "R2 values 0.6340, 0.8068, 0.6482; mean R2=0.6964\n",
      "Validation Error: Avg loss: 3.489602 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:55.627736 Epoch 402, Training loss 3.1645050048828125\n",
      "in params\n",
      "R2 values 0.6910, 0.8016, 0.6706; mean R2=0.7211\n",
      "Validation Error: Avg loss: 3.252045 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:55.922365 Epoch 403, Training loss 4.6227593421936035\n",
      "in params\n",
      "R2 values 0.6357, 0.7686, 0.6635; mean R2=0.6893\n",
      "Validation Error: Avg loss: 3.639802 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:56.219480 Epoch 404, Training loss 4.609261989593506\n",
      "in params\n",
      "R2 values 0.6146, 0.7341, 0.6864; mean R2=0.6784\n",
      "Validation Error: Avg loss: 3.816510 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:56.510071 Epoch 405, Training loss 4.881450176239014\n",
      "in params\n",
      "R2 values 0.6839, 0.6563, 0.6973; mean R2=0.6792\n",
      "Validation Error: Avg loss: 5.193891 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:56.804295 Epoch 406, Training loss 3.9419634342193604\n",
      "in params\n",
      "R2 values 0.6573, 0.4364, 0.7544; mean R2=0.6161\n",
      "Validation Error: Avg loss: 6.643728 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:57.097041 Epoch 407, Training loss 4.5849995613098145\n",
      "in params\n",
      "R2 values 0.4737, 0.6394, 0.5140; mean R2=0.5424\n",
      "Validation Error: Avg loss: 5.654257 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:57.387999 Epoch 408, Training loss 3.6473324298858643\n",
      "in params\n",
      "R2 values 0.6123, 0.6129, 0.5713; mean R2=0.5988\n",
      "Validation Error: Avg loss: 5.839638 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:57.680328 Epoch 409, Training loss 3.874762773513794\n",
      "in params\n",
      "R2 values 0.5264, 0.7331, 0.5590; mean R2=0.6062\n",
      "Validation Error: Avg loss: 5.379241 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:57.978095 Epoch 410, Training loss 4.576362609863281\n",
      "in params\n",
      "R2 values 0.6994, 0.7265, 0.6862; mean R2=0.7040\n",
      "Validation Error: Avg loss: 3.850111 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:58.268616 Epoch 411, Training loss 3.1997408866882324\n",
      "in params\n",
      "R2 values 0.6385, 0.6332, 0.6755; mean R2=0.6491\n",
      "Validation Error: Avg loss: 4.922246 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:58.557408 Epoch 412, Training loss 3.2229115962982178\n",
      "in params\n",
      "R2 values 0.6843, 0.6277, 0.6426; mean R2=0.6515\n",
      "Validation Error: Avg loss: 4.797194 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:58.870894 Epoch 413, Training loss 4.4550347328186035\n",
      "in params\n",
      "R2 values 0.7603, 0.7850, 0.7870; mean R2=0.7774\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2.797840 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:52:59.193744 Epoch 414, Training loss 4.654078006744385\n",
      "in params\n",
      "R2 values 0.6272, 0.7973, 0.5565; mean R2=0.6604\n",
      "Validation Error: Avg loss: 3.694158 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:59.509924 Epoch 415, Training loss 3.9882795810699463\n",
      "in params\n",
      "R2 values 0.6087, 0.6264, 0.5594; mean R2=0.5982\n",
      "Validation Error: Avg loss: 6.110704 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:52:59.811384 Epoch 416, Training loss 3.916485548019409\n",
      "in params\n",
      "R2 values 0.6618, 0.7837, 0.7441; mean R2=0.7299\n",
      "Validation Error: Avg loss: 3.685162 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:00.117053 Epoch 417, Training loss 3.9284908771514893\n",
      "in params\n",
      "R2 values 0.6629, 0.6826, 0.6742; mean R2=0.6732\n",
      "Validation Error: Avg loss: 4.479320 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:00.502925 Epoch 418, Training loss 4.457095146179199\n",
      "in params\n",
      "R2 values 0.5344, 0.6651, 0.6199; mean R2=0.6064\n",
      "Validation Error: Avg loss: 5.243438 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:00.804062 Epoch 419, Training loss 4.198025226593018\n",
      "in params\n",
      "R2 values 0.5597, 0.6467, 0.6091; mean R2=0.6052\n",
      "Validation Error: Avg loss: 4.929797 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:01.095465 Epoch 420, Training loss 3.8582277297973633\n",
      "in params\n",
      "R2 values 0.4565, 0.6921, 0.6414; mean R2=0.5967\n",
      "Validation Error: Avg loss: 4.455458 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:01.421739 Epoch 421, Training loss 4.3425116539001465\n",
      "in params\n",
      "R2 values 0.5821, 0.8173, 0.6725; mean R2=0.6906\n",
      "Validation Error: Avg loss: 3.140124 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:01.721246 Epoch 422, Training loss 5.247563362121582\n",
      "in params\n",
      "R2 values 0.6271, 0.8107, 0.6392; mean R2=0.6923\n",
      "Validation Error: Avg loss: 3.222907 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:02.011369 Epoch 423, Training loss 4.51572847366333\n",
      "in params\n",
      "R2 values 0.5937, 0.6205, 0.5284; mean R2=0.5809\n",
      "Validation Error: Avg loss: 5.153463 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:02.304155 Epoch 424, Training loss 4.428946018218994\n",
      "in params\n",
      "R2 values 0.5781, 0.7331, 0.5958; mean R2=0.6357\n",
      "Validation Error: Avg loss: 4.502027 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:02.601703 Epoch 425, Training loss 4.417202949523926\n",
      "in params\n",
      "R2 values 0.6048, 0.6163, 0.5912; mean R2=0.6041\n",
      "Validation Error: Avg loss: 6.308710 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:02.901635 Epoch 426, Training loss 4.893837928771973\n",
      "in params\n",
      "R2 values 0.7279, 0.6423, 0.6450; mean R2=0.6717\n",
      "Validation Error: Avg loss: 6.435735 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:03.187862 Epoch 427, Training loss 3.021453857421875\n",
      "in params\n",
      "R2 values 0.6745, 0.8009, 0.6300; mean R2=0.7018\n",
      "Validation Error: Avg loss: 3.554581 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:03.480752 Epoch 428, Training loss 4.188241481781006\n",
      "in params\n",
      "R2 values 0.6024, 0.7963, 0.7071; mean R2=0.7019\n",
      "Validation Error: Avg loss: 3.490427 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:03.774967 Epoch 429, Training loss 4.34346342086792\n",
      "in params\n",
      "R2 values 0.6568, 0.8316, 0.6847; mean R2=0.7243\n",
      "Validation Error: Avg loss: 2.804468 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:04.072304 Epoch 430, Training loss 3.285383939743042\n",
      "in params\n",
      "R2 values 0.6858, 0.7336, 0.6767; mean R2=0.6987\n",
      "Validation Error: Avg loss: 3.691044 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:04.383005 Epoch 431, Training loss 4.690628528594971\n",
      "in params\n",
      "R2 values 0.6315, 0.7517, 0.5924; mean R2=0.6585\n",
      "Validation Error: Avg loss: 4.168510 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:04.706792 Epoch 432, Training loss 4.248929500579834\n",
      "in params\n",
      "R2 values 0.6337, 0.8259, 0.6439; mean R2=0.7012\n",
      "Validation Error: Avg loss: 3.308923 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:05.009487 Epoch 433, Training loss 3.739962577819824\n",
      "in params\n",
      "R2 values 0.6555, 0.8429, 0.6541; mean R2=0.7175\n",
      "Validation Error: Avg loss: 3.405891 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:05.308026 Epoch 434, Training loss 4.769476890563965\n",
      "in params\n",
      "R2 values 0.6369, 0.6690, 0.6025; mean R2=0.6361\n",
      "Validation Error: Avg loss: 5.901209 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:05.601797 Epoch 435, Training loss 5.221160411834717\n",
      "in params\n",
      "R2 values 0.6929, 0.7850, 0.6754; mean R2=0.7178\n",
      "Validation Error: Avg loss: 4.840988 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:05.906099 Epoch 436, Training loss 4.574514389038086\n",
      "in params\n",
      "R2 values 0.6478, 0.5952, 0.5711; mean R2=0.6047\n",
      "Validation Error: Avg loss: 5.623142 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:06.200849 Epoch 437, Training loss 4.281187057495117\n",
      "in params\n",
      "R2 values 0.6645, 0.7735, 0.6269; mean R2=0.6883\n",
      "Validation Error: Avg loss: 3.891734 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:06.494722 Epoch 438, Training loss 3.907151699066162\n",
      "in params\n",
      "R2 values 0.7014, 0.8145, 0.7244; mean R2=0.7468\n",
      "Validation Error: Avg loss: 2.835225 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:06.791153 Epoch 439, Training loss 5.07054328918457\n",
      "in params\n",
      "R2 values 0.7395, 0.6986, 0.6629; mean R2=0.7003\n",
      "Validation Error: Avg loss: 4.027790 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:07.108158 Epoch 440, Training loss 4.805439472198486\n",
      "in params\n",
      "R2 values 0.6511, 0.6748, 0.5766; mean R2=0.6342\n",
      "Validation Error: Avg loss: 4.636778 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:07.407378 Epoch 441, Training loss 4.092357635498047\n",
      "in params\n",
      "R2 values 0.7302, 0.7670, 0.6443; mean R2=0.7138\n",
      "Validation Error: Avg loss: 3.439556 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:07.701300 Epoch 442, Training loss 4.228688716888428\n",
      "in params\n",
      "R2 values 0.6524, 0.7384, 0.6140; mean R2=0.6683\n",
      "Validation Error: Avg loss: 4.173342 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:08.001826 Epoch 443, Training loss 3.7505943775177\n",
      "in params\n",
      "R2 values 0.6226, 0.4970, 0.6627; mean R2=0.5941\n",
      "Validation Error: Avg loss: 6.283408 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:08.290794 Epoch 444, Training loss 3.9942378997802734\n",
      "in params\n",
      "R2 values 0.7372, 0.7592, 0.5944; mean R2=0.6969\n",
      "Validation Error: Avg loss: 5.407245 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:08.580507 Epoch 445, Training loss 4.307369709014893\n",
      "in params\n",
      "R2 values 0.7577, 0.7407, 0.7377; mean R2=0.7454\n",
      "Validation Error: Avg loss: 3.411969 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:08.889256 Epoch 446, Training loss 4.254597187042236\n",
      "in params\n",
      "R2 values 0.6998, 0.7835, 0.7126; mean R2=0.7320\n",
      "Validation Error: Avg loss: 3.221903 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:09.184860 Epoch 447, Training loss 4.254016876220703\n",
      "in params\n",
      "R2 values 0.7335, 0.7483, 0.7701; mean R2=0.7507\n",
      "Validation Error: Avg loss: 3.512527 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:09.491531 Epoch 448, Training loss 3.8706047534942627\n",
      "in params\n",
      "R2 values 0.6497, 0.7025, 0.5838; mean R2=0.6453\n",
      "Validation Error: Avg loss: 4.287014 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:09.786941 Epoch 449, Training loss 3.383816719055176\n",
      "in params\n",
      "R2 values 0.6924, 0.7184, 0.6128; mean R2=0.6745\n",
      "Validation Error: Avg loss: 3.987728 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:10.080733 Epoch 450, Training loss 3.9471435546875\n",
      "in params\n",
      "R2 values 0.6545, 0.7398, 0.6011; mean R2=0.6651\n",
      "Validation Error: Avg loss: 4.353213 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:10.373493 Epoch 451, Training loss 3.334214210510254\n",
      "in params\n",
      "R2 values 0.5641, 0.8025, 0.5790; mean R2=0.6485\n",
      "Validation Error: Avg loss: 3.603125 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:10.672542 Epoch 452, Training loss 4.362915992736816\n",
      "in params\n",
      "R2 values 0.7247, 0.7500, 0.6781; mean R2=0.7176\n",
      "Validation Error: Avg loss: 4.451368 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:10.968886 Epoch 453, Training loss 3.6216835975646973\n",
      "in params\n",
      "R2 values 0.7055, 0.8412, 0.6412; mean R2=0.7293\n",
      "Validation Error: Avg loss: 3.749135 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:11.259899 Epoch 454, Training loss 3.6797406673431396\n",
      "in params\n",
      "R2 values 0.7593, 0.7766, 0.7506; mean R2=0.7622\n",
      "Validation Error: Avg loss: 3.744540 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:11.555156 Epoch 455, Training loss 3.5854694843292236\n",
      "in params\n",
      "R2 values 0.6894, 0.5239, 0.5938; mean R2=0.6023\n",
      "Validation Error: Avg loss: 6.366111 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:11.853558 Epoch 456, Training loss 3.696946620941162\n",
      "in params\n",
      "R2 values 0.5948, 0.5838, 0.6022; mean R2=0.5936\n",
      "Validation Error: Avg loss: 5.854750 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:12.139878 Epoch 457, Training loss 2.966187000274658\n",
      "in params\n",
      "R2 values 0.7482, 0.7155, 0.7400; mean R2=0.7346\n",
      "Validation Error: Avg loss: 3.651745 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:12.430937 Epoch 458, Training loss 3.661456346511841\n",
      "in params\n",
      "R2 values 0.6736, 0.7680, 0.7017; mean R2=0.7144\n",
      "Validation Error: Avg loss: 3.375331 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:12.735312 Epoch 459, Training loss 3.622897148132324\n",
      "in params\n",
      "R2 values 0.6503, 0.7525, 0.6343; mean R2=0.6790\n",
      "Validation Error: Avg loss: 3.751330 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:13.060454 Epoch 460, Training loss 3.652273654937744\n",
      "in params\n",
      "R2 values 0.6222, 0.5887, 0.6047; mean R2=0.6052\n",
      "Validation Error: Avg loss: 5.456361 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:53:13.352016 Epoch 461, Training loss 3.8894293308258057\n",
      "in params\n",
      "R2 values 0.6674, 0.5438, 0.5849; mean R2=0.5987\n",
      "Validation Error: Avg loss: 6.658955 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:13.646948 Epoch 462, Training loss 3.623384475708008\n",
      "in params\n",
      "R2 values 0.5873, 0.6145, 0.5845; mean R2=0.5954\n",
      "Validation Error: Avg loss: 6.057417 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:13.944903 Epoch 463, Training loss 4.205002307891846\n",
      "in params\n",
      "R2 values 0.6553, 0.7399, 0.6494; mean R2=0.6815\n",
      "Validation Error: Avg loss: 4.862057 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:14.235421 Epoch 464, Training loss 3.6882758140563965\n",
      "in params\n",
      "R2 values 0.7161, 0.6714, 0.6371; mean R2=0.6749\n",
      "Validation Error: Avg loss: 4.720768 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:14.539202 Epoch 465, Training loss 4.0733208656311035\n",
      "in params\n",
      "R2 values 0.6402, 0.7445, 0.5949; mean R2=0.6599\n",
      "Validation Error: Avg loss: 3.996416 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:14.840033 Epoch 466, Training loss 3.6980063915252686\n",
      "in params\n",
      "R2 values 0.6734, 0.8515, 0.6947; mean R2=0.7399\n",
      "Validation Error: Avg loss: 2.631965 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:15.134531 Epoch 467, Training loss 3.7495691776275635\n",
      "in params\n",
      "R2 values 0.8348, 0.8848, 0.7566; mean R2=0.8254\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2.143976 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:15.444110 Epoch 468, Training loss 3.1786551475524902\n",
      "in params\n",
      "R2 values 0.6805, 0.7350, 0.7137; mean R2=0.7097\n",
      "Validation Error: Avg loss: 3.999241 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:15.731924 Epoch 469, Training loss 3.4090657234191895\n",
      "in params\n",
      "R2 values 0.6559, 0.7581, 0.6624; mean R2=0.6921\n",
      "Validation Error: Avg loss: 3.638592 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:16.026886 Epoch 470, Training loss 3.910149335861206\n",
      "in params\n",
      "R2 values 0.5324, 0.5181, 0.5228; mean R2=0.5245\n",
      "Validation Error: Avg loss: 6.322820 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:16.302845 Epoch 471, Training loss 3.897732973098755\n",
      "in params\n",
      "R2 values 0.7230, 0.8295, 0.6548; mean R2=0.7358\n",
      "Validation Error: Avg loss: 3.001347 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:16.586923 Epoch 472, Training loss 3.6886065006256104\n",
      "in params\n",
      "R2 values 0.6697, 0.8321, 0.6925; mean R2=0.7314\n",
      "Validation Error: Avg loss: 3.260155 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:16.885076 Epoch 473, Training loss 3.2722208499908447\n",
      "in params\n",
      "R2 values 0.6895, 0.6901, 0.6610; mean R2=0.6802\n",
      "Validation Error: Avg loss: 4.834535 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:17.163154 Epoch 474, Training loss 4.601999282836914\n",
      "in params\n",
      "R2 values 0.7345, 0.7146, 0.7209; mean R2=0.7234\n",
      "Validation Error: Avg loss: 3.746073 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:17.447134 Epoch 475, Training loss 4.327293872833252\n",
      "in params\n",
      "R2 values 0.7190, 0.6652, 0.6858; mean R2=0.6900\n",
      "Validation Error: Avg loss: 4.387131 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:17.729946 Epoch 476, Training loss 4.09165096282959\n",
      "in params\n",
      "R2 values 0.7515, 0.6706, 0.6324; mean R2=0.6848\n",
      "Validation Error: Avg loss: 4.473635 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:18.013439 Epoch 477, Training loss 3.56642746925354\n",
      "in params\n",
      "R2 values 0.6740, 0.6913, 0.7254; mean R2=0.6969\n",
      "Validation Error: Avg loss: 4.068022 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:18.291044 Epoch 478, Training loss 2.6378016471862793\n",
      "in params\n",
      "R2 values 0.6428, 0.7696, 0.6690; mean R2=0.6938\n",
      "Validation Error: Avg loss: 3.798741 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:18.574933 Epoch 479, Training loss 4.561562538146973\n",
      "in params\n",
      "R2 values 0.6392, 0.7555, 0.6125; mean R2=0.6691\n",
      "Validation Error: Avg loss: 3.859845 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:18.857808 Epoch 480, Training loss 3.5929431915283203\n",
      "in params\n",
      "R2 values 0.6776, 0.4721, 0.6058; mean R2=0.5852\n",
      "Validation Error: Avg loss: 6.242675 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:19.159350 Epoch 481, Training loss 3.9234726428985596\n",
      "in params\n",
      "R2 values 0.5561, 0.5987, 0.6004; mean R2=0.5851\n",
      "Validation Error: Avg loss: 5.303753 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:19.448240 Epoch 482, Training loss 2.7007341384887695\n",
      "in params\n",
      "R2 values 0.6423, 0.6743, 0.5599; mean R2=0.6255\n",
      "Validation Error: Avg loss: 4.559269 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:19.743948 Epoch 483, Training loss 4.347419738769531\n",
      "in params\n",
      "R2 values 0.6632, 0.7173, 0.6851; mean R2=0.6886\n",
      "Validation Error: Avg loss: 3.887602 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:20.028091 Epoch 484, Training loss 3.9173355102539062\n",
      "in params\n",
      "R2 values 0.7361, 0.7235, 0.6262; mean R2=0.6953\n",
      "Validation Error: Avg loss: 3.806487 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:20.309418 Epoch 485, Training loss 3.7882542610168457\n",
      "in params\n",
      "R2 values 0.7695, 0.6838, 0.7868; mean R2=0.7467\n",
      "Validation Error: Avg loss: 4.023672 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:20.590915 Epoch 486, Training loss 4.2413330078125\n",
      "in params\n",
      "R2 values 0.7449, 0.6630, 0.6641; mean R2=0.6907\n",
      "Validation Error: Avg loss: 4.359964 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:20.883447 Epoch 487, Training loss 5.465222358703613\n",
      "in params\n",
      "R2 values 0.5851, 0.6140, 0.5821; mean R2=0.5937\n",
      "Validation Error: Avg loss: 5.356042 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:21.163052 Epoch 488, Training loss 3.5977792739868164\n",
      "in params\n",
      "R2 values 0.6307, 0.7988, 0.5888; mean R2=0.6728\n",
      "Validation Error: Avg loss: 4.018734 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:21.445201 Epoch 489, Training loss 3.2988760471343994\n",
      "in params\n",
      "R2 values 0.6201, 0.5861, 0.6095; mean R2=0.6053\n",
      "Validation Error: Avg loss: 6.389956 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:21.737266 Epoch 490, Training loss 4.238103866577148\n",
      "in params\n",
      "R2 values 0.6692, 0.5508, 0.5810; mean R2=0.6003\n",
      "Validation Error: Avg loss: 6.867235 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:22.015426 Epoch 491, Training loss 4.035344123840332\n",
      "in params\n",
      "R2 values 0.6364, 0.6757, 0.5862; mean R2=0.6328\n",
      "Validation Error: Avg loss: 5.814388 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:22.295688 Epoch 492, Training loss 4.002634525299072\n",
      "in params\n",
      "R2 values 0.6426, 0.5354, 0.6286; mean R2=0.6022\n",
      "Validation Error: Avg loss: 5.774720 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:22.599486 Epoch 493, Training loss 3.8655309677124023\n",
      "in params\n",
      "R2 values 0.5958, 0.5934, 0.5476; mean R2=0.5789\n",
      "Validation Error: Avg loss: 5.690094 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:22.879349 Epoch 494, Training loss 4.426022052764893\n",
      "in params\n",
      "R2 values 0.6928, 0.7693, 0.6835; mean R2=0.7152\n",
      "Validation Error: Avg loss: 3.451250 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:23.160388 Epoch 495, Training loss 3.3435494899749756\n",
      "in params\n",
      "R2 values 0.6404, 0.7954, 0.6404; mean R2=0.6921\n",
      "Validation Error: Avg loss: 3.542148 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:23.448975 Epoch 496, Training loss 4.026754379272461\n",
      "in params\n",
      "R2 values 0.6910, 0.6802, 0.6274; mean R2=0.6662\n",
      "Validation Error: Avg loss: 4.306968 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:23.758568 Epoch 497, Training loss 4.216668128967285\n",
      "in params\n",
      "R2 values 0.6162, 0.7255, 0.6734; mean R2=0.6717\n",
      "Validation Error: Avg loss: 3.806474 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:24.054496 Epoch 498, Training loss 3.324378490447998\n",
      "in params\n",
      "R2 values 0.6730, 0.7856, 0.5523; mean R2=0.6703\n",
      "Validation Error: Avg loss: 3.702756 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:24.332783 Epoch 499, Training loss 3.9883553981781006\n",
      "in params\n",
      "R2 values 0.7459, 0.7400, 0.7202; mean R2=0.7354\n",
      "Validation Error: Avg loss: 3.790864 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:24.616774 Epoch 500, Training loss 3.7339630126953125\n",
      "in params\n",
      "R2 values 0.7098, 0.7286, 0.7619; mean R2=0.7334\n",
      "Validation Error: Avg loss: 4.554914 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:24.901791 Epoch 501, Training loss 3.8686587810516357\n",
      "in params\n",
      "R2 values 0.6816, 0.8303, 0.7051; mean R2=0.7390\n",
      "Validation Error: Avg loss: 3.156039 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:25.189903 Epoch 502, Training loss 3.3500237464904785\n",
      "in params\n",
      "R2 values 0.7170, 0.8227, 0.6475; mean R2=0.7291\n",
      "Validation Error: Avg loss: 4.249437 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:25.474878 Epoch 503, Training loss 3.7673964500427246\n",
      "in params\n",
      "R2 values 0.6683, 0.6301, 0.6098; mean R2=0.6361\n",
      "Validation Error: Avg loss: 5.226160 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:25.760500 Epoch 504, Training loss 4.137801647186279\n",
      "in params\n",
      "R2 values 0.6224, 0.7191, 0.5758; mean R2=0.6391\n",
      "Validation Error: Avg loss: 4.535882 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:26.053521 Epoch 505, Training loss 4.2132768630981445\n",
      "in params\n",
      "R2 values 0.7303, 0.7024, 0.6835; mean R2=0.7054\n",
      "Validation Error: Avg loss: 4.045521 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:26.337944 Epoch 506, Training loss 4.315271377563477\n",
      "in params\n",
      "R2 values 0.7451, 0.7847, 0.6384; mean R2=0.7227\n",
      "Validation Error: Avg loss: 3.419467 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:53:26.623413 Epoch 507, Training loss 4.110229969024658\n",
      "in params\n",
      "R2 values 0.6181, 0.8117, 0.7026; mean R2=0.7108\n",
      "Validation Error: Avg loss: 3.042340 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:26.915860 Epoch 508, Training loss 2.759922981262207\n",
      "in params\n",
      "R2 values 0.7270, 0.6954, 0.6359; mean R2=0.6861\n",
      "Validation Error: Avg loss: 4.141195 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:27.191280 Epoch 509, Training loss 4.451972961425781\n",
      "in params\n",
      "R2 values 0.7530, 0.6340, 0.6161; mean R2=0.6677\n",
      "Validation Error: Avg loss: 4.931024 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:27.479840 Epoch 510, Training loss 3.9274837970733643\n",
      "in params\n",
      "R2 values 0.7000, 0.7314, 0.6447; mean R2=0.6921\n",
      "Validation Error: Avg loss: 4.412300 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:27.762428 Epoch 511, Training loss 4.76828670501709\n",
      "in params\n",
      "R2 values 0.6754, 0.7149, 0.6016; mean R2=0.6639\n",
      "Validation Error: Avg loss: 4.258561 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:28.041026 Epoch 512, Training loss 3.4389102458953857\n",
      "in params\n",
      "R2 values 0.7780, 0.7479, 0.7163; mean R2=0.7474\n",
      "Validation Error: Avg loss: 3.805799 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:28.320142 Epoch 513, Training loss 5.227387428283691\n",
      "in params\n",
      "R2 values 0.6840, 0.7223, 0.6065; mean R2=0.6709\n",
      "Validation Error: Avg loss: 4.692074 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:28.603340 Epoch 514, Training loss 4.058629989624023\n",
      "in params\n",
      "R2 values 0.7589, 0.5677, 0.6732; mean R2=0.6666\n",
      "Validation Error: Avg loss: 5.174972 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:28.898382 Epoch 515, Training loss 4.219263076782227\n",
      "in params\n",
      "R2 values 0.7723, 0.6804, 0.5623; mean R2=0.6717\n",
      "Validation Error: Avg loss: 4.391518 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:29.199804 Epoch 516, Training loss 3.922858238220215\n",
      "in params\n",
      "R2 values 0.7403, 0.7834, 0.6804; mean R2=0.7347\n",
      "Validation Error: Avg loss: 3.260689 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:29.491461 Epoch 517, Training loss 4.003021240234375\n",
      "in params\n",
      "R2 values 0.7656, 0.8488, 0.6624; mean R2=0.7590\n",
      "Validation Error: Avg loss: 2.705762 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:29.789104 Epoch 518, Training loss 3.4704337120056152\n",
      "in params\n",
      "R2 values 0.6537, 0.7529, 0.6705; mean R2=0.6924\n",
      "Validation Error: Avg loss: 3.680781 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:30.080615 Epoch 519, Training loss 4.190517902374268\n",
      "in params\n",
      "R2 values 0.6430, 0.8405, 0.5987; mean R2=0.6940\n",
      "Validation Error: Avg loss: 3.191696 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:30.364679 Epoch 520, Training loss 3.046420097351074\n",
      "in params\n",
      "R2 values 0.6984, 0.7565, 0.6194; mean R2=0.6915\n",
      "Validation Error: Avg loss: 4.068869 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:30.647740 Epoch 521, Training loss 5.226417541503906\n",
      "in params\n",
      "R2 values 0.6837, 0.7593, 0.5480; mean R2=0.6637\n",
      "Validation Error: Avg loss: 4.058160 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:30.931030 Epoch 522, Training loss 3.8074960708618164\n",
      "in params\n",
      "R2 values 0.6259, 0.6415, 0.6134; mean R2=0.6269\n",
      "Validation Error: Avg loss: 4.907270 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:31.218631 Epoch 523, Training loss 5.194011211395264\n",
      "in params\n",
      "R2 values 0.7593, 0.6906, 0.7416; mean R2=0.7305\n",
      "Validation Error: Avg loss: 4.479403 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:31.505164 Epoch 524, Training loss 3.164499521255493\n",
      "in params\n",
      "R2 values 0.6012, 0.7915, 0.5954; mean R2=0.6627\n",
      "Validation Error: Avg loss: 3.886567 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:31.794251 Epoch 525, Training loss 3.6215322017669678\n",
      "in params\n",
      "R2 values 0.7455, 0.7915, 0.6915; mean R2=0.7428\n",
      "Validation Error: Avg loss: 3.254560 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:32.114436 Epoch 526, Training loss 3.5999295711517334\n",
      "in params\n",
      "R2 values 0.7763, 0.7281, 0.6395; mean R2=0.7146\n",
      "Validation Error: Avg loss: 3.872122 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:32.394368 Epoch 527, Training loss 3.9716784954071045\n",
      "in params\n",
      "R2 values 0.6252, 0.8162, 0.6188; mean R2=0.6867\n",
      "Validation Error: Avg loss: 3.456649 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:32.678454 Epoch 528, Training loss 3.8287434577941895\n",
      "in params\n",
      "R2 values 0.7317, 0.7131, 0.6308; mean R2=0.6919\n",
      "Validation Error: Avg loss: 4.165499 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:32.970485 Epoch 529, Training loss 3.1046910285949707\n",
      "in params\n",
      "R2 values 0.7490, 0.7061, 0.6908; mean R2=0.7153\n",
      "Validation Error: Avg loss: 4.261808 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:33.265824 Epoch 530, Training loss 4.460047721862793\n",
      "in params\n",
      "R2 values 0.7157, 0.6437, 0.7141; mean R2=0.6912\n",
      "Validation Error: Avg loss: 4.657163 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:33.544631 Epoch 531, Training loss 3.93001127243042\n",
      "in params\n",
      "R2 values 0.7905, 0.6928, 0.7110; mean R2=0.7314\n",
      "Validation Error: Avg loss: 4.674512 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:33.832192 Epoch 532, Training loss 3.5408518314361572\n",
      "in params\n",
      "R2 values 0.7151, 0.7654, 0.6578; mean R2=0.7128\n",
      "Validation Error: Avg loss: 4.556449 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:34.115813 Epoch 533, Training loss 4.029775619506836\n",
      "in params\n",
      "R2 values 0.7196, 0.5766, 0.7214; mean R2=0.6725\n",
      "Validation Error: Avg loss: 5.648145 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:34.399398 Epoch 534, Training loss 4.896231174468994\n",
      "in params\n",
      "R2 values 0.7294, 0.7269, 0.7057; mean R2=0.7207\n",
      "Validation Error: Avg loss: 3.794265 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:34.682060 Epoch 535, Training loss 3.361391067504883\n",
      "in params\n",
      "R2 values 0.7198, 0.7402, 0.7617; mean R2=0.7406\n",
      "Validation Error: Avg loss: 3.320582 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:34.985029 Epoch 536, Training loss 3.0833351612091064\n",
      "in params\n",
      "R2 values 0.7391, 0.7480, 0.6924; mean R2=0.7265\n",
      "Validation Error: Avg loss: 3.491134 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:35.261139 Epoch 537, Training loss 4.018174648284912\n",
      "in params\n",
      "R2 values 0.6806, 0.6987, 0.7997; mean R2=0.7263\n",
      "Validation Error: Avg loss: 3.593551 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:35.537432 Epoch 538, Training loss 4.393677234649658\n",
      "in params\n",
      "R2 values 0.6947, 0.7377, 0.8065; mean R2=0.7463\n",
      "Validation Error: Avg loss: 3.217074 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:35.828469 Epoch 539, Training loss 4.478616237640381\n",
      "in params\n",
      "R2 values 0.7672, 0.6596, 0.7180; mean R2=0.7149\n",
      "Validation Error: Avg loss: 4.649387 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:36.107384 Epoch 540, Training loss 3.5974667072296143\n",
      "in params\n",
      "R2 values 0.7638, 0.8251, 0.7225; mean R2=0.7704\n",
      "Validation Error: Avg loss: 2.876023 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:36.388695 Epoch 541, Training loss 4.029367923736572\n",
      "in params\n",
      "R2 values 0.7066, 0.7107, 0.6719; mean R2=0.6964\n",
      "Validation Error: Avg loss: 4.926678 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:36.676914 Epoch 542, Training loss 4.1983208656311035\n",
      "in params\n",
      "R2 values 0.8155, 0.6909, 0.8062; mean R2=0.7709\n",
      "Validation Error: Avg loss: 4.514179 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:36.956267 Epoch 543, Training loss 3.9934804439544678\n",
      "in params\n",
      "R2 values 0.6586, 0.7482, 0.7337; mean R2=0.7135\n",
      "Validation Error: Avg loss: 3.945166 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:37.233526 Epoch 544, Training loss 4.123602867126465\n",
      "in params\n",
      "R2 values 0.6665, 0.6580, 0.6679; mean R2=0.6641\n",
      "Validation Error: Avg loss: 4.454480 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:37.515421 Epoch 545, Training loss 4.096482276916504\n",
      "in params\n",
      "R2 values 0.7446, 0.6507, 0.6708; mean R2=0.6887\n",
      "Validation Error: Avg loss: 4.453123 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:37.800949 Epoch 546, Training loss 4.67047119140625\n",
      "in params\n",
      "R2 values 0.7005, 0.7003, 0.6775; mean R2=0.6927\n",
      "Validation Error: Avg loss: 3.907735 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:38.082290 Epoch 547, Training loss 4.437272548675537\n",
      "in params\n",
      "R2 values 0.6713, 0.8132, 0.5513; mean R2=0.6786\n",
      "Validation Error: Avg loss: 3.396801 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:38.362523 Epoch 548, Training loss 3.2717156410217285\n",
      "in params\n",
      "R2 values 0.6224, 0.8315, 0.6146; mean R2=0.6895\n",
      "Validation Error: Avg loss: 3.265080 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:38.646137 Epoch 549, Training loss 3.4510059356689453\n",
      "in params\n",
      "R2 values 0.7337, 0.7458, 0.7121; mean R2=0.7305\n",
      "Validation Error: Avg loss: 3.815173 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:38.928082 Epoch 550, Training loss 4.263495922088623\n",
      "in params\n",
      "R2 values 0.7299, 0.6032, 0.6405; mean R2=0.6579\n",
      "Validation Error: Avg loss: 5.531110 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:39.229664 Epoch 551, Training loss 3.8940625190734863\n",
      "in params\n",
      "R2 values 0.6565, 0.7379, 0.6243; mean R2=0.6729\n",
      "Validation Error: Avg loss: 4.143347 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:39.513647 Epoch 552, Training loss 3.1800715923309326\n",
      "in params\n",
      "R2 values 0.6956, 0.6655, 0.7254; mean R2=0.6955\n",
      "Validation Error: Avg loss: 4.786909 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:53:39.818446 Epoch 553, Training loss 3.8698813915252686\n",
      "in params\n",
      "R2 values 0.7420, 0.7692, 0.5826; mean R2=0.6980\n",
      "Validation Error: Avg loss: 3.960663 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:40.117255 Epoch 554, Training loss 3.995671272277832\n",
      "in params\n",
      "R2 values 0.5057, 0.3612, 0.5574; mean R2=0.4748\n",
      "Validation Error: Avg loss: 7.632812 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:40.397533 Epoch 555, Training loss 4.527331352233887\n",
      "in params\n",
      "R2 values 0.6865, 0.6276, 0.6569; mean R2=0.6570\n",
      "Validation Error: Avg loss: 4.701545 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:40.690045 Epoch 556, Training loss 4.310677528381348\n",
      "in params\n",
      "R2 values 0.7394, 0.7726, 0.7966; mean R2=0.7695\n",
      "Validation Error: Avg loss: 2.952719 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:40.987300 Epoch 557, Training loss 3.172956943511963\n",
      "in params\n",
      "R2 values 0.6508, 0.5978, 0.6452; mean R2=0.6313\n",
      "Validation Error: Avg loss: 5.484894 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:41.278534 Epoch 558, Training loss 4.505745887756348\n",
      "in params\n",
      "R2 values 0.6947, 0.6785, 0.7485; mean R2=0.7072\n",
      "Validation Error: Avg loss: 3.983350 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:41.556112 Epoch 559, Training loss 3.9577221870422363\n",
      "in params\n",
      "R2 values 0.8113, 0.7801, 0.7225; mean R2=0.7713\n",
      "Validation Error: Avg loss: 3.980453 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:41.836798 Epoch 560, Training loss 3.9334940910339355\n",
      "in params\n",
      "R2 values 0.6186, 0.6923, 0.6066; mean R2=0.6392\n",
      "Validation Error: Avg loss: 4.403218 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:42.119958 Epoch 561, Training loss 4.523988246917725\n",
      "in params\n",
      "R2 values 0.6709, 0.7959, 0.7123; mean R2=0.7264\n",
      "Validation Error: Avg loss: 3.015632 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:42.401951 Epoch 562, Training loss 3.17471981048584\n",
      "in params\n",
      "R2 values 0.6851, 0.7788, 0.6328; mean R2=0.6989\n",
      "Validation Error: Avg loss: 3.453456 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:42.680903 Epoch 563, Training loss 3.800569772720337\n",
      "in params\n",
      "R2 values 0.6737, 0.7934, 0.6757; mean R2=0.7142\n",
      "Validation Error: Avg loss: 3.177019 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:42.958984 Epoch 564, Training loss 4.034770965576172\n",
      "in params\n",
      "R2 values 0.6877, 0.6275, 0.5659; mean R2=0.6270\n",
      "Validation Error: Avg loss: 5.094087 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:43.241648 Epoch 565, Training loss 3.2210426330566406\n",
      "in params\n",
      "R2 values 0.6498, 0.8365, 0.6972; mean R2=0.7278\n",
      "Validation Error: Avg loss: 2.946519 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:43.526693 Epoch 566, Training loss 3.458202362060547\n",
      "in params\n",
      "R2 values 0.7560, 0.7975, 0.7584; mean R2=0.7706\n",
      "Validation Error: Avg loss: 2.996356 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:43.817904 Epoch 567, Training loss 4.049189567565918\n",
      "in params\n",
      "R2 values 0.6738, 0.8502, 0.7223; mean R2=0.7488\n",
      "Validation Error: Avg loss: 2.661998 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:44.109001 Epoch 568, Training loss 3.3814926147460938\n",
      "in params\n",
      "R2 values 0.7230, 0.6945, 0.6869; mean R2=0.7015\n",
      "Validation Error: Avg loss: 3.965060 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:44.392729 Epoch 569, Training loss 4.200700283050537\n",
      "in params\n",
      "R2 values 0.7091, 0.6921, 0.6675; mean R2=0.6896\n",
      "Validation Error: Avg loss: 4.119151 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:44.681341 Epoch 570, Training loss 3.451364755630493\n",
      "in params\n",
      "R2 values 0.6644, 0.6267, 0.7117; mean R2=0.6676\n",
      "Validation Error: Avg loss: 4.619294 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:44.978513 Epoch 571, Training loss 3.6130900382995605\n",
      "in params\n",
      "R2 values 0.6665, 0.6637, 0.6170; mean R2=0.6491\n",
      "Validation Error: Avg loss: 4.666437 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:45.273641 Epoch 572, Training loss 3.2121596336364746\n",
      "in params\n",
      "R2 values 0.7145, 0.6874, 0.7329; mean R2=0.7116\n",
      "Validation Error: Avg loss: 3.927579 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:45.558649 Epoch 573, Training loss 3.781735897064209\n",
      "in params\n",
      "R2 values 0.8503, 0.6661, 0.7075; mean R2=0.7413\n",
      "Validation Error: Avg loss: 5.105721 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:45.843438 Epoch 574, Training loss 3.3901875019073486\n",
      "in params\n",
      "R2 values 0.7045, 0.6494, 0.6600; mean R2=0.6713\n",
      "Validation Error: Avg loss: 4.752310 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:46.119558 Epoch 575, Training loss 4.296330451965332\n",
      "in params\n",
      "R2 values 0.7240, 0.8380, 0.6581; mean R2=0.7400\n",
      "Validation Error: Avg loss: 2.807084 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:46.399938 Epoch 576, Training loss 3.5998711585998535\n",
      "in params\n",
      "R2 values 0.6246, 0.6248, 0.6299; mean R2=0.6264\n",
      "Validation Error: Avg loss: 4.979686 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:46.683219 Epoch 577, Training loss 4.100295543670654\n",
      "in params\n",
      "R2 values 0.6476, 0.6981, 0.7152; mean R2=0.6870\n",
      "Validation Error: Avg loss: 3.981176 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:46.967430 Epoch 578, Training loss 3.8247227668762207\n",
      "in params\n",
      "R2 values 0.7333, 0.7237, 0.7487; mean R2=0.7352\n",
      "Validation Error: Avg loss: 3.574796 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:47.245225 Epoch 579, Training loss 3.2919111251831055\n",
      "in params\n",
      "R2 values 0.6747, 0.7768, 0.7120; mean R2=0.7211\n",
      "Validation Error: Avg loss: 3.410710 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:47.522767 Epoch 580, Training loss 3.1639328002929688\n",
      "in params\n",
      "R2 values 0.5899, 0.6772, 0.5619; mean R2=0.6096\n",
      "Validation Error: Avg loss: 4.723446 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:47.816668 Epoch 581, Training loss 4.53361177444458\n",
      "in params\n",
      "R2 values 0.7452, 0.7355, 0.6524; mean R2=0.7110\n",
      "Validation Error: Avg loss: 4.346991 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:48.110958 Epoch 582, Training loss 3.162992238998413\n",
      "in params\n",
      "R2 values 0.6972, 0.7320, 0.7119; mean R2=0.7137\n",
      "Validation Error: Avg loss: 4.008382 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:48.394650 Epoch 583, Training loss 3.420875310897827\n",
      "in params\n",
      "R2 values 0.7032, 0.7228, 0.6335; mean R2=0.6865\n",
      "Validation Error: Avg loss: 4.562165 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:48.680791 Epoch 584, Training loss 4.201051235198975\n",
      "in params\n",
      "R2 values 0.6088, 0.5603, 0.5619; mean R2=0.5770\n",
      "Validation Error: Avg loss: 5.791610 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:48.968236 Epoch 585, Training loss 3.707601547241211\n",
      "in params\n",
      "R2 values 0.7275, 0.7162, 0.6230; mean R2=0.6889\n",
      "Validation Error: Avg loss: 4.421160 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:49.267095 Epoch 586, Training loss 3.6527762413024902\n",
      "in params\n",
      "R2 values 0.6051, 0.7974, 0.5954; mean R2=0.6660\n",
      "Validation Error: Avg loss: 3.632396 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:49.598613 Epoch 587, Training loss 3.7571866512298584\n",
      "in params\n",
      "R2 values 0.7560, 0.6976, 0.6820; mean R2=0.7118\n",
      "Validation Error: Avg loss: 3.958733 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:49.890787 Epoch 588, Training loss 3.338003635406494\n",
      "in params\n",
      "R2 values 0.6471, 0.7050, 0.6652; mean R2=0.6724\n",
      "Validation Error: Avg loss: 3.991539 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:50.174547 Epoch 589, Training loss 3.376677989959717\n",
      "in params\n",
      "R2 values 0.5953, 0.7575, 0.7319; mean R2=0.6949\n",
      "Validation Error: Avg loss: 3.375889 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:50.452876 Epoch 590, Training loss 3.3292815685272217\n",
      "in params\n",
      "R2 values 0.6984, 0.7805, 0.6188; mean R2=0.6993\n",
      "Validation Error: Avg loss: 3.712003 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:50.738713 Epoch 591, Training loss 3.300816297531128\n",
      "in params\n",
      "R2 values 0.6893, 0.8422, 0.6035; mean R2=0.7116\n",
      "Validation Error: Avg loss: 3.671303 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:51.016838 Epoch 592, Training loss 3.1870596408843994\n",
      "in params\n",
      "R2 values 0.7442, 0.7746, 0.6254; mean R2=0.7147\n",
      "Validation Error: Avg loss: 3.789361 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:51.301759 Epoch 593, Training loss 3.544987440109253\n",
      "in params\n",
      "R2 values 0.6160, 0.7475, 0.6688; mean R2=0.6775\n",
      "Validation Error: Avg loss: 4.388320 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:51.579751 Epoch 594, Training loss 4.114704608917236\n",
      "in params\n",
      "R2 values 0.7070, 0.6660, 0.6210; mean R2=0.6647\n",
      "Validation Error: Avg loss: 4.797513 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:51.867238 Epoch 595, Training loss 4.227895259857178\n",
      "in params\n",
      "R2 values 0.6229, 0.7759, 0.6595; mean R2=0.6861\n",
      "Validation Error: Avg loss: 3.635834 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:52.146591 Epoch 596, Training loss 3.9581918716430664\n",
      "in params\n",
      "R2 values 0.7506, 0.6990, 0.6614; mean R2=0.7037\n",
      "Validation Error: Avg loss: 4.029666 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:52.433307 Epoch 597, Training loss 5.390867710113525\n",
      "in params\n",
      "R2 values 0.6871, 0.7984, 0.6306; mean R2=0.7054\n",
      "Validation Error: Avg loss: 3.398868 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:52.721109 Epoch 598, Training loss 3.2615931034088135\n",
      "in params\n",
      "R2 values 0.7502, 0.7912, 0.6996; mean R2=0.7470\n",
      "Validation Error: Avg loss: 3.118442 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:53:53.026388 Epoch 599, Training loss 2.986375093460083\n",
      "in params\n",
      "R2 values 0.6939, 0.5275, 0.6191; mean R2=0.6135\n",
      "Validation Error: Avg loss: 6.019260 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:53.314064 Epoch 600, Training loss 3.918606996536255\n",
      "in params\n",
      "R2 values 0.6009, 0.7570, 0.6178; mean R2=0.6586\n",
      "Validation Error: Avg loss: 3.976896 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:53.612917 Epoch 601, Training loss 4.160543918609619\n",
      "in params\n",
      "R2 values 0.5967, 0.6548, 0.5848; mean R2=0.6121\n",
      "Validation Error: Avg loss: 5.336389 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:53.904306 Epoch 602, Training loss 3.329343318939209\n",
      "in params\n",
      "R2 values 0.6706, 0.7434, 0.6740; mean R2=0.6960\n",
      "Validation Error: Avg loss: 4.781687 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:54.180526 Epoch 603, Training loss 4.4473958015441895\n",
      "in params\n",
      "R2 values 0.6256, 0.5906, 0.7260; mean R2=0.6474\n",
      "Validation Error: Avg loss: 5.926709 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:54.460472 Epoch 604, Training loss 4.406949043273926\n",
      "in params\n",
      "R2 values 0.5133, 0.4992, 0.4920; mean R2=0.5015\n",
      "Validation Error: Avg loss: 6.966184 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:54.746854 Epoch 605, Training loss 3.429091215133667\n",
      "in params\n",
      "R2 values 0.6440, 0.6212, 0.7004; mean R2=0.6552\n",
      "Validation Error: Avg loss: 4.654078 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:55.037577 Epoch 606, Training loss 3.355576753616333\n",
      "in params\n",
      "R2 values 0.7639, 0.7535, 0.7925; mean R2=0.7700\n",
      "Validation Error: Avg loss: 3.115593 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:55.320162 Epoch 607, Training loss 3.7492690086364746\n",
      "in params\n",
      "R2 values 0.7278, 0.6880, 0.6475; mean R2=0.6877\n",
      "Validation Error: Avg loss: 4.734439 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:55.611629 Epoch 608, Training loss 4.706000804901123\n",
      "in params\n",
      "R2 values 0.8345, 0.8919, 0.7581; mean R2=0.8282\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 1.860158 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:55.929802 Epoch 609, Training loss 3.8740804195404053\n",
      "in params\n",
      "R2 values 0.7371, 0.8005, 0.7228; mean R2=0.7535\n",
      "Validation Error: Avg loss: 2.890060 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:56.213676 Epoch 610, Training loss 3.723404884338379\n",
      "in params\n",
      "R2 values 0.7348, 0.7735, 0.8024; mean R2=0.7702\n",
      "Validation Error: Avg loss: 2.919509 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:56.491641 Epoch 611, Training loss 3.0613391399383545\n",
      "in params\n",
      "R2 values 0.6671, 0.7820, 0.6161; mean R2=0.6884\n",
      "Validation Error: Avg loss: 3.657209 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:56.777303 Epoch 612, Training loss 3.6200904846191406\n",
      "in params\n",
      "R2 values 0.6823, 0.8318, 0.6848; mean R2=0.7330\n",
      "Validation Error: Avg loss: 3.086494 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:57.069566 Epoch 613, Training loss 4.530488967895508\n",
      "in params\n",
      "R2 values 0.7747, 0.8156, 0.7741; mean R2=0.7881\n",
      "Validation Error: Avg loss: 3.136999 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:57.351639 Epoch 614, Training loss 3.6206512451171875\n",
      "in params\n",
      "R2 values 0.7175, 0.7231, 0.7801; mean R2=0.7402\n",
      "Validation Error: Avg loss: 3.785286 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:57.636274 Epoch 615, Training loss 3.794177532196045\n",
      "in params\n",
      "R2 values 0.6632, 0.6845, 0.6669; mean R2=0.6715\n",
      "Validation Error: Avg loss: 4.310194 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:57.913581 Epoch 616, Training loss 3.33019757270813\n",
      "in params\n",
      "R2 values 0.4453, 0.6826, 0.6234; mean R2=0.5837\n",
      "Validation Error: Avg loss: 4.661240 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:58.190432 Epoch 617, Training loss 3.804558038711548\n",
      "in params\n",
      "R2 values 0.6611, 0.7269, 0.6164; mean R2=0.6682\n",
      "Validation Error: Avg loss: 4.068012 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:58.478047 Epoch 618, Training loss 3.3685998916625977\n",
      "in params\n",
      "R2 values 0.6899, 0.7760, 0.6247; mean R2=0.6969\n",
      "Validation Error: Avg loss: 3.572816 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:58.764426 Epoch 619, Training loss 3.862189531326294\n",
      "in params\n",
      "R2 values 0.7715, 0.7287, 0.7808; mean R2=0.7603\n",
      "Validation Error: Avg loss: 3.631432 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:59.046908 Epoch 620, Training loss 3.701728105545044\n",
      "in params\n",
      "R2 values 0.7241, 0.7191, 0.5402; mean R2=0.6611\n",
      "Validation Error: Avg loss: 4.632064 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:59.353764 Epoch 621, Training loss 2.88877272605896\n",
      "in params\n",
      "R2 values 0.7350, 0.7515, 0.7000; mean R2=0.7288\n",
      "Validation Error: Avg loss: 3.638692 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:59.639210 Epoch 622, Training loss 3.1828248500823975\n",
      "in params\n",
      "R2 values 0.7173, 0.8269, 0.5474; mean R2=0.6972\n",
      "Validation Error: Avg loss: 3.661125 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:53:59.929683 Epoch 623, Training loss 3.954169273376465\n",
      "in params\n",
      "R2 values 0.7781, 0.7667, 0.6615; mean R2=0.7354\n",
      "Validation Error: Avg loss: 3.988722 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:00.221538 Epoch 624, Training loss 4.6098246574401855\n",
      "in params\n",
      "R2 values 0.6622, 0.7394, 0.5852; mean R2=0.6622\n",
      "Validation Error: Avg loss: 4.268031 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:00.510709 Epoch 625, Training loss 4.372622489929199\n",
      "in params\n",
      "R2 values 0.7815, 0.6913, 0.6646; mean R2=0.7125\n",
      "Validation Error: Avg loss: 4.273746 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:00.801237 Epoch 626, Training loss 3.330146312713623\n",
      "in params\n",
      "R2 values 0.6430, 0.6961, 0.6203; mean R2=0.6531\n",
      "Validation Error: Avg loss: 4.379426 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:01.090732 Epoch 627, Training loss 3.91483211517334\n",
      "in params\n",
      "R2 values 0.7133, 0.7908, 0.7235; mean R2=0.7425\n",
      "Validation Error: Avg loss: 3.703524 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:01.378088 Epoch 628, Training loss 4.7844462394714355\n",
      "in params\n",
      "R2 values 0.6772, 0.5840, 0.6462; mean R2=0.6358\n",
      "Validation Error: Avg loss: 5.216793 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:01.666220 Epoch 629, Training loss 3.216596841812134\n",
      "in params\n",
      "R2 values 0.7214, 0.6770, 0.6939; mean R2=0.6974\n",
      "Validation Error: Avg loss: 4.121075 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:01.963355 Epoch 630, Training loss 4.016626358032227\n",
      "in params\n",
      "R2 values 0.6669, 0.6503, 0.5604; mean R2=0.6259\n",
      "Validation Error: Avg loss: 5.411293 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:02.245956 Epoch 631, Training loss 3.486649513244629\n",
      "in params\n",
      "R2 values 0.7162, 0.6887, 0.6761; mean R2=0.6937\n",
      "Validation Error: Avg loss: 4.471732 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:02.527756 Epoch 632, Training loss 3.4353246688842773\n",
      "in params\n",
      "R2 values 0.7602, 0.8018, 0.6506; mean R2=0.7375\n",
      "Validation Error: Avg loss: 3.357758 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:02.809958 Epoch 633, Training loss 3.0027456283569336\n",
      "in params\n",
      "R2 values 0.6835, 0.6762, 0.5676; mean R2=0.6424\n",
      "Validation Error: Avg loss: 5.119928 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:03.086276 Epoch 634, Training loss 3.241785764694214\n",
      "in params\n",
      "R2 values 0.7597, 0.5458, 0.7396; mean R2=0.6817\n",
      "Validation Error: Avg loss: 5.720560 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:03.367440 Epoch 635, Training loss 4.052707672119141\n",
      "in params\n",
      "R2 values 0.7424, 0.7456, 0.6425; mean R2=0.7102\n",
      "Validation Error: Avg loss: 4.167217 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:03.653601 Epoch 636, Training loss 3.787118911743164\n",
      "in params\n",
      "R2 values 0.6744, 0.8152, 0.6801; mean R2=0.7232\n",
      "Validation Error: Avg loss: 3.182629 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:03.942187 Epoch 637, Training loss 3.740004777908325\n",
      "in params\n",
      "R2 values 0.7343, 0.7900, 0.6451; mean R2=0.7231\n",
      "Validation Error: Avg loss: 3.361154 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:04.224367 Epoch 638, Training loss 4.377697944641113\n",
      "in params\n",
      "R2 values 0.7556, 0.7942, 0.7579; mean R2=0.7692\n",
      "Validation Error: Avg loss: 2.847995 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:04.509666 Epoch 639, Training loss 4.157197952270508\n",
      "in params\n",
      "R2 values 0.7151, 0.7437, 0.6785; mean R2=0.7124\n",
      "Validation Error: Avg loss: 3.932196 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:04.799155 Epoch 640, Training loss 3.173501968383789\n",
      "in params\n",
      "R2 values 0.6113, 0.7149, 0.6715; mean R2=0.6659\n",
      "Validation Error: Avg loss: 4.470531 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:05.113797 Epoch 641, Training loss 3.345968723297119\n",
      "in params\n",
      "R2 values 0.7395, 0.8446, 0.8168; mean R2=0.8003\n",
      "Validation Error: Avg loss: 3.197231 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:05.398059 Epoch 642, Training loss 3.735107183456421\n",
      "in params\n",
      "R2 values 0.6303, 0.6582, 0.5737; mean R2=0.6207\n",
      "Validation Error: Avg loss: 4.919634 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:05.691023 Epoch 643, Training loss 3.091423273086548\n",
      "in params\n",
      "R2 values 0.6597, 0.6366, 0.6216; mean R2=0.6393\n",
      "Validation Error: Avg loss: 5.234168 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:05.971732 Epoch 644, Training loss 4.822551250457764\n",
      "in params\n",
      "R2 values 0.7385, 0.6509, 0.6879; mean R2=0.6924\n",
      "Validation Error: Avg loss: 4.512121 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:54:06.261452 Epoch 645, Training loss 3.8346962928771973\n",
      "in params\n",
      "R2 values 0.6913, 0.5274, 0.6329; mean R2=0.6172\n",
      "Validation Error: Avg loss: 5.798954 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:06.544843 Epoch 646, Training loss 4.6506829261779785\n",
      "in params\n",
      "R2 values 0.7442, 0.7983, 0.5775; mean R2=0.7067\n",
      "Validation Error: Avg loss: 3.433039 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:06.827326 Epoch 647, Training loss 4.136443138122559\n",
      "in params\n",
      "R2 values 0.6684, 0.6449, 0.6334; mean R2=0.6489\n",
      "Validation Error: Avg loss: 4.666032 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:07.108862 Epoch 648, Training loss 3.4982781410217285\n",
      "in params\n",
      "R2 values 0.7470, 0.8192, 0.7581; mean R2=0.7748\n",
      "Validation Error: Avg loss: 2.748953 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:07.403434 Epoch 649, Training loss 3.2886483669281006\n",
      "in params\n",
      "R2 values 0.6948, 0.6487, 0.6804; mean R2=0.6746\n",
      "Validation Error: Avg loss: 4.483202 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:07.692326 Epoch 650, Training loss 3.8692197799682617\n",
      "in params\n",
      "R2 values 0.7436, 0.7741, 0.6812; mean R2=0.7330\n",
      "Validation Error: Avg loss: 4.272199 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:07.969507 Epoch 651, Training loss 3.735790967941284\n",
      "in params\n",
      "R2 values 0.7680, 0.7607, 0.7402; mean R2=0.7563\n",
      "Validation Error: Avg loss: 3.624367 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:08.247809 Epoch 652, Training loss 4.4760918617248535\n",
      "in params\n",
      "R2 values 0.6343, 0.5119, 0.6340; mean R2=0.5934\n",
      "Validation Error: Avg loss: 7.052660 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:08.527549 Epoch 653, Training loss 5.236954212188721\n",
      "in params\n",
      "R2 values 0.7367, 0.7368, 0.7534; mean R2=0.7423\n",
      "Validation Error: Avg loss: 5.715709 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:08.812402 Epoch 654, Training loss 2.899545192718506\n",
      "in params\n",
      "R2 values 0.7455, 0.7888, 0.6821; mean R2=0.7388\n",
      "Validation Error: Avg loss: 3.636151 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:09.093312 Epoch 655, Training loss 3.04939341545105\n",
      "in params\n",
      "R2 values 0.6896, 0.6401, 0.6453; mean R2=0.6584\n",
      "Validation Error: Avg loss: 4.787252 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:09.404548 Epoch 656, Training loss 2.8933870792388916\n",
      "in params\n",
      "R2 values 0.6048, 0.6445, 0.7479; mean R2=0.6658\n",
      "Validation Error: Avg loss: 4.601982 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:09.705098 Epoch 657, Training loss 4.188992023468018\n",
      "in params\n",
      "R2 values 0.8032, 0.7579, 0.7662; mean R2=0.7758\n",
      "Validation Error: Avg loss: 3.315001 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:09.993778 Epoch 658, Training loss 3.1076841354370117\n",
      "in params\n",
      "R2 values 0.7441, 0.8639, 0.7097; mean R2=0.7726\n",
      "Validation Error: Avg loss: 2.509031 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:10.291598 Epoch 659, Training loss 3.6933367252349854\n",
      "in params\n",
      "R2 values 0.7629, 0.6761, 0.7446; mean R2=0.7279\n",
      "Validation Error: Avg loss: 3.882703 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:10.583633 Epoch 660, Training loss 3.1454861164093018\n",
      "in params\n",
      "R2 values 0.7900, 0.8920, 0.7476; mean R2=0.8099\n",
      "Validation Error: Avg loss: 2.690656 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:10.871415 Epoch 661, Training loss 4.586117744445801\n",
      "in params\n",
      "R2 values 0.6708, 0.6244, 0.5788; mean R2=0.6247\n",
      "Validation Error: Avg loss: 5.049669 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:11.171016 Epoch 662, Training loss 2.8593592643737793\n",
      "in params\n",
      "R2 values 0.7294, 0.6313, 0.6187; mean R2=0.6598\n",
      "Validation Error: Avg loss: 4.873178 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:11.453822 Epoch 663, Training loss 3.529583692550659\n",
      "in params\n",
      "R2 values 0.6431, 0.7358, 0.6736; mean R2=0.6842\n",
      "Validation Error: Avg loss: 3.852168 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:11.737445 Epoch 664, Training loss 3.222489356994629\n",
      "in params\n",
      "R2 values 0.7092, 0.6511, 0.6795; mean R2=0.6799\n",
      "Validation Error: Avg loss: 4.618441 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:12.027229 Epoch 665, Training loss 4.529053688049316\n",
      "in params\n",
      "R2 values 0.6017, 0.6814, 0.6664; mean R2=0.6498\n",
      "Validation Error: Avg loss: 4.497394 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:12.328517 Epoch 666, Training loss 3.393158197402954\n",
      "in params\n",
      "R2 values 0.6864, 0.6759, 0.7356; mean R2=0.6993\n",
      "Validation Error: Avg loss: 4.041264 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:12.616629 Epoch 667, Training loss 3.741831064224243\n",
      "in params\n",
      "R2 values 0.6643, 0.7592, 0.6281; mean R2=0.6839\n",
      "Validation Error: Avg loss: 3.858958 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:12.911687 Epoch 668, Training loss 3.8864381313323975\n",
      "in params\n",
      "R2 values 0.7559, 0.7778, 0.6907; mean R2=0.7415\n",
      "Validation Error: Avg loss: 3.430477 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:13.204984 Epoch 669, Training loss 4.147049427032471\n",
      "in params\n",
      "R2 values 0.6225, 0.6523, 0.6693; mean R2=0.6480\n",
      "Validation Error: Avg loss: 4.647862 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:13.487169 Epoch 670, Training loss 3.96325421333313\n",
      "in params\n",
      "R2 values 0.6615, 0.5565, 0.6097; mean R2=0.6093\n",
      "Validation Error: Avg loss: 5.885236 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:13.769018 Epoch 671, Training loss 4.045169830322266\n",
      "in params\n",
      "R2 values 0.7136, 0.7909, 0.6474; mean R2=0.7173\n",
      "Validation Error: Avg loss: 3.653974 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:14.057418 Epoch 672, Training loss 2.652462959289551\n",
      "in params\n",
      "R2 values 0.6773, 0.7503, 0.6028; mean R2=0.6768\n",
      "Validation Error: Avg loss: 3.980315 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:14.340897 Epoch 673, Training loss 3.633908987045288\n",
      "in params\n",
      "R2 values 0.6522, 0.6335, 0.6834; mean R2=0.6563\n",
      "Validation Error: Avg loss: 4.626900 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:14.630084 Epoch 674, Training loss 3.6910996437072754\n",
      "in params\n",
      "R2 values 0.7623, 0.5658, 0.7576; mean R2=0.6952\n",
      "Validation Error: Avg loss: 4.926229 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:14.912107 Epoch 675, Training loss 3.090087890625\n",
      "in params\n",
      "R2 values 0.6424, 0.5119, 0.5143; mean R2=0.5562\n",
      "Validation Error: Avg loss: 6.383583 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:15.203018 Epoch 676, Training loss 4.1577324867248535\n",
      "in params\n",
      "R2 values 0.7112, 0.7434, 0.6571; mean R2=0.7039\n",
      "Validation Error: Avg loss: 4.024495 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:15.487530 Epoch 677, Training loss 4.131557941436768\n",
      "in params\n",
      "R2 values 0.7018, 0.7033, 0.6361; mean R2=0.6804\n",
      "Validation Error: Avg loss: 4.223670 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:15.777223 Epoch 678, Training loss 3.191375255584717\n",
      "in params\n",
      "R2 values 0.7576, 0.6548, 0.6391; mean R2=0.6838\n",
      "Validation Error: Avg loss: 5.042940 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:16.060475 Epoch 679, Training loss 4.156080722808838\n",
      "in params\n",
      "R2 values 0.6606, 0.6879, 0.6565; mean R2=0.6683\n",
      "Validation Error: Avg loss: 4.691719 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:16.336456 Epoch 680, Training loss 3.3666951656341553\n",
      "in params\n",
      "R2 values 0.7832, 0.8202, 0.7123; mean R2=0.7719\n",
      "Validation Error: Avg loss: 3.140222 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:16.640880 Epoch 681, Training loss 3.5066885948181152\n",
      "in params\n",
      "R2 values 0.6496, 0.7426, 0.6223; mean R2=0.6715\n",
      "Validation Error: Avg loss: 4.194339 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:16.931469 Epoch 682, Training loss 3.108069658279419\n",
      "in params\n",
      "R2 values 0.6772, 0.7552, 0.6472; mean R2=0.6932\n",
      "Validation Error: Avg loss: 3.664335 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:17.216985 Epoch 683, Training loss 4.266076564788818\n",
      "in params\n",
      "R2 values 0.7252, 0.7578, 0.7546; mean R2=0.7458\n",
      "Validation Error: Avg loss: 3.245998 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:17.499194 Epoch 684, Training loss 4.062048435211182\n",
      "in params\n",
      "R2 values 0.7536, 0.6801, 0.6749; mean R2=0.7029\n",
      "Validation Error: Avg loss: 4.111507 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:17.786384 Epoch 685, Training loss 3.159757375717163\n",
      "in params\n",
      "R2 values 0.6513, 0.7988, 0.5815; mean R2=0.6772\n",
      "Validation Error: Avg loss: 3.665414 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:18.074624 Epoch 686, Training loss 3.348072052001953\n",
      "in params\n",
      "R2 values 0.6057, 0.6149, 0.6521; mean R2=0.6242\n",
      "Validation Error: Avg loss: 5.319100 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:18.356514 Epoch 687, Training loss 3.4700186252593994\n",
      "in params\n",
      "R2 values 0.6830, 0.7172, 0.7032; mean R2=0.7011\n",
      "Validation Error: Avg loss: 4.682967 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:18.634607 Epoch 688, Training loss 4.489211559295654\n",
      "in params\n",
      "R2 values 0.6976, 0.6889, 0.6437; mean R2=0.6768\n",
      "Validation Error: Avg loss: 4.838575 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:18.920279 Epoch 689, Training loss 3.581427574157715\n",
      "in params\n",
      "R2 values 0.6719, 0.6712, 0.6854; mean R2=0.6762\n",
      "Validation Error: Avg loss: 4.194177 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:19.206923 Epoch 690, Training loss 3.1325576305389404\n",
      "in params\n",
      "R2 values 0.6883, 0.7460, 0.7103; mean R2=0.7148\n",
      "Validation Error: Avg loss: 3.767871 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:54:19.516951 Epoch 691, Training loss 2.699866533279419\n",
      "in params\n",
      "R2 values 0.6612, 0.7245, 0.6241; mean R2=0.6699\n",
      "Validation Error: Avg loss: 4.373191 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:19.809737 Epoch 692, Training loss 3.657503128051758\n",
      "in params\n",
      "R2 values 0.7363, 0.7692, 0.7502; mean R2=0.7519\n",
      "Validation Error: Avg loss: 3.143389 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:20.110736 Epoch 693, Training loss 3.552706003189087\n",
      "in params\n",
      "R2 values 0.6980, 0.6632, 0.5536; mean R2=0.6383\n",
      "Validation Error: Avg loss: 4.675603 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:20.408157 Epoch 694, Training loss 4.43858528137207\n",
      "in params\n",
      "R2 values 0.6935, 0.7901, 0.6103; mean R2=0.6980\n",
      "Validation Error: Avg loss: 3.951155 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:20.697462 Epoch 695, Training loss 3.4337759017944336\n",
      "in params\n",
      "R2 values 0.6413, 0.6294, 0.6686; mean R2=0.6464\n",
      "Validation Error: Avg loss: 5.247174 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:20.989185 Epoch 696, Training loss 3.339982748031616\n",
      "in params\n",
      "R2 values 0.6664, 0.7459, 0.6764; mean R2=0.6962\n",
      "Validation Error: Avg loss: 4.753469 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:21.278249 Epoch 697, Training loss 3.572993755340576\n",
      "in params\n",
      "R2 values 0.6965, 0.7610, 0.7341; mean R2=0.7305\n",
      "Validation Error: Avg loss: 3.978893 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:21.561553 Epoch 698, Training loss 3.539412260055542\n",
      "in params\n",
      "R2 values 0.7607, 0.6282, 0.7863; mean R2=0.7251\n",
      "Validation Error: Avg loss: 4.341390 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:21.849958 Epoch 699, Training loss 3.833510637283325\n",
      "in params\n",
      "R2 values 0.7769, 0.7244, 0.6781; mean R2=0.7264\n",
      "Validation Error: Avg loss: 3.810321 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:22.129655 Epoch 700, Training loss 3.9760725498199463\n",
      "in params\n",
      "R2 values 0.6856, 0.6713, 0.6587; mean R2=0.6719\n",
      "Validation Error: Avg loss: 4.385046 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:22.417317 Epoch 701, Training loss 4.084387302398682\n",
      "in params\n",
      "R2 values 0.7011, 0.7683, 0.6153; mean R2=0.6949\n",
      "Validation Error: Avg loss: 3.604842 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:22.701123 Epoch 702, Training loss 4.132972717285156\n",
      "in params\n",
      "R2 values 0.6010, 0.8330, 0.7094; mean R2=0.7145\n",
      "Validation Error: Avg loss: 2.765568 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:22.990533 Epoch 703, Training loss 4.003655433654785\n",
      "in params\n",
      "R2 values 0.6032, 0.6749, 0.5575; mean R2=0.6119\n",
      "Validation Error: Avg loss: 4.767025 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:23.279012 Epoch 704, Training loss 4.328760147094727\n",
      "in params\n",
      "R2 values 0.6827, 0.6323, 0.6965; mean R2=0.6705\n",
      "Validation Error: Avg loss: 4.730745 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:23.562459 Epoch 705, Training loss 3.7462844848632812\n",
      "in params\n",
      "R2 values 0.7398, 0.5766, 0.6233; mean R2=0.6466\n",
      "Validation Error: Avg loss: 5.725406 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:23.849589 Epoch 706, Training loss 3.270841121673584\n",
      "in params\n",
      "R2 values 0.6754, 0.8103, 0.7168; mean R2=0.7342\n",
      "Validation Error: Avg loss: 3.231054 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:24.135467 Epoch 707, Training loss 3.9582290649414062\n",
      "in params\n",
      "R2 values 0.8170, 0.7012, 0.7576; mean R2=0.7586\n",
      "Validation Error: Avg loss: 3.923824 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:24.419823 Epoch 708, Training loss 3.9461309909820557\n",
      "in params\n",
      "R2 values 0.6595, 0.7593, 0.5922; mean R2=0.6703\n",
      "Validation Error: Avg loss: 4.495740 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:24.707081 Epoch 709, Training loss 3.1411454677581787\n",
      "in params\n",
      "R2 values 0.6515, 0.6814, 0.6047; mean R2=0.6458\n",
      "Validation Error: Avg loss: 4.450277 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:24.985209 Epoch 710, Training loss 4.021518707275391\n",
      "in params\n",
      "R2 values 0.6712, 0.7418, 0.6940; mean R2=0.7024\n",
      "Validation Error: Avg loss: 3.902995 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:25.279632 Epoch 711, Training loss 3.064497709274292\n",
      "in params\n",
      "R2 values 0.6062, 0.6489, 0.6009; mean R2=0.6187\n",
      "Validation Error: Avg loss: 4.831589 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:25.568816 Epoch 712, Training loss 3.70621395111084\n",
      "in params\n",
      "R2 values 0.8484, 0.7836, 0.7601; mean R2=0.7974\n",
      "Validation Error: Avg loss: 3.135633 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:25.876604 Epoch 713, Training loss 3.62248158454895\n",
      "in params\n",
      "R2 values 0.6607, 0.5501, 0.6705; mean R2=0.6271\n",
      "Validation Error: Avg loss: 5.341794 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:26.200433 Epoch 714, Training loss 3.204627275466919\n",
      "in params\n",
      "R2 values 0.6542, 0.7310, 0.6911; mean R2=0.6921\n",
      "Validation Error: Avg loss: 3.831726 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:26.483919 Epoch 715, Training loss 3.961636781692505\n",
      "in params\n",
      "R2 values 0.7072, 0.7004, 0.6289; mean R2=0.6788\n",
      "Validation Error: Avg loss: 4.192285 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:26.772490 Epoch 716, Training loss 3.320343494415283\n",
      "in params\n",
      "R2 values 0.6058, 0.8072, 0.6152; mean R2=0.6761\n",
      "Validation Error: Avg loss: 3.518490 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:27.056384 Epoch 717, Training loss 4.088155269622803\n",
      "in params\n",
      "R2 values 0.7291, 0.6957, 0.6547; mean R2=0.6932\n",
      "Validation Error: Avg loss: 4.299610 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:27.341220 Epoch 718, Training loss 4.4664626121521\n",
      "in params\n",
      "R2 values 0.7439, 0.7705, 0.6567; mean R2=0.7237\n",
      "Validation Error: Avg loss: 3.428338 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:27.618510 Epoch 719, Training loss 3.9169654846191406\n",
      "in params\n",
      "R2 values 0.7019, 0.7787, 0.6517; mean R2=0.7108\n",
      "Validation Error: Avg loss: 3.734457 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:27.906340 Epoch 720, Training loss 3.3537793159484863\n",
      "in params\n",
      "R2 values 0.7109, 0.6150, 0.6423; mean R2=0.6561\n",
      "Validation Error: Avg loss: 4.971149 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:28.195322 Epoch 721, Training loss 2.5444586277008057\n",
      "in params\n",
      "R2 values 0.7137, 0.8070, 0.6586; mean R2=0.7264\n",
      "Validation Error: Avg loss: 3.615862 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:28.473881 Epoch 722, Training loss 3.6461668014526367\n",
      "in params\n",
      "R2 values 0.6835, 0.7175, 0.6427; mean R2=0.6812\n",
      "Validation Error: Avg loss: 3.967708 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:28.787005 Epoch 723, Training loss 3.034566879272461\n",
      "in params\n",
      "R2 values 0.6328, 0.6853, 0.5974; mean R2=0.6385\n",
      "Validation Error: Avg loss: 4.569421 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:29.085700 Epoch 724, Training loss 3.715183734893799\n",
      "in params\n",
      "R2 values 0.6460, 0.6057, 0.6507; mean R2=0.6341\n",
      "Validation Error: Avg loss: 5.072824 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:29.389190 Epoch 725, Training loss 4.070411682128906\n",
      "in params\n",
      "R2 values 0.7798, 0.7742, 0.8292; mean R2=0.7944\n",
      "Validation Error: Avg loss: 2.830353 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:29.683463 Epoch 726, Training loss 3.4318361282348633\n",
      "in params\n",
      "R2 values 0.6546, 0.7004, 0.6925; mean R2=0.6825\n",
      "Validation Error: Avg loss: 4.002231 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:29.973965 Epoch 727, Training loss 3.7044456005096436\n",
      "in params\n",
      "R2 values 0.7284, 0.8441, 0.7214; mean R2=0.7646\n",
      "Validation Error: Avg loss: 2.840608 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:30.256201 Epoch 728, Training loss 3.8461062908172607\n",
      "in params\n",
      "R2 values 0.6888, 0.5228, 0.6995; mean R2=0.6370\n",
      "Validation Error: Avg loss: 5.586455 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:30.537631 Epoch 729, Training loss 3.784956216812134\n",
      "in params\n",
      "R2 values 0.7039, 0.6605, 0.6572; mean R2=0.6738\n",
      "Validation Error: Avg loss: 4.973887 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:30.824308 Epoch 730, Training loss 4.09323263168335\n",
      "in params\n",
      "R2 values 0.7299, 0.7487, 0.7459; mean R2=0.7415\n",
      "Validation Error: Avg loss: 3.686771 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:31.132335 Epoch 731, Training loss 4.294997692108154\n",
      "in params\n",
      "R2 values 0.7388, 0.7502, 0.6663; mean R2=0.7184\n",
      "Validation Error: Avg loss: 3.725055 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:31.397726 Epoch 732, Training loss 4.160147190093994\n",
      "in params\n",
      "R2 values 0.6284, 0.7089, 0.6739; mean R2=0.6704\n",
      "Validation Error: Avg loss: 3.987919 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:31.672129 Epoch 733, Training loss 4.6465935707092285\n",
      "in params\n",
      "R2 values 0.6711, 0.7394, 0.6158; mean R2=0.6754\n",
      "Validation Error: Avg loss: 3.904575 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:31.944290 Epoch 734, Training loss 4.518237113952637\n",
      "in params\n",
      "R2 values 0.8008, 0.7662, 0.7185; mean R2=0.7619\n",
      "Validation Error: Avg loss: 3.263895 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:32.215803 Epoch 735, Training loss 4.632253170013428\n",
      "in params\n",
      "R2 values 0.7889, 0.5808, 0.7323; mean R2=0.7007\n",
      "Validation Error: Avg loss: 4.758315 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:32.484710 Epoch 736, Training loss 3.518822193145752\n",
      "in params\n",
      "R2 values 0.7331, 0.8039, 0.6917; mean R2=0.7429\n",
      "Validation Error: Avg loss: 3.457453 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:54:32.754757 Epoch 737, Training loss 4.250619888305664\n",
      "in params\n",
      "R2 values 0.6644, 0.7176, 0.7177; mean R2=0.6999\n",
      "Validation Error: Avg loss: 4.643794 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:33.031115 Epoch 738, Training loss 3.7368597984313965\n",
      "in params\n",
      "R2 values 0.7022, 0.6458, 0.6069; mean R2=0.6516\n",
      "Validation Error: Avg loss: 5.515112 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:33.302441 Epoch 739, Training loss 4.068910598754883\n",
      "in params\n",
      "R2 values 0.6282, 0.7230, 0.6558; mean R2=0.6690\n",
      "Validation Error: Avg loss: 3.886855 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:33.573865 Epoch 740, Training loss 4.35835599899292\n",
      "in params\n",
      "R2 values 0.6347, 0.7764, 0.6389; mean R2=0.6834\n",
      "Validation Error: Avg loss: 3.511989 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:33.847946 Epoch 741, Training loss 4.5378007888793945\n",
      "in params\n",
      "R2 values 0.7573, 0.7642, 0.5696; mean R2=0.6970\n",
      "Validation Error: Avg loss: 3.611852 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:34.120609 Epoch 742, Training loss 4.035199165344238\n",
      "in params\n",
      "R2 values 0.6204, 0.7732, 0.5643; mean R2=0.6526\n",
      "Validation Error: Avg loss: 3.755519 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:34.415773 Epoch 743, Training loss 3.7446913719177246\n",
      "in params\n",
      "R2 values 0.6700, 0.6866, 0.6582; mean R2=0.6716\n",
      "Validation Error: Avg loss: 4.296129 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:34.691934 Epoch 744, Training loss 3.2897160053253174\n",
      "in params\n",
      "R2 values 0.7136, 0.6802, 0.7077; mean R2=0.7005\n",
      "Validation Error: Avg loss: 4.027576 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:34.968011 Epoch 745, Training loss 3.162710666656494\n",
      "in params\n",
      "R2 values 0.5714, 0.7038, 0.6308; mean R2=0.6354\n",
      "Validation Error: Avg loss: 4.187887 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:35.238671 Epoch 746, Training loss 4.541660308837891\n",
      "in params\n",
      "R2 values 0.7582, 0.8182, 0.7170; mean R2=0.7644\n",
      "Validation Error: Avg loss: 3.062565 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:35.522249 Epoch 747, Training loss 3.0108258724212646\n",
      "in params\n",
      "R2 values 0.7630, 0.7699, 0.7604; mean R2=0.7644\n",
      "Validation Error: Avg loss: 3.721168 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:35.816031 Epoch 748, Training loss 3.775134801864624\n",
      "in params\n",
      "R2 values 0.6113, 0.6385, 0.6301; mean R2=0.6266\n",
      "Validation Error: Avg loss: 6.469141 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:36.083985 Epoch 749, Training loss 4.690154075622559\n",
      "in params\n",
      "R2 values 0.7569, 0.6675, 0.6079; mean R2=0.6774\n",
      "Validation Error: Avg loss: 5.489929 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:36.357338 Epoch 750, Training loss 5.049357891082764\n",
      "in params\n",
      "R2 values 0.6832, 0.7343, 0.6935; mean R2=0.7037\n",
      "Validation Error: Avg loss: 3.766724 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:36.633319 Epoch 751, Training loss 3.540464162826538\n",
      "in params\n",
      "R2 values 0.7086, 0.7392, 0.6343; mean R2=0.6941\n",
      "Validation Error: Avg loss: 3.913054 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:36.912377 Epoch 752, Training loss 3.724435567855835\n",
      "in params\n",
      "R2 values 0.7251, 0.7232, 0.6536; mean R2=0.7006\n",
      "Validation Error: Avg loss: 4.147192 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:37.179818 Epoch 753, Training loss 4.072192668914795\n",
      "in params\n",
      "R2 values 0.7553, 0.6712, 0.6572; mean R2=0.6946\n",
      "Validation Error: Avg loss: 4.347901 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:37.457228 Epoch 754, Training loss 4.560708045959473\n",
      "in params\n",
      "R2 values 0.8076, 0.6904, 0.7272; mean R2=0.7417\n",
      "Validation Error: Avg loss: 3.920038 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:37.736842 Epoch 755, Training loss 3.7450029850006104\n",
      "in params\n",
      "R2 values 0.6663, 0.6539, 0.6201; mean R2=0.6468\n",
      "Validation Error: Avg loss: 4.511500 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:38.024181 Epoch 756, Training loss 3.7236037254333496\n",
      "in params\n",
      "R2 values 0.7518, 0.7704, 0.6362; mean R2=0.7194\n",
      "Validation Error: Avg loss: 4.196035 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:38.296372 Epoch 757, Training loss 4.067883491516113\n",
      "in params\n",
      "R2 values 0.6977, 0.7246, 0.6931; mean R2=0.7051\n",
      "Validation Error: Avg loss: 4.844239 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:38.578273 Epoch 758, Training loss 4.2472453117370605\n",
      "in params\n",
      "R2 values 0.6115, 0.6790, 0.7144; mean R2=0.6683\n",
      "Validation Error: Avg loss: 5.002533 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:38.854003 Epoch 759, Training loss 4.175893306732178\n",
      "in params\n",
      "R2 values 0.7535, 0.8499, 0.7946; mean R2=0.7993\n",
      "Validation Error: Avg loss: 2.374747 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:39.133430 Epoch 760, Training loss 3.738736867904663\n",
      "in params\n",
      "R2 values 0.7649, 0.8703, 0.7775; mean R2=0.8042\n",
      "Validation Error: Avg loss: 2.138645 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:39.430983 Epoch 761, Training loss 3.6479742527008057\n",
      "in params\n",
      "R2 values 0.5850, 0.8444, 0.6280; mean R2=0.6858\n",
      "Validation Error: Avg loss: 2.961473 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:39.712661 Epoch 762, Training loss 3.186659097671509\n",
      "in params\n",
      "R2 values 0.6966, 0.6729, 0.6518; mean R2=0.6738\n",
      "Validation Error: Avg loss: 4.306210 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:39.985225 Epoch 763, Training loss 3.5885095596313477\n",
      "in params\n",
      "R2 values 0.7475, 0.7184, 0.6905; mean R2=0.7188\n",
      "Validation Error: Avg loss: 3.852756 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:40.254447 Epoch 764, Training loss 3.7751948833465576\n",
      "in params\n",
      "R2 values 0.5839, 0.5790, 0.6076; mean R2=0.5902\n",
      "Validation Error: Avg loss: 5.630478 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:40.531106 Epoch 765, Training loss 3.423462152481079\n",
      "in params\n",
      "R2 values 0.6495, 0.7338, 0.6143; mean R2=0.6658\n",
      "Validation Error: Avg loss: 3.930124 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:40.802006 Epoch 766, Training loss 4.002673625946045\n",
      "in params\n",
      "R2 values 0.6849, 0.7087, 0.6003; mean R2=0.6646\n",
      "Validation Error: Avg loss: 4.360067 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:41.075110 Epoch 767, Training loss 4.807904243469238\n",
      "in params\n",
      "R2 values 0.7197, 0.8314, 0.7029; mean R2=0.7513\n",
      "Validation Error: Avg loss: 2.716697 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:41.347467 Epoch 768, Training loss 3.3268396854400635\n",
      "in params\n",
      "R2 values 0.6365, 0.7392, 0.6357; mean R2=0.6705\n",
      "Validation Error: Avg loss: 4.076437 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:41.621126 Epoch 769, Training loss 3.6990857124328613\n",
      "in params\n",
      "R2 values 0.6689, 0.7976, 0.6298; mean R2=0.6988\n",
      "Validation Error: Avg loss: 3.907994 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:41.893833 Epoch 770, Training loss 2.4878549575805664\n",
      "in params\n",
      "R2 values 0.7366, 0.6976, 0.6059; mean R2=0.6800\n",
      "Validation Error: Avg loss: 4.414464 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:42.167990 Epoch 771, Training loss 4.542168140411377\n",
      "in params\n",
      "R2 values 0.7129, 0.7722, 0.7282; mean R2=0.7378\n",
      "Validation Error: Avg loss: 3.257488 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:42.442257 Epoch 772, Training loss 3.4701287746429443\n",
      "in params\n",
      "R2 values 0.5890, 0.7227, 0.6878; mean R2=0.6665\n",
      "Validation Error: Avg loss: 3.841618 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:42.738124 Epoch 773, Training loss 4.184566020965576\n",
      "in params\n",
      "R2 values 0.7313, 0.7987, 0.7085; mean R2=0.7462\n",
      "Validation Error: Avg loss: 3.040705 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:43.007037 Epoch 774, Training loss 2.728651523590088\n",
      "in params\n",
      "R2 values 0.7408, 0.7860, 0.8154; mean R2=0.7807\n",
      "Validation Error: Avg loss: 2.739575 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:43.280490 Epoch 775, Training loss 4.959774971008301\n",
      "in params\n",
      "R2 values 0.7065, 0.7858, 0.6462; mean R2=0.7128\n",
      "Validation Error: Avg loss: 3.503538 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:43.557829 Epoch 776, Training loss 2.6789603233337402\n",
      "in params\n",
      "R2 values 0.6702, 0.7921, 0.7068; mean R2=0.7230\n",
      "Validation Error: Avg loss: 3.100998 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:43.838713 Epoch 777, Training loss 4.074357986450195\n",
      "in params\n",
      "R2 values 0.6778, 0.7376, 0.7470; mean R2=0.7208\n",
      "Validation Error: Avg loss: 3.530347 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:44.113124 Epoch 778, Training loss 2.9323389530181885\n",
      "in params\n",
      "R2 values 0.7576, 0.7466, 0.7153; mean R2=0.7398\n",
      "Validation Error: Avg loss: 3.684322 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:44.383839 Epoch 779, Training loss 3.7887747287750244\n",
      "in params\n",
      "R2 values 0.7012, 0.6786, 0.5475; mean R2=0.6425\n",
      "Validation Error: Avg loss: 5.197327 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:44.660886 Epoch 780, Training loss 3.586127758026123\n",
      "in params\n",
      "R2 values 0.6782, 0.6544, 0.7048; mean R2=0.6791\n",
      "Validation Error: Avg loss: 4.640195 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:44.929966 Epoch 781, Training loss 4.502603530883789\n",
      "in params\n",
      "R2 values 0.7588, 0.8482, 0.8083; mean R2=0.8051\n",
      "Validation Error: Avg loss: 3.199698 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:45.233551 Epoch 782, Training loss 3.6393070220947266\n",
      "in params\n",
      "R2 values 0.7919, 0.7164, 0.6795; mean R2=0.7293\n",
      "Validation Error: Avg loss: 4.558968 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:54:45.516055 Epoch 783, Training loss 3.695246458053589\n",
      "in params\n",
      "R2 values 0.7516, 0.6491, 0.6091; mean R2=0.6700\n",
      "Validation Error: Avg loss: 5.198696 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:45.794714 Epoch 784, Training loss 3.6054720878601074\n",
      "in params\n",
      "R2 values 0.6314, 0.7394, 0.5901; mean R2=0.6536\n",
      "Validation Error: Avg loss: 4.115805 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:46.084942 Epoch 785, Training loss 3.4053921699523926\n",
      "in params\n",
      "R2 values 0.6381, 0.7022, 0.6288; mean R2=0.6564\n",
      "Validation Error: Avg loss: 4.202679 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:46.355986 Epoch 786, Training loss 5.1181159019470215\n",
      "in params\n",
      "R2 values 0.8053, 0.7749, 0.7149; mean R2=0.7650\n",
      "Validation Error: Avg loss: 3.042854 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:46.629227 Epoch 787, Training loss 3.959052085876465\n",
      "in params\n",
      "R2 values 0.7915, 0.7754, 0.8307; mean R2=0.7992\n",
      "Validation Error: Avg loss: 2.692865 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:46.896194 Epoch 788, Training loss 3.9468841552734375\n",
      "in params\n",
      "R2 values 0.7342, 0.7563, 0.7297; mean R2=0.7401\n",
      "Validation Error: Avg loss: 4.028959 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:47.169465 Epoch 789, Training loss 3.436155080795288\n",
      "in params\n",
      "R2 values 0.6779, 0.6652, 0.6681; mean R2=0.6704\n",
      "Validation Error: Avg loss: 4.291015 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:47.441339 Epoch 790, Training loss 3.8063480854034424\n",
      "in params\n",
      "R2 values 0.7375, 0.6747, 0.6617; mean R2=0.6913\n",
      "Validation Error: Avg loss: 4.665008 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:47.715792 Epoch 791, Training loss 3.537338972091675\n",
      "in params\n",
      "R2 values 0.6900, 0.7329, 0.7199; mean R2=0.7143\n",
      "Validation Error: Avg loss: 4.270753 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:47.990525 Epoch 792, Training loss 2.5339126586914062\n",
      "in params\n",
      "R2 values 0.6428, 0.7097, 0.6289; mean R2=0.6605\n",
      "Validation Error: Avg loss: 4.621826 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:48.259711 Epoch 793, Training loss 3.5268726348876953\n",
      "in params\n",
      "R2 values 0.7214, 0.6833, 0.6862; mean R2=0.6970\n",
      "Validation Error: Avg loss: 4.470824 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:48.529123 Epoch 794, Training loss 3.424247980117798\n",
      "in params\n",
      "R2 values 0.7347, 0.6923, 0.7943; mean R2=0.7404\n",
      "Validation Error: Avg loss: 3.698843 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:48.804251 Epoch 795, Training loss 3.9494431018829346\n",
      "in params\n",
      "R2 values 0.6014, 0.7163, 0.5892; mean R2=0.6356\n",
      "Validation Error: Avg loss: 4.502750 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:49.088414 Epoch 796, Training loss 4.266462326049805\n",
      "in params\n",
      "R2 values 0.7648, 0.8150, 0.7620; mean R2=0.7806\n",
      "Validation Error: Avg loss: 2.737065 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:49.370621 Epoch 797, Training loss 4.415976524353027\n",
      "in params\n",
      "R2 values 0.6414, 0.7125, 0.5850; mean R2=0.6463\n",
      "Validation Error: Avg loss: 4.416505 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:49.670025 Epoch 798, Training loss 3.350454330444336\n",
      "in params\n",
      "R2 values 0.6880, 0.7444, 0.7738; mean R2=0.7354\n",
      "Validation Error: Avg loss: 3.354360 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:49.943136 Epoch 799, Training loss 3.333702325820923\n",
      "in params\n",
      "R2 values 0.7760, 0.8657, 0.7295; mean R2=0.7904\n",
      "Validation Error: Avg loss: 2.313128 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:50.217243 Epoch 800, Training loss 2.8959527015686035\n",
      "in params\n",
      "R2 values 0.6891, 0.6697, 0.6883; mean R2=0.6824\n",
      "Validation Error: Avg loss: 4.981367 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:50.495411 Epoch 801, Training loss 3.646484613418579\n",
      "in params\n",
      "R2 values 0.6451, 0.7173, 0.7143; mean R2=0.6922\n",
      "Validation Error: Avg loss: 5.226580 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:50.778304 Epoch 802, Training loss 4.369502067565918\n",
      "in params\n",
      "R2 values 0.7003, 0.7593, 0.5996; mean R2=0.6864\n",
      "Validation Error: Avg loss: 5.680000 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:51.054325 Epoch 803, Training loss 4.312027454376221\n",
      "in params\n",
      "R2 values 0.6536, 0.5783, 0.5689; mean R2=0.6003\n",
      "Validation Error: Avg loss: 6.971521 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:51.335427 Epoch 804, Training loss 4.830893039703369\n",
      "in params\n",
      "R2 values 0.6675, 0.7269, 0.6491; mean R2=0.6812\n",
      "Validation Error: Avg loss: 5.304147 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:51.613290 Epoch 805, Training loss 3.680549383163452\n",
      "in params\n",
      "R2 values 0.6987, 0.7530, 0.6501; mean R2=0.7006\n",
      "Validation Error: Avg loss: 3.739755 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:51.886060 Epoch 806, Training loss 3.3892343044281006\n",
      "in params\n",
      "R2 values 0.6776, 0.7769, 0.7993; mean R2=0.7513\n",
      "Validation Error: Avg loss: 2.975224 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:52.162347 Epoch 807, Training loss 3.209930896759033\n",
      "in params\n",
      "R2 values 0.7398, 0.8096, 0.7381; mean R2=0.7625\n",
      "Validation Error: Avg loss: 2.915044 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:52.432968 Epoch 808, Training loss 4.717247486114502\n",
      "in params\n",
      "R2 values 0.6480, 0.6574, 0.6334; mean R2=0.6463\n",
      "Validation Error: Avg loss: 4.675144 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:52.708030 Epoch 809, Training loss 3.0682613849639893\n",
      "in params\n",
      "R2 values 0.7353, 0.7720, 0.7490; mean R2=0.7521\n",
      "Validation Error: Avg loss: 3.214951 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:52.978111 Epoch 810, Training loss 3.256319999694824\n",
      "in params\n",
      "R2 values 0.7249, 0.7968, 0.7313; mean R2=0.7510\n",
      "Validation Error: Avg loss: 3.521805 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:53.248232 Epoch 811, Training loss 3.0889883041381836\n",
      "in params\n",
      "R2 values 0.6789, 0.6720, 0.6560; mean R2=0.6690\n",
      "Validation Error: Avg loss: 4.501849 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:53.517228 Epoch 812, Training loss 3.338793992996216\n",
      "in params\n",
      "R2 values 0.7141, 0.8370, 0.6286; mean R2=0.7265\n",
      "Validation Error: Avg loss: 3.116256 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:53.801987 Epoch 813, Training loss 2.906984329223633\n",
      "in params\n",
      "R2 values 0.6035, 0.6224, 0.5616; mean R2=0.5958\n",
      "Validation Error: Avg loss: 5.289989 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:54.082003 Epoch 814, Training loss 3.548105478286743\n",
      "in params\n",
      "R2 values 0.7200, 0.7523, 0.6983; mean R2=0.7235\n",
      "Validation Error: Avg loss: 3.547705 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:54.370376 Epoch 815, Training loss 4.099508285522461\n",
      "in params\n",
      "R2 values 0.7804, 0.7205, 0.6237; mean R2=0.7082\n",
      "Validation Error: Avg loss: 4.388110 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:54.649475 Epoch 816, Training loss 3.371483087539673\n",
      "in params\n",
      "R2 values 0.6281, 0.7857, 0.6717; mean R2=0.6952\n",
      "Validation Error: Avg loss: 3.787717 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:54.919193 Epoch 817, Training loss 3.8298797607421875\n",
      "in params\n",
      "R2 values 0.7838, 0.7614, 0.6890; mean R2=0.7447\n",
      "Validation Error: Avg loss: 3.260078 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:55.195533 Epoch 818, Training loss 4.408477306365967\n",
      "in params\n",
      "R2 values 0.7531, 0.7511, 0.7879; mean R2=0.7640\n",
      "Validation Error: Avg loss: 3.208836 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:55.465561 Epoch 819, Training loss 3.740852117538452\n",
      "in params\n",
      "R2 values 0.7161, 0.7727, 0.6561; mean R2=0.7150\n",
      "Validation Error: Avg loss: 3.433112 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:55.750270 Epoch 820, Training loss 3.2739527225494385\n",
      "in params\n",
      "R2 values 0.7234, 0.6853, 0.6702; mean R2=0.6930\n",
      "Validation Error: Avg loss: 4.232606 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:56.016607 Epoch 821, Training loss 4.459163188934326\n",
      "in params\n",
      "R2 values 0.6722, 0.7729, 0.7586; mean R2=0.7346\n",
      "Validation Error: Avg loss: 3.159347 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:56.293241 Epoch 822, Training loss 3.516322374343872\n",
      "in params\n",
      "R2 values 0.6821, 0.8758, 0.6859; mean R2=0.7479\n",
      "Validation Error: Avg loss: 2.631383 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:56.563613 Epoch 823, Training loss 3.4101240634918213\n",
      "in params\n",
      "R2 values 0.7026, 0.7446, 0.6463; mean R2=0.6978\n",
      "Validation Error: Avg loss: 3.720803 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:56.841116 Epoch 824, Training loss 3.015324592590332\n",
      "in params\n",
      "R2 values 0.6756, 0.8271, 0.6291; mean R2=0.7106\n",
      "Validation Error: Avg loss: 3.310187 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:57.124571 Epoch 825, Training loss 2.54445219039917\n",
      "in params\n",
      "R2 values 0.6775, 0.7328, 0.6317; mean R2=0.6807\n",
      "Validation Error: Avg loss: 4.486357 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:57.397193 Epoch 826, Training loss 2.9869682788848877\n",
      "in params\n",
      "R2 values 0.6889, 0.8131, 0.7517; mean R2=0.7512\n",
      "Validation Error: Avg loss: 2.715920 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:57.669447 Epoch 827, Training loss 3.8752057552337646\n",
      "in params\n",
      "R2 values 0.5626, 0.8712, 0.6984; mean R2=0.7108\n",
      "Validation Error: Avg loss: 2.631435 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:57.959193 Epoch 828, Training loss 4.648782730102539\n",
      "in params\n",
      "R2 values 0.6933, 0.7762, 0.6647; mean R2=0.7114\n",
      "Validation Error: Avg loss: 3.956537 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:54:58.230216 Epoch 829, Training loss 3.9487528800964355\n",
      "in params\n",
      "R2 values 0.6076, 0.6863, 0.6790; mean R2=0.6576\n",
      "Validation Error: Avg loss: 4.241536 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:58.505149 Epoch 830, Training loss 3.1871702671051025\n",
      "in params\n",
      "R2 values 0.6632, 0.8430, 0.7070; mean R2=0.7377\n",
      "Validation Error: Avg loss: 2.749787 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:58.779847 Epoch 831, Training loss 3.0639426708221436\n",
      "in params\n",
      "R2 values 0.6813, 0.8828, 0.7304; mean R2=0.7649\n",
      "Validation Error: Avg loss: 2.236959 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:59.045356 Epoch 832, Training loss 4.001478672027588\n",
      "in params\n",
      "R2 values 0.6639, 0.6706, 0.6685; mean R2=0.6677\n",
      "Validation Error: Avg loss: 4.387276 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:59.322282 Epoch 833, Training loss 3.155491590499878\n",
      "in params\n",
      "R2 values 0.6825, 0.6902, 0.7477; mean R2=0.7068\n",
      "Validation Error: Avg loss: 4.141680 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:59.614001 Epoch 834, Training loss 4.273965358734131\n",
      "in params\n",
      "R2 values 0.6877, 0.6441, 0.6164; mean R2=0.6494\n",
      "Validation Error: Avg loss: 4.907662 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:54:59.886340 Epoch 835, Training loss 3.6200108528137207\n",
      "in params\n",
      "R2 values 0.5937, 0.7500, 0.6502; mean R2=0.6646\n",
      "Validation Error: Avg loss: 4.000006 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:00.209067 Epoch 836, Training loss 4.646438121795654\n",
      "in params\n",
      "R2 values 0.6352, 0.4876, 0.6496; mean R2=0.5908\n",
      "Validation Error: Avg loss: 6.226445 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:00.481534 Epoch 837, Training loss 3.9751698970794678\n",
      "in params\n",
      "R2 values 0.7214, 0.7449, 0.7592; mean R2=0.7418\n",
      "Validation Error: Avg loss: 3.391053 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:00.769765 Epoch 838, Training loss 3.4926626682281494\n",
      "in params\n",
      "R2 values 0.7334, 0.8113, 0.5977; mean R2=0.7141\n",
      "Validation Error: Avg loss: 3.411607 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:01.045189 Epoch 839, Training loss 3.539565086364746\n",
      "in params\n",
      "R2 values 0.6843, 0.6984, 0.5813; mean R2=0.6547\n",
      "Validation Error: Avg loss: 4.350987 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:01.324003 Epoch 840, Training loss 3.7972426414489746\n",
      "in params\n",
      "R2 values 0.7171, 0.8350, 0.7315; mean R2=0.7612\n",
      "Validation Error: Avg loss: 2.703212 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:01.603162 Epoch 841, Training loss 3.036008358001709\n",
      "in params\n",
      "R2 values 0.7604, 0.7338, 0.8490; mean R2=0.7811\n",
      "Validation Error: Avg loss: 3.121636 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:01.926607 Epoch 842, Training loss 3.8054773807525635\n",
      "in params\n",
      "R2 values 0.5947, 0.7010, 0.5181; mean R2=0.6046\n",
      "Validation Error: Avg loss: 4.697463 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:02.206162 Epoch 843, Training loss 3.124589681625366\n",
      "in params\n",
      "R2 values 0.7155, 0.7813, 0.8286; mean R2=0.7751\n",
      "Validation Error: Avg loss: 2.806541 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:02.482203 Epoch 844, Training loss 2.928927421569824\n",
      "in params\n",
      "R2 values 0.5899, 0.6566, 0.5201; mean R2=0.5889\n",
      "Validation Error: Avg loss: 5.256210 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:02.760800 Epoch 845, Training loss 3.7274396419525146\n",
      "in params\n",
      "R2 values 0.7713, 0.7481, 0.7019; mean R2=0.7405\n",
      "Validation Error: Avg loss: 4.121995 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:03.049195 Epoch 846, Training loss 3.9343063831329346\n",
      "in params\n",
      "R2 values 0.7544, 0.7227, 0.6553; mean R2=0.7108\n",
      "Validation Error: Avg loss: 3.800708 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:03.330782 Epoch 847, Training loss 3.736025810241699\n",
      "in params\n",
      "R2 values 0.6919, 0.7831, 0.7092; mean R2=0.7281\n",
      "Validation Error: Avg loss: 3.143753 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:03.610720 Epoch 848, Training loss 2.7722373008728027\n",
      "in params\n",
      "R2 values 0.6863, 0.7881, 0.5841; mean R2=0.6861\n",
      "Validation Error: Avg loss: 3.438496 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:03.895408 Epoch 849, Training loss 3.2704460620880127\n",
      "in params\n",
      "R2 values 0.7778, 0.8474, 0.7885; mean R2=0.8045\n",
      "Validation Error: Avg loss: 3.419413 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:04.172625 Epoch 850, Training loss 4.759701728820801\n",
      "in params\n",
      "R2 values 0.7155, 0.7326, 0.7508; mean R2=0.7330\n",
      "Validation Error: Avg loss: 3.517159 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:04.463916 Epoch 851, Training loss 3.7716240882873535\n",
      "in params\n",
      "R2 values 0.6052, 0.6588, 0.7443; mean R2=0.6694\n",
      "Validation Error: Avg loss: 4.623057 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:04.732581 Epoch 852, Training loss 4.532835960388184\n",
      "in params\n",
      "R2 values 0.6837, 0.7035, 0.6110; mean R2=0.6660\n",
      "Validation Error: Avg loss: 4.391937 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:05.015670 Epoch 853, Training loss 3.742340326309204\n",
      "in params\n",
      "R2 values 0.6384, 0.7382, 0.6803; mean R2=0.6856\n",
      "Validation Error: Avg loss: 3.931606 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:05.290056 Epoch 854, Training loss 3.9573795795440674\n",
      "in params\n",
      "R2 values 0.5698, 0.5638, 0.5891; mean R2=0.5742\n",
      "Validation Error: Avg loss: 5.884262 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:05.560134 Epoch 855, Training loss 4.259773254394531\n",
      "in params\n",
      "R2 values 0.5273, 0.7161, 0.5784; mean R2=0.6073\n",
      "Validation Error: Avg loss: 4.565604 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:05.839976 Epoch 856, Training loss 2.923224687576294\n",
      "in params\n",
      "R2 values 0.7000, 0.7051, 0.6331; mean R2=0.6794\n",
      "Validation Error: Avg loss: 4.148579 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:06.121151 Epoch 857, Training loss 4.50797700881958\n",
      "in params\n",
      "R2 values 0.6660, 0.7665, 0.6912; mean R2=0.7079\n",
      "Validation Error: Avg loss: 3.332734 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:06.402580 Epoch 858, Training loss 2.969557046890259\n",
      "in params\n",
      "R2 values 0.7219, 0.7769, 0.6605; mean R2=0.7198\n",
      "Validation Error: Avg loss: 3.313154 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:06.679810 Epoch 859, Training loss 3.9428493976593018\n",
      "in params\n",
      "R2 values 0.6257, 0.7167, 0.6319; mean R2=0.6581\n",
      "Validation Error: Avg loss: 4.516260 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:06.965346 Epoch 860, Training loss 3.423013687133789\n",
      "in params\n",
      "R2 values 0.7070, 0.6377, 0.6518; mean R2=0.6655\n",
      "Validation Error: Avg loss: 4.572042 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:07.240396 Epoch 861, Training loss 3.831414222717285\n",
      "in params\n",
      "R2 values 0.6642, 0.8606, 0.7646; mean R2=0.7631\n",
      "Validation Error: Avg loss: 3.013547 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:07.510881 Epoch 862, Training loss 3.578735828399658\n",
      "in params\n",
      "R2 values 0.7175, 0.7330, 0.6243; mean R2=0.6916\n",
      "Validation Error: Avg loss: 4.288960 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:07.784846 Epoch 863, Training loss 4.227204322814941\n",
      "in params\n",
      "R2 values 0.7555, 0.5690, 0.6471; mean R2=0.6572\n",
      "Validation Error: Avg loss: 5.929391 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:08.078285 Epoch 864, Training loss 4.830214977264404\n",
      "in params\n",
      "R2 values 0.5637, 0.5796, 0.5548; mean R2=0.5661\n",
      "Validation Error: Avg loss: 6.138737 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:08.378963 Epoch 865, Training loss 3.5815958976745605\n",
      "in params\n",
      "R2 values 0.6874, 0.6699, 0.7120; mean R2=0.6897\n",
      "Validation Error: Avg loss: 4.539957 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:08.650788 Epoch 866, Training loss 2.943596601486206\n",
      "in params\n",
      "R2 values 0.6870, 0.6245, 0.6272; mean R2=0.6462\n",
      "Validation Error: Avg loss: 5.001232 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:08.922791 Epoch 867, Training loss 3.3902413845062256\n",
      "in params\n",
      "R2 values 0.6646, 0.7934, 0.6389; mean R2=0.6990\n",
      "Validation Error: Avg loss: 3.528583 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:09.200669 Epoch 868, Training loss 3.6911778450012207\n",
      "in params\n",
      "R2 values 0.6854, 0.8131, 0.8060; mean R2=0.7681\n",
      "Validation Error: Avg loss: 2.573485 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:09.476898 Epoch 869, Training loss 3.0453195571899414\n",
      "in params\n",
      "R2 values 0.6659, 0.5431, 0.7132; mean R2=0.6407\n",
      "Validation Error: Avg loss: 5.378637 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:09.780731 Epoch 870, Training loss 4.127589225769043\n",
      "in params\n",
      "R2 values 0.6311, 0.6844, 0.6544; mean R2=0.6566\n",
      "Validation Error: Avg loss: 4.249463 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:10.057399 Epoch 871, Training loss 3.659412384033203\n",
      "in params\n",
      "R2 values 0.6763, 0.7589, 0.6853; mean R2=0.7068\n",
      "Validation Error: Avg loss: 3.646128 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:10.336253 Epoch 872, Training loss 3.298060655593872\n",
      "in params\n",
      "R2 values 0.7068, 0.8399, 0.7226; mean R2=0.7564\n",
      "Validation Error: Avg loss: 2.655067 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:10.613240 Epoch 873, Training loss 3.1343801021575928\n",
      "in params\n",
      "R2 values 0.6772, 0.6608, 0.6500; mean R2=0.6627\n",
      "Validation Error: Avg loss: 4.529999 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:10.899328 Epoch 874, Training loss 3.6135873794555664\n",
      "in params\n",
      "R2 values 0.7507, 0.6809, 0.7119; mean R2=0.7145\n",
      "Validation Error: Avg loss: 3.937079 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:55:11.173331 Epoch 875, Training loss 3.5473074913024902\n",
      "in params\n",
      "R2 values 0.7323, 0.7181, 0.7259; mean R2=0.7254\n",
      "Validation Error: Avg loss: 3.634055 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:11.448894 Epoch 876, Training loss 3.6400678157806396\n",
      "in params\n",
      "R2 values 0.5963, 0.5732, 0.6593; mean R2=0.6096\n",
      "Validation Error: Avg loss: 5.313852 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:11.723124 Epoch 877, Training loss 4.053858757019043\n",
      "in params\n",
      "R2 values 0.6399, 0.6960, 0.6667; mean R2=0.6675\n",
      "Validation Error: Avg loss: 4.154262 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:12.013759 Epoch 878, Training loss 3.009697437286377\n",
      "in params\n",
      "R2 values 0.6795, 0.6456, 0.6467; mean R2=0.6573\n",
      "Validation Error: Avg loss: 4.620610 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:12.281687 Epoch 879, Training loss 3.1027159690856934\n",
      "in params\n",
      "R2 values 0.5823, 0.7694, 0.6378; mean R2=0.6632\n",
      "Validation Error: Avg loss: 3.877248 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:12.558856 Epoch 880, Training loss 3.3473918437957764\n",
      "in params\n",
      "R2 values 0.6385, 0.7548, 0.6609; mean R2=0.6847\n",
      "Validation Error: Avg loss: 3.981003 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:12.857134 Epoch 881, Training loss 3.7500979900360107\n",
      "in params\n",
      "R2 values 0.7693, 0.7949, 0.8518; mean R2=0.8053\n",
      "Validation Error: Avg loss: 3.895983 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:13.128318 Epoch 882, Training loss 4.3671698570251465\n",
      "in params\n",
      "R2 values 0.6988, 0.6344, 0.6273; mean R2=0.6535\n",
      "Validation Error: Avg loss: 4.958806 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:13.399861 Epoch 883, Training loss 3.3594794273376465\n",
      "in params\n",
      "R2 values 0.6488, 0.7331, 0.6397; mean R2=0.6739\n",
      "Validation Error: Avg loss: 4.073427 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:13.679824 Epoch 884, Training loss 3.9532129764556885\n",
      "in params\n",
      "R2 values 0.7448, 0.7424, 0.7869; mean R2=0.7580\n",
      "Validation Error: Avg loss: 3.527253 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:13.955397 Epoch 885, Training loss 3.226447105407715\n",
      "in params\n",
      "R2 values 0.6236, 0.6804, 0.6656; mean R2=0.6565\n",
      "Validation Error: Avg loss: 4.304744 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:14.233585 Epoch 886, Training loss 3.4989826679229736\n",
      "in params\n",
      "R2 values 0.6334, 0.6255, 0.7314; mean R2=0.6634\n",
      "Validation Error: Avg loss: 4.661260 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:14.504265 Epoch 887, Training loss 4.053928375244141\n",
      "in params\n",
      "R2 values 0.6647, 0.6383, 0.6741; mean R2=0.6591\n",
      "Validation Error: Avg loss: 4.583438 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:14.785362 Epoch 888, Training loss 3.656461715698242\n",
      "in params\n",
      "R2 values 0.7052, 0.8000, 0.7678; mean R2=0.7577\n",
      "Validation Error: Avg loss: 2.859485 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:15.067271 Epoch 889, Training loss 3.4955670833587646\n",
      "in params\n",
      "R2 values 0.6130, 0.6382, 0.6872; mean R2=0.6461\n",
      "Validation Error: Avg loss: 4.713238 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:15.337034 Epoch 890, Training loss 4.248610973358154\n",
      "in params\n",
      "R2 values 0.5865, 0.6653, 0.6413; mean R2=0.6310\n",
      "Validation Error: Avg loss: 4.771077 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:15.623351 Epoch 891, Training loss 3.870556592941284\n",
      "in params\n",
      "R2 values 0.6369, 0.5819, 0.6168; mean R2=0.6118\n",
      "Validation Error: Avg loss: 5.752634 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:15.925603 Epoch 892, Training loss 3.7284154891967773\n",
      "in params\n",
      "R2 values 0.6259, 0.5660, 0.7557; mean R2=0.6492\n",
      "Validation Error: Avg loss: 5.286698 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:16.204039 Epoch 893, Training loss 3.046967029571533\n",
      "in params\n",
      "R2 values 0.6754, 0.6799, 0.6591; mean R2=0.6715\n",
      "Validation Error: Avg loss: 4.884209 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:16.490702 Epoch 894, Training loss 4.019087314605713\n",
      "in params\n",
      "R2 values 0.7723, 0.6971, 0.7176; mean R2=0.7290\n",
      "Validation Error: Avg loss: 4.039372 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:16.766111 Epoch 895, Training loss 4.910253047943115\n",
      "in params\n",
      "R2 values 0.6710, 0.7280, 0.7100; mean R2=0.7030\n",
      "Validation Error: Avg loss: 3.755509 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:17.044594 Epoch 896, Training loss 3.4481186866760254\n",
      "in params\n",
      "R2 values 0.6517, 0.7264, 0.6378; mean R2=0.6720\n",
      "Validation Error: Avg loss: 3.964885 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:17.317086 Epoch 897, Training loss 3.846010684967041\n",
      "in params\n",
      "R2 values 0.6970, 0.7750, 0.6851; mean R2=0.7190\n",
      "Validation Error: Avg loss: 3.308286 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:17.586605 Epoch 898, Training loss 4.046601295471191\n",
      "in params\n",
      "R2 values 0.6950, 0.6923, 0.6729; mean R2=0.6867\n",
      "Validation Error: Avg loss: 4.010245 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:17.857623 Epoch 899, Training loss 3.6853935718536377\n",
      "in params\n",
      "R2 values 0.7647, 0.6955, 0.8036; mean R2=0.7546\n",
      "Validation Error: Avg loss: 3.542734 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:18.142585 Epoch 900, Training loss 3.739938974380493\n",
      "in params\n",
      "R2 values 0.5884, 0.7104, 0.7110; mean R2=0.6699\n",
      "Validation Error: Avg loss: 4.013204 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:18.417827 Epoch 901, Training loss 3.206636905670166\n",
      "in params\n",
      "R2 values 0.6581, 0.7561, 0.6144; mean R2=0.6762\n",
      "Validation Error: Avg loss: 3.916163 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:18.693811 Epoch 902, Training loss 3.5873608589172363\n",
      "in params\n",
      "R2 values 0.6949, 0.6969, 0.6969; mean R2=0.6962\n",
      "Validation Error: Avg loss: 5.292171 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:18.972149 Epoch 903, Training loss 2.865398645401001\n",
      "in params\n",
      "R2 values 0.7203, 0.7696, 0.6324; mean R2=0.7074\n",
      "Validation Error: Avg loss: 4.425560 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:19.257115 Epoch 904, Training loss 3.8230583667755127\n",
      "in params\n",
      "R2 values 0.6066, 0.7026, 0.5469; mean R2=0.6187\n",
      "Validation Error: Avg loss: 4.513557 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:19.541341 Epoch 905, Training loss 3.103135824203491\n",
      "in params\n",
      "R2 values 0.7500, 0.7698, 0.7599; mean R2=0.7599\n",
      "Validation Error: Avg loss: 3.276803 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:19.829372 Epoch 906, Training loss 3.860506534576416\n",
      "in params\n",
      "R2 values 0.7043, 0.7545, 0.6358; mean R2=0.6982\n",
      "Validation Error: Avg loss: 3.595186 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:20.125056 Epoch 907, Training loss 4.166987895965576\n",
      "in params\n",
      "R2 values 0.7061, 0.7324, 0.7480; mean R2=0.7288\n",
      "Validation Error: Avg loss: 3.594720 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:20.399317 Epoch 908, Training loss 3.725942373275757\n",
      "in params\n",
      "R2 values 0.7743, 0.7347, 0.7022; mean R2=0.7371\n",
      "Validation Error: Avg loss: 3.873204 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:20.674594 Epoch 909, Training loss 4.35298490524292\n",
      "in params\n",
      "R2 values 0.7066, 0.5960, 0.7598; mean R2=0.6875\n",
      "Validation Error: Avg loss: 4.642372 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:20.956982 Epoch 910, Training loss 3.801377058029175\n",
      "in params\n",
      "R2 values 0.7179, 0.7694, 0.6843; mean R2=0.7239\n",
      "Validation Error: Avg loss: 3.247949 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:21.229625 Epoch 911, Training loss 2.7980148792266846\n",
      "in params\n",
      "R2 values 0.7040, 0.6287, 0.6069; mean R2=0.6465\n",
      "Validation Error: Avg loss: 4.771636 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:21.505587 Epoch 912, Training loss 2.654564380645752\n",
      "in params\n",
      "R2 values 0.6792, 0.7044, 0.5609; mean R2=0.6482\n",
      "Validation Error: Avg loss: 4.772911 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:21.786221 Epoch 913, Training loss 2.7177982330322266\n",
      "in params\n",
      "R2 values 0.6899, 0.7375, 0.7489; mean R2=0.7254\n",
      "Validation Error: Avg loss: 3.622075 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:22.062223 Epoch 914, Training loss 3.137110948562622\n",
      "in params\n",
      "R2 values 0.6181, 0.6132, 0.6199; mean R2=0.6171\n",
      "Validation Error: Avg loss: 5.546999 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:22.354990 Epoch 915, Training loss 4.102219581604004\n",
      "in params\n",
      "R2 values 0.7453, 0.7680, 0.7309; mean R2=0.7481\n",
      "Validation Error: Avg loss: 4.194689 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:22.630596 Epoch 916, Training loss 3.620936155319214\n",
      "in params\n",
      "R2 values 0.6303, 0.7664, 0.6123; mean R2=0.6697\n",
      "Validation Error: Avg loss: 3.864400 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:22.906752 Epoch 917, Training loss 3.063901662826538\n",
      "in params\n",
      "R2 values 0.5938, 0.6878, 0.7597; mean R2=0.6804\n",
      "Validation Error: Avg loss: 4.086338 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:23.177237 Epoch 918, Training loss 3.01251482963562\n",
      "in params\n",
      "R2 values 0.7091, 0.6306, 0.5785; mean R2=0.6394\n",
      "Validation Error: Avg loss: 5.151850 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:23.449310 Epoch 919, Training loss 2.838576316833496\n",
      "in params\n",
      "R2 values 0.6525, 0.6681, 0.5967; mean R2=0.6391\n",
      "Validation Error: Avg loss: 4.619992 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:23.725735 Epoch 920, Training loss 3.555312156677246\n",
      "in params\n",
      "R2 values 0.6335, 0.7789, 0.7523; mean R2=0.7216\n",
      "Validation Error: Avg loss: 3.088244 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:55:24.003461 Epoch 921, Training loss 2.907926559448242\n",
      "in params\n",
      "R2 values 0.6339, 0.6597, 0.7170; mean R2=0.6702\n",
      "Validation Error: Avg loss: 4.540915 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:24.277937 Epoch 922, Training loss 4.420529365539551\n",
      "in params\n",
      "R2 values 0.7368, 0.7821, 0.7223; mean R2=0.7471\n",
      "Validation Error: Avg loss: 3.517333 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:24.551519 Epoch 923, Training loss 3.871570587158203\n",
      "in params\n",
      "R2 values 0.7077, 0.6243, 0.6059; mean R2=0.6459\n",
      "Validation Error: Avg loss: 5.163218 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:24.857381 Epoch 924, Training loss 3.6765785217285156\n",
      "in params\n",
      "R2 values 0.6224, 0.6163, 0.6011; mean R2=0.6133\n",
      "Validation Error: Avg loss: 5.088907 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:25.141377 Epoch 925, Training loss 3.555889844894409\n",
      "in params\n",
      "R2 values 0.6339, 0.5973, 0.6397; mean R2=0.6236\n",
      "Validation Error: Avg loss: 5.364788 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:25.415665 Epoch 926, Training loss 3.307062864303589\n",
      "in params\n",
      "R2 values 0.7022, 0.7646, 0.6865; mean R2=0.7177\n",
      "Validation Error: Avg loss: 3.905860 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:25.691116 Epoch 927, Training loss 4.479218482971191\n",
      "in params\n",
      "R2 values 0.6302, 0.7607, 0.6036; mean R2=0.6648\n",
      "Validation Error: Avg loss: 4.128073 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:25.990819 Epoch 928, Training loss 3.376556396484375\n",
      "in params\n",
      "R2 values 0.7098, 0.5686, 0.6829; mean R2=0.6538\n",
      "Validation Error: Avg loss: 5.246260 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:26.265448 Epoch 929, Training loss 3.4913413524627686\n",
      "in params\n",
      "R2 values 0.6795, 0.6138, 0.7233; mean R2=0.6722\n",
      "Validation Error: Avg loss: 4.634558 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:26.533981 Epoch 930, Training loss 3.6180531978607178\n",
      "in params\n",
      "R2 values 0.6503, 0.7125, 0.7509; mean R2=0.7045\n",
      "Validation Error: Avg loss: 3.661053 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:26.815394 Epoch 931, Training loss 3.364990711212158\n",
      "in params\n",
      "R2 values 0.6614, 0.7862, 0.7641; mean R2=0.7372\n",
      "Validation Error: Avg loss: 2.996588 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:27.088853 Epoch 932, Training loss 3.4557292461395264\n",
      "in params\n",
      "R2 values 0.7831, 0.7623, 0.7122; mean R2=0.7525\n",
      "Validation Error: Avg loss: 3.172633 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:27.358906 Epoch 933, Training loss 3.1411352157592773\n",
      "in params\n",
      "R2 values 0.6858, 0.5758, 0.6321; mean R2=0.6313\n",
      "Validation Error: Avg loss: 5.355960 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:27.631958 Epoch 934, Training loss 2.9600489139556885\n",
      "in params\n",
      "R2 values 0.7448, 0.8499, 0.7576; mean R2=0.7841\n",
      "Validation Error: Avg loss: 2.675545 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:27.922372 Epoch 935, Training loss 2.738201141357422\n",
      "in params\n",
      "R2 values 0.6169, 0.7324, 0.7105; mean R2=0.6866\n",
      "Validation Error: Avg loss: 3.883641 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:28.202059 Epoch 936, Training loss 3.331336498260498\n",
      "in params\n",
      "R2 values 0.5943, 0.7802, 0.7162; mean R2=0.6969\n",
      "Validation Error: Avg loss: 3.800934 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:28.476349 Epoch 937, Training loss 3.4305005073547363\n",
      "in params\n",
      "R2 values 0.7509, 0.7301, 0.6551; mean R2=0.7120\n",
      "Validation Error: Avg loss: 4.151964 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:28.753836 Epoch 938, Training loss 3.6989529132843018\n",
      "in params\n",
      "R2 values 0.6335, 0.7304, 0.7333; mean R2=0.6991\n",
      "Validation Error: Avg loss: 3.648663 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:29.036857 Epoch 939, Training loss 3.3697283267974854\n",
      "in params\n",
      "R2 values 0.6236, 0.5034, 0.6792; mean R2=0.6021\n",
      "Validation Error: Avg loss: 5.961093 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:29.313685 Epoch 940, Training loss 2.7849278450012207\n",
      "in params\n",
      "R2 values 0.7190, 0.6127, 0.7172; mean R2=0.6829\n",
      "Validation Error: Avg loss: 4.731842 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:29.588786 Epoch 941, Training loss 2.5729496479034424\n",
      "in params\n",
      "R2 values 0.6666, 0.7811, 0.6583; mean R2=0.7020\n",
      "Validation Error: Avg loss: 3.427513 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:29.875776 Epoch 942, Training loss 2.8559727668762207\n",
      "in params\n",
      "R2 values 0.6677, 0.7479, 0.6533; mean R2=0.6896\n",
      "Validation Error: Avg loss: 3.741966 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:30.158996 Epoch 943, Training loss 3.6072635650634766\n",
      "in params\n",
      "R2 values 0.6202, 0.6140, 0.7089; mean R2=0.6477\n",
      "Validation Error: Avg loss: 5.100318 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:30.496472 Epoch 944, Training loss 3.6507389545440674\n",
      "in params\n",
      "R2 values 0.6064, 0.7351, 0.5186; mean R2=0.6200\n",
      "Validation Error: Avg loss: 4.329328 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:30.771119 Epoch 945, Training loss 4.457525253295898\n",
      "in params\n",
      "R2 values 0.7003, 0.7231, 0.7155; mean R2=0.7129\n",
      "Validation Error: Avg loss: 3.950153 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:31.053915 Epoch 946, Training loss 3.906877040863037\n",
      "in params\n",
      "R2 values 0.6794, 0.5371, 0.6692; mean R2=0.6286\n",
      "Validation Error: Avg loss: 5.746014 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:31.334723 Epoch 947, Training loss 3.217778205871582\n",
      "in params\n",
      "R2 values 0.6387, 0.6357, 0.6192; mean R2=0.6312\n",
      "Validation Error: Avg loss: 5.148408 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:31.610658 Epoch 948, Training loss 4.247220516204834\n",
      "in params\n",
      "R2 values 0.7338, 0.7598, 0.7326; mean R2=0.7421\n",
      "Validation Error: Avg loss: 3.205302 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:31.907413 Epoch 949, Training loss 3.454011917114258\n",
      "in params\n",
      "R2 values 0.6764, 0.7306, 0.6237; mean R2=0.6769\n",
      "Validation Error: Avg loss: 4.299139 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:32.185703 Epoch 950, Training loss 3.061361789703369\n",
      "in params\n",
      "R2 values 0.6790, 0.7318, 0.7139; mean R2=0.7082\n",
      "Validation Error: Avg loss: 3.921402 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:32.461273 Epoch 951, Training loss 3.4442553520202637\n",
      "in params\n",
      "R2 values 0.7924, 0.7290, 0.7586; mean R2=0.7600\n",
      "Validation Error: Avg loss: 3.388994 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:32.735707 Epoch 952, Training loss 4.795241832733154\n",
      "in params\n",
      "R2 values 0.6871, 0.6493, 0.7579; mean R2=0.6981\n",
      "Validation Error: Avg loss: 4.304702 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:33.001640 Epoch 953, Training loss 3.478991985321045\n",
      "in params\n",
      "R2 values 0.7200, 0.7596, 0.7084; mean R2=0.7294\n",
      "Validation Error: Avg loss: 3.595109 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:33.283571 Epoch 954, Training loss 3.459388017654419\n",
      "in params\n",
      "R2 values 0.7218, 0.7314, 0.6357; mean R2=0.6963\n",
      "Validation Error: Avg loss: 4.165768 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:33.555457 Epoch 955, Training loss 4.4578857421875\n",
      "in params\n",
      "R2 values 0.5407, 0.8084, 0.5453; mean R2=0.6315\n",
      "Validation Error: Avg loss: 4.022153 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:33.830372 Epoch 956, Training loss 4.222713947296143\n",
      "in params\n",
      "R2 values 0.7377, 0.8112, 0.7595; mean R2=0.7695\n",
      "Validation Error: Avg loss: 3.091549 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:34.101129 Epoch 957, Training loss 2.731581449508667\n",
      "in params\n",
      "R2 values 0.7431, 0.6143, 0.6891; mean R2=0.6822\n",
      "Validation Error: Avg loss: 4.974283 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:34.375102 Epoch 958, Training loss 3.410935401916504\n",
      "in params\n",
      "R2 values 0.7049, 0.7248, 0.6144; mean R2=0.6814\n",
      "Validation Error: Avg loss: 3.996503 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:34.649943 Epoch 959, Training loss 2.8511099815368652\n",
      "in params\n",
      "R2 values 0.7364, 0.7611, 0.7420; mean R2=0.7465\n",
      "Validation Error: Avg loss: 3.146951 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:34.943953 Epoch 960, Training loss 2.7386138439178467\n",
      "in params\n",
      "R2 values 0.5899, 0.6374, 0.6405; mean R2=0.6226\n",
      "Validation Error: Avg loss: 4.730472 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:35.228171 Epoch 961, Training loss 4.091935157775879\n",
      "in params\n",
      "R2 values 0.6924, 0.9183, 0.7151; mean R2=0.7753\n",
      "Validation Error: Avg loss: 2.083807 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:35.504934 Epoch 962, Training loss 4.09882926940918\n",
      "in params\n",
      "R2 values 0.7014, 0.6755, 0.6058; mean R2=0.6609\n",
      "Validation Error: Avg loss: 4.657896 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:35.792713 Epoch 963, Training loss 3.2767093181610107\n",
      "in params\n",
      "R2 values 0.7413, 0.7380, 0.6340; mean R2=0.7044\n",
      "Validation Error: Avg loss: 3.874077 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:36.091292 Epoch 964, Training loss 3.432368040084839\n",
      "in params\n",
      "R2 values 0.7044, 0.7400, 0.6965; mean R2=0.7137\n",
      "Validation Error: Avg loss: 4.723588 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:36.362582 Epoch 965, Training loss 2.7116689682006836\n",
      "in params\n",
      "R2 values 0.6759, 0.8051, 0.6216; mean R2=0.7009\n",
      "Validation Error: Avg loss: 4.430668 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:36.633692 Epoch 966, Training loss 4.150832653045654\n",
      "in params\n",
      "R2 values 0.8402, 0.7413, 0.7304; mean R2=0.7706\n",
      "Validation Error: Avg loss: 4.254895 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:55:36.901516 Epoch 967, Training loss 3.0281646251678467\n",
      "in params\n",
      "R2 values 0.6064, 0.7102, 0.6049; mean R2=0.6405\n",
      "Validation Error: Avg loss: 4.497343 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:37.173470 Epoch 968, Training loss 4.221456050872803\n",
      "in params\n",
      "R2 values 0.6580, 0.6743, 0.6279; mean R2=0.6534\n",
      "Validation Error: Avg loss: 4.428463 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:37.443653 Epoch 969, Training loss 4.273964881896973\n",
      "in params\n",
      "R2 values 0.6498, 0.6900, 0.6785; mean R2=0.6728\n",
      "Validation Error: Avg loss: 4.230469 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:37.718910 Epoch 970, Training loss 4.254879474639893\n",
      "in params\n",
      "R2 values 0.7029, 0.7547, 0.6599; mean R2=0.7058\n",
      "Validation Error: Avg loss: 3.759081 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:37.996052 Epoch 971, Training loss 2.792167901992798\n",
      "in params\n",
      "R2 values 0.6256, 0.7872, 0.6171; mean R2=0.6766\n",
      "Validation Error: Avg loss: 3.637178 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:38.274227 Epoch 972, Training loss 2.6579811573028564\n",
      "in params\n",
      "R2 values 0.7274, 0.6488, 0.6186; mean R2=0.6649\n",
      "Validation Error: Avg loss: 4.926110 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:38.539282 Epoch 973, Training loss 4.29013729095459\n",
      "in params\n",
      "R2 values 0.5908, 0.6731, 0.6493; mean R2=0.6377\n",
      "Validation Error: Avg loss: 4.444857 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:38.814128 Epoch 974, Training loss 2.356841564178467\n",
      "in params\n",
      "R2 values 0.5949, 0.6190, 0.5787; mean R2=0.5975\n",
      "Validation Error: Avg loss: 5.209483 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:39.089985 Epoch 975, Training loss 3.870156764984131\n",
      "in params\n",
      "R2 values 0.6130, 0.6996, 0.6020; mean R2=0.6382\n",
      "Validation Error: Avg loss: 4.773501 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:39.377701 Epoch 976, Training loss 2.9115731716156006\n",
      "in params\n",
      "R2 values 0.6365, 0.7537, 0.6371; mean R2=0.6758\n",
      "Validation Error: Avg loss: 3.746954 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:39.655827 Epoch 977, Training loss 3.5465965270996094\n",
      "in params\n",
      "R2 values 0.6566, 0.6882, 0.7478; mean R2=0.6976\n",
      "Validation Error: Avg loss: 4.741668 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:39.948072 Epoch 978, Training loss 2.8792126178741455\n",
      "in params\n",
      "R2 values 0.6184, 0.7625, 0.6985; mean R2=0.6932\n",
      "Validation Error: Avg loss: 3.712083 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:40.231800 Epoch 979, Training loss 3.007509469985962\n",
      "in params\n",
      "R2 values 0.6986, 0.7536, 0.5988; mean R2=0.6836\n",
      "Validation Error: Avg loss: 4.207501 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:40.509392 Epoch 980, Training loss 4.089637279510498\n",
      "in params\n",
      "R2 values 0.6584, 0.6160, 0.5746; mean R2=0.6163\n",
      "Validation Error: Avg loss: 5.347976 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:40.794036 Epoch 981, Training loss 2.9641904830932617\n",
      "in params\n",
      "R2 values 0.6037, 0.7192, 0.6179; mean R2=0.6469\n",
      "Validation Error: Avg loss: 4.708880 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:41.074392 Epoch 982, Training loss 2.7573204040527344\n",
      "in params\n",
      "R2 values 0.6659, 0.7931, 0.7210; mean R2=0.7267\n",
      "Validation Error: Avg loss: 3.499130 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:41.349825 Epoch 983, Training loss 3.4481382369995117\n",
      "in params\n",
      "R2 values 0.6181, 0.6573, 0.6543; mean R2=0.6432\n",
      "Validation Error: Avg loss: 4.620886 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:41.632727 Epoch 984, Training loss 4.128218173980713\n",
      "in params\n",
      "R2 values 0.6962, 0.6307, 0.5873; mean R2=0.6381\n",
      "Validation Error: Avg loss: 5.005470 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:41.905212 Epoch 985, Training loss 3.757314682006836\n",
      "in params\n",
      "R2 values 0.6801, 0.7388, 0.7125; mean R2=0.7105\n",
      "Validation Error: Avg loss: 3.783099 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:42.179476 Epoch 986, Training loss 3.9697012901306152\n",
      "in params\n",
      "R2 values 0.6720, 0.8571, 0.6679; mean R2=0.7324\n",
      "Validation Error: Avg loss: 2.925655 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:42.458927 Epoch 987, Training loss 3.9889540672302246\n",
      "in params\n",
      "R2 values 0.6885, 0.6913, 0.6494; mean R2=0.6764\n",
      "Validation Error: Avg loss: 4.259714 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:42.734981 Epoch 988, Training loss 3.4090516567230225\n",
      "in params\n",
      "R2 values 0.7281, 0.6986, 0.6654; mean R2=0.6974\n",
      "Validation Error: Avg loss: 4.135734 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:43.009571 Epoch 989, Training loss 5.15817928314209\n",
      "in params\n",
      "R2 values 0.7234, 0.7216, 0.7438; mean R2=0.7296\n",
      "Validation Error: Avg loss: 3.749931 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:43.281190 Epoch 990, Training loss 3.710736036300659\n",
      "in params\n",
      "R2 values 0.6211, 0.7082, 0.5833; mean R2=0.6375\n",
      "Validation Error: Avg loss: 4.479044 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:43.562577 Epoch 991, Training loss 3.5132410526275635\n",
      "in params\n",
      "R2 values 0.6696, 0.6325, 0.6044; mean R2=0.6355\n",
      "Validation Error: Avg loss: 4.902959 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:43.840622 Epoch 992, Training loss 3.830906391143799\n",
      "in params\n",
      "R2 values 0.6879, 0.6946, 0.6304; mean R2=0.6710\n",
      "Validation Error: Avg loss: 4.139333 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:44.137433 Epoch 993, Training loss 3.629490852355957\n",
      "in params\n",
      "R2 values 0.4821, 0.5363, 0.5491; mean R2=0.5225\n",
      "Validation Error: Avg loss: 6.134194 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:44.419166 Epoch 994, Training loss 3.8905131816864014\n",
      "in params\n",
      "R2 values 0.5380, 0.6928, 0.5806; mean R2=0.6038\n",
      "Validation Error: Avg loss: 4.539574 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:44.696001 Epoch 995, Training loss 2.6398580074310303\n",
      "in params\n",
      "R2 values 0.6220, 0.7240, 0.7111; mean R2=0.6857\n",
      "Validation Error: Avg loss: 3.689360 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:44.976870 Epoch 996, Training loss 3.0692052841186523\n",
      "in params\n",
      "R2 values 0.6634, 0.7506, 0.7212; mean R2=0.7117\n",
      "Validation Error: Avg loss: 3.427294 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:45.247751 Epoch 997, Training loss 3.052764892578125\n",
      "in params\n",
      "R2 values 0.6108, 0.6629, 0.7779; mean R2=0.6839\n",
      "Validation Error: Avg loss: 4.307628 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:45.521903 Epoch 998, Training loss 3.7937090396881104\n",
      "in params\n",
      "R2 values 0.7121, 0.6614, 0.6608; mean R2=0.6781\n",
      "Validation Error: Avg loss: 4.651994 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:45.796332 Epoch 999, Training loss 4.022509574890137\n",
      "in params\n",
      "R2 values 0.6699, 0.5712, 0.6031; mean R2=0.6148\n",
      "Validation Error: Avg loss: 5.529798 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:46.081389 Epoch 1000, Training loss 3.578357219696045\n",
      "in params\n",
      "R2 values 0.7367, 0.7024, 0.6877; mean R2=0.7089\n",
      "Validation Error: Avg loss: 4.254319 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:46.356441 Epoch 1001, Training loss 3.1889612674713135\n",
      "in params\n",
      "R2 values 0.6582, 0.7228, 0.6264; mean R2=0.6691\n",
      "Validation Error: Avg loss: 4.124425 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:46.632093 Epoch 1002, Training loss 4.744430065155029\n",
      "in params\n",
      "R2 values 0.6678, 0.7818, 0.6677; mean R2=0.7057\n",
      "Validation Error: Avg loss: 3.292169 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:46.908020 Epoch 1003, Training loss 3.7303385734558105\n",
      "in params\n",
      "R2 values 0.6416, 0.6629, 0.6526; mean R2=0.6524\n",
      "Validation Error: Avg loss: 4.472856 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:47.184672 Epoch 1004, Training loss 2.643131971359253\n",
      "in params\n",
      "R2 values 0.6560, 0.6348, 0.5875; mean R2=0.6261\n",
      "Validation Error: Avg loss: 4.926918 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:47.459845 Epoch 1005, Training loss 3.6058132648468018\n",
      "in params\n",
      "R2 values 0.6730, 0.7136, 0.6565; mean R2=0.6810\n",
      "Validation Error: Avg loss: 3.960701 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:47.734550 Epoch 1006, Training loss 3.3295974731445312\n",
      "in params\n",
      "R2 values 0.5702, 0.7386, 0.6399; mean R2=0.6496\n",
      "Validation Error: Avg loss: 4.018401 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:48.017857 Epoch 1007, Training loss 4.364083290100098\n",
      "in params\n",
      "R2 values 0.7228, 0.7220, 0.7253; mean R2=0.7233\n",
      "Validation Error: Avg loss: 3.600035 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:48.290688 Epoch 1008, Training loss 4.283517837524414\n",
      "in params\n",
      "R2 values 0.6919, 0.6459, 0.7197; mean R2=0.6859\n",
      "Validation Error: Avg loss: 4.959555 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:48.566757 Epoch 1009, Training loss 3.2888872623443604\n",
      "in params\n",
      "R2 values 0.5982, 0.7631, 0.6279; mean R2=0.6631\n",
      "Validation Error: Avg loss: 4.066339 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:48.849496 Epoch 1010, Training loss 4.276024341583252\n",
      "in params\n",
      "R2 values 0.7369, 0.6627, 0.7254; mean R2=0.7083\n",
      "Validation Error: Avg loss: 4.339768 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:49.120875 Epoch 1011, Training loss 5.465138912200928\n",
      "in params\n",
      "R2 values 0.7824, 0.7765, 0.7612; mean R2=0.7734\n",
      "Validation Error: Avg loss: 3.582050 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:49.400089 Epoch 1012, Training loss 3.2889254093170166\n",
      "in params\n",
      "R2 values 0.6470, 0.6960, 0.5940; mean R2=0.6457\n",
      "Validation Error: Avg loss: 4.810338 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:55:49.689389 Epoch 1013, Training loss 3.6945888996124268\n",
      "in params\n",
      "R2 values 0.7344, 0.6938, 0.7320; mean R2=0.7201\n",
      "Validation Error: Avg loss: 3.983126 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:49.997667 Epoch 1014, Training loss 3.0612738132476807\n",
      "in params\n",
      "R2 values 0.6429, 0.7222, 0.5824; mean R2=0.6491\n",
      "Validation Error: Avg loss: 4.556283 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:50.325657 Epoch 1015, Training loss 3.069959878921509\n",
      "in params\n",
      "R2 values 0.6372, 0.6323, 0.5281; mean R2=0.5992\n",
      "Validation Error: Avg loss: 5.430731 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:50.606121 Epoch 1016, Training loss 3.8678572177886963\n",
      "in params\n",
      "R2 values 0.6782, 0.6719, 0.6094; mean R2=0.6531\n",
      "Validation Error: Avg loss: 4.549334 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:50.881006 Epoch 1017, Training loss 3.398606061935425\n",
      "in params\n",
      "R2 values 0.5768, 0.5711, 0.5121; mean R2=0.5533\n",
      "Validation Error: Avg loss: 6.046294 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:51.166582 Epoch 1018, Training loss 3.966078519821167\n",
      "in params\n",
      "R2 values 0.6634, 0.7141, 0.6462; mean R2=0.6746\n",
      "Validation Error: Avg loss: 4.662908 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:51.436619 Epoch 1019, Training loss 4.207552909851074\n",
      "in params\n",
      "R2 values 0.6349, 0.7038, 0.6354; mean R2=0.6581\n",
      "Validation Error: Avg loss: 4.671077 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:51.708632 Epoch 1020, Training loss 3.0585663318634033\n",
      "in params\n",
      "R2 values 0.6891, 0.5881, 0.6979; mean R2=0.6584\n",
      "Validation Error: Avg loss: 5.017415 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:51.987169 Epoch 1021, Training loss 3.623967409133911\n",
      "in params\n",
      "R2 values 0.7149, 0.7996, 0.7013; mean R2=0.7386\n",
      "Validation Error: Avg loss: 3.192267 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:52.264471 Epoch 1022, Training loss 4.0120038986206055\n",
      "in params\n",
      "R2 values 0.6670, 0.6727, 0.5923; mean R2=0.6440\n",
      "Validation Error: Avg loss: 5.148197 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:52.542561 Epoch 1023, Training loss 3.4809255599975586\n",
      "in params\n",
      "R2 values 0.7056, 0.7056, 0.7208; mean R2=0.7107\n",
      "Validation Error: Avg loss: 3.952463 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:52.837296 Epoch 1024, Training loss 4.007781505584717\n",
      "in params\n",
      "R2 values 0.6548, 0.7905, 0.7755; mean R2=0.7403\n",
      "Validation Error: Avg loss: 2.909902 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:53.128552 Epoch 1025, Training loss 3.3892078399658203\n",
      "in params\n",
      "R2 values 0.6059, 0.6600, 0.7010; mean R2=0.6557\n",
      "Validation Error: Avg loss: 4.487881 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:53.405257 Epoch 1026, Training loss 2.7520651817321777\n",
      "in params\n",
      "R2 values 0.7709, 0.8278, 0.7138; mean R2=0.7708\n",
      "Validation Error: Avg loss: 2.691780 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:53.677655 Epoch 1027, Training loss 2.5497894287109375\n",
      "in params\n",
      "R2 values 0.6854, 0.7243, 0.6125; mean R2=0.6741\n",
      "Validation Error: Avg loss: 3.941558 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:53.956950 Epoch 1028, Training loss 3.1974785327911377\n",
      "in params\n",
      "R2 values 0.7989, 0.7681, 0.6902; mean R2=0.7524\n",
      "Validation Error: Avg loss: 4.102060 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:54.235556 Epoch 1029, Training loss 3.8245391845703125\n",
      "in params\n",
      "R2 values 0.7137, 0.7456, 0.6804; mean R2=0.7132\n",
      "Validation Error: Avg loss: 3.891828 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:54.513276 Epoch 1030, Training loss 5.061425685882568\n",
      "in params\n",
      "R2 values 0.6247, 0.7429, 0.6272; mean R2=0.6649\n",
      "Validation Error: Avg loss: 3.847108 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:54.794314 Epoch 1031, Training loss 3.533413887023926\n",
      "in params\n",
      "R2 values 0.6735, 0.7025, 0.6357; mean R2=0.6706\n",
      "Validation Error: Avg loss: 4.160682 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:55.072522 Epoch 1032, Training loss 3.9644317626953125\n",
      "in params\n",
      "R2 values 0.5980, 0.7230, 0.6899; mean R2=0.6703\n",
      "Validation Error: Avg loss: 3.978285 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:55.346363 Epoch 1033, Training loss 3.644150495529175\n",
      "in params\n",
      "R2 values 0.7614, 0.7834, 0.7234; mean R2=0.7561\n",
      "Validation Error: Avg loss: 3.020944 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:55.624878 Epoch 1034, Training loss 4.0729594230651855\n",
      "in params\n",
      "R2 values 0.5931, 0.5758, 0.5379; mean R2=0.5689\n",
      "Validation Error: Avg loss: 5.845058 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:55.896410 Epoch 1035, Training loss 4.146246910095215\n",
      "in params\n",
      "R2 values 0.7807, 0.8186, 0.7123; mean R2=0.7705\n",
      "Validation Error: Avg loss: 2.793342 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:56.182058 Epoch 1036, Training loss 3.145071029663086\n",
      "in params\n",
      "R2 values 0.7390, 0.7130, 0.7026; mean R2=0.7182\n",
      "Validation Error: Avg loss: 3.662453 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:56.455647 Epoch 1037, Training loss 3.0283734798431396\n",
      "in params\n",
      "R2 values 0.6182, 0.7209, 0.6226; mean R2=0.6539\n",
      "Validation Error: Avg loss: 4.687879 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:56.728852 Epoch 1038, Training loss 3.589695692062378\n",
      "in params\n",
      "R2 values 0.6897, 0.6278, 0.7125; mean R2=0.6766\n",
      "Validation Error: Avg loss: 4.643722 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:57.001507 Epoch 1039, Training loss 3.4263689517974854\n",
      "in params\n",
      "R2 values 0.6891, 0.7121, 0.7617; mean R2=0.7209\n",
      "Validation Error: Avg loss: 4.609394 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:57.271849 Epoch 1040, Training loss 3.430192708969116\n",
      "in params\n",
      "R2 values 0.6577, 0.6918, 0.6485; mean R2=0.6660\n",
      "Validation Error: Avg loss: 4.364368 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:57.539962 Epoch 1041, Training loss 4.18919563293457\n",
      "in params\n",
      "R2 values 0.7344, 0.7101, 0.6751; mean R2=0.7065\n",
      "Validation Error: Avg loss: 3.855541 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:57.814906 Epoch 1042, Training loss 2.93072772026062\n",
      "in params\n",
      "R2 values 0.6471, 0.8031, 0.7157; mean R2=0.7220\n",
      "Validation Error: Avg loss: 2.974701 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:58.079862 Epoch 1043, Training loss 3.157628059387207\n",
      "in params\n",
      "R2 values 0.6826, 0.5162, 0.6046; mean R2=0.6011\n",
      "Validation Error: Avg loss: 5.843701 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:58.367421 Epoch 1044, Training loss 3.2835121154785156\n",
      "in params\n",
      "R2 values 0.6803, 0.7020, 0.6736; mean R2=0.6853\n",
      "Validation Error: Avg loss: 3.976586 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:58.668766 Epoch 1045, Training loss 2.9446818828582764\n",
      "in params\n",
      "R2 values 0.6642, 0.7661, 0.6113; mean R2=0.6806\n",
      "Validation Error: Avg loss: 3.783765 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:58.950037 Epoch 1046, Training loss 2.8359999656677246\n",
      "in params\n",
      "R2 values 0.6451, 0.7597, 0.5993; mean R2=0.6680\n",
      "Validation Error: Avg loss: 4.032134 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:59.225458 Epoch 1047, Training loss 2.918524742126465\n",
      "in params\n",
      "R2 values 0.7135, 0.6576, 0.7640; mean R2=0.7117\n",
      "Validation Error: Avg loss: 4.282852 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:59.491337 Epoch 1048, Training loss 3.5310111045837402\n",
      "in params\n",
      "R2 values 0.8163, 0.6710, 0.7077; mean R2=0.7317\n",
      "Validation Error: Avg loss: 6.056858 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:55:59.774959 Epoch 1049, Training loss 5.108316421508789\n",
      "in params\n",
      "R2 values 0.7097, 0.7773, 0.7111; mean R2=0.7327\n",
      "Validation Error: Avg loss: 3.788147 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:00.074001 Epoch 1050, Training loss 2.9058732986450195\n",
      "in params\n",
      "R2 values 0.6728, 0.6183, 0.6221; mean R2=0.6377\n",
      "Validation Error: Avg loss: 5.397874 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:00.347857 Epoch 1051, Training loss 3.9620296955108643\n",
      "in params\n",
      "R2 values 0.6662, 0.7356, 0.6573; mean R2=0.6863\n",
      "Validation Error: Avg loss: 4.254587 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:00.612836 Epoch 1052, Training loss 3.3494327068328857\n",
      "in params\n",
      "R2 values 0.7267, 0.6696, 0.7009; mean R2=0.6991\n",
      "Validation Error: Avg loss: 4.117907 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:00.885695 Epoch 1053, Training loss 3.0231921672821045\n",
      "in params\n",
      "R2 values 0.6311, 0.7126, 0.6003; mean R2=0.6480\n",
      "Validation Error: Avg loss: 4.356422 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:01.169922 Epoch 1054, Training loss 3.1360762119293213\n",
      "in params\n",
      "R2 values 0.6212, 0.5961, 0.6686; mean R2=0.6286\n",
      "Validation Error: Avg loss: 4.958172 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:01.442433 Epoch 1055, Training loss 3.1159956455230713\n",
      "in params\n",
      "R2 values 0.6782, 0.8767, 0.6557; mean R2=0.7369\n",
      "Validation Error: Avg loss: 2.528437 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:01.723254 Epoch 1056, Training loss 3.8676397800445557\n",
      "in params\n",
      "R2 values 0.5901, 0.7587, 0.5424; mean R2=0.6304\n",
      "Validation Error: Avg loss: 3.989527 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:02.022067 Epoch 1057, Training loss 3.316953420639038\n",
      "in params\n",
      "R2 values 0.7243, 0.7200, 0.6695; mean R2=0.7046\n",
      "Validation Error: Avg loss: 4.226735 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:02.291474 Epoch 1058, Training loss 3.211793899536133\n",
      "in params\n",
      "R2 values 0.7143, 0.7150, 0.6905; mean R2=0.7066\n",
      "Validation Error: Avg loss: 4.818711 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:56:02.565314 Epoch 1059, Training loss 3.5733020305633545\n",
      "in params\n",
      "R2 values 0.5373, 0.6985, 0.6156; mean R2=0.6171\n",
      "Validation Error: Avg loss: 4.685228 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:02.838915 Epoch 1060, Training loss 3.1311192512512207\n",
      "in params\n",
      "R2 values 0.6081, 0.6468, 0.6266; mean R2=0.6272\n",
      "Validation Error: Avg loss: 4.946675 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:03.107130 Epoch 1061, Training loss 3.7201011180877686\n",
      "in params\n",
      "R2 values 0.6387, 0.7211, 0.6802; mean R2=0.6800\n",
      "Validation Error: Avg loss: 3.949757 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:03.383265 Epoch 1062, Training loss 2.8129498958587646\n",
      "in params\n",
      "R2 values 0.6958, 0.7332, 0.7368; mean R2=0.7219\n",
      "Validation Error: Avg loss: 3.665478 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:03.662269 Epoch 1063, Training loss 3.3702852725982666\n",
      "in params\n",
      "R2 values 0.6541, 0.6941, 0.6797; mean R2=0.6760\n",
      "Validation Error: Avg loss: 4.131394 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:03.939692 Epoch 1064, Training loss 2.597750186920166\n",
      "in params\n",
      "R2 values 0.7116, 0.6806, 0.6504; mean R2=0.6809\n",
      "Validation Error: Avg loss: 4.242550 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:04.212574 Epoch 1065, Training loss 3.594008207321167\n",
      "in params\n",
      "R2 values 0.6942, 0.6660, 0.6783; mean R2=0.6795\n",
      "Validation Error: Avg loss: 4.740455 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:04.483567 Epoch 1066, Training loss 4.062999248504639\n",
      "in params\n",
      "R2 values 0.7839, 0.7806, 0.7430; mean R2=0.7692\n",
      "Validation Error: Avg loss: 3.610433 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:04.760838 Epoch 1067, Training loss 3.1697070598602295\n",
      "in params\n",
      "R2 values 0.7121, 0.6132, 0.6472; mean R2=0.6575\n",
      "Validation Error: Avg loss: 5.045691 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:05.031749 Epoch 1068, Training loss 3.6847152709960938\n",
      "in params\n",
      "R2 values 0.6750, 0.6438, 0.7316; mean R2=0.6835\n",
      "Validation Error: Avg loss: 4.801107 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:05.311168 Epoch 1069, Training loss 4.524611473083496\n",
      "in params\n",
      "R2 values 0.7004, 0.7420, 0.6791; mean R2=0.7072\n",
      "Validation Error: Avg loss: 4.109920 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:05.584933 Epoch 1070, Training loss 4.155646800994873\n",
      "in params\n",
      "R2 values 0.7177, 0.7502, 0.6736; mean R2=0.7138\n",
      "Validation Error: Avg loss: 3.915236 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:05.865232 Epoch 1071, Training loss 3.306025981903076\n",
      "in params\n",
      "R2 values 0.6540, 0.7561, 0.6153; mean R2=0.6751\n",
      "Validation Error: Avg loss: 3.891664 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:06.141604 Epoch 1072, Training loss 3.345240831375122\n",
      "in params\n",
      "R2 values 0.6972, 0.6899, 0.6935; mean R2=0.6935\n",
      "Validation Error: Avg loss: 4.069703 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:06.421733 Epoch 1073, Training loss 3.440648078918457\n",
      "in params\n",
      "R2 values 0.6986, 0.6496, 0.6845; mean R2=0.6776\n",
      "Validation Error: Avg loss: 4.450297 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:06.705057 Epoch 1074, Training loss 3.4445817470550537\n",
      "in params\n",
      "R2 values 0.6872, 0.6522, 0.5903; mean R2=0.6432\n",
      "Validation Error: Avg loss: 4.745438 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:07.004694 Epoch 1075, Training loss 3.4847047328948975\n",
      "in params\n",
      "R2 values 0.7700, 0.8233, 0.7294; mean R2=0.7742\n",
      "Validation Error: Avg loss: 2.732826 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:07.279692 Epoch 1076, Training loss 2.6612584590911865\n",
      "in params\n",
      "R2 values 0.6823, 0.7332, 0.5929; mean R2=0.6695\n",
      "Validation Error: Avg loss: 4.206244 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:07.548153 Epoch 1077, Training loss 2.567690849304199\n",
      "in params\n",
      "R2 values 0.6282, 0.7321, 0.7117; mean R2=0.6907\n",
      "Validation Error: Avg loss: 3.785056 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:07.827368 Epoch 1078, Training loss 3.9474480152130127\n",
      "in params\n",
      "R2 values 0.7422, 0.5308, 0.6532; mean R2=0.6421\n",
      "Validation Error: Avg loss: 5.772762 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:08.130465 Epoch 1079, Training loss 3.2167367935180664\n",
      "in params\n",
      "R2 values 0.6458, 0.7462, 0.6320; mean R2=0.6747\n",
      "Validation Error: Avg loss: 4.445953 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:08.408464 Epoch 1080, Training loss 3.6146883964538574\n",
      "in params\n",
      "R2 values 0.7257, 0.7520, 0.7009; mean R2=0.7262\n",
      "Validation Error: Avg loss: 3.422458 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:08.690329 Epoch 1081, Training loss 2.751215696334839\n",
      "in params\n",
      "R2 values 0.6782, 0.6637, 0.6423; mean R2=0.6614\n",
      "Validation Error: Avg loss: 4.504765 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:08.963137 Epoch 1082, Training loss 3.6696276664733887\n",
      "in params\n",
      "R2 values 0.7080, 0.7607, 0.6366; mean R2=0.7018\n",
      "Validation Error: Avg loss: 3.588225 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:09.240704 Epoch 1083, Training loss 3.176605224609375\n",
      "in params\n",
      "R2 values 0.7500, 0.7054, 0.6063; mean R2=0.6872\n",
      "Validation Error: Avg loss: 4.123784 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:09.528023 Epoch 1084, Training loss 2.8583624362945557\n",
      "in params\n",
      "R2 values 0.7048, 0.8113, 0.7056; mean R2=0.7406\n",
      "Validation Error: Avg loss: 3.257486 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:09.806457 Epoch 1085, Training loss 3.736375331878662\n",
      "in params\n",
      "R2 values 0.6660, 0.6882, 0.7076; mean R2=0.6873\n",
      "Validation Error: Avg loss: 4.239835 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:10.116044 Epoch 1086, Training loss 4.873589515686035\n",
      "in params\n",
      "R2 values 0.6717, 0.7687, 0.7048; mean R2=0.7151\n",
      "Validation Error: Avg loss: 3.385439 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:10.398625 Epoch 1087, Training loss 2.7340145111083984\n",
      "in params\n",
      "R2 values 0.7251, 0.8229, 0.7754; mean R2=0.7745\n",
      "Validation Error: Avg loss: 3.325659 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:10.685794 Epoch 1088, Training loss 2.8704893589019775\n",
      "in params\n",
      "R2 values 0.7125, 0.6447, 0.6107; mean R2=0.6559\n",
      "Validation Error: Avg loss: 5.261501 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:10.982728 Epoch 1089, Training loss 3.332343578338623\n",
      "in params\n",
      "R2 values 0.6680, 0.6699, 0.6815; mean R2=0.6731\n",
      "Validation Error: Avg loss: 5.115170 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:11.266412 Epoch 1090, Training loss 4.075640678405762\n",
      "in params\n",
      "R2 values 0.7268, 0.8151, 0.7118; mean R2=0.7512\n",
      "Validation Error: Avg loss: 4.101792 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:11.537509 Epoch 1091, Training loss 3.404113292694092\n",
      "in params\n",
      "R2 values 0.7270, 0.6461, 0.6756; mean R2=0.6829\n",
      "Validation Error: Avg loss: 5.694387 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:11.812690 Epoch 1092, Training loss 3.476919651031494\n",
      "in params\n",
      "R2 values 0.7422, 0.7459, 0.7452; mean R2=0.7444\n",
      "Validation Error: Avg loss: 3.350981 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:12.091492 Epoch 1093, Training loss 3.863830089569092\n",
      "in params\n",
      "R2 values 0.6875, 0.7640, 0.6333; mean R2=0.6949\n",
      "Validation Error: Avg loss: 3.609237 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:12.365901 Epoch 1094, Training loss 3.586550712585449\n",
      "in params\n",
      "R2 values 0.7187, 0.6851, 0.6666; mean R2=0.6901\n",
      "Validation Error: Avg loss: 4.210759 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:12.634373 Epoch 1095, Training loss 3.059784412384033\n",
      "in params\n",
      "R2 values 0.6824, 0.7538, 0.6479; mean R2=0.6947\n",
      "Validation Error: Avg loss: 3.596446 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:12.907542 Epoch 1096, Training loss 2.391120672225952\n",
      "in params\n",
      "R2 values 0.6860, 0.7623, 0.6129; mean R2=0.6871\n",
      "Validation Error: Avg loss: 3.582722 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:13.175362 Epoch 1097, Training loss 3.554651975631714\n",
      "in params\n",
      "R2 values 0.7072, 0.5554, 0.7049; mean R2=0.6558\n",
      "Validation Error: Avg loss: 5.246041 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:13.449580 Epoch 1098, Training loss 2.941624641418457\n",
      "in params\n",
      "R2 values 0.6867, 0.7747, 0.6429; mean R2=0.7014\n",
      "Validation Error: Avg loss: 3.444845 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:13.722354 Epoch 1099, Training loss 3.9543707370758057\n",
      "in params\n",
      "R2 values 0.6893, 0.6623, 0.7414; mean R2=0.6977\n",
      "Validation Error: Avg loss: 4.353300 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:13.991659 Epoch 1100, Training loss 3.587557554244995\n",
      "in params\n",
      "R2 values 0.5855, 0.6694, 0.5848; mean R2=0.6132\n",
      "Validation Error: Avg loss: 5.194860 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:14.263989 Epoch 1101, Training loss 4.2920451164245605\n",
      "in params\n",
      "R2 values 0.6148, 0.7572, 0.6592; mean R2=0.6771\n",
      "Validation Error: Avg loss: 3.593231 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:14.533776 Epoch 1102, Training loss 3.481515645980835\n",
      "in params\n",
      "R2 values 0.6725, 0.8116, 0.6900; mean R2=0.7247\n",
      "Validation Error: Avg loss: 3.060306 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:14.824621 Epoch 1103, Training loss 3.4126265048980713\n",
      "in params\n",
      "R2 values 0.6449, 0.8323, 0.6394; mean R2=0.7055\n",
      "Validation Error: Avg loss: 2.970227 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:15.100796 Epoch 1104, Training loss 3.6559691429138184\n",
      "in params\n",
      "R2 values 0.7402, 0.7416, 0.7271; mean R2=0.7363\n",
      "Validation Error: Avg loss: 3.554594 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:56:15.371795 Epoch 1105, Training loss 3.0554184913635254\n",
      "in params\n",
      "R2 values 0.7360, 0.8026, 0.7355; mean R2=0.7580\n",
      "Validation Error: Avg loss: 2.884780 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:15.647003 Epoch 1106, Training loss 2.883162021636963\n",
      "in params\n",
      "R2 values 0.6719, 0.6522, 0.6310; mean R2=0.6517\n",
      "Validation Error: Avg loss: 4.948191 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:15.924430 Epoch 1107, Training loss 2.6987318992614746\n",
      "in params\n",
      "R2 values 0.6439, 0.7347, 0.6060; mean R2=0.6615\n",
      "Validation Error: Avg loss: 4.158712 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:16.189522 Epoch 1108, Training loss 3.0155582427978516\n",
      "in params\n",
      "R2 values 0.6831, 0.6841, 0.7010; mean R2=0.6894\n",
      "Validation Error: Avg loss: 4.255717 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:16.475589 Epoch 1109, Training loss 3.661869525909424\n",
      "in params\n",
      "R2 values 0.6268, 0.6732, 0.6385; mean R2=0.6462\n",
      "Validation Error: Avg loss: 5.285937 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:16.745114 Epoch 1110, Training loss 2.747004508972168\n",
      "in params\n",
      "R2 values 0.7518, 0.6215, 0.7459; mean R2=0.7064\n",
      "Validation Error: Avg loss: 4.637372 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:17.023748 Epoch 1111, Training loss 3.9977853298187256\n",
      "in params\n",
      "R2 values 0.6660, 0.6410, 0.7260; mean R2=0.6777\n",
      "Validation Error: Avg loss: 5.272505 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:17.311517 Epoch 1112, Training loss 4.822902202606201\n",
      "in params\n",
      "R2 values 0.6810, 0.7565, 0.6775; mean R2=0.7050\n",
      "Validation Error: Avg loss: 3.593053 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:17.594919 Epoch 1113, Training loss 2.983501672744751\n",
      "in params\n",
      "R2 values 0.6241, 0.6680, 0.5921; mean R2=0.6281\n",
      "Validation Error: Avg loss: 4.682809 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:17.868992 Epoch 1114, Training loss 3.2999508380889893\n",
      "in params\n",
      "R2 values 0.5802, 0.7018, 0.5926; mean R2=0.6248\n",
      "Validation Error: Avg loss: 4.419063 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:18.172168 Epoch 1115, Training loss 4.971135139465332\n",
      "in params\n",
      "R2 values 0.5534, 0.6486, 0.6373; mean R2=0.6131\n",
      "Validation Error: Avg loss: 4.738255 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:18.446060 Epoch 1116, Training loss 3.287771463394165\n",
      "in params\n",
      "R2 values 0.6016, 0.5390, 0.5456; mean R2=0.5621\n",
      "Validation Error: Avg loss: 5.910298 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:18.729193 Epoch 1117, Training loss 2.7371463775634766\n",
      "in params\n",
      "R2 values 0.5091, 0.6811, 0.6324; mean R2=0.6075\n",
      "Validation Error: Avg loss: 4.906290 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:19.010874 Epoch 1118, Training loss 3.6588916778564453\n",
      "in params\n",
      "R2 values 0.6426, 0.6874, 0.6971; mean R2=0.6757\n",
      "Validation Error: Avg loss: 4.251316 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:19.286343 Epoch 1119, Training loss 4.2597737312316895\n",
      "in params\n",
      "R2 values 0.6930, 0.6813, 0.7147; mean R2=0.6963\n",
      "Validation Error: Avg loss: 4.228426 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:19.570113 Epoch 1120, Training loss 3.302456855773926\n",
      "in params\n",
      "R2 values 0.6043, 0.6416, 0.5850; mean R2=0.6103\n",
      "Validation Error: Avg loss: 5.408544 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:19.861722 Epoch 1121, Training loss 3.691073417663574\n",
      "in params\n",
      "R2 values 0.7218, 0.7276, 0.7281; mean R2=0.7258\n",
      "Validation Error: Avg loss: 3.615228 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:20.168364 Epoch 1122, Training loss 3.3537821769714355\n",
      "in params\n",
      "R2 values 0.5479, 0.7572, 0.7139; mean R2=0.6730\n",
      "Validation Error: Avg loss: 3.600024 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:20.448036 Epoch 1123, Training loss 2.818784713745117\n",
      "in params\n",
      "R2 values 0.7627, 0.8324, 0.7652; mean R2=0.7867\n",
      "Validation Error: Avg loss: 2.452825 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:20.721773 Epoch 1124, Training loss 2.837045669555664\n",
      "in params\n",
      "R2 values 0.6998, 0.7792, 0.6072; mean R2=0.6954\n",
      "Validation Error: Avg loss: 3.626604 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:21.000676 Epoch 1125, Training loss 2.738039016723633\n",
      "in params\n",
      "R2 values 0.7153, 0.7483, 0.6606; mean R2=0.7081\n",
      "Validation Error: Avg loss: 3.521851 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:21.273052 Epoch 1126, Training loss 3.158313274383545\n",
      "in params\n",
      "R2 values 0.6257, 0.6842, 0.7456; mean R2=0.6852\n",
      "Validation Error: Avg loss: 4.055523 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:21.557544 Epoch 1127, Training loss 3.118490695953369\n",
      "in params\n",
      "R2 values 0.6287, 0.5751, 0.6133; mean R2=0.6057\n",
      "Validation Error: Avg loss: 5.816903 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:21.835977 Epoch 1128, Training loss 4.112893581390381\n",
      "in params\n",
      "R2 values 0.6014, 0.6436, 0.7220; mean R2=0.6557\n",
      "Validation Error: Avg loss: 5.466343 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:22.114811 Epoch 1129, Training loss 3.665220260620117\n",
      "in params\n",
      "R2 values 0.7748, 0.6456, 0.7236; mean R2=0.7147\n",
      "Validation Error: Avg loss: 4.582797 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:22.385712 Epoch 1130, Training loss 2.777900218963623\n",
      "in params\n",
      "R2 values 0.6018, 0.5466, 0.6498; mean R2=0.5994\n",
      "Validation Error: Avg loss: 5.705287 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:22.662371 Epoch 1131, Training loss 4.029447078704834\n",
      "in params\n",
      "R2 values 0.7187, 0.7503, 0.7443; mean R2=0.7378\n",
      "Validation Error: Avg loss: 3.340788 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:22.944840 Epoch 1132, Training loss 3.608680486679077\n",
      "in params\n",
      "R2 values 0.6853, 0.6816, 0.6885; mean R2=0.6852\n",
      "Validation Error: Avg loss: 4.084603 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:23.222939 Epoch 1133, Training loss 3.063416004180908\n",
      "in params\n",
      "R2 values 0.7408, 0.7269, 0.7306; mean R2=0.7328\n",
      "Validation Error: Avg loss: 3.483998 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:23.494073 Epoch 1134, Training loss 3.0194177627563477\n",
      "in params\n",
      "R2 values 0.6542, 0.6623, 0.6741; mean R2=0.6635\n",
      "Validation Error: Avg loss: 4.338062 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:23.763642 Epoch 1135, Training loss 3.9562971591949463\n",
      "in params\n",
      "R2 values 0.7563, 0.7797, 0.6164; mean R2=0.7175\n",
      "Validation Error: Avg loss: 3.930461 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:24.030228 Epoch 1136, Training loss 3.729511260986328\n",
      "in params\n",
      "R2 values 0.6920, 0.6922, 0.7050; mean R2=0.6964\n",
      "Validation Error: Avg loss: 4.213400 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:24.301434 Epoch 1137, Training loss 3.970189094543457\n",
      "in params\n",
      "R2 values 0.6700, 0.6464, 0.7107; mean R2=0.6757\n",
      "Validation Error: Avg loss: 4.913295 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:24.575211 Epoch 1138, Training loss 3.9970362186431885\n",
      "in params\n",
      "R2 values 0.6781, 0.7137, 0.5918; mean R2=0.6612\n",
      "Validation Error: Avg loss: 5.239216 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:24.855937 Epoch 1139, Training loss 3.309852123260498\n",
      "in params\n",
      "R2 values 0.6862, 0.7037, 0.7322; mean R2=0.7074\n",
      "Validation Error: Avg loss: 3.845894 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:25.133098 Epoch 1140, Training loss 2.8957486152648926\n",
      "in params\n",
      "R2 values 0.6059, 0.6359, 0.6405; mean R2=0.6274\n",
      "Validation Error: Avg loss: 4.827672 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:25.411880 Epoch 1141, Training loss 2.9608099460601807\n",
      "in params\n",
      "R2 values 0.7692, 0.6864, 0.7500; mean R2=0.7352\n",
      "Validation Error: Avg loss: 4.017465 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:25.692682 Epoch 1142, Training loss 2.9256443977355957\n",
      "in params\n",
      "R2 values 0.7364, 0.6853, 0.7420; mean R2=0.7212\n",
      "Validation Error: Avg loss: 3.934390 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:25.979751 Epoch 1143, Training loss 3.688728094100952\n",
      "in params\n",
      "R2 values 0.5466, 0.6578, 0.6111; mean R2=0.6052\n",
      "Validation Error: Avg loss: 4.839465 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:26.266763 Epoch 1144, Training loss 3.3043136596679688\n",
      "in params\n",
      "R2 values 0.6750, 0.8400, 0.7630; mean R2=0.7593\n",
      "Validation Error: Avg loss: 2.781894 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:26.543121 Epoch 1145, Training loss 4.191915988922119\n",
      "in params\n",
      "R2 values 0.6836, 0.8024, 0.6555; mean R2=0.7138\n",
      "Validation Error: Avg loss: 3.889921 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:26.815042 Epoch 1146, Training loss 3.2610738277435303\n",
      "in params\n",
      "R2 values 0.7135, 0.7669, 0.6682; mean R2=0.7162\n",
      "Validation Error: Avg loss: 3.604264 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:27.089842 Epoch 1147, Training loss 4.88733434677124\n",
      "in params\n",
      "R2 values 0.6911, 0.6998, 0.7173; mean R2=0.7027\n",
      "Validation Error: Avg loss: 4.457902 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:27.359791 Epoch 1148, Training loss 3.26652455329895\n",
      "in params\n",
      "R2 values 0.6773, 0.8130, 0.7269; mean R2=0.7391\n",
      "Validation Error: Avg loss: 3.651199 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:27.636256 Epoch 1149, Training loss 2.9390130043029785\n",
      "in params\n",
      "R2 values 0.7367, 0.5483, 0.6757; mean R2=0.6536\n",
      "Validation Error: Avg loss: 5.441313 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:27.911970 Epoch 1150, Training loss 3.415221691131592\n",
      "in params\n",
      "R2 values 0.6543, 0.6702, 0.5838; mean R2=0.6361\n",
      "Validation Error: Avg loss: 4.530602 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:56:28.185240 Epoch 1151, Training loss 3.257988214492798\n",
      "in params\n",
      "R2 values 0.6564, 0.8001, 0.6667; mean R2=0.7077\n",
      "Validation Error: Avg loss: 3.275547 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:28.454879 Epoch 1152, Training loss 2.4863500595092773\n",
      "in params\n",
      "R2 values 0.6102, 0.5898, 0.6453; mean R2=0.6151\n",
      "Validation Error: Avg loss: 5.344010 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:28.728876 Epoch 1153, Training loss 4.4988932609558105\n",
      "in params\n",
      "R2 values 0.6418, 0.7206, 0.7190; mean R2=0.6938\n",
      "Validation Error: Avg loss: 3.791420 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:29.008446 Epoch 1154, Training loss 2.995610475540161\n",
      "in params\n",
      "R2 values 0.7107, 0.7111, 0.6675; mean R2=0.6965\n",
      "Validation Error: Avg loss: 4.003468 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:29.288118 Epoch 1155, Training loss 3.537116765975952\n",
      "in params\n",
      "R2 values 0.7172, 0.6762, 0.7408; mean R2=0.7114\n",
      "Validation Error: Avg loss: 4.242902 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:29.571703 Epoch 1156, Training loss 3.1161046028137207\n",
      "in params\n",
      "R2 values 0.7431, 0.7069, 0.7250; mean R2=0.7250\n",
      "Validation Error: Avg loss: 4.455781 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:29.842220 Epoch 1157, Training loss 3.8095834255218506\n",
      "in params\n",
      "R2 values 0.6365, 0.6695, 0.7090; mean R2=0.6717\n",
      "Validation Error: Avg loss: 5.480356 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:30.143168 Epoch 1158, Training loss 3.957057237625122\n",
      "in params\n",
      "R2 values 0.6439, 0.7346, 0.6648; mean R2=0.6811\n",
      "Validation Error: Avg loss: 4.560006 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:30.409269 Epoch 1159, Training loss 2.777876615524292\n",
      "in params\n",
      "R2 values 0.7209, 0.6711, 0.5943; mean R2=0.6621\n",
      "Validation Error: Avg loss: 4.574218 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:30.681301 Epoch 1160, Training loss 3.602288007736206\n",
      "in params\n",
      "R2 values 0.6324, 0.6327, 0.6264; mean R2=0.6305\n",
      "Validation Error: Avg loss: 4.931465 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:30.956421 Epoch 1161, Training loss 2.6616604328155518\n",
      "in params\n",
      "R2 values 0.6105, 0.6047, 0.5591; mean R2=0.5914\n",
      "Validation Error: Avg loss: 5.324114 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:31.238762 Epoch 1162, Training loss 3.67405104637146\n",
      "in params\n",
      "R2 values 0.6821, 0.6534, 0.6586; mean R2=0.6647\n",
      "Validation Error: Avg loss: 4.446959 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:31.516857 Epoch 1163, Training loss 5.016496181488037\n",
      "in params\n",
      "R2 values 0.5155, 0.4930, 0.6001; mean R2=0.5362\n",
      "Validation Error: Avg loss: 6.431812 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:31.794574 Epoch 1164, Training loss 3.283306837081909\n",
      "in params\n",
      "R2 values 0.6987, 0.8522, 0.7662; mean R2=0.7723\n",
      "Validation Error: Avg loss: 2.334772 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:32.072645 Epoch 1165, Training loss 3.5711231231689453\n",
      "in params\n",
      "R2 values 0.6181, 0.6801, 0.6141; mean R2=0.6374\n",
      "Validation Error: Avg loss: 4.612270 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:32.344159 Epoch 1166, Training loss 3.19048810005188\n",
      "in params\n",
      "R2 values 0.6812, 0.7120, 0.6433; mean R2=0.6788\n",
      "Validation Error: Avg loss: 4.579247 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:32.618431 Epoch 1167, Training loss 3.0361485481262207\n",
      "in params\n",
      "R2 values 0.6940, 0.5484, 0.6956; mean R2=0.6460\n",
      "Validation Error: Avg loss: 5.314098 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:32.893695 Epoch 1168, Training loss 2.3184094429016113\n",
      "in params\n",
      "R2 values 0.6982, 0.7472, 0.6410; mean R2=0.6955\n",
      "Validation Error: Avg loss: 3.630817 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:33.164763 Epoch 1169, Training loss 2.846622943878174\n",
      "in params\n",
      "R2 values 0.6914, 0.6628, 0.6776; mean R2=0.6772\n",
      "Validation Error: Avg loss: 4.449486 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:33.437445 Epoch 1170, Training loss 4.050579071044922\n",
      "in params\n",
      "R2 values 0.7073, 0.7492, 0.6421; mean R2=0.6996\n",
      "Validation Error: Avg loss: 3.786728 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:33.718865 Epoch 1171, Training loss 3.8091704845428467\n",
      "in params\n",
      "R2 values 0.6976, 0.7507, 0.6139; mean R2=0.6874\n",
      "Validation Error: Avg loss: 3.805474 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:34.010547 Epoch 1172, Training loss 3.456958532333374\n",
      "in params\n",
      "R2 values 0.6083, 0.5493, 0.6602; mean R2=0.6059\n",
      "Validation Error: Avg loss: 5.635677 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:34.277753 Epoch 1173, Training loss 3.6969501972198486\n",
      "in params\n",
      "R2 values 0.5467, 0.6050, 0.5877; mean R2=0.5798\n",
      "Validation Error: Avg loss: 5.425883 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:34.548289 Epoch 1174, Training loss 3.6213748455047607\n",
      "in params\n",
      "R2 values 0.6520, 0.7335, 0.6103; mean R2=0.6653\n",
      "Validation Error: Avg loss: 4.425692 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:34.834998 Epoch 1175, Training loss 3.1289994716644287\n",
      "in params\n",
      "R2 values 0.5006, 0.6880, 0.5184; mean R2=0.5690\n",
      "Validation Error: Avg loss: 4.862726 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:35.107581 Epoch 1176, Training loss 2.8723316192626953\n",
      "in params\n",
      "R2 values 0.6756, 0.5043, 0.6732; mean R2=0.6177\n",
      "Validation Error: Avg loss: 6.322394 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:35.383845 Epoch 1177, Training loss 4.1799750328063965\n",
      "in params\n",
      "R2 values 0.6211, 0.7874, 0.5838; mean R2=0.6641\n",
      "Validation Error: Avg loss: 3.856492 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:35.661618 Epoch 1178, Training loss 3.233738422393799\n",
      "in params\n",
      "R2 values 0.6332, 0.6705, 0.6585; mean R2=0.6541\n",
      "Validation Error: Avg loss: 4.373269 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:35.933232 Epoch 1179, Training loss 3.79988169670105\n",
      "in params\n",
      "R2 values 0.6410, 0.6577, 0.5959; mean R2=0.6315\n",
      "Validation Error: Avg loss: 4.626897 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:36.204547 Epoch 1180, Training loss 4.335628986358643\n",
      "in params\n",
      "R2 values 0.6829, 0.6501, 0.6440; mean R2=0.6590\n",
      "Validation Error: Avg loss: 4.533599 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:36.479424 Epoch 1181, Training loss 3.980837821960449\n",
      "in params\n",
      "R2 values 0.7444, 0.8246, 0.7355; mean R2=0.7681\n",
      "Validation Error: Avg loss: 2.818366 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:36.759732 Epoch 1182, Training loss 3.507172107696533\n",
      "in params\n",
      "R2 values 0.7272, 0.7629, 0.6644; mean R2=0.7181\n",
      "Validation Error: Avg loss: 3.495812 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:37.029928 Epoch 1183, Training loss 3.899327278137207\n",
      "in params\n",
      "R2 values 0.6140, 0.7304, 0.7092; mean R2=0.6845\n",
      "Validation Error: Avg loss: 3.977339 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:37.302389 Epoch 1184, Training loss 3.1073219776153564\n",
      "in params\n",
      "R2 values 0.7423, 0.7496, 0.6655; mean R2=0.7191\n",
      "Validation Error: Avg loss: 3.573786 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:37.593685 Epoch 1185, Training loss 3.37703275680542\n",
      "in params\n",
      "R2 values 0.7666, 0.8033, 0.8099; mean R2=0.7933\n",
      "Validation Error: Avg loss: 2.921720 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:37.868909 Epoch 1186, Training loss 4.651034355163574\n",
      "in params\n",
      "R2 values 0.6561, 0.6128, 0.6012; mean R2=0.6234\n",
      "Validation Error: Avg loss: 5.325843 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:38.151073 Epoch 1187, Training loss 3.219649314880371\n",
      "in params\n",
      "R2 values 0.7576, 0.8141, 0.7408; mean R2=0.7709\n",
      "Validation Error: Avg loss: 2.767090 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:38.420312 Epoch 1188, Training loss 3.2000162601470947\n",
      "in params\n",
      "R2 values 0.7109, 0.6551, 0.6079; mean R2=0.6580\n",
      "Validation Error: Avg loss: 5.075541 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:38.699486 Epoch 1189, Training loss 4.351437568664551\n",
      "in params\n",
      "R2 values 0.6191, 0.7760, 0.6896; mean R2=0.6949\n",
      "Validation Error: Avg loss: 3.592997 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:38.970414 Epoch 1190, Training loss 3.7622978687286377\n",
      "in params\n",
      "R2 values 0.6048, 0.7217, 0.6380; mean R2=0.6548\n",
      "Validation Error: Avg loss: 4.334062 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:39.279126 Epoch 1191, Training loss 2.9777748584747314\n",
      "in params\n",
      "R2 values 0.6630, 0.7918, 0.5594; mean R2=0.6714\n",
      "Validation Error: Avg loss: 3.765991 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:39.565028 Epoch 1192, Training loss 3.1768758296966553\n",
      "in params\n",
      "R2 values 0.6488, 0.7285, 0.6157; mean R2=0.6643\n",
      "Validation Error: Avg loss: 4.394568 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:39.847205 Epoch 1193, Training loss 4.0867719650268555\n",
      "in params\n",
      "R2 values 0.6222, 0.5997, 0.5940; mean R2=0.6053\n",
      "Validation Error: Avg loss: 5.465164 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:40.140637 Epoch 1194, Training loss 4.007991790771484\n",
      "in params\n",
      "R2 values 0.6766, 0.7279, 0.6400; mean R2=0.6815\n",
      "Validation Error: Avg loss: 4.163073 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:40.409089 Epoch 1195, Training loss 3.4952144622802734\n",
      "in params\n",
      "R2 values 0.5951, 0.7589, 0.5979; mean R2=0.6506\n",
      "Validation Error: Avg loss: 4.001995 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:40.682206 Epoch 1196, Training loss 3.4829888343811035\n",
      "in params\n",
      "R2 values 0.7379, 0.7253, 0.7651; mean R2=0.7428\n",
      "Validation Error: Avg loss: 3.382066 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:56:40.952406 Epoch 1197, Training loss 2.5616164207458496\n",
      "in params\n",
      "R2 values 0.6830, 0.6994, 0.6618; mean R2=0.6814\n",
      "Validation Error: Avg loss: 4.083325 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:41.218453 Epoch 1198, Training loss 3.967905282974243\n",
      "in params\n",
      "R2 values 0.6674, 0.7442, 0.7209; mean R2=0.7108\n",
      "Validation Error: Avg loss: 3.848722 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:41.498621 Epoch 1199, Training loss 3.2257461547851562\n",
      "in params\n",
      "R2 values 0.6784, 0.6404, 0.6875; mean R2=0.6688\n",
      "Validation Error: Avg loss: 4.620265 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:41.769773 Epoch 1200, Training loss 3.9696943759918213\n",
      "in params\n",
      "R2 values 0.6621, 0.6564, 0.6583; mean R2=0.6589\n",
      "Validation Error: Avg loss: 5.109021 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:42.049552 Epoch 1201, Training loss 3.3909876346588135\n",
      "in params\n",
      "R2 values 0.7405, 0.7574, 0.6468; mean R2=0.7149\n",
      "Validation Error: Avg loss: 3.829227 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:42.321215 Epoch 1202, Training loss 3.3225550651550293\n",
      "in params\n",
      "R2 values 0.6575, 0.7093, 0.7090; mean R2=0.6919\n",
      "Validation Error: Avg loss: 4.128819 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:42.599442 Epoch 1203, Training loss 4.43578577041626\n",
      "in params\n",
      "R2 values 0.6853, 0.7165, 0.6386; mean R2=0.6801\n",
      "Validation Error: Avg loss: 4.319928 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:42.880281 Epoch 1204, Training loss 2.6960368156433105\n",
      "in params\n",
      "R2 values 0.6061, 0.7393, 0.6579; mean R2=0.6678\n",
      "Validation Error: Avg loss: 4.325831 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:43.158993 Epoch 1205, Training loss 3.8342978954315186\n",
      "in params\n",
      "R2 values 0.6805, 0.6747, 0.6501; mean R2=0.6684\n",
      "Validation Error: Avg loss: 4.343208 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:43.424804 Epoch 1206, Training loss 3.768329620361328\n",
      "in params\n",
      "R2 values 0.6684, 0.7796, 0.7266; mean R2=0.7249\n",
      "Validation Error: Avg loss: 3.133466 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:43.709156 Epoch 1207, Training loss 3.987523078918457\n",
      "in params\n",
      "R2 values 0.7725, 0.7110, 0.7365; mean R2=0.7400\n",
      "Validation Error: Avg loss: 3.579827 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:44.006393 Epoch 1208, Training loss 2.8162930011749268\n",
      "in params\n",
      "R2 values 0.6994, 0.7913, 0.7621; mean R2=0.7509\n",
      "Validation Error: Avg loss: 3.344192 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:44.276814 Epoch 1209, Training loss 2.5280039310455322\n",
      "in params\n",
      "R2 values 0.5265, 0.7208, 0.5625; mean R2=0.6033\n",
      "Validation Error: Avg loss: 4.622687 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:44.546208 Epoch 1210, Training loss 3.4884390830993652\n",
      "in params\n",
      "R2 values 0.6749, 0.5679, 0.7047; mean R2=0.6492\n",
      "Validation Error: Avg loss: 5.357332 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:44.824685 Epoch 1211, Training loss 3.513185501098633\n",
      "in params\n",
      "R2 values 0.6827, 0.6671, 0.7284; mean R2=0.6928\n",
      "Validation Error: Avg loss: 4.339187 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:45.104836 Epoch 1212, Training loss 3.971245050430298\n",
      "in params\n",
      "R2 values 0.5722, 0.6855, 0.5547; mean R2=0.6041\n",
      "Validation Error: Avg loss: 4.731467 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:45.384915 Epoch 1213, Training loss 3.306352376937866\n",
      "in params\n",
      "R2 values 0.7020, 0.7259, 0.6372; mean R2=0.6883\n",
      "Validation Error: Avg loss: 3.946198 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:45.671768 Epoch 1214, Training loss 2.93526029586792\n",
      "in params\n",
      "R2 values 0.7080, 0.6730, 0.6956; mean R2=0.6922\n",
      "Validation Error: Avg loss: 4.131693 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:45.947761 Epoch 1215, Training loss 3.6968648433685303\n",
      "in params\n",
      "R2 values 0.7317, 0.7618, 0.6728; mean R2=0.7221\n",
      "Validation Error: Avg loss: 3.418683 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:46.225809 Epoch 1216, Training loss 3.5411481857299805\n",
      "in params\n",
      "R2 values 0.6613, 0.7070, 0.5944; mean R2=0.6543\n",
      "Validation Error: Avg loss: 4.544433 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:46.507219 Epoch 1217, Training loss 3.1548328399658203\n",
      "in params\n",
      "R2 values 0.7340, 0.7036, 0.7437; mean R2=0.7271\n",
      "Validation Error: Avg loss: 4.103242 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:46.796252 Epoch 1218, Training loss 2.9835002422332764\n",
      "in params\n",
      "R2 values 0.7370, 0.6911, 0.6717; mean R2=0.6999\n",
      "Validation Error: Avg loss: 4.045547 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:47.090218 Epoch 1219, Training loss 3.533144235610962\n",
      "in params\n",
      "R2 values 0.6665, 0.6872, 0.6651; mean R2=0.6730\n",
      "Validation Error: Avg loss: 4.672407 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:47.374837 Epoch 1220, Training loss 3.7945220470428467\n",
      "in params\n",
      "R2 values 0.7715, 0.6796, 0.6821; mean R2=0.7111\n",
      "Validation Error: Avg loss: 4.253145 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:47.668281 Epoch 1221, Training loss 3.546834945678711\n",
      "in params\n",
      "R2 values 0.6415, 0.7448, 0.7122; mean R2=0.6995\n",
      "Validation Error: Avg loss: 3.560343 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:47.941371 Epoch 1222, Training loss 3.8441927433013916\n",
      "in params\n",
      "R2 values 0.7098, 0.7184, 0.7398; mean R2=0.7227\n",
      "Validation Error: Avg loss: 3.906365 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:48.216001 Epoch 1223, Training loss 3.1823458671569824\n",
      "in params\n",
      "R2 values 0.7281, 0.7805, 0.7673; mean R2=0.7587\n",
      "Validation Error: Avg loss: 3.173702 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:48.489614 Epoch 1224, Training loss 2.5624358654022217\n",
      "in params\n",
      "R2 values 0.5844, 0.6243, 0.5797; mean R2=0.5961\n",
      "Validation Error: Avg loss: 5.194187 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:48.771988 Epoch 1225, Training loss 3.2288055419921875\n",
      "in params\n",
      "R2 values 0.6252, 0.6395, 0.6030; mean R2=0.6226\n",
      "Validation Error: Avg loss: 4.956359 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:49.040716 Epoch 1226, Training loss 3.46669864654541\n",
      "in params\n",
      "R2 values 0.7140, 0.6463, 0.6669; mean R2=0.6757\n",
      "Validation Error: Avg loss: 4.864426 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:49.316385 Epoch 1227, Training loss 2.5750136375427246\n",
      "in params\n",
      "R2 values 0.6831, 0.7855, 0.6994; mean R2=0.7227\n",
      "Validation Error: Avg loss: 3.255137 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:49.599339 Epoch 1228, Training loss 3.6626908779144287\n",
      "in params\n",
      "R2 values 0.6600, 0.7589, 0.5973; mean R2=0.6721\n",
      "Validation Error: Avg loss: 3.830055 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:49.884579 Epoch 1229, Training loss 3.546583652496338\n",
      "in params\n",
      "R2 values 0.5377, 0.6286, 0.5965; mean R2=0.5876\n",
      "Validation Error: Avg loss: 5.443822 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:50.169589 Epoch 1230, Training loss 2.8874382972717285\n",
      "in params\n",
      "R2 values 0.7817, 0.7581, 0.7542; mean R2=0.7647\n",
      "Validation Error: Avg loss: 3.567398 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:50.466557 Epoch 1231, Training loss 2.869713544845581\n",
      "in params\n",
      "R2 values 0.6096, 0.7055, 0.7138; mean R2=0.6763\n",
      "Validation Error: Avg loss: 4.096860 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:50.755162 Epoch 1232, Training loss 2.92553448677063\n",
      "in params\n",
      "R2 values 0.7477, 0.7676, 0.7086; mean R2=0.7413\n",
      "Validation Error: Avg loss: 3.707732 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:51.048816 Epoch 1233, Training loss 3.1166441440582275\n",
      "in params\n",
      "R2 values 0.6931, 0.7856, 0.6758; mean R2=0.7182\n",
      "Validation Error: Avg loss: 3.443816 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:51.327930 Epoch 1234, Training loss 2.981034994125366\n",
      "in params\n",
      "R2 values 0.6784, 0.7424, 0.7445; mean R2=0.7218\n",
      "Validation Error: Avg loss: 3.431325 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:51.604358 Epoch 1235, Training loss 3.348388433456421\n",
      "in params\n",
      "R2 values 0.7259, 0.6936, 0.6057; mean R2=0.6750\n",
      "Validation Error: Avg loss: 4.208784 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:51.878995 Epoch 1236, Training loss 3.1584718227386475\n",
      "in params\n",
      "R2 values 0.7641, 0.7115, 0.7170; mean R2=0.7309\n",
      "Validation Error: Avg loss: 3.964267 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:52.157613 Epoch 1237, Training loss 3.783968210220337\n",
      "in params\n",
      "R2 values 0.5929, 0.6531, 0.5846; mean R2=0.6102\n",
      "Validation Error: Avg loss: 4.757696 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:52.426514 Epoch 1238, Training loss 3.2194712162017822\n",
      "in params\n",
      "R2 values 0.6843, 0.7996, 0.6993; mean R2=0.7277\n",
      "Validation Error: Avg loss: 3.264774 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:52.704144 Epoch 1239, Training loss 3.873049259185791\n",
      "in params\n",
      "R2 values 0.7362, 0.7364, 0.7489; mean R2=0.7405\n",
      "Validation Error: Avg loss: 4.389559 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:52.980108 Epoch 1240, Training loss 3.174146890640259\n",
      "in params\n",
      "R2 values 0.6160, 0.6518, 0.6316; mean R2=0.6331\n",
      "Validation Error: Avg loss: 5.004334 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:53.263843 Epoch 1241, Training loss 2.98770809173584\n",
      "in params\n",
      "R2 values 0.7891, 0.6596, 0.7410; mean R2=0.7299\n",
      "Validation Error: Avg loss: 4.334414 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:53.567063 Epoch 1242, Training loss 4.682577610015869\n",
      "in params\n",
      "R2 values 0.6410, 0.7634, 0.6643; mean R2=0.6896\n",
      "Validation Error: Avg loss: 4.169561 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:56:53.848733 Epoch 1243, Training loss 4.235268592834473\n",
      "in params\n",
      "R2 values 0.5357, 0.4591, 0.5655; mean R2=0.5201\n",
      "Validation Error: Avg loss: 6.732795 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:54.121617 Epoch 1244, Training loss 3.9976322650909424\n",
      "in params\n",
      "R2 values 0.6265, 0.4666, 0.7207; mean R2=0.6046\n",
      "Validation Error: Avg loss: 6.089086 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:54.398470 Epoch 1245, Training loss 2.289686441421509\n",
      "in params\n",
      "R2 values 0.6361, 0.7069, 0.6947; mean R2=0.6792\n",
      "Validation Error: Avg loss: 4.012285 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:54.676032 Epoch 1246, Training loss 3.4474997520446777\n",
      "in params\n",
      "R2 values 0.6493, 0.6337, 0.5661; mean R2=0.6163\n",
      "Validation Error: Avg loss: 5.815604 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:54.949779 Epoch 1247, Training loss 3.340198040008545\n",
      "in params\n",
      "R2 values 0.7081, 0.6390, 0.6432; mean R2=0.6634\n",
      "Validation Error: Avg loss: 4.759048 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:55.228130 Epoch 1248, Training loss 3.1318321228027344\n",
      "in params\n",
      "R2 values 0.4995, 0.7459, 0.6212; mean R2=0.6222\n",
      "Validation Error: Avg loss: 4.351653 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:55.513333 Epoch 1249, Training loss 2.457225799560547\n",
      "in params\n",
      "R2 values 0.5495, 0.6665, 0.6754; mean R2=0.6305\n",
      "Validation Error: Avg loss: 4.734829 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:55.792630 Epoch 1250, Training loss 3.5770254135131836\n",
      "in params\n",
      "R2 values 0.6593, 0.7538, 0.6071; mean R2=0.6734\n",
      "Validation Error: Avg loss: 4.509176 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:56.066462 Epoch 1251, Training loss 3.1112098693847656\n",
      "in params\n",
      "R2 values 0.5651, 0.8004, 0.6568; mean R2=0.6741\n",
      "Validation Error: Avg loss: 4.218481 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:56.348056 Epoch 1252, Training loss 3.066720485687256\n",
      "in params\n",
      "R2 values 0.5958, 0.7464, 0.7207; mean R2=0.6876\n",
      "Validation Error: Avg loss: 3.931639 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:56.646828 Epoch 1253, Training loss 3.720036029815674\n",
      "in params\n",
      "R2 values 0.5413, 0.6308, 0.5123; mean R2=0.5615\n",
      "Validation Error: Avg loss: 5.516899 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:56.935313 Epoch 1254, Training loss 3.3643274307250977\n",
      "in params\n",
      "R2 values 0.7528, 0.7754, 0.6878; mean R2=0.7386\n",
      "Validation Error: Avg loss: 3.172722 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:57.211791 Epoch 1255, Training loss 3.1688127517700195\n",
      "in params\n",
      "R2 values 0.5962, 0.7582, 0.6459; mean R2=0.6668\n",
      "Validation Error: Avg loss: 3.825316 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:57.485268 Epoch 1256, Training loss 3.5055508613586426\n",
      "in params\n",
      "R2 values 0.6186, 0.8460, 0.7101; mean R2=0.7249\n",
      "Validation Error: Avg loss: 2.685084 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:57.764113 Epoch 1257, Training loss 3.2414534091949463\n",
      "in params\n",
      "R2 values 0.6214, 0.5099, 0.6292; mean R2=0.5868\n",
      "Validation Error: Avg loss: 5.886284 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:58.042078 Epoch 1258, Training loss 2.6452412605285645\n",
      "in params\n",
      "R2 values 0.7052, 0.6990, 0.7715; mean R2=0.7252\n",
      "Validation Error: Avg loss: 3.882054 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:58.323738 Epoch 1259, Training loss 4.0485053062438965\n",
      "in params\n",
      "R2 values 0.7766, 0.7453, 0.7143; mean R2=0.7454\n",
      "Validation Error: Avg loss: 3.424254 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:58.600583 Epoch 1260, Training loss 2.8173439502716064\n",
      "in params\n",
      "R2 values 0.5713, 0.7388, 0.6178; mean R2=0.6426\n",
      "Validation Error: Avg loss: 4.000222 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:58.883690 Epoch 1261, Training loss 3.044201135635376\n",
      "in params\n",
      "R2 values 0.6358, 0.6604, 0.6679; mean R2=0.6547\n",
      "Validation Error: Avg loss: 4.427892 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:59.167169 Epoch 1262, Training loss 3.0404539108276367\n",
      "in params\n",
      "R2 values 0.6259, 0.6877, 0.6510; mean R2=0.6549\n",
      "Validation Error: Avg loss: 4.172515 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:59.452307 Epoch 1263, Training loss 2.854970693588257\n",
      "in params\n",
      "R2 values 0.6334, 0.7195, 0.6708; mean R2=0.6745\n",
      "Validation Error: Avg loss: 3.867728 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:56:59.731663 Epoch 1264, Training loss 4.253942966461182\n",
      "in params\n",
      "R2 values 0.6192, 0.7530, 0.6660; mean R2=0.6794\n",
      "Validation Error: Avg loss: 4.166661 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:00.003956 Epoch 1265, Training loss 3.8175864219665527\n",
      "in params\n",
      "R2 values 0.5212, 0.8025, 0.7003; mean R2=0.6747\n",
      "Validation Error: Avg loss: 4.130885 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:00.297374 Epoch 1266, Training loss 2.9419054985046387\n",
      "in params\n",
      "R2 values 0.5813, 0.7382, 0.6349; mean R2=0.6515\n",
      "Validation Error: Avg loss: 4.297981 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:00.575899 Epoch 1267, Training loss 3.193727970123291\n",
      "in params\n",
      "R2 values 0.6965, 0.8630, 0.7631; mean R2=0.7742\n",
      "Validation Error: Avg loss: 3.323537 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:00.851365 Epoch 1268, Training loss 4.033369064331055\n",
      "in params\n",
      "R2 values 0.6428, 0.7288, 0.7448; mean R2=0.7055\n",
      "Validation Error: Avg loss: 3.939448 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:01.128511 Epoch 1269, Training loss 4.968957424163818\n",
      "in params\n",
      "R2 values 0.6453, 0.6512, 0.6563; mean R2=0.6509\n",
      "Validation Error: Avg loss: 5.314320 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:01.402853 Epoch 1270, Training loss 4.451993942260742\n",
      "in params\n",
      "R2 values 0.6098, 0.8493, 0.6475; mean R2=0.7022\n",
      "Validation Error: Avg loss: 3.610712 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:01.692967 Epoch 1271, Training loss 3.0598738193511963\n",
      "in params\n",
      "R2 values 0.6236, 0.7446, 0.5979; mean R2=0.6554\n",
      "Validation Error: Avg loss: 3.942748 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:01.964399 Epoch 1272, Training loss 3.9827585220336914\n",
      "in params\n",
      "R2 values 0.6993, 0.7773, 0.7422; mean R2=0.7396\n",
      "Validation Error: Avg loss: 3.421845 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:02.235839 Epoch 1273, Training loss 3.3497867584228516\n",
      "in params\n",
      "R2 values 0.7177, 0.7100, 0.7219; mean R2=0.7166\n",
      "Validation Error: Avg loss: 3.757570 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:02.512316 Epoch 1274, Training loss 3.0488197803497314\n",
      "in params\n",
      "R2 values 0.7093, 0.7411, 0.7117; mean R2=0.7207\n",
      "Validation Error: Avg loss: 3.587676 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:02.801714 Epoch 1275, Training loss 2.8617477416992188\n",
      "in params\n",
      "R2 values 0.6115, 0.6098, 0.5651; mean R2=0.5955\n",
      "Validation Error: Avg loss: 5.304376 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:03.094414 Epoch 1276, Training loss 3.695066213607788\n",
      "in params\n",
      "R2 values 0.6600, 0.6289, 0.6298; mean R2=0.6395\n",
      "Validation Error: Avg loss: 4.910521 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:03.369136 Epoch 1277, Training loss 3.6983540058135986\n",
      "in params\n",
      "R2 values 0.7066, 0.7785, 0.6429; mean R2=0.7093\n",
      "Validation Error: Avg loss: 3.777373 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:03.643694 Epoch 1278, Training loss 4.19425630569458\n",
      "in params\n",
      "R2 values 0.6288, 0.7282, 0.5782; mean R2=0.6451\n",
      "Validation Error: Avg loss: 4.137612 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:03.929569 Epoch 1279, Training loss 3.441706895828247\n",
      "in params\n",
      "R2 values 0.5664, 0.7660, 0.5834; mean R2=0.6386\n",
      "Validation Error: Avg loss: 4.081551 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:04.207632 Epoch 1280, Training loss 3.3000600337982178\n",
      "in params\n",
      "R2 values 0.6501, 0.6382, 0.6205; mean R2=0.6363\n",
      "Validation Error: Avg loss: 4.885867 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:04.487309 Epoch 1281, Training loss 3.335127115249634\n",
      "in params\n",
      "R2 values 0.6600, 0.6844, 0.7032; mean R2=0.6825\n",
      "Validation Error: Avg loss: 4.059148 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:04.768930 Epoch 1282, Training loss 3.921894073486328\n",
      "in params\n",
      "R2 values 0.7055, 0.8165, 0.7197; mean R2=0.7472\n",
      "Validation Error: Avg loss: 2.799351 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:05.044839 Epoch 1283, Training loss 3.464111089706421\n",
      "in params\n",
      "R2 values 0.7021, 0.6857, 0.6927; mean R2=0.6935\n",
      "Validation Error: Avg loss: 4.122824 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:05.318918 Epoch 1284, Training loss 2.8435628414154053\n",
      "in params\n",
      "R2 values 0.4525, 0.7103, 0.5904; mean R2=0.5844\n",
      "Validation Error: Avg loss: 4.567388 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:05.602503 Epoch 1285, Training loss 3.3491976261138916\n",
      "in params\n",
      "R2 values 0.7177, 0.7761, 0.7687; mean R2=0.7542\n",
      "Validation Error: Avg loss: 3.249374 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:05.881408 Epoch 1286, Training loss 2.535325527191162\n",
      "in params\n",
      "R2 values 0.6930, 0.8131, 0.6811; mean R2=0.7290\n",
      "Validation Error: Avg loss: 3.702914 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:06.158182 Epoch 1287, Training loss 3.5125608444213867\n",
      "in params\n",
      "R2 values 0.7253, 0.7034, 0.6633; mean R2=0.6974\n",
      "Validation Error: Avg loss: 4.596084 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:06.441319 Epoch 1288, Training loss 3.497199296951294\n",
      "in params\n",
      "R2 values 0.5999, 0.6568, 0.6566; mean R2=0.6377\n",
      "Validation Error: Avg loss: 4.676849 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:57:06.733559 Epoch 1289, Training loss 3.4251761436462402\n",
      "in params\n",
      "R2 values 0.6774, 0.6081, 0.6636; mean R2=0.6497\n",
      "Validation Error: Avg loss: 5.194387 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:07.025114 Epoch 1290, Training loss 2.9438772201538086\n",
      "in params\n",
      "R2 values 0.7066, 0.5511, 0.6876; mean R2=0.6484\n",
      "Validation Error: Avg loss: 5.297139 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:07.299334 Epoch 1291, Training loss 3.8702049255371094\n",
      "in params\n",
      "R2 values 0.6690, 0.7622, 0.6813; mean R2=0.7042\n",
      "Validation Error: Avg loss: 3.874635 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:07.571769 Epoch 1292, Training loss 3.250739336013794\n",
      "in params\n",
      "R2 values 0.5971, 0.6444, 0.6877; mean R2=0.6431\n",
      "Validation Error: Avg loss: 4.630211 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:07.847668 Epoch 1293, Training loss 3.6294243335723877\n",
      "in params\n",
      "R2 values 0.6004, 0.6116, 0.5894; mean R2=0.6005\n",
      "Validation Error: Avg loss: 5.460009 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:08.123602 Epoch 1294, Training loss 3.1455636024475098\n",
      "in params\n",
      "R2 values 0.6176, 0.7966, 0.6233; mean R2=0.6792\n",
      "Validation Error: Avg loss: 3.436652 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:08.401844 Epoch 1295, Training loss 2.3029417991638184\n",
      "in params\n",
      "R2 values 0.6126, 0.7031, 0.6601; mean R2=0.6586\n",
      "Validation Error: Avg loss: 4.637492 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:08.678652 Epoch 1296, Training loss 3.0416953563690186\n",
      "in params\n",
      "R2 values 0.6205, 0.6665, 0.7073; mean R2=0.6648\n",
      "Validation Error: Avg loss: 4.907559 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:08.956665 Epoch 1297, Training loss 3.612684488296509\n",
      "in params\n",
      "R2 values 0.5645, 0.5906, 0.6445; mean R2=0.5998\n",
      "Validation Error: Avg loss: 5.431796 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:09.235586 Epoch 1298, Training loss 2.927276134490967\n",
      "in params\n",
      "R2 values 0.7134, 0.7141, 0.7114; mean R2=0.7130\n",
      "Validation Error: Avg loss: 4.222718 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:09.514389 Epoch 1299, Training loss 2.5489964485168457\n",
      "in params\n",
      "R2 values 0.7684, 0.8570, 0.7118; mean R2=0.7790\n",
      "Validation Error: Avg loss: 2.463810 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:09.791761 Epoch 1300, Training loss 3.675171375274658\n",
      "in params\n",
      "R2 values 0.6656, 0.7224, 0.6016; mean R2=0.6632\n",
      "Validation Error: Avg loss: 4.052053 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:10.064893 Epoch 1301, Training loss 2.8588919639587402\n",
      "in params\n",
      "R2 values 0.5922, 0.6788, 0.7036; mean R2=0.6582\n",
      "Validation Error: Avg loss: 4.203795 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:10.362735 Epoch 1302, Training loss 2.699082851409912\n",
      "in params\n",
      "R2 values 0.7249, 0.7468, 0.6271; mean R2=0.6996\n",
      "Validation Error: Avg loss: 3.746765 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:10.644137 Epoch 1303, Training loss 3.5538785457611084\n",
      "in params\n",
      "R2 values 0.7346, 0.7640, 0.7189; mean R2=0.7391\n",
      "Validation Error: Avg loss: 3.246476 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:10.924379 Epoch 1304, Training loss 3.202296495437622\n",
      "in params\n",
      "R2 values 0.6689, 0.7147, 0.6454; mean R2=0.6763\n",
      "Validation Error: Avg loss: 4.071875 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:11.204887 Epoch 1305, Training loss 4.2358832359313965\n",
      "in params\n",
      "R2 values 0.6714, 0.6535, 0.6822; mean R2=0.6691\n",
      "Validation Error: Avg loss: 4.486395 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:11.480689 Epoch 1306, Training loss 3.330831527709961\n",
      "in params\n",
      "R2 values 0.6934, 0.5772, 0.7254; mean R2=0.6653\n",
      "Validation Error: Avg loss: 4.950759 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:11.767334 Epoch 1307, Training loss 3.447216033935547\n",
      "in params\n",
      "R2 values 0.5692, 0.6293, 0.5797; mean R2=0.5927\n",
      "Validation Error: Avg loss: 5.649822 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:12.054648 Epoch 1308, Training loss 3.8241968154907227\n",
      "in params\n",
      "R2 values 0.5961, 0.6615, 0.6359; mean R2=0.6312\n",
      "Validation Error: Avg loss: 4.675192 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:12.378676 Epoch 1309, Training loss 3.9709653854370117\n",
      "in params\n",
      "R2 values 0.7109, 0.7662, 0.7310; mean R2=0.7361\n",
      "Validation Error: Avg loss: 3.206510 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:12.664621 Epoch 1310, Training loss 2.926038980484009\n",
      "in params\n",
      "R2 values 0.6438, 0.8278, 0.7717; mean R2=0.7478\n",
      "Validation Error: Avg loss: 2.877374 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:12.940892 Epoch 1311, Training loss 2.5116262435913086\n",
      "in params\n",
      "R2 values 0.7377, 0.5854, 0.7035; mean R2=0.6755\n",
      "Validation Error: Avg loss: 4.929469 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:13.213560 Epoch 1312, Training loss 3.9482243061065674\n",
      "in params\n",
      "R2 values 0.6024, 0.7796, 0.6602; mean R2=0.6807\n",
      "Validation Error: Avg loss: 3.403203 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:13.489535 Epoch 1313, Training loss 3.7040703296661377\n",
      "in params\n",
      "R2 values 0.5098, 0.7209, 0.6422; mean R2=0.6243\n",
      "Validation Error: Avg loss: 4.044897 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:13.767291 Epoch 1314, Training loss 3.5962350368499756\n",
      "in params\n",
      "R2 values 0.6930, 0.8274, 0.7579; mean R2=0.7594\n",
      "Validation Error: Avg loss: 2.659662 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:14.041717 Epoch 1315, Training loss 4.018738746643066\n",
      "in params\n",
      "R2 values 0.7056, 0.7858, 0.7442; mean R2=0.7452\n",
      "Validation Error: Avg loss: 3.081553 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:14.316202 Epoch 1316, Training loss 3.39516019821167\n",
      "in params\n",
      "R2 values 0.6491, 0.6767, 0.5919; mean R2=0.6393\n",
      "Validation Error: Avg loss: 4.996875 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:14.593101 Epoch 1317, Training loss 3.1065728664398193\n",
      "in params\n",
      "R2 values 0.6314, 0.7157, 0.6285; mean R2=0.6585\n",
      "Validation Error: Avg loss: 4.310591 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:14.865846 Epoch 1318, Training loss 3.3082687854766846\n",
      "in params\n",
      "R2 values 0.5568, 0.5724, 0.6374; mean R2=0.5889\n",
      "Validation Error: Avg loss: 5.620094 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:15.147906 Epoch 1319, Training loss 3.1735997200012207\n",
      "in params\n",
      "R2 values 0.6992, 0.8377, 0.6506; mean R2=0.7292\n",
      "Validation Error: Avg loss: 3.083247 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:15.426135 Epoch 1320, Training loss 3.057486057281494\n",
      "in params\n",
      "R2 values 0.5738, 0.6970, 0.5654; mean R2=0.6121\n",
      "Validation Error: Avg loss: 4.502523 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:15.697940 Epoch 1321, Training loss 3.054514169692993\n",
      "in params\n",
      "R2 values 0.6291, 0.7549, 0.6494; mean R2=0.6778\n",
      "Validation Error: Avg loss: 3.711759 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:15.985868 Epoch 1322, Training loss 3.5126700401306152\n",
      "in params\n",
      "R2 values 0.5870, 0.8337, 0.6709; mean R2=0.6972\n",
      "Validation Error: Avg loss: 3.101323 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:16.254788 Epoch 1323, Training loss 3.565333604812622\n",
      "in params\n",
      "R2 values 0.7124, 0.6920, 0.7036; mean R2=0.7027\n",
      "Validation Error: Avg loss: 4.495904 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:16.527217 Epoch 1324, Training loss 3.5876309871673584\n",
      "in params\n",
      "R2 values 0.7569, 0.8001, 0.7279; mean R2=0.7616\n",
      "Validation Error: Avg loss: 3.735605 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:16.808683 Epoch 1325, Training loss 3.608309268951416\n",
      "in params\n",
      "R2 values 0.7048, 0.7561, 0.6314; mean R2=0.6974\n",
      "Validation Error: Avg loss: 4.251451 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:17.084234 Epoch 1326, Training loss 3.8041954040527344\n",
      "in params\n",
      "R2 values 0.5988, 0.7390, 0.6367; mean R2=0.6582\n",
      "Validation Error: Avg loss: 3.996208 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:17.358585 Epoch 1327, Training loss 3.7185611724853516\n",
      "in params\n",
      "R2 values 0.6721, 0.6216, 0.7177; mean R2=0.6705\n",
      "Validation Error: Avg loss: 4.941219 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:17.635741 Epoch 1328, Training loss 3.251981019973755\n",
      "in params\n",
      "R2 values 0.7112, 0.6005, 0.6700; mean R2=0.6606\n",
      "Validation Error: Avg loss: 4.861116 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:17.909659 Epoch 1329, Training loss 4.689629554748535\n",
      "in params\n",
      "R2 values 0.7060, 0.7796, 0.7018; mean R2=0.7291\n",
      "Validation Error: Avg loss: 3.218487 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:18.196368 Epoch 1330, Training loss 2.825679063796997\n",
      "in params\n",
      "R2 values 0.5940, 0.5968, 0.6019; mean R2=0.5976\n",
      "Validation Error: Avg loss: 5.301291 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:18.473236 Epoch 1331, Training loss 4.054961204528809\n",
      "in params\n",
      "R2 values 0.6572, 0.7833, 0.7293; mean R2=0.7233\n",
      "Validation Error: Avg loss: 3.207953 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:18.746849 Epoch 1332, Training loss 3.072437286376953\n",
      "in params\n",
      "R2 values 0.7125, 0.5903, 0.6876; mean R2=0.6634\n",
      "Validation Error: Avg loss: 4.986988 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:19.018535 Epoch 1333, Training loss 3.2329018115997314\n",
      "in params\n",
      "R2 values 0.6375, 0.7256, 0.5789; mean R2=0.6473\n",
      "Validation Error: Avg loss: 4.968421 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:19.296150 Epoch 1334, Training loss 3.828902244567871\n",
      "in params\n",
      "R2 values 0.6154, 0.7366, 0.6840; mean R2=0.6786\n",
      "Validation Error: Avg loss: 4.833755 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:57:19.574897 Epoch 1335, Training loss 4.161208629608154\n",
      "in params\n",
      "R2 values 0.5977, 0.6612, 0.6751; mean R2=0.6447\n",
      "Validation Error: Avg loss: 5.099457 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:19.855044 Epoch 1336, Training loss 3.983532190322876\n",
      "in params\n",
      "R2 values 0.7974, 0.6467, 0.7665; mean R2=0.7368\n",
      "Validation Error: Avg loss: 4.044265 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:20.129874 Epoch 1337, Training loss 4.536453723907471\n",
      "in params\n",
      "R2 values 0.6867, 0.7866, 0.6286; mean R2=0.7006\n",
      "Validation Error: Avg loss: 3.463635 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:20.425513 Epoch 1338, Training loss 3.819201707839966\n",
      "in params\n",
      "R2 values 0.7282, 0.6779, 0.6587; mean R2=0.6883\n",
      "Validation Error: Avg loss: 4.273250 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:20.718683 Epoch 1339, Training loss 2.760505437850952\n",
      "in params\n",
      "R2 values 0.6586, 0.7461, 0.6096; mean R2=0.6715\n",
      "Validation Error: Avg loss: 4.006347 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:20.990688 Epoch 1340, Training loss 2.3972578048706055\n",
      "in params\n",
      "R2 values 0.6918, 0.5693, 0.7301; mean R2=0.6638\n",
      "Validation Error: Avg loss: 5.030805 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:21.263893 Epoch 1341, Training loss 4.122427463531494\n",
      "in params\n",
      "R2 values 0.7219, 0.7056, 0.6546; mean R2=0.6940\n",
      "Validation Error: Avg loss: 3.992812 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:21.542556 Epoch 1342, Training loss 3.011075019836426\n",
      "in params\n",
      "R2 values 0.6520, 0.5870, 0.4791; mean R2=0.5727\n",
      "Validation Error: Avg loss: 5.805662 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:21.852354 Epoch 1343, Training loss 2.9972856044769287\n",
      "in params\n",
      "R2 values 0.7269, 0.6286, 0.7265; mean R2=0.6940\n",
      "Validation Error: Avg loss: 4.467999 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:22.119807 Epoch 1344, Training loss 3.622239828109741\n",
      "in params\n",
      "R2 values 0.6829, 0.6213, 0.7097; mean R2=0.6713\n",
      "Validation Error: Avg loss: 5.791584 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:22.385721 Epoch 1345, Training loss 3.537909746170044\n",
      "in params\n",
      "R2 values 0.7371, 0.7706, 0.7983; mean R2=0.7687\n",
      "Validation Error: Avg loss: 3.729339 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:22.656643 Epoch 1346, Training loss 4.2357177734375\n",
      "in params\n",
      "R2 values 0.6185, 0.8650, 0.6641; mean R2=0.7159\n",
      "Validation Error: Avg loss: 4.092274 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:22.930258 Epoch 1347, Training loss 4.144637584686279\n",
      "in params\n",
      "R2 values 0.6881, 0.7791, 0.6233; mean R2=0.6968\n",
      "Validation Error: Avg loss: 3.627784 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:23.208341 Epoch 1348, Training loss 4.687195777893066\n",
      "in params\n",
      "R2 values 0.7543, 0.7243, 0.7280; mean R2=0.7355\n",
      "Validation Error: Avg loss: 3.686527 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:23.487811 Epoch 1349, Training loss 3.282766103744507\n",
      "in params\n",
      "R2 values 0.7853, 0.7741, 0.7270; mean R2=0.7621\n",
      "Validation Error: Avg loss: 3.078322 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:23.765679 Epoch 1350, Training loss 4.244254112243652\n",
      "in params\n",
      "R2 values 0.5774, 0.6999, 0.6175; mean R2=0.6316\n",
      "Validation Error: Avg loss: 4.323911 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:24.049345 Epoch 1351, Training loss 3.1521646976470947\n",
      "in params\n",
      "R2 values 0.6655, 0.7625, 0.6625; mean R2=0.6968\n",
      "Validation Error: Avg loss: 3.452132 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:24.326710 Epoch 1352, Training loss 4.046666622161865\n",
      "in params\n",
      "R2 values 0.6129, 0.7828, 0.5953; mean R2=0.6637\n",
      "Validation Error: Avg loss: 3.990802 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:24.603181 Epoch 1353, Training loss 3.237013578414917\n",
      "in params\n",
      "R2 values 0.7268, 0.6803, 0.6296; mean R2=0.6789\n",
      "Validation Error: Avg loss: 5.325691 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:24.884920 Epoch 1354, Training loss 3.3777544498443604\n",
      "in params\n",
      "R2 values 0.6841, 0.7969, 0.6838; mean R2=0.7216\n",
      "Validation Error: Avg loss: 3.524857 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:25.168213 Epoch 1355, Training loss 3.8236982822418213\n",
      "in params\n",
      "R2 values 0.5814, 0.5180, 0.6087; mean R2=0.5693\n",
      "Validation Error: Avg loss: 6.425709 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:25.443118 Epoch 1356, Training loss 3.6521825790405273\n",
      "in params\n",
      "R2 values 0.6905, 0.7496, 0.6215; mean R2=0.6872\n",
      "Validation Error: Avg loss: 4.067546 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:25.719076 Epoch 1357, Training loss 3.2351865768432617\n",
      "in params\n",
      "R2 values 0.7194, 0.6536, 0.6538; mean R2=0.6756\n",
      "Validation Error: Avg loss: 4.521817 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:25.998520 Epoch 1358, Training loss 2.676222801208496\n",
      "in params\n",
      "R2 values 0.6530, 0.5056, 0.5862; mean R2=0.5816\n",
      "Validation Error: Avg loss: 6.145143 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:26.271115 Epoch 1359, Training loss 2.871387004852295\n",
      "in params\n",
      "R2 values 0.6264, 0.7512, 0.6519; mean R2=0.6765\n",
      "Validation Error: Avg loss: 3.800777 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:26.544298 Epoch 1360, Training loss 3.752298593521118\n",
      "in params\n",
      "R2 values 0.7816, 0.7212, 0.6268; mean R2=0.7099\n",
      "Validation Error: Avg loss: 3.868828 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:26.830491 Epoch 1361, Training loss 2.5856924057006836\n",
      "in params\n",
      "R2 values 0.7291, 0.7724, 0.6724; mean R2=0.7246\n",
      "Validation Error: Avg loss: 3.540470 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:27.114823 Epoch 1362, Training loss 3.5279083251953125\n",
      "in params\n",
      "R2 values 0.6435, 0.6147, 0.6132; mean R2=0.6238\n",
      "Validation Error: Avg loss: 5.395605 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:27.386768 Epoch 1363, Training loss 5.135105609893799\n",
      "in params\n",
      "R2 values 0.6824, 0.7053, 0.5893; mean R2=0.6590\n",
      "Validation Error: Avg loss: 4.203405 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:27.666010 Epoch 1364, Training loss 2.975100040435791\n",
      "in params\n",
      "R2 values 0.7041, 0.8509, 0.7501; mean R2=0.7684\n",
      "Validation Error: Avg loss: 3.251450 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:27.939504 Epoch 1365, Training loss 3.2032992839813232\n",
      "in params\n",
      "R2 values 0.6375, 0.7918, 0.6092; mean R2=0.6795\n",
      "Validation Error: Avg loss: 3.621353 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:28.214769 Epoch 1366, Training loss 3.6144368648529053\n",
      "in params\n",
      "R2 values 0.5958, 0.8057, 0.5363; mean R2=0.6459\n",
      "Validation Error: Avg loss: 3.611673 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:28.487607 Epoch 1367, Training loss 3.574618101119995\n",
      "in params\n",
      "R2 values 0.6457, 0.7187, 0.6498; mean R2=0.6714\n",
      "Validation Error: Avg loss: 3.882401 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:28.772246 Epoch 1368, Training loss 3.4541072845458984\n",
      "in params\n",
      "R2 values 0.6147, 0.8063, 0.6682; mean R2=0.6964\n",
      "Validation Error: Avg loss: 3.094394 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:29.063357 Epoch 1369, Training loss 4.256439208984375\n",
      "in params\n",
      "R2 values 0.6241, 0.7494, 0.7328; mean R2=0.7021\n",
      "Validation Error: Avg loss: 3.483349 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:29.343764 Epoch 1370, Training loss 2.7870490550994873\n",
      "in params\n",
      "R2 values 0.6915, 0.6179, 0.6963; mean R2=0.6686\n",
      "Validation Error: Avg loss: 6.347153 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:29.623040 Epoch 1371, Training loss 3.700070858001709\n",
      "in params\n",
      "R2 values 0.7169, 0.8289, 0.6747; mean R2=0.7402\n",
      "Validation Error: Avg loss: 3.382149 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:29.902108 Epoch 1372, Training loss 3.2010128498077393\n",
      "in params\n",
      "R2 values 0.6313, 0.7534, 0.6964; mean R2=0.6937\n",
      "Validation Error: Avg loss: 4.013481 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:30.184993 Epoch 1373, Training loss 3.8354203701019287\n",
      "in params\n",
      "R2 values 0.6834, 0.7411, 0.7223; mean R2=0.7156\n",
      "Validation Error: Avg loss: 4.111741 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:30.460031 Epoch 1374, Training loss 3.7969071865081787\n",
      "in params\n",
      "R2 values 0.6274, 0.7282, 0.5773; mean R2=0.6443\n",
      "Validation Error: Avg loss: 4.607569 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:30.748560 Epoch 1375, Training loss 2.733348846435547\n",
      "in params\n",
      "R2 values 0.7151, 0.8527, 0.6542; mean R2=0.7406\n",
      "Validation Error: Avg loss: 2.859075 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:31.023591 Epoch 1376, Training loss 3.005178451538086\n",
      "in params\n",
      "R2 values 0.6336, 0.7269, 0.7021; mean R2=0.6875\n",
      "Validation Error: Avg loss: 3.803497 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:31.322707 Epoch 1377, Training loss 4.67877721786499\n",
      "in params\n",
      "R2 values 0.6879, 0.8469, 0.7261; mean R2=0.7536\n",
      "Validation Error: Avg loss: 2.553948 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:31.605776 Epoch 1378, Training loss 3.507092237472534\n",
      "in params\n",
      "R2 values 0.6977, 0.6965, 0.6875; mean R2=0.6939\n",
      "Validation Error: Avg loss: 3.933612 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:31.905852 Epoch 1379, Training loss 2.932615280151367\n",
      "in params\n",
      "R2 values 0.6491, 0.6012, 0.5908; mean R2=0.6137\n",
      "Validation Error: Avg loss: 5.416383 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:32.183441 Epoch 1380, Training loss 5.385368824005127\n",
      "in params\n",
      "R2 values 0.7138, 0.6567, 0.6390; mean R2=0.6699\n",
      "Validation Error: Avg loss: 4.747201 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:57:32.464729 Epoch 1381, Training loss 3.689521551132202\n",
      "in params\n",
      "R2 values 0.7199, 0.6911, 0.6791; mean R2=0.6967\n",
      "Validation Error: Avg loss: 4.822151 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:32.737943 Epoch 1382, Training loss 2.8411781787872314\n",
      "in params\n",
      "R2 values 0.7021, 0.6276, 0.6750; mean R2=0.6682\n",
      "Validation Error: Avg loss: 4.723680 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:33.008826 Epoch 1383, Training loss 3.566410541534424\n",
      "in params\n",
      "R2 values 0.7457, 0.6509, 0.6517; mean R2=0.6828\n",
      "Validation Error: Avg loss: 4.627903 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:33.278526 Epoch 1384, Training loss 3.084996223449707\n",
      "in params\n",
      "R2 values 0.6598, 0.7389, 0.7098; mean R2=0.7028\n",
      "Validation Error: Avg loss: 3.805255 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:33.557689 Epoch 1385, Training loss 3.5203912258148193\n",
      "in params\n",
      "R2 values 0.5463, 0.5204, 0.6232; mean R2=0.5633\n",
      "Validation Error: Avg loss: 5.998180 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:33.834754 Epoch 1386, Training loss 3.2116925716400146\n",
      "in params\n",
      "R2 values 0.6546, 0.5863, 0.6461; mean R2=0.6290\n",
      "Validation Error: Avg loss: 5.272255 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:34.106136 Epoch 1387, Training loss 3.1509008407592773\n",
      "in params\n",
      "R2 values 0.6326, 0.8155, 0.6551; mean R2=0.7011\n",
      "Validation Error: Avg loss: 3.062670 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:34.379731 Epoch 1388, Training loss 2.7921555042266846\n",
      "in params\n",
      "R2 values 0.6547, 0.8116, 0.7070; mean R2=0.7244\n",
      "Validation Error: Avg loss: 2.919188 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:34.656887 Epoch 1389, Training loss 3.811840772628784\n",
      "in params\n",
      "R2 values 0.7118, 0.7164, 0.6207; mean R2=0.6830\n",
      "Validation Error: Avg loss: 4.295115 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:34.947758 Epoch 1390, Training loss 3.3988983631134033\n",
      "in params\n",
      "R2 values 0.6636, 0.7839, 0.6753; mean R2=0.7076\n",
      "Validation Error: Avg loss: 3.718502 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:35.226868 Epoch 1391, Training loss 3.0477845668792725\n",
      "in params\n",
      "R2 values 0.6980, 0.7486, 0.7611; mean R2=0.7359\n",
      "Validation Error: Avg loss: 4.146408 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:35.502897 Epoch 1392, Training loss 2.420358419418335\n",
      "in params\n",
      "R2 values 0.6304, 0.8584, 0.6929; mean R2=0.7272\n",
      "Validation Error: Avg loss: 3.195829 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:35.781691 Epoch 1393, Training loss 3.751769781112671\n",
      "in params\n",
      "R2 values 0.6603, 0.7425, 0.6632; mean R2=0.6887\n",
      "Validation Error: Avg loss: 3.769359 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:36.060284 Epoch 1394, Training loss 3.517927885055542\n",
      "in params\n",
      "R2 values 0.5084, 0.7275, 0.6502; mean R2=0.6287\n",
      "Validation Error: Avg loss: 4.060332 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:36.335819 Epoch 1395, Training loss 3.2477126121520996\n",
      "in params\n",
      "R2 values 0.5781, 0.7134, 0.6490; mean R2=0.6468\n",
      "Validation Error: Avg loss: 4.146112 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:36.610646 Epoch 1396, Training loss 2.848870038986206\n",
      "in params\n",
      "R2 values 0.5931, 0.7329, 0.6433; mean R2=0.6564\n",
      "Validation Error: Avg loss: 4.041414 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:36.897794 Epoch 1397, Training loss 4.566412925720215\n",
      "in params\n",
      "R2 values 0.6838, 0.6635, 0.6700; mean R2=0.6724\n",
      "Validation Error: Avg loss: 4.378688 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:37.172325 Epoch 1398, Training loss 2.9261398315429688\n",
      "in params\n",
      "R2 values 0.7251, 0.6925, 0.7024; mean R2=0.7066\n",
      "Validation Error: Avg loss: 3.953537 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:37.456612 Epoch 1399, Training loss 3.706850051879883\n",
      "in params\n",
      "R2 values 0.6880, 0.8990, 0.7701; mean R2=0.7857\n",
      "Validation Error: Avg loss: 2.371684 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:37.732361 Epoch 1400, Training loss 2.6774983406066895\n",
      "in params\n",
      "R2 values 0.7321, 0.6851, 0.7382; mean R2=0.7185\n",
      "Validation Error: Avg loss: 3.896637 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:38.010610 Epoch 1401, Training loss 3.8425445556640625\n",
      "in params\n",
      "R2 values 0.6380, 0.6531, 0.7162; mean R2=0.6691\n",
      "Validation Error: Avg loss: 4.613889 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:38.273751 Epoch 1402, Training loss 3.6675703525543213\n",
      "in params\n",
      "R2 values 0.7537, 0.6730, 0.7870; mean R2=0.7379\n",
      "Validation Error: Avg loss: 3.806423 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:38.548596 Epoch 1403, Training loss 2.4981672763824463\n",
      "in params\n",
      "R2 values 0.6703, 0.7023, 0.6812; mean R2=0.6846\n",
      "Validation Error: Avg loss: 4.300008 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:38.828198 Epoch 1404, Training loss 3.4519383907318115\n",
      "in params\n",
      "R2 values 0.5913, 0.6339, 0.5741; mean R2=0.5998\n",
      "Validation Error: Avg loss: 5.815562 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:39.108448 Epoch 1405, Training loss 2.6376025676727295\n",
      "in params\n",
      "R2 values 0.6385, 0.7535, 0.6400; mean R2=0.6773\n",
      "Validation Error: Avg loss: 4.161371 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:39.383567 Epoch 1406, Training loss 3.2085108757019043\n",
      "in params\n",
      "R2 values 0.7342, 0.7108, 0.5802; mean R2=0.6751\n",
      "Validation Error: Avg loss: 4.212117 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:39.665986 Epoch 1407, Training loss 3.933070421218872\n",
      "in params\n",
      "R2 values 0.6644, 0.6810, 0.6211; mean R2=0.6555\n",
      "Validation Error: Avg loss: 4.362965 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:39.942163 Epoch 1408, Training loss 3.5139997005462646\n",
      "in params\n",
      "R2 values 0.6398, 0.7701, 0.6978; mean R2=0.7026\n",
      "Validation Error: Avg loss: 3.848731 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:40.223834 Epoch 1409, Training loss 2.1989834308624268\n",
      "in params\n",
      "R2 values 0.7319, 0.6948, 0.7052; mean R2=0.7106\n",
      "Validation Error: Avg loss: 3.883143 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:40.509130 Epoch 1410, Training loss 3.6305737495422363\n",
      "in params\n",
      "R2 values 0.6359, 0.5406, 0.5929; mean R2=0.5898\n",
      "Validation Error: Avg loss: 6.143447 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:40.798160 Epoch 1411, Training loss 3.7577643394470215\n",
      "in params\n",
      "R2 values 0.7751, 0.7438, 0.7308; mean R2=0.7499\n",
      "Validation Error: Avg loss: 3.336904 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:41.079798 Epoch 1412, Training loss 4.0742597579956055\n",
      "in params\n",
      "R2 values 0.7041, 0.7294, 0.6995; mean R2=0.7110\n",
      "Validation Error: Avg loss: 4.012026 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:41.358019 Epoch 1413, Training loss 3.4760594367980957\n",
      "in params\n",
      "R2 values 0.6391, 0.7056, 0.6309; mean R2=0.6585\n",
      "Validation Error: Avg loss: 4.984982 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:41.630667 Epoch 1414, Training loss 2.984968423843384\n",
      "in params\n",
      "R2 values 0.6335, 0.7923, 0.6361; mean R2=0.6873\n",
      "Validation Error: Avg loss: 3.320893 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:41.906281 Epoch 1415, Training loss 2.800401449203491\n",
      "in params\n",
      "R2 values 0.6990, 0.7976, 0.6565; mean R2=0.7177\n",
      "Validation Error: Avg loss: 3.455683 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:42.186228 Epoch 1416, Training loss 3.5736734867095947\n",
      "in params\n",
      "R2 values 0.5563, 0.5699, 0.5904; mean R2=0.5722\n",
      "Validation Error: Avg loss: 5.584841 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:42.456776 Epoch 1417, Training loss 3.2624523639678955\n",
      "in params\n",
      "R2 values 0.6708, 0.7128, 0.6260; mean R2=0.6699\n",
      "Validation Error: Avg loss: 4.042983 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:42.736586 Epoch 1418, Training loss 2.4388558864593506\n",
      "in params\n",
      "R2 values 0.5716, 0.6474, 0.6607; mean R2=0.6266\n",
      "Validation Error: Avg loss: 4.663773 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:43.010496 Epoch 1419, Training loss 3.2510077953338623\n",
      "in params\n",
      "R2 values 0.6750, 0.6446, 0.5966; mean R2=0.6387\n",
      "Validation Error: Avg loss: 5.078465 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:43.286467 Epoch 1420, Training loss 3.902496337890625\n",
      "in params\n",
      "R2 values 0.7033, 0.7861, 0.6827; mean R2=0.7240\n",
      "Validation Error: Avg loss: 3.557890 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:43.561429 Epoch 1421, Training loss 2.7091453075408936\n",
      "in params\n",
      "R2 values 0.6021, 0.5531, 0.5833; mean R2=0.5795\n",
      "Validation Error: Avg loss: 6.397305 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:43.841895 Epoch 1422, Training loss 4.166916370391846\n",
      "in params\n",
      "R2 values 0.6792, 0.6169, 0.6161; mean R2=0.6374\n",
      "Validation Error: Avg loss: 5.744446 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:44.124857 Epoch 1423, Training loss 4.584639072418213\n",
      "in params\n",
      "R2 values 0.6096, 0.7052, 0.6544; mean R2=0.6564\n",
      "Validation Error: Avg loss: 5.194066 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:44.394216 Epoch 1424, Training loss 3.27793025970459\n",
      "in params\n",
      "R2 values 0.5966, 0.3429, 0.5202; mean R2=0.4866\n",
      "Validation Error: Avg loss: 8.235949 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:44.674397 Epoch 1425, Training loss 3.2628512382507324\n",
      "in params\n",
      "R2 values 0.6253, 0.7728, 0.6382; mean R2=0.6787\n",
      "Validation Error: Avg loss: 3.741876 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:44.949383 Epoch 1426, Training loss 4.477505207061768\n",
      "in params\n",
      "R2 values 0.5403, 0.6131, 0.5186; mean R2=0.5573\n",
      "Validation Error: Avg loss: 5.536355 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:57:45.228514 Epoch 1427, Training loss 3.3131725788116455\n",
      "in params\n",
      "R2 values 0.6673, 0.6705, 0.6573; mean R2=0.6650\n",
      "Validation Error: Avg loss: 4.366236 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:45.497651 Epoch 1428, Training loss 4.642695426940918\n",
      "in params\n",
      "R2 values 0.6280, 0.6445, 0.6391; mean R2=0.6372\n",
      "Validation Error: Avg loss: 4.716657 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:45.786787 Epoch 1429, Training loss 3.572618246078491\n",
      "in params\n",
      "R2 values 0.7579, 0.7921, 0.7080; mean R2=0.7526\n",
      "Validation Error: Avg loss: 3.056590 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:46.061108 Epoch 1430, Training loss 3.1242241859436035\n",
      "in params\n",
      "R2 values 0.7090, 0.7194, 0.7018; mean R2=0.7101\n",
      "Validation Error: Avg loss: 4.592071 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:46.332255 Epoch 1431, Training loss 2.989654302597046\n",
      "in params\n",
      "R2 values 0.6270, 0.6201, 0.6528; mean R2=0.6333\n",
      "Validation Error: Avg loss: 5.439277 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:46.599055 Epoch 1432, Training loss 3.507368326187134\n",
      "in params\n",
      "R2 values 0.6834, 0.6622, 0.7153; mean R2=0.6870\n",
      "Validation Error: Avg loss: 5.485164 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:46.875150 Epoch 1433, Training loss 4.645384788513184\n",
      "in params\n",
      "R2 values 0.7541, 0.6732, 0.8074; mean R2=0.7449\n",
      "Validation Error: Avg loss: 5.328530 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:47.153405 Epoch 1434, Training loss 3.5475900173187256\n",
      "in params\n",
      "R2 values 0.7231, 0.6061, 0.6923; mean R2=0.6738\n",
      "Validation Error: Avg loss: 5.008684 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:47.419561 Epoch 1435, Training loss 2.949840784072876\n",
      "in params\n",
      "R2 values 0.6457, 0.7853, 0.7176; mean R2=0.7162\n",
      "Validation Error: Avg loss: 3.487316 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:47.701114 Epoch 1436, Training loss 3.0778439044952393\n",
      "in params\n",
      "R2 values 0.6135, 0.7218, 0.7033; mean R2=0.6795\n",
      "Validation Error: Avg loss: 4.363987 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:47.977408 Epoch 1437, Training loss 3.206092596054077\n",
      "in params\n",
      "R2 values 0.6671, 0.5676, 0.5543; mean R2=0.5964\n",
      "Validation Error: Avg loss: 5.604906 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:48.255801 Epoch 1438, Training loss 3.6221656799316406\n",
      "in params\n",
      "R2 values 0.4686, 0.6305, 0.6852; mean R2=0.5948\n",
      "Validation Error: Avg loss: 4.825914 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:48.529693 Epoch 1439, Training loss 3.0698277950286865\n",
      "in params\n",
      "R2 values 0.8087, 0.6964, 0.7630; mean R2=0.7560\n",
      "Validation Error: Avg loss: 3.662963 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:48.807691 Epoch 1440, Training loss 2.471163034439087\n",
      "in params\n",
      "R2 values 0.6255, 0.5430, 0.5748; mean R2=0.5811\n",
      "Validation Error: Avg loss: 6.095197 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:49.094992 Epoch 1441, Training loss 3.8048095703125\n",
      "in params\n",
      "R2 values 0.6262, 0.6713, 0.6235; mean R2=0.6403\n",
      "Validation Error: Avg loss: 4.791188 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:49.364277 Epoch 1442, Training loss 3.3153460025787354\n",
      "in params\n",
      "R2 values 0.7811, 0.7280, 0.7081; mean R2=0.7391\n",
      "Validation Error: Avg loss: 4.875372 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:49.697416 Epoch 1443, Training loss 3.856226921081543\n",
      "in params\n",
      "R2 values 0.6891, 0.6017, 0.6301; mean R2=0.6403\n",
      "Validation Error: Avg loss: 5.149539 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:49.974595 Epoch 1444, Training loss 3.579983711242676\n",
      "in params\n",
      "R2 values 0.7203, 0.7891, 0.6509; mean R2=0.7201\n",
      "Validation Error: Avg loss: 3.425884 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:50.257671 Epoch 1445, Training loss 4.178481578826904\n",
      "in params\n",
      "R2 values 0.7307, 0.6695, 0.6758; mean R2=0.6920\n",
      "Validation Error: Avg loss: 4.264450 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:50.532481 Epoch 1446, Training loss 3.1838061809539795\n",
      "in params\n",
      "R2 values 0.5724, 0.6785, 0.7320; mean R2=0.6610\n",
      "Validation Error: Avg loss: 4.277679 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:50.835458 Epoch 1447, Training loss 4.218653678894043\n",
      "in params\n",
      "R2 values 0.6629, 0.6952, 0.6516; mean R2=0.6699\n",
      "Validation Error: Avg loss: 4.207410 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:51.109607 Epoch 1448, Training loss 3.316314935684204\n",
      "in params\n",
      "R2 values 0.7195, 0.6607, 0.6626; mean R2=0.6809\n",
      "Validation Error: Avg loss: 4.383280 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:51.385727 Epoch 1449, Training loss 2.187115430831909\n",
      "in params\n",
      "R2 values 0.7318, 0.6517, 0.7368; mean R2=0.7067\n",
      "Validation Error: Avg loss: 4.155309 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:51.658087 Epoch 1450, Training loss 2.5452358722686768\n",
      "in params\n",
      "R2 values 0.6269, 0.5417, 0.5593; mean R2=0.5759\n",
      "Validation Error: Avg loss: 5.938591 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:51.928994 Epoch 1451, Training loss 3.5299813747406006\n",
      "in params\n",
      "R2 values 0.7059, 0.7169, 0.6487; mean R2=0.6905\n",
      "Validation Error: Avg loss: 4.160143 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:52.205001 Epoch 1452, Training loss 3.849748134613037\n",
      "in params\n",
      "R2 values 0.6736, 0.5998, 0.6556; mean R2=0.6430\n",
      "Validation Error: Avg loss: 4.916783 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:52.481855 Epoch 1453, Training loss 3.420088768005371\n",
      "in params\n",
      "R2 values 0.7455, 0.6416, 0.6924; mean R2=0.6931\n",
      "Validation Error: Avg loss: 4.401579 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:52.767053 Epoch 1454, Training loss 4.05519437789917\n",
      "in params\n",
      "R2 values 0.6821, 0.6396, 0.5579; mean R2=0.6265\n",
      "Validation Error: Avg loss: 5.089607 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:53.053071 Epoch 1455, Training loss 2.7470505237579346\n",
      "in params\n",
      "R2 values 0.6950, 0.6753, 0.6644; mean R2=0.6782\n",
      "Validation Error: Avg loss: 4.145051 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:53.322695 Epoch 1456, Training loss 2.915539026260376\n",
      "in params\n",
      "R2 values 0.7084, 0.5884, 0.6635; mean R2=0.6534\n",
      "Validation Error: Avg loss: 4.920107 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:53.597930 Epoch 1457, Training loss 4.892198085784912\n",
      "in params\n",
      "R2 values 0.7270, 0.7527, 0.7301; mean R2=0.7366\n",
      "Validation Error: Avg loss: 3.375853 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:53.876739 Epoch 1458, Training loss 3.28342342376709\n",
      "in params\n",
      "R2 values 0.6604, 0.6127, 0.6331; mean R2=0.6354\n",
      "Validation Error: Avg loss: 5.126196 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:54.162778 Epoch 1459, Training loss 3.1774511337280273\n",
      "in params\n",
      "R2 values 0.6745, 0.5509, 0.7120; mean R2=0.6458\n",
      "Validation Error: Avg loss: 5.461967 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:54.437830 Epoch 1460, Training loss 4.346951007843018\n",
      "in params\n",
      "R2 values 0.6166, 0.8353, 0.5845; mean R2=0.6788\n",
      "Validation Error: Avg loss: 3.278713 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:54.715563 Epoch 1461, Training loss 3.756463050842285\n",
      "in params\n",
      "R2 values 0.7596, 0.7379, 0.6937; mean R2=0.7304\n",
      "Validation Error: Avg loss: 3.643875 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:54.991366 Epoch 1462, Training loss 4.370931625366211\n",
      "in params\n",
      "R2 values 0.6804, 0.6331, 0.6747; mean R2=0.6628\n",
      "Validation Error: Avg loss: 4.692048 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:55.269908 Epoch 1463, Training loss 2.5025899410247803\n",
      "in params\n",
      "R2 values 0.6737, 0.6390, 0.6115; mean R2=0.6414\n",
      "Validation Error: Avg loss: 4.877803 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:55.549339 Epoch 1464, Training loss 2.8843250274658203\n",
      "in params\n",
      "R2 values 0.7260, 0.7589, 0.6218; mean R2=0.7022\n",
      "Validation Error: Avg loss: 3.556573 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:55.824661 Epoch 1465, Training loss 3.457530975341797\n",
      "in params\n",
      "R2 values 0.6216, 0.7481, 0.6240; mean R2=0.6646\n",
      "Validation Error: Avg loss: 3.710498 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:56.100628 Epoch 1466, Training loss 3.9525508880615234\n",
      "in params\n",
      "R2 values 0.6711, 0.7201, 0.7316; mean R2=0.7076\n",
      "Validation Error: Avg loss: 3.615034 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:56.368836 Epoch 1467, Training loss 2.838465690612793\n",
      "in params\n",
      "R2 values 0.6250, 0.6114, 0.6120; mean R2=0.6161\n",
      "Validation Error: Avg loss: 5.160674 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:56.651415 Epoch 1468, Training loss 3.285830497741699\n",
      "in params\n",
      "R2 values 0.7134, 0.6211, 0.6475; mean R2=0.6606\n",
      "Validation Error: Avg loss: 5.706654 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:56.935256 Epoch 1469, Training loss 3.2973341941833496\n",
      "in params\n",
      "R2 values 0.7515, 0.6413, 0.6562; mean R2=0.6830\n",
      "Validation Error: Avg loss: 4.766617 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:57.217252 Epoch 1470, Training loss 4.431083679199219\n",
      "in params\n",
      "R2 values 0.5704, 0.7650, 0.6257; mean R2=0.6537\n",
      "Validation Error: Avg loss: 4.023584 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:57.490375 Epoch 1471, Training loss 2.632991075515747\n",
      "in params\n",
      "R2 values 0.5971, 0.7197, 0.6576; mean R2=0.6581\n",
      "Validation Error: Avg loss: 4.079509 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:57.772377 Epoch 1472, Training loss 3.496467351913452\n",
      "in params\n",
      "R2 values 0.7523, 0.7024, 0.6535; mean R2=0.7027\n",
      "Validation Error: Avg loss: 4.067526 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:57:58.049607 Epoch 1473, Training loss 2.7812297344207764\n",
      "in params\n",
      "R2 values 0.5583, 0.7769, 0.6411; mean R2=0.6588\n",
      "Validation Error: Avg loss: 3.682499 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:58.325408 Epoch 1474, Training loss 2.8869402408599854\n",
      "in params\n",
      "R2 values 0.6618, 0.6780, 0.5958; mean R2=0.6452\n",
      "Validation Error: Avg loss: 4.409580 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:58.602377 Epoch 1475, Training loss 3.0132124423980713\n",
      "in params\n",
      "R2 values 0.6464, 0.6922, 0.6807; mean R2=0.6731\n",
      "Validation Error: Avg loss: 4.106483 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:58.892748 Epoch 1476, Training loss 3.3118605613708496\n",
      "in params\n",
      "R2 values 0.6184, 0.8317, 0.6986; mean R2=0.7162\n",
      "Validation Error: Avg loss: 3.033881 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:59.168511 Epoch 1477, Training loss 3.9533379077911377\n",
      "in params\n",
      "R2 values 0.6515, 0.8638, 0.5783; mean R2=0.6979\n",
      "Validation Error: Avg loss: 3.209782 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:59.443525 Epoch 1478, Training loss 3.574368476867676\n",
      "in params\n",
      "R2 values 0.7323, 0.4862, 0.7090; mean R2=0.6425\n",
      "Validation Error: Avg loss: 5.992729 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:59.725554 Epoch 1479, Training loss 3.9744744300842285\n",
      "in params\n",
      "R2 values 0.6715, 0.7880, 0.6908; mean R2=0.7168\n",
      "Validation Error: Avg loss: 3.188270 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:57:59.996578 Epoch 1480, Training loss 4.2056803703308105\n",
      "in params\n",
      "R2 values 0.7418, 0.6927, 0.6906; mean R2=0.7083\n",
      "Validation Error: Avg loss: 4.106778 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:00.274762 Epoch 1481, Training loss 3.486464500427246\n",
      "in params\n",
      "R2 values 0.6886, 0.6356, 0.7478; mean R2=0.6907\n",
      "Validation Error: Avg loss: 4.951695 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:00.645644 Epoch 1482, Training loss 3.361891984939575\n",
      "in params\n",
      "R2 values 0.6728, 0.7799, 0.6645; mean R2=0.7057\n",
      "Validation Error: Avg loss: 3.623573 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:00.935682 Epoch 1483, Training loss 2.882800579071045\n",
      "in params\n",
      "R2 values 0.6183, 0.7161, 0.6291; mean R2=0.6545\n",
      "Validation Error: Avg loss: 4.401835 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:01.211624 Epoch 1484, Training loss 3.5904176235198975\n",
      "in params\n",
      "R2 values 0.6880, 0.7237, 0.6331; mean R2=0.6816\n",
      "Validation Error: Avg loss: 4.138825 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:01.486760 Epoch 1485, Training loss 2.8237292766571045\n",
      "in params\n",
      "R2 values 0.6757, 0.6406, 0.6572; mean R2=0.6578\n",
      "Validation Error: Avg loss: 4.722708 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:01.764237 Epoch 1486, Training loss 2.995551109313965\n",
      "in params\n",
      "R2 values 0.7280, 0.7022, 0.7415; mean R2=0.7239\n",
      "Validation Error: Avg loss: 3.734346 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:02.053396 Epoch 1487, Training loss 3.501796245574951\n",
      "in params\n",
      "R2 values 0.6840, 0.7307, 0.6359; mean R2=0.6835\n",
      "Validation Error: Avg loss: 3.871276 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:02.351730 Epoch 1488, Training loss 3.0360710620880127\n",
      "in params\n",
      "R2 values 0.6253, 0.6310, 0.6260; mean R2=0.6274\n",
      "Validation Error: Avg loss: 5.036497 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:02.627698 Epoch 1489, Training loss 3.240206718444824\n",
      "in params\n",
      "R2 values 0.7050, 0.6657, 0.6943; mean R2=0.6884\n",
      "Validation Error: Avg loss: 4.357681 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:02.902833 Epoch 1490, Training loss 3.613802909851074\n",
      "in params\n",
      "R2 values 0.6385, 0.5714, 0.6091; mean R2=0.6063\n",
      "Validation Error: Avg loss: 5.704844 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:03.177401 Epoch 1491, Training loss 2.6432154178619385\n",
      "in params\n",
      "R2 values 0.7107, 0.6323, 0.7058; mean R2=0.6829\n",
      "Validation Error: Avg loss: 4.492344 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:03.451195 Epoch 1492, Training loss 3.1940834522247314\n",
      "in params\n",
      "R2 values 0.6507, 0.5207, 0.6334; mean R2=0.6016\n",
      "Validation Error: Avg loss: 5.839963 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:03.729298 Epoch 1493, Training loss 2.947995901107788\n",
      "in params\n",
      "R2 values 0.6200, 0.6033, 0.7755; mean R2=0.6663\n",
      "Validation Error: Avg loss: 4.733428 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:04.005765 Epoch 1494, Training loss 3.5135326385498047\n",
      "in params\n",
      "R2 values 0.7170, 0.5852, 0.6921; mean R2=0.6648\n",
      "Validation Error: Avg loss: 5.135635 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:04.275955 Epoch 1495, Training loss 3.615570306777954\n",
      "in params\n",
      "R2 values 0.7161, 0.7398, 0.6849; mean R2=0.7136\n",
      "Validation Error: Avg loss: 3.601390 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:04.550294 Epoch 1496, Training loss 3.4712719917297363\n",
      "in params\n",
      "R2 values 0.6896, 0.8231, 0.7386; mean R2=0.7504\n",
      "Validation Error: Avg loss: 2.833772 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:04.833878 Epoch 1497, Training loss 2.875894784927368\n",
      "in params\n",
      "R2 values 0.6610, 0.6539, 0.5661; mean R2=0.6270\n",
      "Validation Error: Avg loss: 4.789207 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:05.128586 Epoch 1498, Training loss 3.2262094020843506\n",
      "in params\n",
      "R2 values 0.6420, 0.5525, 0.7284; mean R2=0.6410\n",
      "Validation Error: Avg loss: 5.253267 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:05.399727 Epoch 1499, Training loss 2.951306104660034\n",
      "in params\n",
      "R2 values 0.6879, 0.7625, 0.7072; mean R2=0.7192\n",
      "Validation Error: Avg loss: 3.642338 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:05.675764 Epoch 1500, Training loss 3.4817357063293457\n",
      "in params\n",
      "R2 values 0.6208, 0.6220, 0.6501; mean R2=0.6310\n",
      "Validation Error: Avg loss: 5.293748 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:05.955080 Epoch 1501, Training loss 3.3709805011749268\n",
      "in params\n",
      "R2 values 0.6789, 0.6821, 0.6269; mean R2=0.6626\n",
      "Validation Error: Avg loss: 4.268050 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:06.227826 Epoch 1502, Training loss 3.6331398487091064\n",
      "in params\n",
      "R2 values 0.7332, 0.7282, 0.6805; mean R2=0.7140\n",
      "Validation Error: Avg loss: 3.616371 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:06.506559 Epoch 1503, Training loss 3.368960380554199\n",
      "in params\n",
      "R2 values 0.6405, 0.7583, 0.6174; mean R2=0.6721\n",
      "Validation Error: Avg loss: 3.694090 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:06.786679 Epoch 1504, Training loss 3.4357824325561523\n",
      "in params\n",
      "R2 values 0.6335, 0.7359, 0.6619; mean R2=0.6771\n",
      "Validation Error: Avg loss: 3.721839 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:07.060059 Epoch 1505, Training loss 3.706636428833008\n",
      "in params\n",
      "R2 values 0.7618, 0.7199, 0.7211; mean R2=0.7343\n",
      "Validation Error: Avg loss: 3.605862 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:07.344572 Epoch 1506, Training loss 3.291351795196533\n",
      "in params\n",
      "R2 values 0.6031, 0.6773, 0.7118; mean R2=0.6641\n",
      "Validation Error: Avg loss: 4.620442 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:07.628886 Epoch 1507, Training loss 3.040437698364258\n",
      "in params\n",
      "R2 values 0.7229, 0.8175, 0.7555; mean R2=0.7653\n",
      "Validation Error: Avg loss: 3.327538 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:07.904844 Epoch 1508, Training loss 3.2803738117218018\n",
      "in params\n",
      "R2 values 0.6528, 0.7864, 0.5668; mean R2=0.6686\n",
      "Validation Error: Avg loss: 4.735313 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:08.180437 Epoch 1509, Training loss 3.2726387977600098\n",
      "in params\n",
      "R2 values 0.6161, 0.6596, 0.5759; mean R2=0.6172\n",
      "Validation Error: Avg loss: 5.151554 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:08.457393 Epoch 1510, Training loss 3.9191765785217285\n",
      "in params\n",
      "R2 values 0.7603, 0.6797, 0.6897; mean R2=0.7099\n",
      "Validation Error: Avg loss: 4.264928 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:08.734815 Epoch 1511, Training loss 4.0986199378967285\n",
      "in params\n",
      "R2 values 0.6469, 0.6473, 0.5712; mean R2=0.6218\n",
      "Validation Error: Avg loss: 4.923563 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:09.003318 Epoch 1512, Training loss 3.4046554565429688\n",
      "in params\n",
      "R2 values 0.7580, 0.6015, 0.6653; mean R2=0.6749\n",
      "Validation Error: Avg loss: 4.831872 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:09.277959 Epoch 1513, Training loss 2.585721015930176\n",
      "in params\n",
      "R2 values 0.7574, 0.8141, 0.7991; mean R2=0.7902\n",
      "Validation Error: Avg loss: 2.598982 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:09.556614 Epoch 1514, Training loss 3.9713680744171143\n",
      "in params\n",
      "R2 values 0.6253, 0.5660, 0.5903; mean R2=0.5939\n",
      "Validation Error: Avg loss: 5.454229 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:09.845474 Epoch 1515, Training loss 3.3028018474578857\n",
      "in params\n",
      "R2 values 0.6984, 0.6590, 0.7029; mean R2=0.6868\n",
      "Validation Error: Avg loss: 4.312812 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:10.130233 Epoch 1516, Training loss 2.9670956134796143\n",
      "in params\n",
      "R2 values 0.7136, 0.8099, 0.7107; mean R2=0.7447\n",
      "Validation Error: Avg loss: 2.924532 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:10.445867 Epoch 1517, Training loss 4.147395133972168\n",
      "in params\n",
      "R2 values 0.6513, 0.7178, 0.5957; mean R2=0.6549\n",
      "Validation Error: Avg loss: 4.178090 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:10.750174 Epoch 1518, Training loss 3.695340394973755\n",
      "in params\n",
      "R2 values 0.7122, 0.7932, 0.8095; mean R2=0.7716\n",
      "Validation Error: Avg loss: 4.036136 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:58:11.043568 Epoch 1519, Training loss 3.232147455215454\n",
      "in params\n",
      "R2 values 0.6840, 0.7874, 0.7351; mean R2=0.7355\n",
      "Validation Error: Avg loss: 3.132899 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:11.318720 Epoch 1520, Training loss 3.1183888912200928\n",
      "in params\n",
      "R2 values 0.7666, 0.8436, 0.7431; mean R2=0.7845\n",
      "Validation Error: Avg loss: 2.808269 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:11.596092 Epoch 1521, Training loss 3.4856693744659424\n",
      "in params\n",
      "R2 values 0.6728, 0.5417, 0.5331; mean R2=0.5826\n",
      "Validation Error: Avg loss: 5.904597 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:11.868610 Epoch 1522, Training loss 2.5381832122802734\n",
      "in params\n",
      "R2 values 0.6736, 0.6847, 0.6103; mean R2=0.6562\n",
      "Validation Error: Avg loss: 4.435741 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:12.146742 Epoch 1523, Training loss 3.86667537689209\n",
      "in params\n",
      "R2 values 0.5326, 0.7410, 0.6071; mean R2=0.6269\n",
      "Validation Error: Avg loss: 4.173017 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:12.431259 Epoch 1524, Training loss 3.5502445697784424\n",
      "in params\n",
      "R2 values 0.6410, 0.6921, 0.6084; mean R2=0.6472\n",
      "Validation Error: Avg loss: 4.414119 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:12.712975 Epoch 1525, Training loss 3.3393592834472656\n",
      "in params\n",
      "R2 values 0.6198, 0.6823, 0.6751; mean R2=0.6591\n",
      "Validation Error: Avg loss: 4.350679 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:13.006561 Epoch 1526, Training loss 3.3062148094177246\n",
      "in params\n",
      "R2 values 0.6494, 0.6869, 0.6515; mean R2=0.6626\n",
      "Validation Error: Avg loss: 4.565869 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:13.282017 Epoch 1527, Training loss 2.6055054664611816\n",
      "in params\n",
      "R2 values 0.6423, 0.7331, 0.6718; mean R2=0.6824\n",
      "Validation Error: Avg loss: 4.157586 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:13.552950 Epoch 1528, Training loss 2.7303783893585205\n",
      "in params\n",
      "R2 values 0.7326, 0.6272, 0.7848; mean R2=0.7148\n",
      "Validation Error: Avg loss: 4.639637 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:13.837990 Epoch 1529, Training loss 2.8383994102478027\n",
      "in params\n",
      "R2 values 0.6390, 0.7114, 0.5931; mean R2=0.6479\n",
      "Validation Error: Avg loss: 4.702181 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:14.117244 Epoch 1530, Training loss 3.1058225631713867\n",
      "in params\n",
      "R2 values 0.7780, 0.8731, 0.7892; mean R2=0.8134\n",
      "Validation Error: Avg loss: 2.252094 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:14.395307 Epoch 1531, Training loss 2.9499757289886475\n",
      "in params\n",
      "R2 values 0.6292, 0.7715, 0.7247; mean R2=0.7085\n",
      "Validation Error: Avg loss: 3.245147 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:14.669614 Epoch 1532, Training loss 2.555859327316284\n",
      "in params\n",
      "R2 values 0.7049, 0.8416, 0.6444; mean R2=0.7303\n",
      "Validation Error: Avg loss: 2.845479 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:14.945189 Epoch 1533, Training loss 4.526630878448486\n",
      "in params\n",
      "R2 values 0.6036, 0.7334, 0.5958; mean R2=0.6443\n",
      "Validation Error: Avg loss: 4.106851 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:15.229283 Epoch 1534, Training loss 2.2380471229553223\n",
      "in params\n",
      "R2 values 0.7564, 0.8085, 0.6595; mean R2=0.7415\n",
      "Validation Error: Avg loss: 3.219376 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:15.507704 Epoch 1535, Training loss 3.4760634899139404\n",
      "in params\n",
      "R2 values 0.6984, 0.7366, 0.6643; mean R2=0.6998\n",
      "Validation Error: Avg loss: 4.169557 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:15.791046 Epoch 1536, Training loss 4.160427093505859\n",
      "in params\n",
      "R2 values 0.6545, 0.8032, 0.6135; mean R2=0.6904\n",
      "Validation Error: Avg loss: 3.785811 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:16.064891 Epoch 1537, Training loss 3.5451157093048096\n",
      "in params\n",
      "R2 values 0.6496, 0.6296, 0.6465; mean R2=0.6419\n",
      "Validation Error: Avg loss: 4.937688 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:16.340321 Epoch 1538, Training loss 3.358992576599121\n",
      "in params\n",
      "R2 values 0.6721, 0.6169, 0.6336; mean R2=0.6409\n",
      "Validation Error: Avg loss: 5.129857 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:16.615668 Epoch 1539, Training loss 2.869570732116699\n",
      "in params\n",
      "R2 values 0.7104, 0.7885, 0.7610; mean R2=0.7533\n",
      "Validation Error: Avg loss: 3.159803 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:16.892231 Epoch 1540, Training loss 2.709481954574585\n",
      "in params\n",
      "R2 values 0.5888, 0.7765, 0.5825; mean R2=0.6493\n",
      "Validation Error: Avg loss: 3.718320 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:17.162418 Epoch 1541, Training loss 2.58886456489563\n",
      "in params\n",
      "R2 values 0.7148, 0.7913, 0.7038; mean R2=0.7366\n",
      "Validation Error: Avg loss: 3.088808 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:17.443455 Epoch 1542, Training loss 3.3440871238708496\n",
      "in params\n",
      "R2 values 0.7275, 0.8175, 0.6855; mean R2=0.7435\n",
      "Validation Error: Avg loss: 2.820193 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:17.721361 Epoch 1543, Training loss 2.797264575958252\n",
      "in params\n",
      "R2 values 0.6468, 0.6299, 0.6822; mean R2=0.6530\n",
      "Validation Error: Avg loss: 5.086199 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:17.990986 Epoch 1544, Training loss 4.111081123352051\n",
      "in params\n",
      "R2 values 0.7184, 0.7792, 0.6862; mean R2=0.7279\n",
      "Validation Error: Avg loss: 3.255166 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:18.269251 Epoch 1545, Training loss 3.0039150714874268\n",
      "in params\n",
      "R2 values 0.8097, 0.7931, 0.7801; mean R2=0.7943\n",
      "Validation Error: Avg loss: 2.691354 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:18.556970 Epoch 1546, Training loss 3.7056963443756104\n",
      "in params\n",
      "R2 values 0.8015, 0.6552, 0.6579; mean R2=0.7049\n",
      "Validation Error: Avg loss: 5.311441 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:18.845626 Epoch 1547, Training loss 3.054013252258301\n",
      "in params\n",
      "R2 values 0.6144, 0.7902, 0.6832; mean R2=0.6959\n",
      "Validation Error: Avg loss: 4.074521 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:19.122374 Epoch 1548, Training loss 3.5321242809295654\n",
      "in params\n",
      "R2 values 0.6003, 0.7389, 0.7071; mean R2=0.6821\n",
      "Validation Error: Avg loss: 3.874721 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:19.398397 Epoch 1549, Training loss 3.1659538745880127\n",
      "in params\n",
      "R2 values 0.6311, 0.6376, 0.6950; mean R2=0.6545\n",
      "Validation Error: Avg loss: 4.794780 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:19.683012 Epoch 1550, Training loss 3.3402693271636963\n",
      "in params\n",
      "R2 values 0.6590, 0.7437, 0.7322; mean R2=0.7116\n",
      "Validation Error: Avg loss: 3.598001 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:19.965274 Epoch 1551, Training loss 3.153214931488037\n",
      "in params\n",
      "R2 values 0.6583, 0.6947, 0.6548; mean R2=0.6692\n",
      "Validation Error: Avg loss: 4.202922 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:20.248244 Epoch 1552, Training loss 4.973504543304443\n",
      "in params\n",
      "R2 values 0.5892, 0.6618, 0.5357; mean R2=0.5955\n",
      "Validation Error: Avg loss: 4.961174 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:20.524858 Epoch 1553, Training loss 3.114210844039917\n",
      "in params\n",
      "R2 values 0.7470, 0.7628, 0.7729; mean R2=0.7609\n",
      "Validation Error: Avg loss: 3.301390 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:20.823544 Epoch 1554, Training loss 2.3656296730041504\n",
      "in params\n",
      "R2 values 0.6511, 0.6698, 0.6676; mean R2=0.6628\n",
      "Validation Error: Avg loss: 4.306441 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:21.105110 Epoch 1555, Training loss 3.423444986343384\n",
      "in params\n",
      "R2 values 0.6277, 0.6976, 0.4686; mean R2=0.5979\n",
      "Validation Error: Avg loss: 5.017648 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:21.379748 Epoch 1556, Training loss 3.0902910232543945\n",
      "in params\n",
      "R2 values 0.7939, 0.7791, 0.7969; mean R2=0.7900\n",
      "Validation Error: Avg loss: 3.053024 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:21.658402 Epoch 1557, Training loss 3.18302845954895\n",
      "in params\n",
      "R2 values 0.6669, 0.7266, 0.6512; mean R2=0.6816\n",
      "Validation Error: Avg loss: 3.906334 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:21.950971 Epoch 1558, Training loss 3.607546806335449\n",
      "in params\n",
      "R2 values 0.7809, 0.6442, 0.7558; mean R2=0.7270\n",
      "Validation Error: Avg loss: 4.331720 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:22.228347 Epoch 1559, Training loss 2.8085129261016846\n",
      "in params\n",
      "R2 values 0.6796, 0.6552, 0.6345; mean R2=0.6564\n",
      "Validation Error: Avg loss: 4.635114 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:22.508372 Epoch 1560, Training loss 2.982283353805542\n",
      "in params\n",
      "R2 values 0.6633, 0.7867, 0.5822; mean R2=0.6774\n",
      "Validation Error: Avg loss: 3.550766 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:22.782531 Epoch 1561, Training loss 4.080469608306885\n",
      "in params\n",
      "R2 values 0.7129, 0.7849, 0.6888; mean R2=0.7289\n",
      "Validation Error: Avg loss: 3.182433 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:23.057976 Epoch 1562, Training loss 3.1458325386047363\n",
      "in params\n",
      "R2 values 0.7170, 0.7899, 0.6307; mean R2=0.7125\n",
      "Validation Error: Avg loss: 3.374481 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:23.336398 Epoch 1563, Training loss 4.000748157501221\n",
      "in params\n",
      "R2 values 0.7161, 0.5626, 0.7039; mean R2=0.6609\n",
      "Validation Error: Avg loss: 5.113210 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:23.618381 Epoch 1564, Training loss 2.911909341812134\n",
      "in params\n",
      "R2 values 0.6935, 0.7115, 0.7123; mean R2=0.7058\n",
      "Validation Error: Avg loss: 3.835864 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:58:23.899066 Epoch 1565, Training loss 3.5308570861816406\n",
      "in params\n",
      "R2 values 0.6184, 0.7149, 0.5589; mean R2=0.6307\n",
      "Validation Error: Avg loss: 4.576034 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:24.175298 Epoch 1566, Training loss 2.5906622409820557\n",
      "in params\n",
      "R2 values 0.7989, 0.7511, 0.8009; mean R2=0.7836\n",
      "Validation Error: Avg loss: 3.696198 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:24.452476 Epoch 1567, Training loss 2.8779566287994385\n",
      "in params\n",
      "R2 values 0.7956, 0.7150, 0.6657; mean R2=0.7254\n",
      "Validation Error: Avg loss: 4.024377 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:24.733742 Epoch 1568, Training loss 3.9591500759124756\n",
      "in params\n",
      "R2 values 0.5074, 0.6414, 0.5536; mean R2=0.5675\n",
      "Validation Error: Avg loss: 5.242136 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:25.008855 Epoch 1569, Training loss 2.947845935821533\n",
      "in params\n",
      "R2 values 0.6893, 0.6444, 0.5222; mean R2=0.6186\n",
      "Validation Error: Avg loss: 5.038206 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:25.286884 Epoch 1570, Training loss 3.314465284347534\n",
      "in params\n",
      "R2 values 0.6644, 0.6181, 0.6663; mean R2=0.6496\n",
      "Validation Error: Avg loss: 4.806137 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:25.563405 Epoch 1571, Training loss 3.3957316875457764\n",
      "in params\n",
      "R2 values 0.6416, 0.6700, 0.6218; mean R2=0.6445\n",
      "Validation Error: Avg loss: 4.610931 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:25.839751 Epoch 1572, Training loss 2.938048839569092\n",
      "in params\n",
      "R2 values 0.6028, 0.7413, 0.6281; mean R2=0.6574\n",
      "Validation Error: Avg loss: 3.883559 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:26.116507 Epoch 1573, Training loss 3.7182610034942627\n",
      "in params\n",
      "R2 values 0.7440, 0.7714, 0.7082; mean R2=0.7412\n",
      "Validation Error: Avg loss: 3.260175 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:26.397245 Epoch 1574, Training loss 3.1086926460266113\n",
      "in params\n",
      "R2 values 0.7010, 0.8478, 0.6873; mean R2=0.7453\n",
      "Validation Error: Avg loss: 3.355812 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:26.675440 Epoch 1575, Training loss 2.458395481109619\n",
      "in params\n",
      "R2 values 0.6037, 0.7244, 0.6990; mean R2=0.6757\n",
      "Validation Error: Avg loss: 4.195331 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:26.978062 Epoch 1576, Training loss 3.0605390071868896\n",
      "in params\n",
      "R2 values 0.6646, 0.7605, 0.6763; mean R2=0.7004\n",
      "Validation Error: Avg loss: 5.097198 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:27.257987 Epoch 1577, Training loss 3.2624704837799072\n",
      "in params\n",
      "R2 values 0.6735, 0.6923, 0.7143; mean R2=0.6934\n",
      "Validation Error: Avg loss: 4.988794 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:27.547023 Epoch 1578, Training loss 4.22475004196167\n",
      "in params\n",
      "R2 values 0.5897, 0.6786, 0.5872; mean R2=0.6185\n",
      "Validation Error: Avg loss: 4.974290 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:27.827525 Epoch 1579, Training loss 4.014585494995117\n",
      "in params\n",
      "R2 values 0.6735, 0.7849, 0.7319; mean R2=0.7301\n",
      "Validation Error: Avg loss: 3.058023 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:28.111616 Epoch 1580, Training loss 3.287899971008301\n",
      "in params\n",
      "R2 values 0.6857, 0.7141, 0.6790; mean R2=0.6929\n",
      "Validation Error: Avg loss: 3.897987 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:28.390928 Epoch 1581, Training loss 3.694153308868408\n",
      "in params\n",
      "R2 values 0.6179, 0.7030, 0.6549; mean R2=0.6586\n",
      "Validation Error: Avg loss: 4.179874 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:28.676069 Epoch 1582, Training loss 2.780039072036743\n",
      "in params\n",
      "R2 values 0.5897, 0.6823, 0.6104; mean R2=0.6275\n",
      "Validation Error: Avg loss: 4.446781 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:28.949256 Epoch 1583, Training loss 3.4928762912750244\n",
      "in params\n",
      "R2 values 0.6466, 0.7998, 0.6378; mean R2=0.6947\n",
      "Validation Error: Avg loss: 3.437484 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:29.233751 Epoch 1584, Training loss 3.938960313796997\n",
      "in params\n",
      "R2 values 0.6406, 0.6755, 0.6097; mean R2=0.6419\n",
      "Validation Error: Avg loss: 4.659456 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:29.512173 Epoch 1585, Training loss 3.3289315700531006\n",
      "in params\n",
      "R2 values 0.6728, 0.8010, 0.7194; mean R2=0.7310\n",
      "Validation Error: Avg loss: 2.969272 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:29.798500 Epoch 1586, Training loss 2.788975238800049\n",
      "in params\n",
      "R2 values 0.6973, 0.6335, 0.6130; mean R2=0.6480\n",
      "Validation Error: Avg loss: 4.715219 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:30.087283 Epoch 1587, Training loss 2.8689565658569336\n",
      "in params\n",
      "R2 values 0.7073, 0.8159, 0.7043; mean R2=0.7425\n",
      "Validation Error: Avg loss: 2.846693 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:30.376701 Epoch 1588, Training loss 3.095795154571533\n",
      "in params\n",
      "R2 values 0.6592, 0.8143, 0.7147; mean R2=0.7294\n",
      "Validation Error: Avg loss: 2.968858 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:30.655225 Epoch 1589, Training loss 3.440477132797241\n",
      "in params\n",
      "R2 values 0.6803, 0.7397, 0.6533; mean R2=0.6911\n",
      "Validation Error: Avg loss: 3.775754 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:30.950395 Epoch 1590, Training loss 2.859657049179077\n",
      "in params\n",
      "R2 values 0.6092, 0.8453, 0.7038; mean R2=0.7194\n",
      "Validation Error: Avg loss: 2.646814 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:31.225576 Epoch 1591, Training loss 2.680861473083496\n",
      "in params\n",
      "R2 values 0.5372, 0.7394, 0.6138; mean R2=0.6301\n",
      "Validation Error: Avg loss: 5.528566 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:31.501270 Epoch 1592, Training loss 2.491712808609009\n",
      "in params\n",
      "R2 values 0.6698, 0.6552, 0.7292; mean R2=0.6847\n",
      "Validation Error: Avg loss: 4.323041 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:31.779805 Epoch 1593, Training loss 3.110879898071289\n",
      "in params\n",
      "R2 values 0.7198, 0.8002, 0.6092; mean R2=0.7097\n",
      "Validation Error: Avg loss: 3.446891 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:32.056799 Epoch 1594, Training loss 2.333578109741211\n",
      "in params\n",
      "R2 values 0.6316, 0.6944, 0.7117; mean R2=0.6792\n",
      "Validation Error: Avg loss: 3.996262 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:32.330566 Epoch 1595, Training loss 3.7063419818878174\n",
      "in params\n",
      "R2 values 0.7199, 0.7435, 0.7123; mean R2=0.7252\n",
      "Validation Error: Avg loss: 3.416710 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:32.622184 Epoch 1596, Training loss 3.111711025238037\n",
      "in params\n",
      "R2 values 0.5793, 0.6584, 0.6831; mean R2=0.6402\n",
      "Validation Error: Avg loss: 4.434011 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:32.896359 Epoch 1597, Training loss 4.181489944458008\n",
      "in params\n",
      "R2 values 0.6255, 0.6915, 0.6629; mean R2=0.6600\n",
      "Validation Error: Avg loss: 4.367491 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:33.175639 Epoch 1598, Training loss 2.8154475688934326\n",
      "in params\n",
      "R2 values 0.5233, 0.4577, 0.5786; mean R2=0.5199\n",
      "Validation Error: Avg loss: 6.761154 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:33.445524 Epoch 1599, Training loss 3.7775065898895264\n",
      "in params\n",
      "R2 values 0.6715, 0.6455, 0.6272; mean R2=0.6480\n",
      "Validation Error: Avg loss: 4.805572 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:33.732328 Epoch 1600, Training loss 2.7370355129241943\n",
      "in params\n",
      "R2 values 0.6697, 0.7079, 0.6260; mean R2=0.6679\n",
      "Validation Error: Avg loss: 4.135132 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:34.012192 Epoch 1601, Training loss 3.280730724334717\n",
      "in params\n",
      "R2 values 0.7110, 0.7558, 0.7700; mean R2=0.7456\n",
      "Validation Error: Avg loss: 3.297862 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:34.292808 Epoch 1602, Training loss 2.4638218879699707\n",
      "in params\n",
      "R2 values 0.7321, 0.7133, 0.6637; mean R2=0.7030\n",
      "Validation Error: Avg loss: 4.024891 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:34.573750 Epoch 1603, Training loss 4.561696529388428\n",
      "in params\n",
      "R2 values 0.6459, 0.7004, 0.5552; mean R2=0.6338\n",
      "Validation Error: Avg loss: 4.699576 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:34.851191 Epoch 1604, Training loss 3.0556585788726807\n",
      "in params\n",
      "R2 values 0.6815, 0.7868, 0.6795; mean R2=0.7159\n",
      "Validation Error: Avg loss: 3.283005 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:35.132706 Epoch 1605, Training loss 3.0744855403900146\n",
      "in params\n",
      "R2 values 0.8090, 0.8884, 0.7364; mean R2=0.8113\n",
      "Validation Error: Avg loss: 2.213645 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:35.432958 Epoch 1606, Training loss 3.2600154876708984\n",
      "in params\n",
      "R2 values 0.6801, 0.7586, 0.7547; mean R2=0.7312\n",
      "Validation Error: Avg loss: 3.253592 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:35.711372 Epoch 1607, Training loss 3.0983242988586426\n",
      "in params\n",
      "R2 values 0.7436, 0.6724, 0.7204; mean R2=0.7122\n",
      "Validation Error: Avg loss: 3.948123 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:35.993486 Epoch 1608, Training loss 4.131968021392822\n",
      "in params\n",
      "R2 values 0.7728, 0.7033, 0.6868; mean R2=0.7210\n",
      "Validation Error: Avg loss: 3.769988 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:36.268608 Epoch 1609, Training loss 3.253011703491211\n",
      "in params\n",
      "R2 values 0.7191, 0.7816, 0.7598; mean R2=0.7535\n",
      "Validation Error: Avg loss: 3.227874 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:36.544033 Epoch 1610, Training loss 3.07079815864563\n",
      "in params\n",
      "R2 values 0.6755, 0.6681, 0.6052; mean R2=0.6496\n",
      "Validation Error: Avg loss: 5.135157 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:58:36.816993 Epoch 1611, Training loss 3.3501598834991455\n",
      "in params\n",
      "R2 values 0.7565, 0.8105, 0.6941; mean R2=0.7537\n",
      "Validation Error: Avg loss: 3.412464 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:37.095899 Epoch 1612, Training loss 4.328023910522461\n",
      "in params\n",
      "R2 values 0.7838, 0.6476, 0.6755; mean R2=0.7023\n",
      "Validation Error: Avg loss: 4.529233 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:37.371952 Epoch 1613, Training loss 3.1684439182281494\n",
      "in params\n",
      "R2 values 0.6556, 0.6928, 0.7229; mean R2=0.6904\n",
      "Validation Error: Avg loss: 4.261622 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:37.653050 Epoch 1614, Training loss 2.620473861694336\n",
      "in params\n",
      "R2 values 0.6238, 0.6281, 0.6212; mean R2=0.6244\n",
      "Validation Error: Avg loss: 4.996944 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:37.932652 Epoch 1615, Training loss 2.7401294708251953\n",
      "in params\n",
      "R2 values 0.6962, 0.8022, 0.7229; mean R2=0.7405\n",
      "Validation Error: Avg loss: 3.005035 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:38.210891 Epoch 1616, Training loss 3.34415864944458\n",
      "in params\n",
      "R2 values 0.6811, 0.7726, 0.6268; mean R2=0.6935\n",
      "Validation Error: Avg loss: 3.557420 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:38.491776 Epoch 1617, Training loss 3.6802141666412354\n",
      "in params\n",
      "R2 values 0.6167, 0.7593, 0.7044; mean R2=0.6935\n",
      "Validation Error: Avg loss: 3.580289 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:38.772799 Epoch 1618, Training loss 3.7305164337158203\n",
      "in params\n",
      "R2 values 0.7318, 0.7216, 0.7214; mean R2=0.7249\n",
      "Validation Error: Avg loss: 3.642638 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:39.058317 Epoch 1619, Training loss 3.579843521118164\n",
      "in params\n",
      "R2 values 0.7301, 0.7233, 0.7031; mean R2=0.7188\n",
      "Validation Error: Avg loss: 3.798835 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:39.331641 Epoch 1620, Training loss 3.5922884941101074\n",
      "in params\n",
      "R2 values 0.5998, 0.6636, 0.5460; mean R2=0.6031\n",
      "Validation Error: Avg loss: 4.812819 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:39.622750 Epoch 1621, Training loss 3.174260139465332\n",
      "in params\n",
      "R2 values 0.6125, 0.6621, 0.5841; mean R2=0.6196\n",
      "Validation Error: Avg loss: 4.885347 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:39.903989 Epoch 1622, Training loss 4.134925842285156\n",
      "in params\n",
      "R2 values 0.5415, 0.5443, 0.5860; mean R2=0.5573\n",
      "Validation Error: Avg loss: 6.474590 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:40.186135 Epoch 1623, Training loss 2.467658758163452\n",
      "in params\n",
      "R2 values 0.6674, 0.8398, 0.6195; mean R2=0.7089\n",
      "Validation Error: Avg loss: 3.028427 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:40.461716 Epoch 1624, Training loss 4.409190654754639\n",
      "in params\n",
      "R2 values 0.7402, 0.7711, 0.7398; mean R2=0.7504\n",
      "Validation Error: Avg loss: 3.142369 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:40.741981 Epoch 1625, Training loss 3.4251983165740967\n",
      "in params\n",
      "R2 values 0.5909, 0.6872, 0.5778; mean R2=0.6187\n",
      "Validation Error: Avg loss: 4.656009 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:41.034987 Epoch 1626, Training loss 4.024863243103027\n",
      "in params\n",
      "R2 values 0.6464, 0.6619, 0.6675; mean R2=0.6586\n",
      "Validation Error: Avg loss: 4.601069 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:41.315140 Epoch 1627, Training loss 4.15134334564209\n",
      "in params\n",
      "R2 values 0.7585, 0.6760, 0.6795; mean R2=0.7046\n",
      "Validation Error: Avg loss: 4.188675 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:41.584659 Epoch 1628, Training loss 2.6702890396118164\n",
      "in params\n",
      "R2 values 0.6519, 0.6622, 0.6179; mean R2=0.6440\n",
      "Validation Error: Avg loss: 4.658803 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:41.868355 Epoch 1629, Training loss 3.5888867378234863\n",
      "in params\n",
      "R2 values 0.7166, 0.6584, 0.6823; mean R2=0.6858\n",
      "Validation Error: Avg loss: 4.802159 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:42.145374 Epoch 1630, Training loss 3.716362714767456\n",
      "in params\n",
      "R2 values 0.6971, 0.7011, 0.6326; mean R2=0.6769\n",
      "Validation Error: Avg loss: 4.863499 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:42.421347 Epoch 1631, Training loss 3.384310722351074\n",
      "in params\n",
      "R2 values 0.4977, 0.7928, 0.6326; mean R2=0.6410\n",
      "Validation Error: Avg loss: 3.964325 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:42.708843 Epoch 1632, Training loss 2.984039068222046\n",
      "in params\n",
      "R2 values 0.7765, 0.7121, 0.7775; mean R2=0.7554\n",
      "Validation Error: Avg loss: 3.422729 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:42.991428 Epoch 1633, Training loss 2.881014347076416\n",
      "in params\n",
      "R2 values 0.5568, 0.6720, 0.6249; mean R2=0.6179\n",
      "Validation Error: Avg loss: 4.728312 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:43.273008 Epoch 1634, Training loss 3.635108470916748\n",
      "in params\n",
      "R2 values 0.7317, 0.6326, 0.7556; mean R2=0.7066\n",
      "Validation Error: Avg loss: 4.531299 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:43.573053 Epoch 1635, Training loss 3.972353935241699\n",
      "in params\n",
      "R2 values 0.7121, 0.6204, 0.7488; mean R2=0.6938\n",
      "Validation Error: Avg loss: 4.389983 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:43.850695 Epoch 1636, Training loss 4.024170875549316\n",
      "in params\n",
      "R2 values 0.6566, 0.8057, 0.6759; mean R2=0.7127\n",
      "Validation Error: Avg loss: 3.296289 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:44.126630 Epoch 1637, Training loss 3.7411842346191406\n",
      "in params\n",
      "R2 values 0.6578, 0.7388, 0.6888; mean R2=0.6951\n",
      "Validation Error: Avg loss: 3.876169 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:44.403543 Epoch 1638, Training loss 2.6793816089630127\n",
      "in params\n",
      "R2 values 0.5871, 0.7352, 0.6347; mean R2=0.6523\n",
      "Validation Error: Avg loss: 4.633642 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:44.682434 Epoch 1639, Training loss 4.45804500579834\n",
      "in params\n",
      "R2 values 0.7286, 0.7929, 0.7233; mean R2=0.7483\n",
      "Validation Error: Avg loss: 3.068328 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:44.962249 Epoch 1640, Training loss 2.5083348751068115\n",
      "in params\n",
      "R2 values 0.7376, 0.7049, 0.6940; mean R2=0.7121\n",
      "Validation Error: Avg loss: 3.887019 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:45.240419 Epoch 1641, Training loss 4.461801528930664\n",
      "in params\n",
      "R2 values 0.6642, 0.6973, 0.6583; mean R2=0.6733\n",
      "Validation Error: Avg loss: 4.112157 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:45.519328 Epoch 1642, Training loss 2.9270551204681396\n",
      "in params\n",
      "R2 values 0.5882, 0.5740, 0.6491; mean R2=0.6038\n",
      "Validation Error: Avg loss: 5.447683 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:45.796384 Epoch 1643, Training loss 3.429100513458252\n",
      "in params\n",
      "R2 values 0.7363, 0.7708, 0.6628; mean R2=0.7233\n",
      "Validation Error: Avg loss: 3.469822 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:46.072980 Epoch 1644, Training loss 2.5238301753997803\n",
      "in params\n",
      "R2 values 0.6364, 0.7871, 0.5933; mean R2=0.6723\n",
      "Validation Error: Avg loss: 3.715976 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:46.360177 Epoch 1645, Training loss 3.211541175842285\n",
      "in params\n",
      "R2 values 0.7063, 0.5908, 0.6305; mean R2=0.6425\n",
      "Validation Error: Avg loss: 5.060530 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:46.639843 Epoch 1646, Training loss 2.7095706462860107\n",
      "in params\n",
      "R2 values 0.6998, 0.7239, 0.6211; mean R2=0.6816\n",
      "Validation Error: Avg loss: 3.979225 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:46.933023 Epoch 1647, Training loss 2.330481767654419\n",
      "in params\n",
      "R2 values 0.6771, 0.6987, 0.6675; mean R2=0.6811\n",
      "Validation Error: Avg loss: 4.159002 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:47.210808 Epoch 1648, Training loss 4.178232669830322\n",
      "in params\n",
      "R2 values 0.7181, 0.6297, 0.6980; mean R2=0.6819\n",
      "Validation Error: Avg loss: 4.833343 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:47.489542 Epoch 1649, Training loss 2.708137273788452\n",
      "in params\n",
      "R2 values 0.6455, 0.7563, 0.6942; mean R2=0.6987\n",
      "Validation Error: Avg loss: 4.197647 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:47.766417 Epoch 1650, Training loss 2.849611282348633\n",
      "in params\n",
      "R2 values 0.6785, 0.8582, 0.7655; mean R2=0.7674\n",
      "Validation Error: Avg loss: 2.378665 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:48.058115 Epoch 1651, Training loss 2.3163130283355713\n",
      "in params\n",
      "R2 values 0.7266, 0.7069, 0.7245; mean R2=0.7193\n",
      "Validation Error: Avg loss: 4.080444 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:48.335361 Epoch 1652, Training loss 2.4111785888671875\n",
      "in params\n",
      "R2 values 0.6822, 0.7534, 0.7094; mean R2=0.7150\n",
      "Validation Error: Avg loss: 3.369595 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:48.610401 Epoch 1653, Training loss 4.014594554901123\n",
      "in params\n",
      "R2 values 0.6734, 0.7188, 0.6243; mean R2=0.6721\n",
      "Validation Error: Avg loss: 3.951102 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:48.889769 Epoch 1654, Training loss 3.2775282859802246\n",
      "in params\n",
      "R2 values 0.7139, 0.7576, 0.6257; mean R2=0.6990\n",
      "Validation Error: Avg loss: 4.158833 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:49.166517 Epoch 1655, Training loss 2.1972548961639404\n",
      "in params\n",
      "R2 values 0.6092, 0.6331, 0.6408; mean R2=0.6277\n",
      "Validation Error: Avg loss: 4.910825 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:49.445933 Epoch 1656, Training loss 2.2664785385131836\n",
      "in params\n",
      "R2 values 0.6622, 0.7239, 0.7511; mean R2=0.7124\n",
      "Validation Error: Avg loss: 3.633037 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:58:49.731203 Epoch 1657, Training loss 3.6941373348236084\n",
      "in params\n",
      "R2 values 0.8009, 0.6096, 0.7445; mean R2=0.7183\n",
      "Validation Error: Avg loss: 6.020648 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:50.005474 Epoch 1658, Training loss 3.3878135681152344\n",
      "in params\n",
      "R2 values 0.6650, 0.7544, 0.6751; mean R2=0.6982\n",
      "Validation Error: Avg loss: 3.704473 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:50.289983 Epoch 1659, Training loss 2.8479583263397217\n",
      "in params\n",
      "R2 values 0.6702, 0.4709, 0.6960; mean R2=0.6124\n",
      "Validation Error: Avg loss: 5.971953 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:50.577347 Epoch 1660, Training loss 2.681931257247925\n",
      "in params\n",
      "R2 values 0.5651, 0.4754, 0.5819; mean R2=0.5408\n",
      "Validation Error: Avg loss: 6.500525 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:50.858072 Epoch 1661, Training loss 3.083103895187378\n",
      "in params\n",
      "R2 values 0.6549, 0.7933, 0.7451; mean R2=0.7311\n",
      "Validation Error: Avg loss: 3.742751 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:51.150405 Epoch 1662, Training loss 3.678588628768921\n",
      "in params\n",
      "R2 values 0.5901, 0.7294, 0.5690; mean R2=0.6295\n",
      "Validation Error: Avg loss: 4.435294 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:51.425727 Epoch 1663, Training loss 3.9629929065704346\n",
      "in params\n",
      "R2 values 0.7665, 0.7157, 0.7085; mean R2=0.7302\n",
      "Validation Error: Avg loss: 3.738344 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:51.713597 Epoch 1664, Training loss 2.618553876876831\n",
      "in params\n",
      "R2 values 0.6803, 0.7814, 0.6780; mean R2=0.7132\n",
      "Validation Error: Avg loss: 3.553117 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:52.020875 Epoch 1665, Training loss 2.948117733001709\n",
      "in params\n",
      "R2 values 0.6500, 0.5980, 0.5908; mean R2=0.6129\n",
      "Validation Error: Avg loss: 5.272569 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:52.301352 Epoch 1666, Training loss 2.7174549102783203\n",
      "in params\n",
      "R2 values 0.7032, 0.7503, 0.7391; mean R2=0.7309\n",
      "Validation Error: Avg loss: 3.549682 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:52.588848 Epoch 1667, Training loss 2.751223087310791\n",
      "in params\n",
      "R2 values 0.6358, 0.5897, 0.6588; mean R2=0.6281\n",
      "Validation Error: Avg loss: 5.208767 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:52.860704 Epoch 1668, Training loss 2.6276068687438965\n",
      "in params\n",
      "R2 values 0.7844, 0.7897, 0.7938; mean R2=0.7893\n",
      "Validation Error: Avg loss: 3.194088 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:53.136605 Epoch 1669, Training loss 3.8850839138031006\n",
      "in params\n",
      "R2 values 0.6372, 0.5743, 0.6201; mean R2=0.6105\n",
      "Validation Error: Avg loss: 5.463322 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:53.411790 Epoch 1670, Training loss 3.4812183380126953\n",
      "in params\n",
      "R2 values 0.6770, 0.6592, 0.5921; mean R2=0.6428\n",
      "Validation Error: Avg loss: 5.305528 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:53.688198 Epoch 1671, Training loss 4.274778842926025\n",
      "in params\n",
      "R2 values 0.6611, 0.6748, 0.6117; mean R2=0.6492\n",
      "Validation Error: Avg loss: 4.709460 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:53.970041 Epoch 1672, Training loss 2.849996566772461\n",
      "in params\n",
      "R2 values 0.6616, 0.7460, 0.6140; mean R2=0.6739\n",
      "Validation Error: Avg loss: 3.774434 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:54.252543 Epoch 1673, Training loss 2.823904514312744\n",
      "in params\n",
      "R2 values 0.7141, 0.7273, 0.6589; mean R2=0.7001\n",
      "Validation Error: Avg loss: 3.920210 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:54.536095 Epoch 1674, Training loss 3.1510989665985107\n",
      "in params\n",
      "R2 values 0.7289, 0.8791, 0.8359; mean R2=0.8146\n",
      "Validation Error: Avg loss: 1.990578 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:54.820430 Epoch 1675, Training loss 3.492584228515625\n",
      "in params\n",
      "R2 values 0.6326, 0.5602, 0.7069; mean R2=0.6333\n",
      "Validation Error: Avg loss: 5.257074 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:55.107570 Epoch 1676, Training loss 2.9392638206481934\n",
      "in params\n",
      "R2 values 0.6921, 0.4973, 0.6534; mean R2=0.6143\n",
      "Validation Error: Avg loss: 6.069771 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:55.386996 Epoch 1677, Training loss 2.7224533557891846\n",
      "in params\n",
      "R2 values 0.7447, 0.6765, 0.6460; mean R2=0.6891\n",
      "Validation Error: Avg loss: 4.132395 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:55.663851 Epoch 1678, Training loss 3.2749698162078857\n",
      "in params\n",
      "R2 values 0.7120, 0.7066, 0.7792; mean R2=0.7326\n",
      "Validation Error: Avg loss: 3.562934 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:55.941856 Epoch 1679, Training loss 3.92966628074646\n",
      "in params\n",
      "R2 values 0.6679, 0.8203, 0.7348; mean R2=0.7410\n",
      "Validation Error: Avg loss: 2.931730 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:56.220107 Epoch 1680, Training loss 3.7805449962615967\n",
      "in params\n",
      "R2 values 0.6564, 0.8646, 0.7023; mean R2=0.7411\n",
      "Validation Error: Avg loss: 3.481421 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:56.497192 Epoch 1681, Training loss 2.4985547065734863\n",
      "in params\n",
      "R2 values 0.6107, 0.7516, 0.6815; mean R2=0.6813\n",
      "Validation Error: Avg loss: 3.948374 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:56.771696 Epoch 1682, Training loss 2.906256675720215\n",
      "in params\n",
      "R2 values 0.7064, 0.7177, 0.6442; mean R2=0.6895\n",
      "Validation Error: Avg loss: 4.733551 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:57.055425 Epoch 1683, Training loss 3.1720123291015625\n",
      "in params\n",
      "R2 values 0.7605, 0.6855, 0.6942; mean R2=0.7134\n",
      "Validation Error: Avg loss: 4.236751 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:57.334352 Epoch 1684, Training loss 2.983574867248535\n",
      "in params\n",
      "R2 values 0.5575, 0.7671, 0.6279; mean R2=0.6509\n",
      "Validation Error: Avg loss: 3.806459 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:57.612988 Epoch 1685, Training loss 3.408278703689575\n",
      "in params\n",
      "R2 values 0.6118, 0.6430, 0.5735; mean R2=0.6094\n",
      "Validation Error: Avg loss: 5.333338 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:57.905779 Epoch 1686, Training loss 2.9613029956817627\n",
      "in params\n",
      "R2 values 0.7077, 0.6503, 0.6144; mean R2=0.6575\n",
      "Validation Error: Avg loss: 4.731037 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:58.184812 Epoch 1687, Training loss 3.7546401023864746\n",
      "in params\n",
      "R2 values 0.6906, 0.7899, 0.6897; mean R2=0.7234\n",
      "Validation Error: Avg loss: 3.431159 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:58.461586 Epoch 1688, Training loss 2.7871639728546143\n",
      "in params\n",
      "R2 values 0.6080, 0.6933, 0.5840; mean R2=0.6285\n",
      "Validation Error: Avg loss: 4.468796 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:58.741824 Epoch 1689, Training loss 3.4068377017974854\n",
      "in params\n",
      "R2 values 0.7112, 0.7553, 0.5995; mean R2=0.6887\n",
      "Validation Error: Avg loss: 3.771043 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:59.026749 Epoch 1690, Training loss 3.1256115436553955\n",
      "in params\n",
      "R2 values 0.6280, 0.7162, 0.7184; mean R2=0.6875\n",
      "Validation Error: Avg loss: 4.191367 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:59.310405 Epoch 1691, Training loss 3.8261516094207764\n",
      "in params\n",
      "R2 values 0.6137, 0.6876, 0.5843; mean R2=0.6285\n",
      "Validation Error: Avg loss: 5.342552 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:59.593036 Epoch 1692, Training loss 2.868492364883423\n",
      "in params\n",
      "R2 values 0.5484, 0.7081, 0.6648; mean R2=0.6404\n",
      "Validation Error: Avg loss: 4.350728 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:58:59.880291 Epoch 1693, Training loss 3.780587673187256\n",
      "in params\n",
      "R2 values 0.6749, 0.4714, 0.6529; mean R2=0.5997\n",
      "Validation Error: Avg loss: 6.231514 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:00.169032 Epoch 1694, Training loss 3.8029565811157227\n",
      "in params\n",
      "R2 values 0.6469, 0.6796, 0.6948; mean R2=0.6738\n",
      "Validation Error: Avg loss: 4.261451 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:00.452207 Epoch 1695, Training loss 2.773721933364868\n",
      "in params\n",
      "R2 values 0.6742, 0.8192, 0.6779; mean R2=0.7238\n",
      "Validation Error: Avg loss: 3.254838 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:00.736701 Epoch 1696, Training loss 2.528663396835327\n",
      "in params\n",
      "R2 values 0.6915, 0.6181, 0.6578; mean R2=0.6558\n",
      "Validation Error: Avg loss: 4.983170 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:01.029383 Epoch 1697, Training loss 2.5375800132751465\n",
      "in params\n",
      "R2 values 0.6128, 0.7328, 0.6840; mean R2=0.6765\n",
      "Validation Error: Avg loss: 3.912703 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:01.305462 Epoch 1698, Training loss 4.805447101593018\n",
      "in params\n",
      "R2 values 0.6256, 0.7025, 0.5931; mean R2=0.6404\n",
      "Validation Error: Avg loss: 4.428043 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:01.584726 Epoch 1699, Training loss 3.1755237579345703\n",
      "in params\n",
      "R2 values 0.7418, 0.7292, 0.7414; mean R2=0.7375\n",
      "Validation Error: Avg loss: 3.572750 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:01.869149 Epoch 1700, Training loss 2.4030323028564453\n",
      "in params\n",
      "R2 values 0.7076, 0.5789, 0.7258; mean R2=0.6708\n",
      "Validation Error: Avg loss: 5.363562 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:02.146552 Epoch 1701, Training loss 2.9510867595672607\n",
      "in params\n",
      "R2 values 0.6644, 0.6494, 0.6730; mean R2=0.6623\n",
      "Validation Error: Avg loss: 4.855928 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:02.425629 Epoch 1702, Training loss 2.4953882694244385\n",
      "in params\n",
      "R2 values 0.6684, 0.8078, 0.6966; mean R2=0.7243\n",
      "Validation Error: Avg loss: 3.216668 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:59:02.716725 Epoch 1703, Training loss 3.3628334999084473\n",
      "in params\n",
      "R2 values 0.6811, 0.7198, 0.7334; mean R2=0.7114\n",
      "Validation Error: Avg loss: 4.252571 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:02.990985 Epoch 1704, Training loss 3.1875298023223877\n",
      "in params\n",
      "R2 values 0.6093, 0.8215, 0.6138; mean R2=0.6815\n",
      "Validation Error: Avg loss: 3.159710 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:03.277485 Epoch 1705, Training loss 4.065834999084473\n",
      "in params\n",
      "R2 values 0.6739, 0.5611, 0.7276; mean R2=0.6542\n",
      "Validation Error: Avg loss: 5.071702 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:03.549249 Epoch 1706, Training loss 3.218712568283081\n",
      "in params\n",
      "R2 values 0.7419, 0.8090, 0.6293; mean R2=0.7267\n",
      "Validation Error: Avg loss: 3.116253 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:03.830335 Epoch 1707, Training loss 3.791510581970215\n",
      "in params\n",
      "R2 values 0.7031, 0.6147, 0.7531; mean R2=0.6903\n",
      "Validation Error: Avg loss: 4.448030 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:04.117226 Epoch 1708, Training loss 4.139383792877197\n",
      "in params\n",
      "R2 values 0.6385, 0.6932, 0.6686; mean R2=0.6668\n",
      "Validation Error: Avg loss: 4.114616 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:04.388623 Epoch 1709, Training loss 2.5025014877319336\n",
      "in params\n",
      "R2 values 0.6102, 0.6216, 0.6269; mean R2=0.6196\n",
      "Validation Error: Avg loss: 4.880315 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:04.667269 Epoch 1710, Training loss 3.3811120986938477\n",
      "in params\n",
      "R2 values 0.5869, 0.7104, 0.5191; mean R2=0.6055\n",
      "Validation Error: Avg loss: 5.090866 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:04.948638 Epoch 1711, Training loss 3.2858505249023438\n",
      "in params\n",
      "R2 values 0.7441, 0.6857, 0.6903; mean R2=0.7067\n",
      "Validation Error: Avg loss: 4.630142 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:05.232177 Epoch 1712, Training loss 2.5400280952453613\n",
      "in params\n",
      "R2 values 0.7007, 0.8108, 0.7289; mean R2=0.7468\n",
      "Validation Error: Avg loss: 3.718685 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:05.509129 Epoch 1713, Training loss 3.699028968811035\n",
      "in params\n",
      "R2 values 0.6688, 0.6572, 0.6660; mean R2=0.6640\n",
      "Validation Error: Avg loss: 5.176610 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:05.791972 Epoch 1714, Training loss 3.0920028686523438\n",
      "in params\n",
      "R2 values 0.6414, 0.6486, 0.6538; mean R2=0.6479\n",
      "Validation Error: Avg loss: 4.673470 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:06.067923 Epoch 1715, Training loss 3.3549885749816895\n",
      "in params\n",
      "R2 values 0.6561, 0.7357, 0.7459; mean R2=0.7125\n",
      "Validation Error: Avg loss: 3.471638 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:06.344466 Epoch 1716, Training loss 2.818817138671875\n",
      "in params\n",
      "R2 values 0.6894, 0.8823, 0.7124; mean R2=0.7614\n",
      "Validation Error: Avg loss: 2.939132 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:06.617763 Epoch 1717, Training loss 3.8020412921905518\n",
      "in params\n",
      "R2 values 0.6799, 0.5297, 0.5495; mean R2=0.5864\n",
      "Validation Error: Avg loss: 6.062933 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:06.895932 Epoch 1718, Training loss 4.032618045806885\n",
      "in params\n",
      "R2 values 0.5288, 0.6857, 0.8093; mean R2=0.6746\n",
      "Validation Error: Avg loss: 4.130679 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:07.171124 Epoch 1719, Training loss 3.7346367835998535\n",
      "in params\n",
      "R2 values 0.6770, 0.6966, 0.6274; mean R2=0.6670\n",
      "Validation Error: Avg loss: 4.125403 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:07.448174 Epoch 1720, Training loss 3.409222364425659\n",
      "in params\n",
      "R2 values 0.5727, 0.7086, 0.7609; mean R2=0.6807\n",
      "Validation Error: Avg loss: 4.030837 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:07.733040 Epoch 1721, Training loss 2.8363869190216064\n",
      "in params\n",
      "R2 values 0.6106, 0.7135, 0.7573; mean R2=0.6938\n",
      "Validation Error: Avg loss: 3.991191 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:08.023539 Epoch 1722, Training loss 3.0585527420043945\n",
      "in params\n",
      "R2 values 0.5777, 0.7663, 0.6928; mean R2=0.6789\n",
      "Validation Error: Avg loss: 3.563458 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:08.302303 Epoch 1723, Training loss 2.9446980953216553\n",
      "in params\n",
      "R2 values 0.6418, 0.5788, 0.6340; mean R2=0.6182\n",
      "Validation Error: Avg loss: 5.430612 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:08.593054 Epoch 1724, Training loss 3.072385549545288\n",
      "in params\n",
      "R2 values 0.6057, 0.6302, 0.6924; mean R2=0.6428\n",
      "Validation Error: Avg loss: 4.861907 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:08.888649 Epoch 1725, Training loss 2.7218382358551025\n",
      "in params\n",
      "R2 values 0.6532, 0.7492, 0.6274; mean R2=0.6766\n",
      "Validation Error: Avg loss: 3.793330 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:09.165417 Epoch 1726, Training loss 3.8238749504089355\n",
      "in params\n",
      "R2 values 0.5910, 0.6634, 0.5786; mean R2=0.6110\n",
      "Validation Error: Avg loss: 4.913606 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:09.444408 Epoch 1727, Training loss 3.2950994968414307\n",
      "in params\n",
      "R2 values 0.6601, 0.6989, 0.6751; mean R2=0.6780\n",
      "Validation Error: Avg loss: 4.776007 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:09.731984 Epoch 1728, Training loss 3.194126605987549\n",
      "in params\n",
      "R2 values 0.6524, 0.7103, 0.6625; mean R2=0.6751\n",
      "Validation Error: Avg loss: 4.123985 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:10.005311 Epoch 1729, Training loss 4.114948749542236\n",
      "in params\n",
      "R2 values 0.6598, 0.7313, 0.7284; mean R2=0.7065\n",
      "Validation Error: Avg loss: 4.045470 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:10.290733 Epoch 1730, Training loss 2.949105978012085\n",
      "in params\n",
      "R2 values 0.6927, 0.6842, 0.6536; mean R2=0.6768\n",
      "Validation Error: Avg loss: 4.236722 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:10.566277 Epoch 1731, Training loss 3.589381694793701\n",
      "in params\n",
      "R2 values 0.5806, 0.7346, 0.5461; mean R2=0.6204\n",
      "Validation Error: Avg loss: 4.497780 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:10.843573 Epoch 1732, Training loss 3.474461078643799\n",
      "in params\n",
      "R2 values 0.6171, 0.6943, 0.6056; mean R2=0.6390\n",
      "Validation Error: Avg loss: 4.623544 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:11.138798 Epoch 1733, Training loss 3.7144320011138916\n",
      "in params\n",
      "R2 values 0.5983, 0.6522, 0.5286; mean R2=0.5930\n",
      "Validation Error: Avg loss: 5.124680 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:11.418603 Epoch 1734, Training loss 3.0869104862213135\n",
      "in params\n",
      "R2 values 0.6973, 0.6196, 0.7473; mean R2=0.6881\n",
      "Validation Error: Avg loss: 4.513220 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:11.694210 Epoch 1735, Training loss 2.759876251220703\n",
      "in params\n",
      "R2 values 0.6523, 0.7503, 0.5860; mean R2=0.6628\n",
      "Validation Error: Avg loss: 4.152955 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:11.984531 Epoch 1736, Training loss 4.018277168273926\n",
      "in params\n",
      "R2 values 0.6199, 0.7505, 0.6768; mean R2=0.6824\n",
      "Validation Error: Avg loss: 3.841159 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:12.256013 Epoch 1737, Training loss 3.4984982013702393\n",
      "in params\n",
      "R2 values 0.7150, 0.7309, 0.6614; mean R2=0.7024\n",
      "Validation Error: Avg loss: 3.833150 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:12.543968 Epoch 1738, Training loss 2.836970090866089\n",
      "in params\n",
      "R2 values 0.5502, 0.6343, 0.5923; mean R2=0.5923\n",
      "Validation Error: Avg loss: 5.302726 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:12.836463 Epoch 1739, Training loss 2.572964906692505\n",
      "in params\n",
      "R2 values 0.5368, 0.5060, 0.5695; mean R2=0.5375\n",
      "Validation Error: Avg loss: 6.322024 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:13.112700 Epoch 1740, Training loss 2.6978821754455566\n",
      "in params\n",
      "R2 values 0.5857, 0.6341, 0.6946; mean R2=0.6381\n",
      "Validation Error: Avg loss: 4.593754 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:13.384744 Epoch 1741, Training loss 4.011641502380371\n",
      "in params\n",
      "R2 values 0.6263, 0.6707, 0.5753; mean R2=0.6241\n",
      "Validation Error: Avg loss: 4.599747 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:13.661462 Epoch 1742, Training loss 3.5674707889556885\n",
      "in params\n",
      "R2 values 0.6974, 0.6080, 0.6535; mean R2=0.6529\n",
      "Validation Error: Avg loss: 5.080118 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:13.935733 Epoch 1743, Training loss 2.9899778366088867\n",
      "in params\n",
      "R2 values 0.6795, 0.6162, 0.6717; mean R2=0.6558\n",
      "Validation Error: Avg loss: 5.261617 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:14.208675 Epoch 1744, Training loss 3.3196115493774414\n",
      "in params\n",
      "R2 values 0.7344, 0.7676, 0.7017; mean R2=0.7346\n",
      "Validation Error: Avg loss: 3.505816 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:14.478766 Epoch 1745, Training loss 3.0212059020996094\n",
      "in params\n",
      "R2 values 0.6863, 0.5958, 0.6199; mean R2=0.6340\n",
      "Validation Error: Avg loss: 5.105524 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:14.762824 Epoch 1746, Training loss 4.3592376708984375\n",
      "in params\n",
      "R2 values 0.7225, 0.6231, 0.7540; mean R2=0.6999\n",
      "Validation Error: Avg loss: 4.343998 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:15.031965 Epoch 1747, Training loss 3.0637664794921875\n",
      "in params\n",
      "R2 values 0.6630, 0.7332, 0.7119; mean R2=0.7027\n",
      "Validation Error: Avg loss: 3.923720 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:15.310645 Epoch 1748, Training loss 2.909482955932617\n",
      "in params\n",
      "R2 values 0.6891, 0.8119, 0.6556; mean R2=0.7188\n",
      "Validation Error: Avg loss: 3.775255 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:59:15.581826 Epoch 1749, Training loss 3.145725965499878\n",
      "in params\n",
      "R2 values 0.6655, 0.5780, 0.6375; mean R2=0.6270\n",
      "Validation Error: Avg loss: 5.627365 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:15.856364 Epoch 1750, Training loss 3.852534055709839\n",
      "in params\n",
      "R2 values 0.7121, 0.7653, 0.6809; mean R2=0.7194\n",
      "Validation Error: Avg loss: 4.360159 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:16.130585 Epoch 1751, Training loss 2.7933480739593506\n",
      "in params\n",
      "R2 values 0.5616, 0.6193, 0.6101; mean R2=0.5970\n",
      "Validation Error: Avg loss: 5.316127 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:16.402534 Epoch 1752, Training loss 3.5008554458618164\n",
      "in params\n",
      "R2 values 0.6780, 0.7649, 0.7038; mean R2=0.7156\n",
      "Validation Error: Avg loss: 3.457392 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:16.681782 Epoch 1753, Training loss 3.9100494384765625\n",
      "in params\n",
      "R2 values 0.6183, 0.7642, 0.6421; mean R2=0.6749\n",
      "Validation Error: Avg loss: 3.795776 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:16.960569 Epoch 1754, Training loss 3.0625383853912354\n",
      "in params\n",
      "R2 values 0.5936, 0.6666, 0.6176; mean R2=0.6259\n",
      "Validation Error: Avg loss: 4.624636 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:17.258516 Epoch 1755, Training loss 3.032412528991699\n",
      "in params\n",
      "R2 values 0.6771, 0.7356, 0.5804; mean R2=0.6644\n",
      "Validation Error: Avg loss: 4.011063 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:17.532099 Epoch 1756, Training loss 3.0574159622192383\n",
      "in params\n",
      "R2 values 0.5487, 0.6380, 0.5685; mean R2=0.5851\n",
      "Validation Error: Avg loss: 5.052194 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:17.812080 Epoch 1757, Training loss 2.5811166763305664\n",
      "in params\n",
      "R2 values 0.6737, 0.8304, 0.7348; mean R2=0.7463\n",
      "Validation Error: Avg loss: 3.093592 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:18.082716 Epoch 1758, Training loss 3.110682487487793\n",
      "in params\n",
      "R2 values 0.6935, 0.7798, 0.6090; mean R2=0.6941\n",
      "Validation Error: Avg loss: 3.547398 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:18.365531 Epoch 1759, Training loss 3.214667558670044\n",
      "in params\n",
      "R2 values 0.7074, 0.6232, 0.6144; mean R2=0.6483\n",
      "Validation Error: Avg loss: 4.904789 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:18.639561 Epoch 1760, Training loss 3.655895471572876\n",
      "in params\n",
      "R2 values 0.6928, 0.6922, 0.6300; mean R2=0.6716\n",
      "Validation Error: Avg loss: 4.182198 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:18.914323 Epoch 1761, Training loss 3.435926914215088\n",
      "in params\n",
      "R2 values 0.7407, 0.7131, 0.6610; mean R2=0.7049\n",
      "Validation Error: Avg loss: 4.003229 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:19.191637 Epoch 1762, Training loss 2.809987783432007\n",
      "in params\n",
      "R2 values 0.7283, 0.6217, 0.6909; mean R2=0.6803\n",
      "Validation Error: Avg loss: 4.534324 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:19.476046 Epoch 1763, Training loss 2.561502695083618\n",
      "in params\n",
      "R2 values 0.7846, 0.7771, 0.7988; mean R2=0.7868\n",
      "Validation Error: Avg loss: 2.840947 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:19.762186 Epoch 1764, Training loss 2.6844241619110107\n",
      "in params\n",
      "R2 values 0.6842, 0.7742, 0.6534; mean R2=0.7039\n",
      "Validation Error: Avg loss: 3.585347 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:20.054555 Epoch 1765, Training loss 2.568392753601074\n",
      "in params\n",
      "R2 values 0.6031, 0.6364, 0.6493; mean R2=0.6296\n",
      "Validation Error: Avg loss: 4.800665 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:20.334845 Epoch 1766, Training loss 2.7611377239227295\n",
      "in params\n",
      "R2 values 0.6849, 0.5993, 0.6022; mean R2=0.6288\n",
      "Validation Error: Avg loss: 5.119119 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:20.613300 Epoch 1767, Training loss 3.0354416370391846\n",
      "in params\n",
      "R2 values 0.6264, 0.6217, 0.5672; mean R2=0.6051\n",
      "Validation Error: Avg loss: 5.258737 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:20.889023 Epoch 1768, Training loss 2.628316640853882\n",
      "in params\n",
      "R2 values 0.7837, 0.8853, 0.8916; mean R2=0.8535\n",
      "New best, saving checkpoint...\n",
      "Validation Error: Avg loss: 2.535777 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:21.195205 Epoch 1769, Training loss 3.205536127090454\n",
      "in params\n",
      "R2 values 0.6525, 0.7577, 0.6645; mean R2=0.6916\n",
      "Validation Error: Avg loss: 3.632722 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:21.464118 Epoch 1770, Training loss 3.1654105186462402\n",
      "in params\n",
      "R2 values 0.7960, 0.7874, 0.7745; mean R2=0.7860\n",
      "Validation Error: Avg loss: 2.808496 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:21.737245 Epoch 1771, Training loss 2.6293585300445557\n",
      "in params\n",
      "R2 values 0.6134, 0.7792, 0.7294; mean R2=0.7073\n",
      "Validation Error: Avg loss: 3.218524 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:22.011042 Epoch 1772, Training loss 3.158822774887085\n",
      "in params\n",
      "R2 values 0.7181, 0.8346, 0.7111; mean R2=0.7546\n",
      "Validation Error: Avg loss: 2.813371 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:22.280952 Epoch 1773, Training loss 3.016240119934082\n",
      "in params\n",
      "R2 values 0.8355, 0.6820, 0.6604; mean R2=0.7260\n",
      "Validation Error: Avg loss: 4.076797 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:22.553744 Epoch 1774, Training loss 3.009448528289795\n",
      "in params\n",
      "R2 values 0.5768, 0.8036, 0.5638; mean R2=0.6481\n",
      "Validation Error: Avg loss: 4.162549 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:22.832829 Epoch 1775, Training loss 2.6429290771484375\n",
      "in params\n",
      "R2 values 0.6178, 0.7586, 0.6069; mean R2=0.6611\n",
      "Validation Error: Avg loss: 3.976738 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:23.120760 Epoch 1776, Training loss 2.4344193935394287\n",
      "in params\n",
      "R2 values 0.6814, 0.7357, 0.6103; mean R2=0.6758\n",
      "Validation Error: Avg loss: 4.048975 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:23.393187 Epoch 1777, Training loss 3.941206216812134\n",
      "in params\n",
      "R2 values 0.8109, 0.6600, 0.7807; mean R2=0.7505\n",
      "Validation Error: Avg loss: 4.276317 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:23.668310 Epoch 1778, Training loss 2.9454846382141113\n",
      "in params\n",
      "R2 values 0.5677, 0.7216, 0.6477; mean R2=0.6457\n",
      "Validation Error: Avg loss: 4.616410 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:23.944350 Epoch 1779, Training loss 3.4621763229370117\n",
      "in params\n",
      "R2 values 0.6724, 0.5895, 0.7055; mean R2=0.6558\n",
      "Validation Error: Avg loss: 5.355460 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:24.212424 Epoch 1780, Training loss 3.1117734909057617\n",
      "in params\n",
      "R2 values 0.7149, 0.7158, 0.7297; mean R2=0.7201\n",
      "Validation Error: Avg loss: 3.778954 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:24.486339 Epoch 1781, Training loss 3.6479668617248535\n",
      "in params\n",
      "R2 values 0.5556, 0.6413, 0.7279; mean R2=0.6416\n",
      "Validation Error: Avg loss: 4.693449 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:24.768302 Epoch 1782, Training loss 3.2909839153289795\n",
      "in params\n",
      "R2 values 0.6677, 0.8009, 0.6964; mean R2=0.7217\n",
      "Validation Error: Avg loss: 3.078419 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:25.055376 Epoch 1783, Training loss 3.8511452674865723\n",
      "in params\n",
      "R2 values 0.6221, 0.7158, 0.6621; mean R2=0.6667\n",
      "Validation Error: Avg loss: 3.979638 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:25.356566 Epoch 1784, Training loss 2.852869749069214\n",
      "in params\n",
      "R2 values 0.7027, 0.7092, 0.7231; mean R2=0.7117\n",
      "Validation Error: Avg loss: 3.732545 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:25.634458 Epoch 1785, Training loss 3.7242512702941895\n",
      "in params\n",
      "R2 values 0.6920, 0.7272, 0.6935; mean R2=0.7042\n",
      "Validation Error: Avg loss: 3.679821 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:25.910558 Epoch 1786, Training loss 2.988870859146118\n",
      "in params\n",
      "R2 values 0.6535, 0.7190, 0.5875; mean R2=0.6533\n",
      "Validation Error: Avg loss: 4.540265 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:26.183645 Epoch 1787, Training loss 3.7679431438446045\n",
      "in params\n",
      "R2 values 0.6180, 0.6468, 0.6296; mean R2=0.6314\n",
      "Validation Error: Avg loss: 4.880864 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:26.460195 Epoch 1788, Training loss 2.646043539047241\n",
      "in params\n",
      "R2 values 0.6467, 0.7256, 0.7097; mean R2=0.6940\n",
      "Validation Error: Avg loss: 4.062630 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:26.739528 Epoch 1789, Training loss 3.08963680267334\n",
      "in params\n",
      "R2 values 0.6288, 0.6572, 0.6483; mean R2=0.6448\n",
      "Validation Error: Avg loss: 4.622963 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:27.013541 Epoch 1790, Training loss 3.9395220279693604\n",
      "in params\n",
      "R2 values 0.5856, 0.7541, 0.7139; mean R2=0.6845\n",
      "Validation Error: Avg loss: 3.471492 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:27.285797 Epoch 1791, Training loss 5.310594081878662\n",
      "in params\n",
      "R2 values 0.7450, 0.7276, 0.7041; mean R2=0.7256\n",
      "Validation Error: Avg loss: 3.588164 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:27.564296 Epoch 1792, Training loss 4.602822780609131\n",
      "in params\n",
      "R2 values 0.6429, 0.7147, 0.7115; mean R2=0.6897\n",
      "Validation Error: Avg loss: 3.774974 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:27.839590 Epoch 1793, Training loss 2.5985043048858643\n",
      "in params\n",
      "R2 values 0.5771, 0.6926, 0.6339; mean R2=0.6345\n",
      "Validation Error: Avg loss: 4.639812 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:28.132681 Epoch 1794, Training loss 2.5429563522338867\n",
      "in params\n",
      "R2 values 0.6850, 0.7706, 0.7227; mean R2=0.7261\n",
      "Validation Error: Avg loss: 3.681099 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:59:28.407968 Epoch 1795, Training loss 3.160050868988037\n",
      "in params\n",
      "R2 values 0.7002, 0.7204, 0.6546; mean R2=0.6917\n",
      "Validation Error: Avg loss: 3.975618 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:28.680846 Epoch 1796, Training loss 3.127589225769043\n",
      "in params\n",
      "R2 values 0.5631, 0.6882, 0.6252; mean R2=0.6255\n",
      "Validation Error: Avg loss: 4.420518 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:28.966401 Epoch 1797, Training loss 3.690166473388672\n",
      "in params\n",
      "R2 values 0.5871, 0.6583, 0.6356; mean R2=0.6270\n",
      "Validation Error: Avg loss: 4.591932 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:29.239734 Epoch 1798, Training loss 3.2026515007019043\n",
      "in params\n",
      "R2 values 0.7803, 0.6630, 0.7485; mean R2=0.7306\n",
      "Validation Error: Avg loss: 4.097798 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:29.516206 Epoch 1799, Training loss 3.2452375888824463\n",
      "in params\n",
      "R2 values 0.6699, 0.6109, 0.7224; mean R2=0.6677\n",
      "Validation Error: Avg loss: 4.568327 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:29.793396 Epoch 1800, Training loss 2.0839192867279053\n",
      "in params\n",
      "R2 values 0.6587, 0.5827, 0.6301; mean R2=0.6238\n",
      "Validation Error: Avg loss: 5.227102 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:30.070396 Epoch 1801, Training loss 3.087480068206787\n",
      "in params\n",
      "R2 values 0.6249, 0.7507, 0.7731; mean R2=0.7162\n",
      "Validation Error: Avg loss: 3.295976 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:30.348820 Epoch 1802, Training loss 3.2755963802337646\n",
      "in params\n",
      "R2 values 0.6940, 0.6779, 0.6550; mean R2=0.6756\n",
      "Validation Error: Avg loss: 4.252298 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:30.632318 Epoch 1803, Training loss 4.145100116729736\n",
      "in params\n",
      "R2 values 0.6052, 0.5767, 0.6057; mean R2=0.5959\n",
      "Validation Error: Avg loss: 5.341774 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:30.922325 Epoch 1804, Training loss 2.3774077892303467\n",
      "in params\n",
      "R2 values 0.5868, 0.6494, 0.5952; mean R2=0.6105\n",
      "Validation Error: Avg loss: 4.994703 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:31.211019 Epoch 1805, Training loss 3.204998016357422\n",
      "in params\n",
      "R2 values 0.6422, 0.6064, 0.6498; mean R2=0.6328\n",
      "Validation Error: Avg loss: 4.961531 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:31.483763 Epoch 1806, Training loss 2.214754104614258\n",
      "in params\n",
      "R2 values 0.6108, 0.7396, 0.6497; mean R2=0.6667\n",
      "Validation Error: Avg loss: 4.204764 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:31.755747 Epoch 1807, Training loss 3.035426378250122\n",
      "in params\n",
      "R2 values 0.6407, 0.6164, 0.6445; mean R2=0.6339\n",
      "Validation Error: Avg loss: 5.361123 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:32.028789 Epoch 1808, Training loss 3.030966281890869\n",
      "in params\n",
      "R2 values 0.6691, 0.6677, 0.6028; mean R2=0.6466\n",
      "Validation Error: Avg loss: 4.582841 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:32.302705 Epoch 1809, Training loss 3.7655041217803955\n",
      "in params\n",
      "R2 values 0.6269, 0.7508, 0.6782; mean R2=0.6853\n",
      "Validation Error: Avg loss: 3.604308 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:32.583252 Epoch 1810, Training loss 2.8739349842071533\n",
      "in params\n",
      "R2 values 0.6427, 0.7045, 0.6762; mean R2=0.6744\n",
      "Validation Error: Avg loss: 4.001196 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:32.856306 Epoch 1811, Training loss 3.5022428035736084\n",
      "in params\n",
      "R2 values 0.7597, 0.7237, 0.8165; mean R2=0.7667\n",
      "Validation Error: Avg loss: 3.251482 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:33.144249 Epoch 1812, Training loss 3.108081579208374\n",
      "in params\n",
      "R2 values 0.5477, 0.6717, 0.6959; mean R2=0.6384\n",
      "Validation Error: Avg loss: 4.434845 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:33.415112 Epoch 1813, Training loss 3.5994181632995605\n",
      "in params\n",
      "R2 values 0.6859, 0.6520, 0.6012; mean R2=0.6464\n",
      "Validation Error: Avg loss: 4.938185 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:33.719204 Epoch 1814, Training loss 3.7569797039031982\n",
      "in params\n",
      "R2 values 0.5848, 0.5827, 0.7424; mean R2=0.6366\n",
      "Validation Error: Avg loss: 5.219169 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:33.997423 Epoch 1815, Training loss 3.1435887813568115\n",
      "in params\n",
      "R2 values 0.6922, 0.7380, 0.6807; mean R2=0.7036\n",
      "Validation Error: Avg loss: 3.645187 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:34.273316 Epoch 1816, Training loss 2.6640841960906982\n",
      "in params\n",
      "R2 values 0.6350, 0.7472, 0.6528; mean R2=0.6784\n",
      "Validation Error: Avg loss: 4.147615 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:34.548837 Epoch 1817, Training loss 2.727119207382202\n",
      "in params\n",
      "R2 values 0.6363, 0.7242, 0.7714; mean R2=0.7107\n",
      "Validation Error: Avg loss: 4.934453 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:34.825942 Epoch 1818, Training loss 4.572399616241455\n",
      "in params\n",
      "R2 values 0.7442, 0.6259, 0.6761; mean R2=0.6820\n",
      "Validation Error: Avg loss: 5.152662 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:35.114456 Epoch 1819, Training loss 2.807899236679077\n",
      "in params\n",
      "R2 values 0.6680, 0.7720, 0.6567; mean R2=0.6989\n",
      "Validation Error: Avg loss: 3.609236 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:35.395108 Epoch 1820, Training loss 2.8672053813934326\n",
      "in params\n",
      "R2 values 0.6835, 0.7186, 0.7488; mean R2=0.7170\n",
      "Validation Error: Avg loss: 3.609171 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:35.675690 Epoch 1821, Training loss 2.8510332107543945\n",
      "in params\n",
      "R2 values 0.6715, 0.6335, 0.6465; mean R2=0.6505\n",
      "Validation Error: Avg loss: 4.695591 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:35.947816 Epoch 1822, Training loss 4.215586185455322\n",
      "in params\n",
      "R2 values 0.7453, 0.6437, 0.7126; mean R2=0.7005\n",
      "Validation Error: Avg loss: 4.325958 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:36.222718 Epoch 1823, Training loss 3.946160078048706\n",
      "in params\n",
      "R2 values 0.6798, 0.6482, 0.6899; mean R2=0.6727\n",
      "Validation Error: Avg loss: 4.400128 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:36.501297 Epoch 1824, Training loss 3.6433043479919434\n",
      "in params\n",
      "R2 values 0.7117, 0.6815, 0.6999; mean R2=0.6977\n",
      "Validation Error: Avg loss: 4.068636 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:36.778201 Epoch 1825, Training loss 2.4241535663604736\n",
      "in params\n",
      "R2 values 0.7351, 0.7360, 0.6695; mean R2=0.7135\n",
      "Validation Error: Avg loss: 3.662868 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:37.064804 Epoch 1826, Training loss 3.324906349182129\n",
      "in params\n",
      "R2 values 0.7028, 0.6008, 0.5905; mean R2=0.6314\n",
      "Validation Error: Avg loss: 5.162196 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:37.341012 Epoch 1827, Training loss 4.354226112365723\n",
      "in params\n",
      "R2 values 0.7044, 0.6074, 0.6956; mean R2=0.6691\n",
      "Validation Error: Avg loss: 4.915645 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:37.609477 Epoch 1828, Training loss 4.4278059005737305\n",
      "in params\n",
      "R2 values 0.6149, 0.7877, 0.6402; mean R2=0.6809\n",
      "Validation Error: Avg loss: 3.462512 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:37.890188 Epoch 1829, Training loss 3.7214841842651367\n",
      "in params\n",
      "R2 values 0.6577, 0.7226, 0.6910; mean R2=0.6904\n",
      "Validation Error: Avg loss: 4.088178 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:38.173594 Epoch 1830, Training loss 2.970336437225342\n",
      "in params\n",
      "R2 values 0.6325, 0.7063, 0.6024; mean R2=0.6471\n",
      "Validation Error: Avg loss: 4.399075 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:38.441174 Epoch 1831, Training loss 3.417449474334717\n",
      "in params\n",
      "R2 values 0.6167, 0.6754, 0.6399; mean R2=0.6440\n",
      "Validation Error: Avg loss: 4.567227 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:38.717176 Epoch 1832, Training loss 3.5514473915100098\n",
      "in params\n",
      "R2 values 0.5700, 0.6980, 0.7404; mean R2=0.6694\n",
      "Validation Error: Avg loss: 3.924181 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:38.996596 Epoch 1833, Training loss 2.8092856407165527\n",
      "in params\n",
      "R2 values 0.6265, 0.6766, 0.5658; mean R2=0.6230\n",
      "Validation Error: Avg loss: 4.612183 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:39.268233 Epoch 1834, Training loss 2.9565443992614746\n",
      "in params\n",
      "R2 values 0.6469, 0.5236, 0.6129; mean R2=0.5945\n",
      "Validation Error: Avg loss: 5.732258 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:39.548330 Epoch 1835, Training loss 3.2627856731414795\n",
      "in params\n",
      "R2 values 0.7741, 0.6640, 0.7495; mean R2=0.7292\n",
      "Validation Error: Avg loss: 3.962463 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:39.826093 Epoch 1836, Training loss 3.483520984649658\n",
      "in params\n",
      "R2 values 0.7775, 0.8312, 0.7608; mean R2=0.7898\n",
      "Validation Error: Avg loss: 2.484886 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:40.096284 Epoch 1837, Training loss 3.2097890377044678\n",
      "in params\n",
      "R2 values 0.7336, 0.6563, 0.6611; mean R2=0.6837\n",
      "Validation Error: Avg loss: 4.646983 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:40.370012 Epoch 1838, Training loss 3.1245248317718506\n",
      "in params\n",
      "R2 values 0.6708, 0.6571, 0.6388; mean R2=0.6556\n",
      "Validation Error: Avg loss: 4.618088 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:40.655271 Epoch 1839, Training loss 3.195223331451416\n",
      "in params\n",
      "R2 values 0.6017, 0.7381, 0.5952; mean R2=0.6450\n",
      "Validation Error: Avg loss: 4.191101 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:40.949523 Epoch 1840, Training loss 2.2338311672210693\n",
      "in params\n",
      "R2 values 0.7529, 0.8112, 0.6703; mean R2=0.7448\n",
      "Validation Error: Avg loss: 3.002868 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:59:41.229803 Epoch 1841, Training loss 2.965075731277466\n",
      "in params\n",
      "R2 values 0.5233, 0.4426, 0.5648; mean R2=0.5102\n",
      "Validation Error: Avg loss: 7.246916 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:41.526541 Epoch 1842, Training loss 3.0799081325531006\n",
      "in params\n",
      "R2 values 0.6546, 0.6748, 0.6599; mean R2=0.6631\n",
      "Validation Error: Avg loss: 4.496296 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:41.825392 Epoch 1843, Training loss 3.315340042114258\n",
      "in params\n",
      "R2 values 0.6476, 0.6353, 0.6444; mean R2=0.6424\n",
      "Validation Error: Avg loss: 5.070992 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:42.098341 Epoch 1844, Training loss 3.2765166759490967\n",
      "in params\n",
      "R2 values 0.6834, 0.7178, 0.6471; mean R2=0.6828\n",
      "Validation Error: Avg loss: 3.991599 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:42.377628 Epoch 1845, Training loss 2.2387585639953613\n",
      "in params\n",
      "R2 values 0.6799, 0.7844, 0.7317; mean R2=0.7320\n",
      "Validation Error: Avg loss: 3.237913 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:42.660273 Epoch 1846, Training loss 3.0581884384155273\n",
      "in params\n",
      "R2 values 0.7678, 0.8155, 0.7465; mean R2=0.7766\n",
      "Validation Error: Avg loss: 2.618023 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:42.938464 Epoch 1847, Training loss 3.593137741088867\n",
      "in params\n",
      "R2 values 0.5996, 0.7167, 0.5936; mean R2=0.6366\n",
      "Validation Error: Avg loss: 4.516062 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:43.220015 Epoch 1848, Training loss 3.1617519855499268\n",
      "in params\n",
      "R2 values 0.6421, 0.6745, 0.6632; mean R2=0.6599\n",
      "Validation Error: Avg loss: 4.301514 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:43.499142 Epoch 1849, Training loss 2.8062448501586914\n",
      "in params\n",
      "R2 values 0.6325, 0.5366, 0.6483; mean R2=0.6058\n",
      "Validation Error: Avg loss: 5.709430 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:43.776703 Epoch 1850, Training loss 1.9131741523742676\n",
      "in params\n",
      "R2 values 0.6206, 0.7219, 0.6650; mean R2=0.6692\n",
      "Validation Error: Avg loss: 3.885539 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:44.068135 Epoch 1851, Training loss 2.296137571334839\n",
      "in params\n",
      "R2 values 0.5894, 0.5775, 0.6274; mean R2=0.5981\n",
      "Validation Error: Avg loss: 5.383512 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:44.345960 Epoch 1852, Training loss 2.4887030124664307\n",
      "in params\n",
      "R2 values 0.6324, 0.8405, 0.5976; mean R2=0.6902\n",
      "Validation Error: Avg loss: 3.340441 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:44.627458 Epoch 1853, Training loss 4.1212944984436035\n",
      "in params\n",
      "R2 values 0.6562, 0.6729, 0.6540; mean R2=0.6610\n",
      "Validation Error: Avg loss: 4.376409 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:44.913567 Epoch 1854, Training loss 2.508167266845703\n",
      "in params\n",
      "R2 values 0.6090, 0.7220, 0.7029; mean R2=0.6780\n",
      "Validation Error: Avg loss: 3.812355 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:45.192589 Epoch 1855, Training loss 3.7338738441467285\n",
      "in params\n",
      "R2 values 0.6822, 0.7518, 0.6883; mean R2=0.7074\n",
      "Validation Error: Avg loss: 3.834234 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:45.466274 Epoch 1856, Training loss 2.9696340560913086\n",
      "in params\n",
      "R2 values 0.6615, 0.6032, 0.6893; mean R2=0.6513\n",
      "Validation Error: Avg loss: 5.067744 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:45.749590 Epoch 1857, Training loss 3.1951262950897217\n",
      "in params\n",
      "R2 values 0.6822, 0.6119, 0.6253; mean R2=0.6398\n",
      "Validation Error: Avg loss: 5.305174 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:46.025408 Epoch 1858, Training loss 2.6644208431243896\n",
      "in params\n",
      "R2 values 0.6117, 0.6469, 0.6924; mean R2=0.6503\n",
      "Validation Error: Avg loss: 4.651164 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:46.300055 Epoch 1859, Training loss 3.2452948093414307\n",
      "in params\n",
      "R2 values 0.6314, 0.6902, 0.6680; mean R2=0.6632\n",
      "Validation Error: Avg loss: 4.211081 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:46.571585 Epoch 1860, Training loss 3.1771414279937744\n",
      "in params\n",
      "R2 values 0.7257, 0.7051, 0.6110; mean R2=0.6806\n",
      "Validation Error: Avg loss: 4.128640 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:46.852151 Epoch 1861, Training loss 3.43635892868042\n",
      "in params\n",
      "R2 values 0.7177, 0.7300, 0.7014; mean R2=0.7164\n",
      "Validation Error: Avg loss: 3.643667 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:47.126779 Epoch 1862, Training loss 3.3565051555633545\n",
      "in params\n",
      "R2 values 0.6553, 0.5308, 0.5560; mean R2=0.5807\n",
      "Validation Error: Avg loss: 6.096218 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:47.398837 Epoch 1863, Training loss 4.2074713706970215\n",
      "in params\n",
      "R2 values 0.6551, 0.8444, 0.6973; mean R2=0.7323\n",
      "Validation Error: Avg loss: 2.876496 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:47.674204 Epoch 1864, Training loss 3.559981107711792\n",
      "in params\n",
      "R2 values 0.7474, 0.7908, 0.7912; mean R2=0.7765\n",
      "Validation Error: Avg loss: 2.921093 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:47.949200 Epoch 1865, Training loss 2.572587490081787\n",
      "in params\n",
      "R2 values 0.7103, 0.6017, 0.6400; mean R2=0.6507\n",
      "Validation Error: Avg loss: 5.111792 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:48.229803 Epoch 1866, Training loss 2.3630573749542236\n",
      "in params\n",
      "R2 values 0.6993, 0.5583, 0.5674; mean R2=0.6083\n",
      "Validation Error: Avg loss: 6.002165 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:48.498895 Epoch 1867, Training loss 2.734135150909424\n",
      "in params\n",
      "R2 values 0.6991, 0.7855, 0.7250; mean R2=0.7365\n",
      "Validation Error: Avg loss: 3.290818 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:48.780762 Epoch 1868, Training loss 2.9846017360687256\n",
      "in params\n",
      "R2 values 0.6502, 0.6022, 0.6579; mean R2=0.6368\n",
      "Validation Error: Avg loss: 5.039947 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:49.056196 Epoch 1869, Training loss 2.8587045669555664\n",
      "in params\n",
      "R2 values 0.7580, 0.6532, 0.6337; mean R2=0.6816\n",
      "Validation Error: Avg loss: 4.494905 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:49.336109 Epoch 1870, Training loss 2.6600184440612793\n",
      "in params\n",
      "R2 values 0.6871, 0.7770, 0.7265; mean R2=0.7302\n",
      "Validation Error: Avg loss: 3.298932 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:49.659986 Epoch 1871, Training loss 3.3425116539001465\n",
      "in params\n",
      "R2 values 0.7233, 0.7484, 0.7670; mean R2=0.7463\n",
      "Validation Error: Avg loss: 3.444340 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:49.941466 Epoch 1872, Training loss 3.0981252193450928\n",
      "in params\n",
      "R2 values 0.4704, 0.7299, 0.5650; mean R2=0.5884\n",
      "Validation Error: Avg loss: 4.359029 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:50.216916 Epoch 1873, Training loss 3.485222816467285\n",
      "in params\n",
      "R2 values 0.6863, 0.8371, 0.6055; mean R2=0.7096\n",
      "Validation Error: Avg loss: 3.039356 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:50.492881 Epoch 1874, Training loss 2.5626988410949707\n",
      "in params\n",
      "R2 values 0.6438, 0.6999, 0.6281; mean R2=0.6573\n",
      "Validation Error: Avg loss: 4.489227 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:50.776346 Epoch 1875, Training loss 4.2847394943237305\n",
      "in params\n",
      "R2 values 0.7174, 0.6981, 0.6543; mean R2=0.6900\n",
      "Validation Error: Avg loss: 4.236285 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:51.050551 Epoch 1876, Training loss 2.6090245246887207\n",
      "in params\n",
      "R2 values 0.7947, 0.6602, 0.7091; mean R2=0.7213\n",
      "Validation Error: Avg loss: 4.368439 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:51.344142 Epoch 1877, Training loss 3.5226128101348877\n",
      "in params\n",
      "R2 values 0.5722, 0.5697, 0.6994; mean R2=0.6138\n",
      "Validation Error: Avg loss: 5.439909 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:51.619742 Epoch 1878, Training loss 3.65563702583313\n",
      "in params\n",
      "R2 values 0.6426, 0.6665, 0.5998; mean R2=0.6363\n",
      "Validation Error: Avg loss: 4.605001 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:51.897896 Epoch 1879, Training loss 2.84435772895813\n",
      "in params\n",
      "R2 values 0.6169, 0.7140, 0.5532; mean R2=0.6280\n",
      "Validation Error: Avg loss: 4.535918 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:52.180192 Epoch 1880, Training loss 4.163501739501953\n",
      "in params\n",
      "R2 values 0.7094, 0.5606, 0.5668; mean R2=0.6122\n",
      "Validation Error: Avg loss: 5.670736 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:52.460826 Epoch 1881, Training loss 3.2864768505096436\n",
      "in params\n",
      "R2 values 0.6507, 0.6237, 0.6489; mean R2=0.6411\n",
      "Validation Error: Avg loss: 4.782849 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:52.736942 Epoch 1882, Training loss 2.1626334190368652\n",
      "in params\n",
      "R2 values 0.6740, 0.5855, 0.6743; mean R2=0.6446\n",
      "Validation Error: Avg loss: 5.045291 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:53.011942 Epoch 1883, Training loss 3.2978179454803467\n",
      "in params\n",
      "R2 values 0.7590, 0.7288, 0.7484; mean R2=0.7454\n",
      "Validation Error: Avg loss: 3.650618 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:53.295625 Epoch 1884, Training loss 2.972459316253662\n",
      "in params\n",
      "R2 values 0.6161, 0.5277, 0.5546; mean R2=0.5662\n",
      "Validation Error: Avg loss: 6.067124 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:53.570813 Epoch 1885, Training loss 2.8492414951324463\n",
      "in params\n",
      "R2 values 0.7055, 0.7270, 0.6365; mean R2=0.6896\n",
      "Validation Error: Avg loss: 3.841475 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:53.848350 Epoch 1886, Training loss 2.5145468711853027\n",
      "in params\n",
      "R2 values 0.7336, 0.7997, 0.7636; mean R2=0.7656\n",
      "Validation Error: Avg loss: 2.901759 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 13:59:54.124983 Epoch 1887, Training loss 4.150945663452148\n",
      "in params\n",
      "R2 values 0.7213, 0.7565, 0.6329; mean R2=0.7035\n",
      "Validation Error: Avg loss: 3.595745 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:54.400646 Epoch 1888, Training loss 4.227626323699951\n",
      "in params\n",
      "R2 values 0.6526, 0.7686, 0.7571; mean R2=0.7261\n",
      "Validation Error: Avg loss: 3.139410 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:54.674553 Epoch 1889, Training loss 1.9507241249084473\n",
      "in params\n",
      "R2 values 0.6844, 0.8516, 0.6631; mean R2=0.7331\n",
      "Validation Error: Avg loss: 2.787869 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:54.969550 Epoch 1890, Training loss 2.9395978450775146\n",
      "in params\n",
      "R2 values 0.5848, 0.6949, 0.5774; mean R2=0.6191\n",
      "Validation Error: Avg loss: 4.613885 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:55.252148 Epoch 1891, Training loss 3.705925703048706\n",
      "in params\n",
      "R2 values 0.7399, 0.7166, 0.6747; mean R2=0.7104\n",
      "Validation Error: Avg loss: 3.832326 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:55.526435 Epoch 1892, Training loss 2.356483221054077\n",
      "in params\n",
      "R2 values 0.7013, 0.7434, 0.6467; mean R2=0.6971\n",
      "Validation Error: Avg loss: 4.055935 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:55.804530 Epoch 1893, Training loss 3.671152353286743\n",
      "in params\n",
      "R2 values 0.6730, 0.8787, 0.7211; mean R2=0.7576\n",
      "Validation Error: Avg loss: 2.333032 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:56.078043 Epoch 1894, Training loss 2.562394618988037\n",
      "in params\n",
      "R2 values 0.6765, 0.6883, 0.6858; mean R2=0.6835\n",
      "Validation Error: Avg loss: 4.247473 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:56.352671 Epoch 1895, Training loss 2.7715744972229004\n",
      "in params\n",
      "R2 values 0.6407, 0.7120, 0.6855; mean R2=0.6794\n",
      "Validation Error: Avg loss: 3.843288 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:56.633260 Epoch 1896, Training loss 3.9365041255950928\n",
      "in params\n",
      "R2 values 0.6788, 0.7108, 0.6951; mean R2=0.6949\n",
      "Validation Error: Avg loss: 3.933600 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:56.911920 Epoch 1897, Training loss 2.4321885108947754\n",
      "in params\n",
      "R2 values 0.7477, 0.6475, 0.7283; mean R2=0.7078\n",
      "Validation Error: Avg loss: 4.974800 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:57.186138 Epoch 1898, Training loss 2.6435554027557373\n",
      "in params\n",
      "R2 values 0.8015, 0.7463, 0.7467; mean R2=0.7648\n",
      "Validation Error: Avg loss: 3.432827 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:57.461574 Epoch 1899, Training loss 3.2494022846221924\n",
      "in params\n",
      "R2 values 0.6169, 0.5907, 0.6510; mean R2=0.6196\n",
      "Validation Error: Avg loss: 5.146598 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:57.739657 Epoch 1900, Training loss 3.735717535018921\n",
      "in params\n",
      "R2 values 0.6007, 0.6234, 0.6165; mean R2=0.6135\n",
      "Validation Error: Avg loss: 4.957440 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:58.018197 Epoch 1901, Training loss 4.360124588012695\n",
      "in params\n",
      "R2 values 0.4847, 0.5750, 0.6015; mean R2=0.5538\n",
      "Validation Error: Avg loss: 5.658767 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:58.302715 Epoch 1902, Training loss 3.8625540733337402\n",
      "in params\n",
      "R2 values 0.6250, 0.7622, 0.7822; mean R2=0.7231\n",
      "Validation Error: Avg loss: 3.277665 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:58.572392 Epoch 1903, Training loss 2.732267379760742\n",
      "in params\n",
      "R2 values 0.7465, 0.7407, 0.6363; mean R2=0.7078\n",
      "Validation Error: Avg loss: 3.778404 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:58.849842 Epoch 1904, Training loss 3.015742540359497\n",
      "in params\n",
      "R2 values 0.5921, 0.6749, 0.6189; mean R2=0.6286\n",
      "Validation Error: Avg loss: 5.221617 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:59.124184 Epoch 1905, Training loss 2.9265036582946777\n",
      "in params\n",
      "R2 values 0.6412, 0.7265, 0.6812; mean R2=0.6830\n",
      "Validation Error: Avg loss: 4.101727 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:59.403647 Epoch 1906, Training loss 3.4074466228485107\n",
      "in params\n",
      "R2 values 0.6965, 0.6482, 0.6427; mean R2=0.6625\n",
      "Validation Error: Avg loss: 4.723528 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:59.691985 Epoch 1907, Training loss 3.274014711380005\n",
      "in params\n",
      "R2 values 0.6787, 0.6677, 0.6589; mean R2=0.6684\n",
      "Validation Error: Avg loss: 4.407629 \n",
      "\n",
      "in params\n",
      "2023-11-08 13:59:59.971752 Epoch 1908, Training loss 2.6191084384918213\n",
      "in params\n",
      "R2 values 0.6325, 0.6292, 0.6147; mean R2=0.6255\n",
      "Validation Error: Avg loss: 4.927097 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:00.569806 Epoch 1909, Training loss 2.1504805088043213\n",
      "in params\n",
      "R2 values 0.6259, 0.7841, 0.7207; mean R2=0.7102\n",
      "Validation Error: Avg loss: 3.199687 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:00.845837 Epoch 1910, Training loss 2.3851499557495117\n",
      "in params\n",
      "R2 values 0.6352, 0.5348, 0.5898; mean R2=0.5866\n",
      "Validation Error: Avg loss: 5.751609 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:01.123616 Epoch 1911, Training loss 3.4795968532562256\n",
      "in params\n",
      "R2 values 0.6801, 0.6793, 0.6792; mean R2=0.6795\n",
      "Validation Error: Avg loss: 4.346554 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:01.421727 Epoch 1912, Training loss 2.8150062561035156\n",
      "in params\n",
      "R2 values 0.6890, 0.6187, 0.6376; mean R2=0.6484\n",
      "Validation Error: Avg loss: 4.811148 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:01.694377 Epoch 1913, Training loss 2.4471819400787354\n",
      "in params\n",
      "R2 values 0.6944, 0.5886, 0.6441; mean R2=0.6424\n",
      "Validation Error: Avg loss: 5.439131 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:01.966336 Epoch 1914, Training loss 3.7461259365081787\n",
      "in params\n",
      "R2 values 0.7697, 0.7835, 0.7840; mean R2=0.7790\n",
      "Validation Error: Avg loss: 3.021723 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:02.839452 Epoch 1915, Training loss 3.3842225074768066\n",
      "in params\n",
      "R2 values 0.6461, 0.7207, 0.6697; mean R2=0.6788\n",
      "Validation Error: Avg loss: 4.026040 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:03.146969 Epoch 1916, Training loss 2.2059543132781982\n",
      "in params\n",
      "R2 values 0.6711, 0.6735, 0.7067; mean R2=0.6838\n",
      "Validation Error: Avg loss: 4.242235 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:03.435106 Epoch 1917, Training loss 3.0328774452209473\n",
      "in params\n",
      "R2 values 0.6545, 0.7673, 0.7428; mean R2=0.7215\n",
      "Validation Error: Avg loss: 3.242281 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:03.715743 Epoch 1918, Training loss 2.9666061401367188\n",
      "in params\n",
      "R2 values 0.5900, 0.7020, 0.7036; mean R2=0.6652\n",
      "Validation Error: Avg loss: 4.110846 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:04.004740 Epoch 1919, Training loss 3.2003297805786133\n",
      "in params\n",
      "R2 values 0.6716, 0.7274, 0.6216; mean R2=0.6735\n",
      "Validation Error: Avg loss: 4.222084 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:04.275922 Epoch 1920, Training loss 3.4827663898468018\n",
      "in params\n",
      "R2 values 0.7498, 0.7441, 0.6681; mean R2=0.7207\n",
      "Validation Error: Avg loss: 3.625158 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:04.550268 Epoch 1921, Training loss 3.5929508209228516\n",
      "in params\n",
      "R2 values 0.6314, 0.6495, 0.6027; mean R2=0.6279\n",
      "Validation Error: Avg loss: 4.965945 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:04.827671 Epoch 1922, Training loss 2.730678081512451\n",
      "in params\n",
      "R2 values 0.7080, 0.8443, 0.6957; mean R2=0.7494\n",
      "Validation Error: Avg loss: 2.589347 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:05.097753 Epoch 1923, Training loss 3.7481441497802734\n",
      "in params\n",
      "R2 values 0.6319, 0.6069, 0.6605; mean R2=0.6331\n",
      "Validation Error: Avg loss: 5.018374 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:05.379566 Epoch 1924, Training loss 2.5770177841186523\n",
      "in params\n",
      "R2 values 0.6570, 0.7986, 0.6382; mean R2=0.6980\n",
      "Validation Error: Avg loss: 3.508473 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:05.658570 Epoch 1925, Training loss 2.8911266326904297\n",
      "in params\n",
      "R2 values 0.7117, 0.6838, 0.6828; mean R2=0.6927\n",
      "Validation Error: Avg loss: 4.078222 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:05.928340 Epoch 1926, Training loss 3.4118528366088867\n",
      "in params\n",
      "R2 values 0.6663, 0.6612, 0.6568; mean R2=0.6614\n",
      "Validation Error: Avg loss: 4.638993 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:06.199398 Epoch 1927, Training loss 3.8951315879821777\n",
      "in params\n",
      "R2 values 0.5886, 0.7968, 0.6649; mean R2=0.6834\n",
      "Validation Error: Avg loss: 3.529553 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:06.476592 Epoch 1928, Training loss 3.1932711601257324\n",
      "in params\n",
      "R2 values 0.6259, 0.5552, 0.5813; mean R2=0.5875\n",
      "Validation Error: Avg loss: 5.914073 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:06.756770 Epoch 1929, Training loss 3.1089608669281006\n",
      "in params\n",
      "R2 values 0.5261, 0.7041, 0.6057; mean R2=0.6119\n",
      "Validation Error: Avg loss: 4.558436 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:07.034665 Epoch 1930, Training loss 2.2155253887176514\n",
      "in params\n",
      "R2 values 0.6315, 0.6899, 0.6933; mean R2=0.6716\n",
      "Validation Error: Avg loss: 4.145470 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:07.307138 Epoch 1931, Training loss 3.0661327838897705\n",
      "in params\n",
      "R2 values 0.7698, 0.6684, 0.7132; mean R2=0.7171\n",
      "Validation Error: Avg loss: 4.057521 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:07.584991 Epoch 1932, Training loss 2.8070058822631836\n",
      "in params\n",
      "R2 values 0.7341, 0.8050, 0.7404; mean R2=0.7598\n",
      "Validation Error: Avg loss: 2.907127 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 14:00:07.859929 Epoch 1933, Training loss 2.5222978591918945\n",
      "in params\n",
      "R2 values 0.6053, 0.6846, 0.6125; mean R2=0.6341\n",
      "Validation Error: Avg loss: 4.831207 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:08.138167 Epoch 1934, Training loss 2.9360601902008057\n",
      "in params\n",
      "R2 values 0.6618, 0.6968, 0.7116; mean R2=0.6901\n",
      "Validation Error: Avg loss: 4.576491 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:08.420001 Epoch 1935, Training loss 3.2183353900909424\n",
      "in params\n",
      "R2 values 0.6483, 0.5999, 0.6897; mean R2=0.6459\n",
      "Validation Error: Avg loss: 5.256449 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:08.708687 Epoch 1936, Training loss 3.8097076416015625\n",
      "in params\n",
      "R2 values 0.7081, 0.5658, 0.7041; mean R2=0.6593\n",
      "Validation Error: Avg loss: 5.614710 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:09.020975 Epoch 1937, Training loss 3.001850128173828\n",
      "in params\n",
      "R2 values 0.6730, 0.7186, 0.6579; mean R2=0.6832\n",
      "Validation Error: Avg loss: 3.979128 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:09.297222 Epoch 1938, Training loss 3.156494617462158\n",
      "in params\n",
      "R2 values 0.5996, 0.6481, 0.6495; mean R2=0.6324\n",
      "Validation Error: Avg loss: 4.712258 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:09.569397 Epoch 1939, Training loss 3.6350181102752686\n",
      "in params\n",
      "R2 values 0.5627, 0.7527, 0.6446; mean R2=0.6533\n",
      "Validation Error: Avg loss: 3.808019 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:09.855389 Epoch 1940, Training loss 3.236666202545166\n",
      "in params\n",
      "R2 values 0.5284, 0.5045, 0.5303; mean R2=0.5211\n",
      "Validation Error: Avg loss: 6.620368 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:10.129263 Epoch 1941, Training loss 3.7757692337036133\n",
      "in params\n",
      "R2 values 0.5928, 0.6255, 0.6946; mean R2=0.6376\n",
      "Validation Error: Avg loss: 4.820265 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:10.406270 Epoch 1942, Training loss 3.9507691860198975\n",
      "in params\n",
      "R2 values 0.6727, 0.5114, 0.5793; mean R2=0.5878\n",
      "Validation Error: Avg loss: 6.037283 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:10.680068 Epoch 1943, Training loss 2.9572949409484863\n",
      "in params\n",
      "R2 values 0.6103, 0.5332, 0.6004; mean R2=0.5813\n",
      "Validation Error: Avg loss: 6.121203 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:10.960827 Epoch 1944, Training loss 2.8504865169525146\n",
      "in params\n",
      "R2 values 0.6984, 0.7592, 0.7629; mean R2=0.7402\n",
      "Validation Error: Avg loss: 3.177912 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:11.232803 Epoch 1945, Training loss 2.5996522903442383\n",
      "in params\n",
      "R2 values 0.5977, 0.6015, 0.5900; mean R2=0.5964\n",
      "Validation Error: Avg loss: 5.747053 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:11.525268 Epoch 1946, Training loss 4.120172023773193\n",
      "in params\n",
      "R2 values 0.6761, 0.6754, 0.6497; mean R2=0.6671\n",
      "Validation Error: Avg loss: 4.661281 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:11.801995 Epoch 1947, Training loss 3.0383176803588867\n",
      "in params\n",
      "R2 values 0.5596, 0.6193, 0.6887; mean R2=0.6225\n",
      "Validation Error: Avg loss: 4.711921 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:12.095035 Epoch 1948, Training loss 2.8615238666534424\n",
      "in params\n",
      "R2 values 0.6087, 0.6803, 0.6359; mean R2=0.6416\n",
      "Validation Error: Avg loss: 4.420112 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:12.368266 Epoch 1949, Training loss 4.139027118682861\n",
      "in params\n",
      "R2 values 0.6724, 0.6339, 0.6194; mean R2=0.6419\n",
      "Validation Error: Avg loss: 4.913095 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:12.641931 Epoch 1950, Training loss 4.0489349365234375\n",
      "in params\n",
      "R2 values 0.5971, 0.8120, 0.6558; mean R2=0.6883\n",
      "Validation Error: Avg loss: 3.446323 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:12.918982 Epoch 1951, Training loss 3.392883777618408\n",
      "in params\n",
      "R2 values 0.7432, 0.6679, 0.7358; mean R2=0.7156\n",
      "Validation Error: Avg loss: 4.439192 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:13.198408 Epoch 1952, Training loss 2.479764699935913\n",
      "in params\n",
      "R2 values 0.6329, 0.7280, 0.6896; mean R2=0.6835\n",
      "Validation Error: Avg loss: 3.739254 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:13.480157 Epoch 1953, Training loss 3.708303213119507\n",
      "in params\n",
      "R2 values 0.6546, 0.6675, 0.5985; mean R2=0.6402\n",
      "Validation Error: Avg loss: 4.867276 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:13.750797 Epoch 1954, Training loss 3.985274076461792\n",
      "in params\n",
      "R2 values 0.6440, 0.8513, 0.7559; mean R2=0.7504\n",
      "Validation Error: Avg loss: 3.138361 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:14.018693 Epoch 1955, Training loss 3.625025510787964\n",
      "in params\n",
      "R2 values 0.5905, 0.6143, 0.5909; mean R2=0.5986\n",
      "Validation Error: Avg loss: 5.500025 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:14.293614 Epoch 1956, Training loss 3.6529366970062256\n",
      "in params\n",
      "R2 values 0.6204, 0.4932, 0.6110; mean R2=0.5749\n",
      "Validation Error: Avg loss: 6.630273 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:14.571021 Epoch 1957, Training loss 2.600785255432129\n",
      "in params\n",
      "R2 values 0.6345, 0.8339, 0.6379; mean R2=0.7021\n",
      "Validation Error: Avg loss: 3.345494 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:14.851876 Epoch 1958, Training loss 4.319868564605713\n",
      "in params\n",
      "R2 values 0.6558, 0.7863, 0.6416; mean R2=0.6946\n",
      "Validation Error: Avg loss: 3.427874 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:15.134002 Epoch 1959, Training loss 2.7079222202301025\n",
      "in params\n",
      "R2 values 0.6645, 0.8296, 0.7589; mean R2=0.7510\n",
      "Validation Error: Avg loss: 2.792969 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:15.410608 Epoch 1960, Training loss 3.3636417388916016\n",
      "in params\n",
      "R2 values 0.5658, 0.5919, 0.6232; mean R2=0.5936\n",
      "Validation Error: Avg loss: 5.249897 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:15.691962 Epoch 1961, Training loss 2.995253562927246\n",
      "in params\n",
      "R2 values 0.5984, 0.7789, 0.6634; mean R2=0.6802\n",
      "Validation Error: Avg loss: 3.498345 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:15.967382 Epoch 1962, Training loss 2.475255012512207\n",
      "in params\n",
      "R2 values 0.7230, 0.6897, 0.7215; mean R2=0.7114\n",
      "Validation Error: Avg loss: 3.986740 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:16.247259 Epoch 1963, Training loss 2.705963134765625\n",
      "in params\n",
      "R2 values 0.6882, 0.7933, 0.7042; mean R2=0.7286\n",
      "Validation Error: Avg loss: 3.075973 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:16.524777 Epoch 1964, Training loss 4.3419013023376465\n",
      "in params\n",
      "R2 values 0.6292, 0.7041, 0.6523; mean R2=0.6619\n",
      "Validation Error: Avg loss: 4.192636 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:16.803505 Epoch 1965, Training loss 2.2686140537261963\n",
      "in params\n",
      "R2 values 0.7102, 0.6477, 0.6869; mean R2=0.6816\n",
      "Validation Error: Avg loss: 4.507000 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:17.088671 Epoch 1966, Training loss 2.842068910598755\n",
      "in params\n",
      "R2 values 0.7011, 0.6784, 0.6941; mean R2=0.6912\n",
      "Validation Error: Avg loss: 4.520932 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:17.385411 Epoch 1967, Training loss 2.719740152359009\n",
      "in params\n",
      "R2 values 0.6999, 0.5822, 0.7178; mean R2=0.6666\n",
      "Validation Error: Avg loss: 5.033652 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:17.664643 Epoch 1968, Training loss 4.278378009796143\n",
      "in params\n",
      "R2 values 0.7210, 0.7398, 0.7072; mean R2=0.7227\n",
      "Validation Error: Avg loss: 3.615676 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:17.956119 Epoch 1969, Training loss 2.7836666107177734\n",
      "in params\n",
      "R2 values 0.6586, 0.7308, 0.7479; mean R2=0.7124\n",
      "Validation Error: Avg loss: 3.539302 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:18.237755 Epoch 1970, Training loss 3.0345420837402344\n",
      "in params\n",
      "R2 values 0.6094, 0.6771, 0.5903; mean R2=0.6256\n",
      "Validation Error: Avg loss: 4.577338 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:18.519759 Epoch 1971, Training loss 2.5808427333831787\n",
      "in params\n",
      "R2 values 0.7692, 0.8082, 0.7496; mean R2=0.7757\n",
      "Validation Error: Avg loss: 2.799676 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:18.797858 Epoch 1972, Training loss 3.9020848274230957\n",
      "in params\n",
      "R2 values 0.6005, 0.6520, 0.6477; mean R2=0.6334\n",
      "Validation Error: Avg loss: 4.748577 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:19.072969 Epoch 1973, Training loss 4.2017598152160645\n",
      "in params\n",
      "R2 values 0.6413, 0.7518, 0.5833; mean R2=0.6588\n",
      "Validation Error: Avg loss: 3.876332 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:19.341762 Epoch 1974, Training loss 2.8862509727478027\n",
      "in params\n",
      "R2 values 0.6041, 0.6931, 0.6683; mean R2=0.6552\n",
      "Validation Error: Avg loss: 4.578737 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:19.629831 Epoch 1975, Training loss 4.116182327270508\n",
      "in params\n",
      "R2 values 0.7102, 0.7089, 0.7445; mean R2=0.7212\n",
      "Validation Error: Avg loss: 3.681023 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:19.937584 Epoch 1976, Training loss 3.483503818511963\n",
      "in params\n",
      "R2 values 0.6384, 0.6411, 0.6375; mean R2=0.6390\n",
      "Validation Error: Avg loss: 4.931291 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:20.225292 Epoch 1977, Training loss 3.219316005706787\n",
      "in params\n",
      "R2 values 0.5711, 0.6432, 0.6841; mean R2=0.6328\n",
      "Validation Error: Avg loss: 5.302029 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:20.501172 Epoch 1978, Training loss 3.616030216217041\n",
      "in params\n",
      "R2 values 0.7511, 0.6991, 0.7168; mean R2=0.7223\n",
      "Validation Error: Avg loss: 3.859676 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in params\n",
      "2023-11-08 14:00:20.783860 Epoch 1979, Training loss 2.863628625869751\n",
      "in params\n",
      "R2 values 0.6311, 0.6599, 0.6673; mean R2=0.6528\n",
      "Validation Error: Avg loss: 4.950440 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:21.077811 Epoch 1980, Training loss 3.1305489540100098\n",
      "in params\n",
      "R2 values 0.6329, 0.8415, 0.7446; mean R2=0.7397\n",
      "Validation Error: Avg loss: 2.629277 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:21.362817 Epoch 1981, Training loss 3.530647039413452\n",
      "in params\n",
      "R2 values 0.5728, 0.5981, 0.6276; mean R2=0.5995\n",
      "Validation Error: Avg loss: 5.178166 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:21.669341 Epoch 1982, Training loss 2.7962045669555664\n",
      "in params\n",
      "R2 values 0.6777, 0.7547, 0.5383; mean R2=0.6569\n",
      "Validation Error: Avg loss: 4.414841 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:21.948753 Epoch 1983, Training loss 2.2462031841278076\n",
      "in params\n",
      "R2 values 0.6296, 0.5602, 0.5421; mean R2=0.5773\n",
      "Validation Error: Avg loss: 5.885975 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:22.225555 Epoch 1984, Training loss 3.88417387008667\n",
      "in params\n",
      "R2 values 0.5495, 0.6305, 0.6083; mean R2=0.5961\n",
      "Validation Error: Avg loss: 4.986664 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:22.502292 Epoch 1985, Training loss 2.4953019618988037\n",
      "in params\n",
      "R2 values 0.6103, 0.6299, 0.5695; mean R2=0.6032\n",
      "Validation Error: Avg loss: 5.107814 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:22.771924 Epoch 1986, Training loss 3.3483216762542725\n",
      "in params\n",
      "R2 values 0.6644, 0.7677, 0.6356; mean R2=0.6892\n",
      "Validation Error: Avg loss: 3.565466 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:23.042502 Epoch 1987, Training loss 2.330535650253296\n",
      "in params\n",
      "R2 values 0.7588, 0.7289, 0.7560; mean R2=0.7479\n",
      "Validation Error: Avg loss: 3.505569 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:23.315497 Epoch 1988, Training loss 2.7418487071990967\n",
      "in params\n",
      "R2 values 0.6760, 0.7004, 0.7202; mean R2=0.6989\n",
      "Validation Error: Avg loss: 3.823452 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:23.605896 Epoch 1989, Training loss 1.8274976015090942\n",
      "in params\n",
      "R2 values 0.6775, 0.5553, 0.4826; mean R2=0.5718\n",
      "Validation Error: Avg loss: 6.048604 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:23.880883 Epoch 1990, Training loss 3.670724630355835\n",
      "in params\n",
      "R2 values 0.6440, 0.5043, 0.6560; mean R2=0.6015\n",
      "Validation Error: Avg loss: 5.779595 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:24.156735 Epoch 1991, Training loss 2.0971720218658447\n",
      "in params\n",
      "R2 values 0.6782, 0.6829, 0.6990; mean R2=0.6867\n",
      "Validation Error: Avg loss: 4.041058 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:24.430330 Epoch 1992, Training loss 3.1330928802490234\n",
      "in params\n",
      "R2 values 0.6349, 0.7584, 0.5161; mean R2=0.6364\n",
      "Validation Error: Avg loss: 4.021146 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:24.707987 Epoch 1993, Training loss 3.8375394344329834\n",
      "in params\n",
      "R2 values 0.6663, 0.8512, 0.6874; mean R2=0.7350\n",
      "Validation Error: Avg loss: 2.632991 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:24.982174 Epoch 1994, Training loss 2.6864683628082275\n",
      "in params\n",
      "R2 values 0.6311, 0.8189, 0.7087; mean R2=0.7196\n",
      "Validation Error: Avg loss: 2.885380 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:25.254283 Epoch 1995, Training loss 4.154193878173828\n",
      "in params\n",
      "R2 values 0.6840, 0.6320, 0.6724; mean R2=0.6628\n",
      "Validation Error: Avg loss: 4.738245 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:25.537339 Epoch 1996, Training loss 2.88212251663208\n",
      "in params\n",
      "R2 values 0.6816, 0.7320, 0.7112; mean R2=0.7083\n",
      "Validation Error: Avg loss: 3.694236 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:25.815413 Epoch 1997, Training loss 3.1834075450897217\n",
      "in params\n",
      "R2 values 0.7635, 0.5121, 0.6875; mean R2=0.6544\n",
      "Validation Error: Avg loss: 5.657382 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:26.091831 Epoch 1998, Training loss 3.4830026626586914\n",
      "in params\n",
      "R2 values 0.6714, 0.6864, 0.6899; mean R2=0.6826\n",
      "Validation Error: Avg loss: 4.574702 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:26.370188 Epoch 1999, Training loss 3.4056921005249023\n",
      "in params\n",
      "R2 values 0.6073, 0.7122, 0.5848; mean R2=0.6348\n",
      "Validation Error: Avg loss: 4.376182 \n",
      "\n",
      "in params\n",
      "2023-11-08 14:00:26.646355 Epoch 2000, Training loss 2.6933205127716064\n",
      "in params\n",
      "R2 values 0.6527, 0.6050, 0.5938; mean R2=0.6172\n",
      "Validation Error: Avg loss: 5.270646 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose between 'Mixed', 'ICCD', or 'Params'\n",
    "features_to_use = 'Params' \n",
    "\n",
    "n_epochs=2000\n",
    "learning_rate = 0.011161751166183152\n",
    "L2 = 0.00027243494911370175\n",
    "\n",
    "checkpoint_name = 'Growth Kinetics Param Input Checkpoint'\n",
    "\n",
    "model = MixedICCDNet(features=features_to_use,\n",
    "                     l1=64,        # MLP nodes layer 1 for ICCD features\n",
    "                     l2=32,        # MLP nodes layer 2 for ICCD features\n",
    "                     param_l1=48,  # MLP nodes layer 1 for parameter features\n",
    "                     param_out=32, # MLP nodes layer 2 for parameter features\n",
    "                     c1=16,        # MLP nodes layer 1 for combined features\n",
    "                     c2=24,        # MLP nodes layer 1 for combined features\n",
    "                     c3=32)        # MLP nodes layer 1 for combined features\n",
    "\n",
    "# Train the model\n",
    "results = train(model,train_loader,val_loader, n_epochs, learning_rate, L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "591e1b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, val_loss_list, r2_list, best_R2, best_val_predictions,\\\n",
    "best_val_actuals,best_train_predictions, best_train_actuals = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "000a4ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best r2 value was: 0.8535401915186039\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('The best r2 value was:', best_R2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_loss_list, label='Train',alpha=0.8)\n",
    "ax.plot(val_loss_list,label='Test',alpha=0.8)\n",
    "\n",
    "#ax.set_ylim(0,2000)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MSE Loss')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "321a7c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r2_array = np.array(r2_list)\n",
    "labels = ['s$_0$', 's$_1$', 'J', 'mean']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(r2_array.shape[1]):\n",
    "    ax.plot(r2_array[:,i],label=labels[i],alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('r$^2$')\n",
    "ax.legend()\n",
    "ax.tick_params(axis='both')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "957ed1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_predictions(train_pred, train_actual, val_pred, val_actual, index, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    r2_train = pearsonr(train_actual[:,index], train_pred[:,index])[0]**2\n",
    "    r2_val = pearsonr(val_actual[:,index], val_pred[:,index])[0]**2\n",
    "    \n",
    "    ax.scatter(train_actual[:,index],train_pred[:,index],label='Train')\n",
    "    ax.scatter(val_actual[:,index],val_pred[:,index],label='Validation')\n",
    "    ax.plot(train_actual[:,index],train_actual[:,index],c='k')\n",
    "    \n",
    "    plt.text(0.02, 0.98, 'r$^2_{train}$ = %.4f\\nr$^2_{val}$ = %.4f' % (r2_train,r2_val),\n",
    "     horizontalalignment='left',\n",
    "     verticalalignment='top',\n",
    "     transform = ax.transAxes)\n",
    "\n",
    "    ax.legend(loc='upper center')\n",
    "        \n",
    "    ax.set_xlabel('{} actual'.format(title))\n",
    "    ax.set_ylabel('{} predicted'.format(title))\n",
    "    ax.tick_params(axis='both')\n",
    "    \n",
    "    return ax\n",
    "\n",
    "labels = ['s$_0$', 's$_1$', 'J']\n",
    "atten = [10,1,1000]\n",
    "\n",
    "for i,label in enumerate(labels):\n",
    "    ax = plot_predictions(best_train_predictions/atten[i],best_train_actuals/atten[i],\n",
    "                     best_val_predictions/atten[i], best_val_actuals/atten[i],i,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70e61b",
   "metadata": {},
   "source": [
    "# Train for growth kinetics using Mixed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d225f44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 127\n",
      "Number of training samples: 88\n",
      "Number of validation samples: 39\n"
     ]
    }
   ],
   "source": [
    "datafile = 'PLD data.json'\n",
    "\n",
    "# set the target to anomaly to train for P, E1, and E2.\n",
    "# set the target to 'growth' to train for s0, s1, and J\n",
    "target_params = 'growth'\n",
    "\n",
    "BATCH_SIZE = 88\n",
    "\n",
    "#############################\n",
    "if target_params == 'anomaly':\n",
    "    normalize_PTE1E2 = False\n",
    "else:\n",
    "    normalize_PTE1E2 = True\n",
    "\n",
    "train_data, val_data = load_data(datafile, target_params, normalize_PTE1E2=normalize_PTE1E2, train_percent=70)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a805e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedICCDNet(nn.Module):\n",
    "    def __init__(self,l1=64,l2=32,param_l1=48,param_out=32,c1=16,c2=24,c3=32):\n",
    "        super(MixedICCDNet, self).__init__()\n",
    "        # ICCD imaging feature inputs, the full image size is BATCH,C,frames,H,W where it is N,50,40,40\n",
    "        self.ICCD_features_ = nn.Sequential(\n",
    "            #Spatial convolution\n",
    "            nn.Conv3d(1,64, kernel_size=(1,3,3), stride=(1,1,1), padding=(0,1,1)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            #Temportal convolution\n",
    "            nn.Conv3d(64,64,kernel_size=(3,1,1), stride=(1,1,1), padding=(1,0,0)),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "\n",
    "            #Downsample\n",
    "            nn.AvgPool3d(kernel_size=(2,2,2),stride=(2,2,2)),\n",
    "\n",
    "            #Spatial convolution\n",
    "            nn.Conv3d(64,128, kernel_size=(1,3,3), stride=(1,1,1), padding=(0,1,1)),\n",
    "            nn.BatchNorm3d(128),\n",
    "            #Temportal convolution\n",
    "            nn.Conv3d(128,128,kernel_size=(3,1,1), stride=(1,1,1), padding=(1,0,0)),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "\n",
    "            #Downsample\n",
    "            nn.AvgPool3d(kernel_size=(2,2,2),stride=(2,2,2)),\n",
    "\n",
    "            #Spatial convolution\n",
    "            nn.Conv3d(128,256, kernel_size=(1,3,3), stride=(1,1,1), padding=(0,1,1)),\n",
    "            nn.BatchNorm3d(256),\n",
    "            #Temportal convolution\n",
    "            nn.Conv3d(256,256,kernel_size=(3,1,1), stride=(1,1,1), padding=(1,0,0)),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "\n",
    "            #Downsample\n",
    "            nn.AvgPool3d(kernel_size=(2,2,2),stride=(2,2,2)),\n",
    "\n",
    "            nn.Flatten(start_dim=1),\n",
    "            nn.Linear(256*6*5*5,l1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(l1,l2),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            #nn.Linear(l2,3)\n",
    "        )\n",
    "        \n",
    "        self.parameter_features = nn.Sequential(\n",
    "            nn.Linear(4,param_l1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(param_l1,param_out),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            #nn.Linear(param_out,3)\n",
    "        )\n",
    "        \n",
    "        self.combined_features_ = nn.Sequential(\n",
    "            nn.Linear(l2+param_out,c1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(c1,c2),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(c2,c3),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(c3,3),\n",
    "        )\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        x=self.ICCD_features_(x)\n",
    "        y=self.parameter_features(y)\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        y=y.view(y.shape[0],-1)        \n",
    "        z = torch.cat((x,y),1)\n",
    "        z = self.combined_features_(z)        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcfcb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_best(config,ICCD_checkpoint=None, MLP_checkpoint=None):\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    r2_list = []\n",
    "    print(config['c1'],config['c2'],config['c3'])\n",
    "    print(\"I'M TRAINING, I'M TRAINING!!\")\n",
    "    model = MixedICCDNet(l1=config['l1'],l2=config['l2'],param_l1=config['param_l1'],param_out=config['param_out'],c1=config['c1'],c2=config['c2'])\n",
    "    \n",
    "    if ICCD_checkpoint:\n",
    "        weights = torch.load(ICCD_checkpoint)\n",
    "        model.load_state_dict(weights,strict=False)\n",
    "        #Freeze all layers in the ICCD_features_ part\n",
    "        for param in model.ICCD_features_.parameters():\n",
    "            param.requires_grad = False\n",
    "        print('Loaded ICCD layers...')\n",
    "        for param in model.ICCD_features_.parameters():\n",
    "            if param.requires_grad:\n",
    "                print('ERROR:Found trainable in ICCD')\n",
    "        \n",
    "    if MLP_checkpoint:\n",
    "        weights = torch.load(MLP_checkpoint)\n",
    "        model.load_state_dict(weights,strict=False)\n",
    "        #Freeze all layers in the parameter_features part\n",
    "        for param in model.parameter_features.parameters():\n",
    "            param.requires_grad = False\n",
    "        print('Loaded parameter MLP layers...')\n",
    "        for param in model.parameter_features.parameters():\n",
    "            if param.requires_grad:\n",
    "                print('ERROR:Found trainable in ICCD')\n",
    "    \n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        print('Using GPU.')\n",
    "        device = \"cuda:0\"    \n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print('Using multiple GPUs.')\n",
    "            model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer=optim.Adam(model.parameters(),lr=config['lr'],amsgrad=True,weight_decay=config['weight_decay'])\n",
    "    \n",
    "    BATCH_SIZE = 88\n",
    "    train_data, val_data = load_data(datafile, train_percent=70)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    #print('Total image feature params:',sum(p.numel() for p in model.ICCD_features_.parameters()))\n",
    "    #print('Total model params:',sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "    loss_values = []\n",
    "    val_loss_values = []\n",
    "    best_R2 = 0.0\n",
    "    n_epochs=2000\n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        loss_train = 0.0\n",
    "        for id_batch, (image1,params,target) in enumerate(train_loader):\n",
    "            image1=image1.to(device)\n",
    "            params=params.to(device)\n",
    "            score = target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_pred = model(image1,params)\n",
    "            loss = loss_fn(y_pred, score)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        loss_values.append(loss_train/len(train_loader))\n",
    "        print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch,\n",
    "                                                          loss_train / len(train_loader)))\n",
    "        \n",
    "        train_pred, train_actuals = y_pred.cpu(), score.cpu()\n",
    "        size = len(val_loader.dataset)\n",
    "        num_batches = len(val_loader)\n",
    "        test_loss = 0.0\n",
    "        train_loss_list.append(loss_train)\n",
    "        \n",
    "        for (image1,params,target) in val_loader:\n",
    "            with torch.no_grad():\n",
    "                image1=image1.to(device)\n",
    "                params=params.to(device)\n",
    "                score = target.to(device)\n",
    "                pred = model(image1,params)\n",
    "                test_loss += loss_fn(pred, score).item()\n",
    "                pr2 = pearsonr(score[:,0].cpu(), pred[:,0].cpu())[0]**2\n",
    "                e1r2 = pearsonr(score[:,1].cpu(), pred[:,1].cpu())[0]**2\n",
    "                e2r2 = pearsonr(score[:,2].cpu(), pred[:,2].cpu())[0]**2\n",
    "                meanR2 = np.array([pr2,e1r2,e2r2]).mean()\n",
    "                print('R2 values {:.4f}, {:.4f}, {:.4f}; mean R2={:.4f}'.format(pr2, e1r2, e2r2, meanR2))\n",
    "                r2_list.append([pr2, e1r2, e2r2,meanR2])\n",
    "                \n",
    "        if meanR2>best_R2:\n",
    "            print('New best, saving checkpoint...')\n",
    "            best_R2 = meanR2\n",
    "            best_val_predictions, best_val_actuals = pred.cpu().detach(), score.cpu().detach()\n",
    "            best_train_predictions, best_train_actuals = train_pred.cpu().detach(), train_actuals.cpu().detach()\n",
    "            \n",
    "            torch.save(model.state_dict(), 'Model Checkpoints/103023 MixedICCDNet_3HL.model'.format(config['l1'],config['l2'], config['lr'],config['weight_decay']))\n",
    "        test_loss /= num_batches\n",
    "        test_loss_list.append(test_loss)\n",
    "        val_loss_values.append(test_loss)\n",
    "        print(f\"Test Error: Avg loss: {test_loss:>8f} \\n\")\n",
    "        #train.report({\"mean_R2\": meanR2})\n",
    "        \n",
    "    return best_R2, train_loss_list, test_loss_list, r2_list, best_train_predictions, best_train_actuals, best_val_predictions, best_val_actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f3b59f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('ICCD_features_.0.weight',\n",
       "              tensor([[[[[-0.1287,  0.2480, -0.0449],\n",
       "                         [ 0.2529,  0.0185,  0.2721],\n",
       "                         [ 0.0271,  0.0582, -0.3907]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0671, -0.0004, -0.1629],\n",
       "                         [-0.1324, -0.1244, -0.2062],\n",
       "                         [ 0.1572,  0.0480, -0.1947]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0518, -0.0058, -0.2445],\n",
       "                         [ 0.1375, -0.2268,  0.1626],\n",
       "                         [ 0.2572,  0.2073, -0.3331]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0168, -0.1507, -0.0854],\n",
       "                         [-0.0257, -0.2819,  0.0974],\n",
       "                         [ 0.1311,  0.1231,  0.0042]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.1594, -0.1955, -0.3071],\n",
       "                         [-0.0687,  0.1508,  0.0592],\n",
       "                         [-0.0349,  0.1109,  0.2021]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0516,  0.2362, -0.1178],\n",
       "                         [ 0.2241,  0.2970,  0.0968],\n",
       "                         [ 0.0346,  0.1447, -0.2480]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.2058, -0.2828,  0.0351],\n",
       "                         [-0.2771, -0.0947,  0.2198],\n",
       "                         [-0.2707, -0.2086,  0.0538]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.2137,  0.2858, -0.0197],\n",
       "                         [ 0.3082, -0.3181,  0.1288],\n",
       "                         [ 0.2399, -0.2725,  0.0229]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.2793, -0.2320,  0.0392],\n",
       "                         [ 0.0104, -0.0214,  0.0621],\n",
       "                         [-0.1468, -0.2837, -0.2815]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.2654, -0.2735,  0.1957],\n",
       "                         [ 0.2276,  0.0766, -0.0948],\n",
       "                         [-0.0619,  0.1165,  0.1341]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.1448,  0.1453,  0.2284],\n",
       "                         [-0.2225,  0.2206, -0.0356],\n",
       "                         [ 0.2598,  0.1966,  0.0903]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.2643, -0.1681, -0.3028],\n",
       "                         [ 0.2269, -0.1368, -0.1273],\n",
       "                         [ 0.0726, -0.1613, -0.0825]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0866, -0.3067,  0.0764],\n",
       "                         [-0.0605,  0.2857, -0.1132],\n",
       "                         [-0.0008,  0.3203, -0.0906]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0909, -0.2941, -0.0398],\n",
       "                         [ 0.0587, -0.1970,  0.1778],\n",
       "                         [-0.1444, -0.1365, -0.0488]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.3098,  0.1747, -0.1382],\n",
       "                         [-0.1782,  0.1020, -0.1573],\n",
       "                         [-0.0554,  0.2440,  0.0736]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.1341,  0.1273, -0.0830],\n",
       "                         [ 0.0911, -0.2963, -0.2254],\n",
       "                         [-0.1340,  0.1412,  0.2347]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0753,  0.3017,  0.1780],\n",
       "                         [-0.2085, -0.1094, -0.1984],\n",
       "                         [-0.1292, -0.1928, -0.0402]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.2700,  0.2589, -0.1994],\n",
       "                         [-0.3080,  0.3844,  0.2855],\n",
       "                         [ 0.1850, -0.0208,  0.2050]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.3153,  0.0382, -0.0188],\n",
       "                         [ 0.1497, -0.2374,  0.2524],\n",
       "                         [-0.0064, -0.1177,  0.2923]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.2023, -0.2930,  0.2772],\n",
       "                         [ 0.0761, -0.1824,  0.2169],\n",
       "                         [ 0.0488, -0.1726, -0.2502]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.1182,  0.1992,  0.1609],\n",
       "                         [ 0.0623, -0.3180,  0.1780],\n",
       "                         [-0.1677, -0.0465, -0.1406]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.3154, -0.0224, -0.0403],\n",
       "                         [ 0.2807,  0.2499, -0.1791],\n",
       "                         [-0.2293,  0.0952, -0.1301]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.2051, -0.0967, -0.1190],\n",
       "                         [ 0.1444, -0.2837,  0.0320],\n",
       "                         [-0.1104,  0.0747,  0.1955]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.1341,  0.2804, -0.1608],\n",
       "                         [ 0.1136, -0.0110,  0.1708],\n",
       "                         [ 0.1178, -0.0367,  0.2519]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.2469,  0.0213,  0.1015],\n",
       "                         [ 0.1907,  0.1094,  0.2766],\n",
       "                         [ 0.2794,  0.2198,  0.0075]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.2399, -0.3269, -0.0174],\n",
       "                         [ 0.0563,  0.1992,  0.1272],\n",
       "                         [-0.0418, -0.1240, -0.2524]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.2460, -0.1775, -0.0409],\n",
       "                         [-0.1556,  0.1979,  0.1612],\n",
       "                         [-0.0215, -0.3504,  0.2160]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0098,  0.3195, -0.0926],\n",
       "                         [ 0.1025,  0.0547, -0.2535],\n",
       "                         [-0.2107,  0.2261, -0.0710]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.1573, -0.1754, -0.0279],\n",
       "                         [ 0.2603, -0.0974, -0.1528],\n",
       "                         [ 0.0715, -0.0556, -0.1511]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.1775, -0.0181,  0.3612],\n",
       "                         [-0.3082, -0.1905,  0.0490],\n",
       "                         [-0.0402, -0.0556,  0.1873]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0313,  0.0398,  0.0440],\n",
       "                         [ 0.1054,  0.0809,  0.1620],\n",
       "                         [-0.0947, -0.0579, -0.0154]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.1101, -0.2411, -0.1778],\n",
       "                         [-0.1775,  0.0971,  0.1548],\n",
       "                         [-0.0331,  0.0849,  0.2207]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0396, -0.0968,  0.1174],\n",
       "                         [ 0.2034,  0.2597, -0.2958],\n",
       "                         [-0.1738,  0.0883,  0.0185]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0512, -0.0823,  0.0336],\n",
       "                         [ 0.0496,  0.1530, -0.1453],\n",
       "                         [ 0.0676, -0.1800,  0.0287]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.1732,  0.1015,  0.0474],\n",
       "                         [-0.2328,  0.2644, -0.2228],\n",
       "                         [-0.2071,  0.1683, -0.2614]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.2017,  0.2636,  0.1735],\n",
       "                         [-0.2856,  0.0208,  0.2971],\n",
       "                         [-0.1315, -0.2528,  0.2546]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.2446, -0.2825,  0.2849],\n",
       "                         [ 0.3040, -0.0750,  0.2674],\n",
       "                         [-0.2277,  0.0204, -0.0221]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.2895, -0.3377, -0.0203],\n",
       "                         [ 0.0999,  0.2566, -0.2979],\n",
       "                         [-0.1599, -0.2108, -0.2735]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0641, -0.2273, -0.1718],\n",
       "                         [-0.1325, -0.3261,  0.0908],\n",
       "                         [-0.0780,  0.0427, -0.0894]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0182, -0.0356,  0.1490],\n",
       "                         [-0.2474,  0.1580,  0.1467],\n",
       "                         [-0.0024, -0.2751,  0.2259]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.1594,  0.1936,  0.0417],\n",
       "                         [ 0.2357, -0.0370,  0.1326],\n",
       "                         [ 0.0153,  0.3300, -0.1005]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.3177, -0.2818, -0.2035],\n",
       "                         [ 0.0903,  0.1562,  0.0410],\n",
       "                         [-0.3265, -0.2782,  0.0988]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.2084, -0.1598,  0.1668],\n",
       "                         [ 0.2540, -0.2357,  0.3092],\n",
       "                         [-0.3195, -0.2299,  0.2339]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.1984,  0.2345,  0.1684],\n",
       "                         [-0.2420,  0.2347, -0.3442],\n",
       "                         [-0.1074, -0.0288,  0.3145]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0796,  0.0092, -0.2599],\n",
       "                         [ 0.2242, -0.2590,  0.0160],\n",
       "                         [-0.1288, -0.0597, -0.0565]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0036,  0.2917, -0.2462],\n",
       "                         [ 0.1264,  0.2981, -0.1764],\n",
       "                         [-0.2920, -0.0731,  0.0415]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.2046,  0.1908, -0.2125],\n",
       "                         [ 0.0109,  0.1516,  0.2765],\n",
       "                         [-0.1067,  0.1177, -0.0841]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.1821,  0.0336, -0.2822],\n",
       "                         [ 0.0498, -0.0353, -0.1916],\n",
       "                         [ 0.2279, -0.0964, -0.0078]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0186, -0.2028, -0.2227],\n",
       "                         [ 0.2021, -0.1743,  0.1363],\n",
       "                         [ 0.2538,  0.2625, -0.0128]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0424, -0.1202, -0.1410],\n",
       "                         [-0.0691, -0.1799, -0.0451],\n",
       "                         [ 0.3425, -0.0855,  0.0239]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.1648, -0.2764,  0.2894],\n",
       "                         [-0.2782,  0.2123, -0.1074],\n",
       "                         [ 0.1901, -0.0718, -0.1269]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0590, -0.1233, -0.2494],\n",
       "                         [ 0.0991, -0.1963, -0.0243],\n",
       "                         [ 0.2293, -0.1670, -0.2481]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0294,  0.3049,  0.1164],\n",
       "                         [-0.2788,  0.1550,  0.1591],\n",
       "                         [-0.0900,  0.0292, -0.2796]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0577, -0.1633,  0.0769],\n",
       "                         [-0.2570, -0.3736, -0.2890],\n",
       "                         [ 0.1338, -0.3183,  0.2255]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.1537, -0.1046, -0.0264],\n",
       "                         [ 0.0980, -0.2315,  0.1580],\n",
       "                         [-0.0049, -0.2388,  0.2291]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.1176,  0.3247, -0.1732],\n",
       "                         [ 0.0433, -0.1178, -0.1271],\n",
       "                         [ 0.2388,  0.1170,  0.2181]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.2021,  0.1402,  0.1354],\n",
       "                         [-0.1176,  0.3356,  0.0207],\n",
       "                         [ 0.1488, -0.0666,  0.1603]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.3072, -0.2462, -0.0999],\n",
       "                         [ 0.2115, -0.1282,  0.2825],\n",
       "                         [ 0.3156, -0.2529,  0.2068]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.1238, -0.0710,  0.0162],\n",
       "                         [-0.1064, -0.0621, -0.0777],\n",
       "                         [-0.2936,  0.2237, -0.2880]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0950,  0.2231,  0.1910],\n",
       "                         [ 0.1518,  0.2814, -0.2800],\n",
       "                         [ 0.0781, -0.3128, -0.0984]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.1955, -0.0856, -0.1309],\n",
       "                         [-0.1357,  0.1945,  0.1782],\n",
       "                         [-0.0821,  0.1959, -0.3345]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0674,  0.1737, -0.2999],\n",
       "                         [-0.1867,  0.3152, -0.0153],\n",
       "                         [-0.2054, -0.2451, -0.0028]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.2510,  0.2124, -0.0859],\n",
       "                         [ 0.2438, -0.1063, -0.3089],\n",
       "                         [ 0.1351,  0.0024,  0.3299]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.2589, -0.0180,  0.1824],\n",
       "                         [ 0.1053, -0.0485,  0.1791],\n",
       "                         [-0.2926, -0.0056,  0.1453]]]]])),\n",
       "             ('ICCD_features_.0.bias',\n",
       "              tensor([-2.1209e-02,  9.9688e-05,  1.5901e-04,  1.2387e-02,  3.0509e-04,\n",
       "                       1.3608e-03,  2.1330e-02, -6.4483e-05, -7.9117e-06, -2.8771e-05,\n",
       "                       4.0405e-03,  4.4748e-04,  1.7361e-03, -2.4710e-04,  3.0310e-04,\n",
       "                      -1.6951e-02,  1.0373e-04, -4.3599e-04,  1.2446e-04, -6.7561e-04,\n",
       "                       5.2943e-03,  4.8928e-03, -5.6016e-03, -2.1816e-04, -7.0478e-05,\n",
       "                       8.6555e-03, -3.0977e-03,  6.2849e-03, -1.8633e-04, -8.4326e-03,\n",
       "                      -1.1048e-03, -4.8657e-04, -3.0441e-04,  3.8630e-04, -9.5795e-05,\n",
       "                       9.5632e-05,  5.1546e-04, -7.7469e-03,  2.3326e-04, -1.5511e-02,\n",
       "                       2.0256e-04, -6.9660e-05, -3.1488e-03,  1.1238e-04,  6.9166e-04,\n",
       "                      -2.4499e-02, -1.0216e-03, -2.1363e-04, -5.0113e-04,  3.1004e-03,\n",
       "                      -3.0110e-03, -5.0162e-03, -8.9827e-05,  6.0835e-05, -1.2940e-02,\n",
       "                      -9.3928e-05,  1.9605e-04, -2.6118e-02, -9.6844e-03,  1.7225e-04,\n",
       "                       2.6310e-03, -4.3444e-03,  7.7386e-04,  4.0373e-04])),\n",
       "             ('ICCD_features_.1.weight',\n",
       "              tensor([1.0079, 0.9981, 0.9906, 0.9823, 0.9987, 1.0072, 0.9967, 0.9837, 0.9874,\n",
       "                      0.9909, 0.9913, 0.9875, 1.0141, 0.9923, 0.9811, 1.0254, 0.9771, 0.9836,\n",
       "                      0.9953, 0.9829, 0.9836, 0.9927, 0.9823, 0.9935, 0.9929, 0.9880, 1.0363,\n",
       "                      0.9979, 0.9852, 0.9707, 0.9823, 0.9850, 0.9774, 1.0245, 0.9899, 1.0097,\n",
       "                      0.9898, 0.9868, 0.9895, 0.9958, 0.9852, 1.0000, 0.9897, 0.9982, 0.9732,\n",
       "                      1.0131, 0.9992, 0.9760, 0.9684, 1.0063, 1.0295, 0.9937, 1.0062, 0.9722,\n",
       "                      1.0138, 0.9861, 0.9812, 1.0183, 0.9968, 1.0272, 1.0512, 0.9819, 0.9968,\n",
       "                      0.9863])),\n",
       "             ('ICCD_features_.1.bias',\n",
       "              tensor([-0.0838, -0.0373,  0.2045, -0.1044, -0.2544,  0.1187,  0.1446,  0.0082,\n",
       "                       0.0521,  0.2271,  0.0386, -0.1070, -0.2950, -0.1720,  0.0197,  0.0483,\n",
       "                       0.0448,  0.0956,  0.0648, -0.1221, -0.1841, -0.0202, -0.2106, -0.1125,\n",
       "                       0.1361, -0.0897,  0.0654, -0.2381, -0.1127,  0.0968, -0.0209,  0.0015,\n",
       "                       0.0386,  0.0683, -0.2226,  0.1702,  0.0377, -0.0693, -0.1874, -0.0755,\n",
       "                       0.1902,  0.1693, -0.0880,  0.0922,  0.1091,  0.1942, -0.0117,  0.1712,\n",
       "                       0.0139, -0.1212, -0.0057,  0.0153,  0.1900, -0.2485,  0.1045,  0.1086,\n",
       "                       0.0880,  0.0801, -0.0518, -0.0380, -0.0290,  0.0561,  0.0033,  0.0178])),\n",
       "             ('ICCD_features_.1.running_mean',\n",
       "              tensor([ 0.0234, -0.0772,  0.0024, -0.0114, -0.0327,  0.1030, -0.1230,  0.0829,\n",
       "                      -0.1589,  0.0819,  0.1089, -0.1316,  0.0057, -0.0749,  0.0527, -0.0201,\n",
       "                      -0.0458,  0.1496,  0.0936, -0.0692, -0.0221,  0.0534, -0.0579,  0.0831,\n",
       "                       0.2043, -0.0767,  0.0116,  0.0161, -0.0250, -0.0368,  0.0324, -0.0255,\n",
       "                       0.0235, -0.0032, -0.0720,  0.0194,  0.0045, -0.1003, -0.1167,  0.0026,\n",
       "                       0.1371, -0.1433, -0.0301,  0.0592, -0.0834, -0.0278,  0.0208, -0.0683,\n",
       "                       0.0355, -0.0293, -0.0043, -0.0932,  0.0212, -0.1454, -0.0099,  0.0565,\n",
       "                       0.0782, -0.0306, -0.0854,  0.0201,  0.0033, -0.0785,  0.0942,  0.0706])),\n",
       "             ('ICCD_features_.1.running_var',\n",
       "              tensor([0.0081, 0.0196, 0.0028, 0.0029, 0.0060, 0.0344, 0.0673, 0.0231, 0.0768,\n",
       "                      0.0208, 0.0344, 0.0545, 0.0017, 0.0177, 0.0095, 0.0010, 0.0093, 0.0695,\n",
       "                      0.0270, 0.0158, 0.0042, 0.0100, 0.0097, 0.0218, 0.1266, 0.0229, 0.0016,\n",
       "                      0.0016, 0.0040, 0.0064, 0.0038, 0.0046, 0.0026, 0.0004, 0.0165, 0.0068,\n",
       "                      0.0024, 0.0287, 0.0421, 0.0031, 0.0574, 0.0630, 0.0059, 0.0123, 0.0219,\n",
       "                      0.0017, 0.0026, 0.0158, 0.0072, 0.0050, 0.0009, 0.0259, 0.0041, 0.0667,\n",
       "                      0.0009, 0.0111, 0.0198, 0.0035, 0.0178, 0.0036, 0.0010, 0.0173, 0.0284,\n",
       "                      0.0166])),\n",
       "             ('ICCD_features_.1.num_batches_tracked', tensor(730)),\n",
       "             ('ICCD_features_.2.weight',\n",
       "              tensor([[[[[-0.0604]],\n",
       "              \n",
       "                        [[ 0.0589]],\n",
       "              \n",
       "                        [[-0.1064]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0161]],\n",
       "              \n",
       "                        [[ 0.0017]],\n",
       "              \n",
       "                        [[ 0.0452]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0460]],\n",
       "              \n",
       "                        [[-0.0703]],\n",
       "              \n",
       "                        [[-0.0553]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0918]],\n",
       "              \n",
       "                        [[-0.0407]],\n",
       "              \n",
       "                        [[ 0.0397]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0289]],\n",
       "              \n",
       "                        [[ 0.0475]],\n",
       "              \n",
       "                        [[-0.0465]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0119]],\n",
       "              \n",
       "                        [[-0.0770]],\n",
       "              \n",
       "                        [[-0.0057]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0658]],\n",
       "              \n",
       "                        [[-0.0380]],\n",
       "              \n",
       "                        [[ 0.0286]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0431]],\n",
       "              \n",
       "                        [[-0.0364]],\n",
       "              \n",
       "                        [[ 0.0544]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0588]],\n",
       "              \n",
       "                        [[ 0.0102]],\n",
       "              \n",
       "                        [[ 0.0696]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-0.0542]],\n",
       "              \n",
       "                        [[-0.0125]],\n",
       "              \n",
       "                        [[-0.0584]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0372]],\n",
       "              \n",
       "                        [[-0.0338]],\n",
       "              \n",
       "                        [[-0.0353]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0357]],\n",
       "              \n",
       "                        [[ 0.0529]],\n",
       "              \n",
       "                        [[-0.0633]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0302]],\n",
       "              \n",
       "                        [[-0.0095]],\n",
       "              \n",
       "                        [[-0.0441]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0449]],\n",
       "              \n",
       "                        [[ 0.0014]],\n",
       "              \n",
       "                        [[ 0.0220]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0449]],\n",
       "              \n",
       "                        [[ 0.0765]],\n",
       "              \n",
       "                        [[ 0.0527]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0649]],\n",
       "              \n",
       "                        [[-0.0905]],\n",
       "              \n",
       "                        [[ 0.0030]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0761]],\n",
       "              \n",
       "                        [[-0.0406]],\n",
       "              \n",
       "                        [[-0.0201]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0278]],\n",
       "              \n",
       "                        [[-0.0042]],\n",
       "              \n",
       "                        [[ 0.0267]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0537]],\n",
       "              \n",
       "                        [[ 0.0778]],\n",
       "              \n",
       "                        [[ 0.0452]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0061]],\n",
       "              \n",
       "                        [[ 0.0140]],\n",
       "              \n",
       "                        [[ 0.0441]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0075]],\n",
       "              \n",
       "                        [[ 0.0321]],\n",
       "              \n",
       "                        [[ 0.0260]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-0.0180]],\n",
       "              \n",
       "                        [[ 0.0732]],\n",
       "              \n",
       "                        [[-0.0295]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0203]],\n",
       "              \n",
       "                        [[-0.0269]],\n",
       "              \n",
       "                        [[-0.0352]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0039]],\n",
       "              \n",
       "                        [[-0.0173]],\n",
       "              \n",
       "                        [[ 0.0510]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0621]],\n",
       "              \n",
       "                        [[ 0.0559]],\n",
       "              \n",
       "                        [[-0.0713]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0362]],\n",
       "              \n",
       "                        [[-0.0713]],\n",
       "              \n",
       "                        [[ 0.0449]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0058]],\n",
       "              \n",
       "                        [[ 0.0608]],\n",
       "              \n",
       "                        [[ 0.0671]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0024]],\n",
       "              \n",
       "                        [[-0.0814]],\n",
       "              \n",
       "                        [[ 0.0199]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0265]],\n",
       "              \n",
       "                        [[-0.0153]],\n",
       "              \n",
       "                        [[-0.0546]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0382]],\n",
       "              \n",
       "                        [[ 0.0390]],\n",
       "              \n",
       "                        [[-0.0233]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0366]],\n",
       "              \n",
       "                        [[ 0.0152]],\n",
       "              \n",
       "                        [[-0.0806]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0217]],\n",
       "              \n",
       "                        [[ 0.0129]],\n",
       "              \n",
       "                        [[ 0.0089]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0495]],\n",
       "              \n",
       "                        [[-0.0416]],\n",
       "              \n",
       "                        [[-0.0713]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-0.0631]],\n",
       "              \n",
       "                        [[ 0.0911]],\n",
       "              \n",
       "                        [[-0.0050]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0187]],\n",
       "              \n",
       "                        [[ 0.0365]],\n",
       "              \n",
       "                        [[ 0.0155]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0285]],\n",
       "              \n",
       "                        [[ 0.0262]],\n",
       "              \n",
       "                        [[ 0.0254]]]]])),\n",
       "             ('ICCD_features_.2.bias',\n",
       "              tensor([-5.2973e-05,  1.2782e-05,  2.9417e-06,  2.4583e-03, -2.9898e-04,\n",
       "                       6.4628e-05,  5.3699e-05, -8.7015e-05, -4.4870e-05, -1.8350e-04,\n",
       "                       2.7139e-05, -1.8923e-04, -1.3136e-04, -6.7922e-06,  5.8438e-06,\n",
       "                      -2.4018e-05, -1.5405e-07, -2.2131e-05,  7.3095e-06, -2.5765e-06,\n",
       "                       5.7161e-04,  1.5676e-05,  1.5175e-05,  4.8497e-05, -1.6308e-05,\n",
       "                       2.2410e-05, -1.7458e-05, -7.7982e-06, -7.8758e-07, -1.8842e-04,\n",
       "                      -1.8878e-04, -5.5749e-07,  3.5946e-04,  5.3707e-06, -1.8940e-04,\n",
       "                      -2.5602e-05,  1.7329e-04, -5.1166e-06, -2.1050e-06, -3.7297e-05,\n",
       "                      -2.4768e-05, -8.4906e-05,  2.6843e-05, -3.9340e-04,  9.7557e-06,\n",
       "                      -3.1842e-06, -8.2047e-06, -7.0440e-07,  1.9737e-06, -1.1829e-04,\n",
       "                       2.1249e-06,  3.9219e-06,  5.9353e-06,  5.8536e-07, -3.2856e-05,\n",
       "                      -7.2931e-06, -1.4738e-05,  1.3593e-04, -1.7775e-05,  9.9719e-05,\n",
       "                       1.1495e-06, -4.1971e-05,  5.2546e-05,  1.9254e-05])),\n",
       "             ('ICCD_features_.3.weight',\n",
       "              tensor([0.9904, 0.9983, 0.9922, 1.0340, 0.9966, 1.0037, 1.0142, 1.0092, 1.0051,\n",
       "                      1.0183, 0.9846, 0.9743, 1.0767, 0.9438, 0.9348, 0.9700, 0.9573, 0.9368,\n",
       "                      0.9801, 0.9604, 1.0203, 0.9653, 0.9659, 0.9711, 0.9405, 0.9633, 0.9712,\n",
       "                      1.0064, 0.9682, 0.9914, 0.9997, 1.0114, 1.0096, 0.9732, 1.0339, 0.9618,\n",
       "                      0.9982, 0.9594, 0.9348, 1.0427, 0.9850, 0.9770, 1.0117, 1.0185, 0.9563,\n",
       "                      0.9951, 0.9645, 0.9596, 0.9567, 0.9974, 0.9311, 0.9996, 0.9743, 0.9118,\n",
       "                      0.9756, 0.9475, 0.9799, 1.0021, 0.9978, 1.0631, 0.9553, 1.0248, 0.9863,\n",
       "                      0.9817])),\n",
       "             ('ICCD_features_.3.bias',\n",
       "              tensor([-0.0018, -0.0489, -0.0465, -0.0419, -0.0412, -0.0208,  0.0021, -0.0291,\n",
       "                      -0.0110, -0.0258, -0.0048, -0.0322, -0.0327, -0.0499, -0.0529, -0.0389,\n",
       "                      -0.0619, -0.0482, -0.1005, -0.0259, -0.0178, -0.0262, -0.0400, -0.0329,\n",
       "                      -0.0731, -0.0264, -0.0195, -0.0244, -0.0366, -0.0584, -0.0216, -0.0088,\n",
       "                      -0.0463, -0.0137, -0.0367, -0.0271, -0.0501, -0.0322, -0.0588, -0.0230,\n",
       "                      -0.0070, -0.0145,  0.0069, -0.0465, -0.0324,  0.0002, -0.0285, -0.0258,\n",
       "                      -0.0555, -0.0125, -0.0430, -0.0134, -0.0109, -0.0616, -0.0299, -0.0506,\n",
       "                      -0.0286, -0.0206, -0.0268, -0.0097, -0.0703, -0.0301, -0.0821, -0.0169])),\n",
       "             ('ICCD_features_.3.running_mean',\n",
       "              tensor([-2.0729e-01,  6.2415e-02,  8.0614e-02,  2.0661e-01,  5.5334e-03,\n",
       "                       9.5208e-02,  4.6959e-02,  4.2266e-02, -1.4515e-01,  1.3842e-02,\n",
       "                      -2.6956e-02, -8.9723e-03, -1.3294e-01,  2.3515e-01, -1.2852e-01,\n",
       "                      -1.0129e-03,  5.4974e-02,  6.7728e-02,  5.8795e-02,  1.0264e-02,\n",
       "                       1.5998e-01, -2.8498e-01, -5.8631e-03, -4.3089e-02,  1.1107e-01,\n",
       "                      -2.0150e-02, -1.7181e-01,  5.1014e-02,  1.4445e-01, -8.5460e-02,\n",
       "                      -2.2886e-02, -1.1179e-01, -8.3397e-02, -2.3946e-01,  8.0917e-02,\n",
       "                      -5.4478e-02,  1.2709e-01, -6.5618e-02,  2.7373e-01, -9.5249e-02,\n",
       "                      -2.8771e-02, -3.8617e-02,  1.9801e-01, -1.2405e-02, -1.1972e-01,\n",
       "                      -1.3960e-01, -7.7118e-02, -4.8083e-02,  3.2865e-02, -3.5798e-02,\n",
       "                       1.7701e-01, -2.5304e-01, -1.8060e-01,  1.9099e-01, -1.8562e-01,\n",
       "                       3.1985e-03, -3.2429e-02,  1.0006e-02, -5.1211e-02,  9.4377e-02,\n",
       "                      -6.5132e-02, -5.5907e-02, -5.8666e-05, -1.8128e-01])),\n",
       "             ('ICCD_features_.3.running_var',\n",
       "              tensor([11.8651,  0.1239,  0.3853,  0.1423,  0.4658,  0.5254,  1.1938,  0.3001,\n",
       "                       1.1961,  0.5915,  4.0599,  0.5264,  0.3825,  8.2047,  2.1109,  0.4019,\n",
       "                       0.9590,  0.4121,  0.5668,  2.2128,  0.4551,  7.9988,  0.9591,  0.2250,\n",
       "                       1.4894,  1.1825,  3.1553,  0.8077,  1.0643,  0.3579,  0.4783,  1.1676,\n",
       "                       0.3512, 10.4448,  0.4723,  0.8351,  0.9540,  1.6273,  6.7878,  0.2996,\n",
       "                       1.7199,  4.6704,  0.4274,  0.5755,  5.7079,  2.5258,  3.9250,  5.3023,\n",
       "                       5.2398,  0.2220,  3.1088, 13.1975,  0.6686,  3.8505,  1.0592,  1.0005,\n",
       "                       0.5710,  0.9049,  0.9233,  0.3078,  0.9245,  0.5572,  0.2714,  2.0791])),\n",
       "             ('ICCD_features_.3.num_batches_tracked', tensor(730)),\n",
       "             ('ICCD_features_.6.weight',\n",
       "              tensor([[[[[-2.0014e-02,  5.6096e-03, -1.2047e-02],\n",
       "                         [-5.2700e-02,  1.1957e-02, -4.6734e-02],\n",
       "                         [-5.9484e-02, -7.0080e-03, -1.7879e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-1.3837e-02,  2.5454e-02, -5.1118e-02],\n",
       "                         [ 3.7128e-02, -1.5899e-02,  2.2388e-02],\n",
       "                         [ 1.7203e-03, -3.2049e-02, -1.4270e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 6.5619e-03, -1.7707e-02, -1.2753e-02],\n",
       "                         [-1.9161e-02, -4.0537e-02, -3.3490e-02],\n",
       "                         [-8.4376e-03, -4.8567e-02, -6.3771e-02]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 4.0777e-02,  9.0899e-03, -8.8693e-04],\n",
       "                         [-5.6189e-03, -1.6893e-02, -6.2035e-03],\n",
       "                         [-1.9440e-02,  2.4466e-02, -3.6199e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 1.2225e-02, -4.9733e-02,  9.2855e-03],\n",
       "                         [ 5.4258e-03,  9.3712e-04,  6.9039e-03],\n",
       "                         [-2.9675e-02, -5.2543e-03, -1.4380e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-4.3640e-02, -4.1772e-02,  4.9136e-03],\n",
       "                         [-2.1899e-02,  6.7808e-04, -3.2672e-02],\n",
       "                         [ 1.0244e-02,  8.8518e-03, -5.0876e-03]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 1.3453e-02,  3.4244e-02, -3.0739e-02],\n",
       "                         [-1.7041e-02, -3.0826e-03,  3.9557e-03],\n",
       "                         [ 1.3024e-02, -1.9547e-02,  9.2969e-04]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 2.3735e-02,  3.6228e-02,  2.0164e-02],\n",
       "                         [-1.7368e-02,  1.5957e-02,  3.4383e-02],\n",
       "                         [-2.4043e-02,  2.4995e-02, -3.4119e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 5.7567e-03,  1.2482e-02,  4.5331e-02],\n",
       "                         [-2.4515e-02,  5.1626e-03,  2.2390e-02],\n",
       "                         [-3.9688e-03,  4.1418e-03,  4.1244e-02]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-2.0651e-02, -6.2427e-03, -1.8359e-02],\n",
       "                         [-1.5684e-02,  2.0183e-02, -1.4583e-02],\n",
       "                         [-3.0176e-02, -9.1143e-03, -1.7941e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-1.1774e-02,  4.9946e-03,  4.4788e-02],\n",
       "                         [-3.3571e-02, -4.1910e-03,  1.9650e-02],\n",
       "                         [-3.6431e-02,  2.5586e-02, -2.5724e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-2.4622e-02,  1.1682e-02,  1.7583e-02],\n",
       "                         [-3.9612e-02,  1.3160e-02, -2.5926e-02],\n",
       "                         [-3.9861e-03, -6.4711e-03,  2.3400e-02]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 3.9132e-03,  1.4856e-02, -2.5652e-02],\n",
       "                         [-4.9315e-02, -4.2194e-02, -2.7308e-03],\n",
       "                         [-2.5525e-02, -4.7849e-02,  3.8886e-03]]],\n",
       "              \n",
       "              \n",
       "                       [[[-5.9321e-02, -1.3828e-02, -2.9342e-02],\n",
       "                         [-4.5580e-02, -5.3806e-02, -4.7891e-02],\n",
       "                         [ 2.2598e-02, -2.4361e-02, -3.7477e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 1.3263e-02,  4.6410e-02, -2.1664e-02],\n",
       "                         [ 4.3453e-02,  3.5641e-02,  3.1099e-02],\n",
       "                         [-2.9031e-02, -2.6119e-02,  2.5406e-02]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 1.4146e-02,  1.0587e-02, -1.2523e-02],\n",
       "                         [ 1.0617e-02, -2.7985e-02,  1.8327e-02],\n",
       "                         [ 7.3565e-03, -3.1370e-02,  2.2456e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 5.0900e-02,  4.9441e-02, -3.1334e-02],\n",
       "                         [ 1.7499e-02,  1.3903e-02,  1.7200e-02],\n",
       "                         [-2.8063e-02, -2.8576e-02,  4.5389e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-7.1091e-03, -3.2470e-02,  4.1208e-02],\n",
       "                         [ 3.8259e-02, -5.5949e-03,  1.7293e-02],\n",
       "                         [-6.4308e-03,  4.4046e-02, -2.2131e-02]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-1.5812e-02,  1.1358e-02, -3.5797e-02],\n",
       "                         [-4.2123e-02,  5.5598e-03, -4.3703e-02],\n",
       "                         [-2.4660e-02, -1.0881e-02, -5.0294e-03]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 1.7119e-02, -3.5175e-03,  4.4840e-02],\n",
       "                         [ 2.7950e-02, -2.3562e-02,  1.4879e-02],\n",
       "                         [ 1.6041e-02,  4.7764e-02,  1.5000e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 5.3331e-02,  2.8918e-02,  2.3022e-02],\n",
       "                         [ 6.2996e-02,  3.2482e-02,  2.5493e-02],\n",
       "                         [ 2.8481e-02, -9.9378e-03,  4.1403e-02]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-1.4158e-02,  1.0257e-02,  3.3876e-02],\n",
       "                         [ 2.3281e-02,  3.2437e-02, -3.2424e-02],\n",
       "                         [ 8.4642e-03, -1.8397e-02, -4.0952e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 2.2240e-02, -5.9983e-03,  2.2794e-02],\n",
       "                         [ 5.1757e-02,  1.6066e-02,  8.2324e-03],\n",
       "                         [ 1.8399e-02, -2.4087e-02, -2.8284e-04]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 2.7202e-02,  1.6457e-02,  3.3023e-02],\n",
       "                         [-2.1182e-02,  4.0540e-02, -6.3750e-03],\n",
       "                         [ 2.3599e-02,  3.4981e-02, -1.1251e-02]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-2.3165e-02,  2.2421e-02, -5.2481e-03],\n",
       "                         [-2.3418e-02,  9.7015e-05, -4.2663e-02],\n",
       "                         [-5.0452e-02, -2.6914e-02, -3.9487e-03]]],\n",
       "              \n",
       "              \n",
       "                       [[[-2.1047e-02, -4.4737e-02,  4.0584e-02],\n",
       "                         [ 2.1267e-02, -5.7886e-02,  3.0443e-02],\n",
       "                         [-4.1654e-03, -6.3619e-03,  1.7504e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 5.0628e-02,  1.1307e-02, -1.6914e-02],\n",
       "                         [ 4.9437e-02, -1.6928e-02,  3.0504e-02],\n",
       "                         [ 3.5932e-02,  3.0753e-02,  3.2797e-02]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 1.0576e-02, -1.3405e-02,  1.0491e-02],\n",
       "                         [-1.9830e-02,  1.0367e-02,  5.2314e-03],\n",
       "                         [-3.4681e-02,  2.7020e-03,  3.2691e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 5.8608e-02,  1.6825e-02,  3.5078e-02],\n",
       "                         [-1.5540e-03,  3.9803e-02,  4.0123e-02],\n",
       "                         [ 7.5351e-02,  5.9733e-02,  5.0526e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-1.6232e-02,  4.1620e-02, -4.5029e-03],\n",
       "                         [ 8.8336e-03,  3.9797e-02,  4.1219e-02],\n",
       "                         [ 1.8049e-02,  4.6457e-02,  5.5196e-02]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-2.0107e-02, -1.6903e-02,  1.2915e-02],\n",
       "                         [-2.7939e-02, -3.4657e-02, -1.1767e-02],\n",
       "                         [ 1.0283e-02,  1.0401e-02,  3.4845e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 4.7355e-02,  3.3970e-02, -3.0655e-02],\n",
       "                         [-2.5662e-03,  1.4588e-03, -3.5742e-02],\n",
       "                         [-2.1889e-02, -6.0620e-02, -6.4048e-03]]],\n",
       "              \n",
       "              \n",
       "                       [[[-1.4882e-02, -1.5405e-02, -1.3135e-02],\n",
       "                         [-4.8276e-02, -3.4640e-02,  2.7494e-02],\n",
       "                         [-4.0892e-02, -1.8875e-02, -2.9868e-02]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-5.3290e-02,  5.2247e-03, -2.8501e-02],\n",
       "                         [-2.5218e-02, -1.9253e-02, -7.9901e-03],\n",
       "                         [-8.9662e-03, -4.1306e-04, -5.5989e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 3.7922e-02, -1.8798e-02, -1.5185e-03],\n",
       "                         [ 2.1584e-02,  2.2298e-02, -2.7094e-02],\n",
       "                         [ 3.0392e-02,  4.8286e-02,  3.2859e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-1.6574e-02,  2.5019e-02, -3.1581e-02],\n",
       "                         [ 2.7646e-02,  4.3984e-03,  1.0275e-02],\n",
       "                         [-1.5157e-02, -2.5350e-02, -3.2216e-02]]]]])),\n",
       "             ('ICCD_features_.6.bias',\n",
       "              tensor([-1.7751e-06, -9.3285e-06, -1.2542e-06,  7.5861e-07,  1.8603e-07,\n",
       "                       4.9631e-05, -1.0262e-05,  2.1499e-05,  5.9696e-07, -1.8295e-05,\n",
       "                       3.9432e-06,  7.0428e-06, -2.5877e-05, -9.8805e-06, -3.0865e-05,\n",
       "                       1.5325e-05, -1.2995e-06, -5.8977e-06, -8.3956e-06,  1.2861e-06,\n",
       "                       7.4960e-06, -6.1859e-06, -7.1908e-06,  1.3806e-06,  3.7397e-05,\n",
       "                      -1.7708e-06,  1.6502e-05,  6.5217e-06, -4.4057e-06, -1.4869e-05,\n",
       "                      -1.9413e-05, -6.7436e-06,  6.3907e-07, -1.5068e-05, -5.0372e-06,\n",
       "                      -5.4240e-06,  1.5436e-05, -1.5448e-04,  2.6572e-06,  5.3302e-06,\n",
       "                       4.1523e-07,  1.7036e-05, -1.1545e-06, -6.1336e-06,  4.3829e-06,\n",
       "                       1.5559e-05, -1.5313e-05, -4.8753e-06,  2.3705e-06, -3.2190e-05,\n",
       "                      -4.6020e-06,  1.5849e-05,  7.1249e-06, -8.0146e-06, -5.2002e-05,\n",
       "                      -1.8365e-06, -1.9381e-06,  3.3093e-06, -4.0901e-05,  1.6292e-06,\n",
       "                      -3.2930e-05, -8.0009e-06, -1.5900e-04, -4.1402e-07, -4.3630e-06,\n",
       "                       4.4815e-05, -3.6251e-06, -4.6825e-06,  1.5974e-05,  2.7388e-06,\n",
       "                       1.5413e-06, -5.9939e-06, -1.0626e-05, -2.0762e-05, -6.1826e-06,\n",
       "                      -3.5034e-05, -8.4964e-06, -1.9327e-06, -6.7471e-07,  5.7621e-06,\n",
       "                       3.7558e-06,  5.3848e-06,  1.4693e-06,  4.5549e-06,  4.3343e-05,\n",
       "                       6.2169e-06, -2.5475e-06,  1.2610e-05,  9.1284e-06,  5.6291e-06,\n",
       "                      -7.9795e-06,  5.3821e-06,  4.1573e-06,  1.0950e-04, -2.1996e-05,\n",
       "                       1.0460e-04, -1.6945e-05,  3.9078e-05, -2.8691e-06, -5.9214e-06,\n",
       "                       4.2546e-06, -6.5821e-05, -3.4259e-06, -9.1623e-06,  3.3092e-06,\n",
       "                       5.2241e-06, -1.7398e-06,  5.9932e-06,  6.4221e-06,  7.7700e-06,\n",
       "                      -2.0624e-06, -2.1708e-06,  7.8336e-06,  9.1802e-06, -5.2673e-06,\n",
       "                       1.6257e-05,  2.4487e-05, -5.7082e-06,  5.0240e-05,  1.2361e-05,\n",
       "                       1.4288e-06, -2.3040e-06,  5.4538e-07, -6.5704e-06,  5.7876e-05,\n",
       "                       2.9770e-06,  1.3285e-06,  9.4082e-06])),\n",
       "             ('ICCD_features_.7.weight',\n",
       "              tensor([0.9839, 0.9676, 0.9709, 0.9815, 0.9836, 0.9792, 0.9603, 0.9847, 0.9839,\n",
       "                      0.9827, 0.9799, 0.9528, 1.0014, 1.0244, 0.9981, 0.9656, 0.9652, 0.9834,\n",
       "                      1.0014, 0.9838, 0.9869, 0.9745, 0.9990, 0.9603, 0.9784, 0.9792, 0.9898,\n",
       "                      1.0027, 1.0131, 0.9703, 0.9893, 0.9417, 0.9685, 1.0370, 0.9620, 0.9689,\n",
       "                      0.9253, 1.0485, 0.9705, 0.9894, 0.9673, 0.9648, 0.9818, 1.0468, 0.9823,\n",
       "                      0.9793, 0.9635, 0.9592, 0.9353, 0.9992, 0.9547, 0.9953, 0.9813, 0.9762,\n",
       "                      0.9805, 0.9825, 0.9786, 0.9772, 1.0238, 0.9723, 0.9845, 0.9765, 1.0292,\n",
       "                      1.0077, 0.9668, 1.0233, 0.9843, 0.9735, 0.9793, 0.9829, 1.0219, 0.9815,\n",
       "                      1.0070, 0.9905, 1.0079, 0.9932, 0.9605, 0.9628, 0.9827, 0.9452, 0.9666,\n",
       "                      0.9940, 0.9664, 0.9929, 0.9573, 0.9799, 1.0291, 1.0189, 0.9794, 0.9820,\n",
       "                      0.9739, 0.9841, 1.0198, 1.0037, 0.9963, 0.9730, 0.9818, 1.0338, 0.9749,\n",
       "                      0.9974, 0.9648, 0.9958, 0.9757, 0.9912, 0.9787, 0.9843, 0.9938, 0.9756,\n",
       "                      0.9780, 0.9379, 0.9569, 0.9699, 0.9664, 1.0062, 0.9780, 0.9839, 1.0171,\n",
       "                      1.0539, 1.0070, 0.9891, 0.9714, 1.0045, 0.9627, 1.0078, 0.9774, 0.9662,\n",
       "                      0.9718, 0.9727])),\n",
       "             ('ICCD_features_.7.bias',\n",
       "              tensor([-0.1227, -0.0522, -0.0735,  0.0463, -0.0605,  0.1452, -0.0401,  0.0605,\n",
       "                      -0.0944,  0.0601,  0.1194, -0.0689,  0.0985,  0.0867,  0.0848, -0.1187,\n",
       "                      -0.0566, -0.0689, -0.0669,  0.0347, -0.1566, -0.0756, -0.0215,  0.1320,\n",
       "                       0.0107,  0.1443,  0.0542,  0.1262,  0.0963, -0.0995,  0.1182, -0.0471,\n",
       "                       0.0862,  0.1346,  0.0758,  0.0016,  0.0227, -0.0741,  0.0515, -0.1184,\n",
       "                       0.0441, -0.1125, -0.0274, -0.1309, -0.0410, -0.1193,  0.0976, -0.0867,\n",
       "                      -0.0887,  0.0976, -0.0532,  0.0136, -0.0327,  0.1110,  0.0445,  0.0031,\n",
       "                       0.1257, -0.0164,  0.1121,  0.0283,  0.0006,  0.0218, -0.1211, -0.1309,\n",
       "                       0.1263, -0.1094, -0.0691,  0.0782,  0.0262,  0.1418,  0.0142, -0.0355,\n",
       "                      -0.1706, -0.1167,  0.0816, -0.1349, -0.1034,  0.0634,  0.1413, -0.0427,\n",
       "                       0.0196, -0.1202,  0.1004,  0.0376, -0.0219, -0.0235,  0.1488, -0.1226,\n",
       "                       0.0878,  0.0096,  0.0650,  0.1168,  0.0570,  0.1299, -0.0215, -0.0278,\n",
       "                      -0.0846, -0.1460, -0.0691, -0.1219,  0.1120, -0.0640, -0.0437,  0.1027,\n",
       "                       0.0271,  0.0538,  0.1107, -0.0837, -0.0899, -0.0897, -0.0353,  0.0881,\n",
       "                      -0.1104,  0.0427,  0.1248,  0.1416,  0.0993,  0.1721, -0.1215, -0.0138,\n",
       "                      -0.0079, -0.0858,  0.1225, -0.1584,  0.0580,  0.0984,  0.0354, -0.0937])),\n",
       "             ('ICCD_features_.7.running_mean',\n",
       "              tensor([-1.7440, -0.5750, -0.4095, -0.9251,  0.3410,  0.8178,  0.7949, -0.7142,\n",
       "                       0.9775,  0.2426,  0.4987, -1.1449,  0.8263,  1.4842,  1.9080, -0.4592,\n",
       "                      -2.1469,  0.4391, -0.1276,  2.3214, -0.7155, -1.6263,  1.2412, -1.2061,\n",
       "                       1.0487,  0.2821, -0.7954,  1.4093,  1.9401, -0.2774,  0.6003, -0.0899,\n",
       "                      -0.8486,  1.9494,  1.4906, -1.2014,  1.4382,  1.4177,  1.3476, -1.0614,\n",
       "                      -0.8391, -1.0933,  0.5353, -1.4305, -0.3303, -0.1474,  0.5832, -0.0276,\n",
       "                      -1.0126,  0.9816,  0.4094, -0.9832,  1.8792, -0.5275, -1.3918,  1.9426,\n",
       "                       1.5995,  0.4822,  1.0269, -0.3314,  0.9138,  1.9995, -0.9564, -1.8650,\n",
       "                       2.2126, -0.0850,  1.2206,  0.3031, -0.4044,  0.3680, -1.4383, -1.2758,\n",
       "                      -2.5047, -0.0233,  0.5181, -0.8134,  0.8658,  2.1438,  0.2765, -1.6271,\n",
       "                      -0.8271, -0.1866,  1.1074,  0.7964,  0.1688,  1.4402,  1.9113, -1.0007,\n",
       "                       1.4111,  0.2855,  0.9017, -0.9767, -2.0135,  1.9915, -1.7742, -1.6350,\n",
       "                      -0.9805, -1.5900, -0.5340, -0.3326, -1.2391,  0.5424, -0.8996,  1.8256,\n",
       "                       0.1866,  0.8914,  2.1425, -1.1862,  0.0497, -1.1206,  0.9283, -1.1182,\n",
       "                      -0.0430, -1.0400,  1.7611,  0.7196,  1.3877,  2.2834, -1.4283,  0.8817,\n",
       "                      -0.0639,  0.1162,  0.2723, -2.1539, -0.4429,  1.2219,  0.6254, -0.6965])),\n",
       "             ('ICCD_features_.7.running_var',\n",
       "              tensor([0.2074, 0.2401, 0.8055, 0.2250, 0.2115, 0.3764, 0.5417, 0.0942, 0.2087,\n",
       "                      0.2368, 0.2110, 0.2718, 0.4106, 0.2292, 0.3907, 0.2577, 0.4788, 0.2052,\n",
       "                      0.1936, 0.7088, 0.2691, 0.5886, 0.3344, 0.5352, 0.2081, 0.7474, 0.2628,\n",
       "                      0.2133, 0.3586, 0.4579, 0.3237, 1.1354, 0.9696, 0.2257, 1.0387, 0.4132,\n",
       "                      0.7589, 0.2285, 0.5439, 0.5140, 0.6982, 0.3488, 0.3193, 0.2480, 0.5624,\n",
       "                      0.6751, 0.2486, 0.2987, 1.6709, 0.1766, 1.5433, 0.1938, 1.0183, 0.4188,\n",
       "                      0.2347, 0.2186, 1.1139, 0.9421, 0.2480, 0.1082, 0.2614, 1.0613, 0.2214,\n",
       "                      0.2076, 0.7210, 0.2214, 0.2002, 0.2129, 0.3491, 1.5820, 0.3988, 2.3844,\n",
       "                      1.2720, 0.3401, 0.5497, 0.3286, 0.4301, 1.1739, 0.7478, 0.3965, 1.7849,\n",
       "                      0.2086, 1.8159, 0.3499, 1.0830, 0.5791, 0.2010, 0.2339, 0.1834, 0.5129,\n",
       "                      0.1189, 0.3471, 0.3002, 0.2848, 0.7175, 0.3330, 0.2305, 0.2620, 0.4070,\n",
       "                      0.3502, 0.4598, 0.4132, 0.4880, 0.2204, 0.5469, 0.1999, 0.3354, 0.3640,\n",
       "                      0.9901, 0.4325, 0.6886, 0.4740, 0.5472, 0.1736, 0.3997, 0.7974, 0.1454,\n",
       "                      0.4080, 0.2513, 0.7771, 0.5771, 0.2940, 1.4394, 0.2561, 0.2963, 1.7111,\n",
       "                      0.8986, 0.6287])),\n",
       "             ('ICCD_features_.7.num_batches_tracked', tensor(730)),\n",
       "             ('ICCD_features_.8.weight',\n",
       "              tensor([[[[[ 0.0466]],\n",
       "              \n",
       "                        [[-0.0310]],\n",
       "              \n",
       "                        [[-0.0565]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0375]],\n",
       "              \n",
       "                        [[ 0.0181]],\n",
       "              \n",
       "                        [[-0.0342]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0244]],\n",
       "              \n",
       "                        [[ 0.0063]],\n",
       "              \n",
       "                        [[-0.0056]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0384]],\n",
       "              \n",
       "                        [[ 0.0339]],\n",
       "              \n",
       "                        [[ 0.0565]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0289]],\n",
       "              \n",
       "                        [[-0.0381]],\n",
       "              \n",
       "                        [[ 0.0159]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0056]],\n",
       "              \n",
       "                        [[ 0.0502]],\n",
       "              \n",
       "                        [[ 0.0160]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0105]],\n",
       "              \n",
       "                        [[ 0.0115]],\n",
       "              \n",
       "                        [[ 0.0379]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0279]],\n",
       "              \n",
       "                        [[-0.0534]],\n",
       "              \n",
       "                        [[-0.0580]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0763]],\n",
       "              \n",
       "                        [[ 0.0376]],\n",
       "              \n",
       "                        [[-0.0119]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0436]],\n",
       "              \n",
       "                        [[ 0.0254]],\n",
       "              \n",
       "                        [[ 0.0634]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0047]],\n",
       "              \n",
       "                        [[ 0.0168]],\n",
       "              \n",
       "                        [[ 0.0343]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0402]],\n",
       "              \n",
       "                        [[ 0.0311]],\n",
       "              \n",
       "                        [[ 0.0317]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0143]],\n",
       "              \n",
       "                        [[ 0.0219]],\n",
       "              \n",
       "                        [[ 0.0311]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0444]],\n",
       "              \n",
       "                        [[ 0.0022]],\n",
       "              \n",
       "                        [[-0.0199]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0242]],\n",
       "              \n",
       "                        [[-0.0530]],\n",
       "              \n",
       "                        [[ 0.0121]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0246]],\n",
       "              \n",
       "                        [[-0.0599]],\n",
       "              \n",
       "                        [[-0.0574]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0074]],\n",
       "              \n",
       "                        [[-0.0490]],\n",
       "              \n",
       "                        [[-0.0589]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0423]],\n",
       "              \n",
       "                        [[ 0.0481]],\n",
       "              \n",
       "                        [[ 0.0491]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0363]],\n",
       "              \n",
       "                        [[-0.0677]],\n",
       "              \n",
       "                        [[ 0.0142]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0370]],\n",
       "              \n",
       "                        [[-0.0403]],\n",
       "              \n",
       "                        [[-0.0585]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0449]],\n",
       "              \n",
       "                        [[-0.0270]],\n",
       "              \n",
       "                        [[ 0.0175]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0360]],\n",
       "              \n",
       "                        [[-0.0280]],\n",
       "              \n",
       "                        [[ 0.0013]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0259]],\n",
       "              \n",
       "                        [[ 0.0522]],\n",
       "              \n",
       "                        [[-0.0282]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0527]],\n",
       "              \n",
       "                        [[ 0.0252]],\n",
       "              \n",
       "                        [[-0.0353]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0456]],\n",
       "              \n",
       "                        [[ 0.0448]],\n",
       "              \n",
       "                        [[-0.0162]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0358]],\n",
       "              \n",
       "                        [[-0.0229]],\n",
       "              \n",
       "                        [[-0.0193]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0366]],\n",
       "              \n",
       "                        [[-0.0031]],\n",
       "              \n",
       "                        [[-0.0282]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-0.0249]],\n",
       "              \n",
       "                        [[ 0.0181]],\n",
       "              \n",
       "                        [[ 0.0272]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0006]],\n",
       "              \n",
       "                        [[ 0.0043]],\n",
       "              \n",
       "                        [[ 0.0253]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0032]],\n",
       "              \n",
       "                        [[ 0.0145]],\n",
       "              \n",
       "                        [[ 0.0160]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0134]],\n",
       "              \n",
       "                        [[ 0.0497]],\n",
       "              \n",
       "                        [[-0.0350]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0030]],\n",
       "              \n",
       "                        [[ 0.0101]],\n",
       "              \n",
       "                        [[-0.0285]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0364]],\n",
       "              \n",
       "                        [[ 0.0465]],\n",
       "              \n",
       "                        [[-0.0015]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-0.0438]],\n",
       "              \n",
       "                        [[-0.0303]],\n",
       "              \n",
       "                        [[ 0.0029]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0049]],\n",
       "              \n",
       "                        [[ 0.0176]],\n",
       "              \n",
       "                        [[-0.0521]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0100]],\n",
       "              \n",
       "                        [[ 0.0421]],\n",
       "              \n",
       "                        [[-0.0035]]]]])),\n",
       "             ('ICCD_features_.8.bias',\n",
       "              tensor([-2.9429e-06,  1.3644e-06,  3.4779e-06,  3.5879e-06, -1.6906e-06,\n",
       "                      -2.8032e-05,  8.4168e-07,  3.5829e-05, -5.7141e-06,  6.7901e-07,\n",
       "                       1.2035e-05, -2.7162e-05,  1.4300e-07, -4.7980e-06, -8.2969e-06,\n",
       "                      -4.4953e-06,  5.2945e-06,  2.1296e-05,  8.9403e-06,  3.8351e-06,\n",
       "                      -1.1608e-06,  2.7865e-06,  1.1177e-06,  1.9468e-06, -2.9269e-07,\n",
       "                       1.3647e-06,  2.0150e-06,  2.9699e-05,  1.8804e-06,  1.5472e-05,\n",
       "                      -4.0994e-06, -3.6194e-06, -3.7784e-06, -1.7722e-05,  3.8756e-06,\n",
       "                      -1.1071e-06,  1.3681e-06, -2.2398e-06,  4.1992e-07, -2.3963e-06,\n",
       "                       5.4889e-06,  1.9307e-06, -1.8694e-05,  3.5514e-06, -2.1387e-06,\n",
       "                      -7.1890e-06, -1.8012e-05,  6.3032e-07,  1.6887e-06,  5.1552e-06,\n",
       "                       5.2957e-06, -2.0650e-08,  7.5637e-06,  1.3531e-06,  2.8088e-07,\n",
       "                      -2.9135e-08,  8.2092e-06, -1.3579e-06,  1.5259e-05,  1.0187e-06,\n",
       "                       7.2547e-06,  2.5821e-06, -2.8383e-06,  2.2912e-05, -9.8088e-07,\n",
       "                      -1.4771e-05,  2.7564e-07,  3.6751e-06, -2.7130e-05, -7.9608e-06,\n",
       "                       1.1743e-05,  6.0125e-06, -2.9605e-07,  2.3250e-06, -8.1256e-06,\n",
       "                      -1.5604e-06, -2.3293e-07,  6.0057e-06,  3.8063e-06, -1.4670e-06,\n",
       "                      -4.2151e-07,  1.1661e-06, -9.5566e-06,  1.4925e-05, -3.4533e-05,\n",
       "                       2.3984e-06,  2.8687e-06, -4.9001e-06, -2.1542e-06,  2.2187e-05,\n",
       "                      -1.6965e-05,  7.6389e-08, -9.7293e-06, -3.7786e-06,  9.0813e-06,\n",
       "                      -5.8234e-06, -1.1861e-05, -4.5249e-07, -1.3201e-05,  3.2313e-06,\n",
       "                       2.9813e-07, -5.4296e-07, -1.1869e-06, -2.8300e-06,  3.9674e-06,\n",
       "                      -4.7117e-06,  2.9630e-06,  3.3722e-06, -2.8951e-06,  4.3307e-07,\n",
       "                       2.6607e-06,  1.2947e-07,  3.5475e-06,  2.9155e-06,  1.7299e-05,\n",
       "                      -2.2878e-06,  1.8698e-06,  1.2770e-05,  1.2423e-05, -7.1164e-05,\n",
       "                      -1.2681e-06, -3.3382e-05,  7.0766e-06,  3.7987e-06, -2.2520e-06,\n",
       "                       2.8467e-05, -1.9647e-06,  2.0914e-06])),\n",
       "             ('ICCD_features_.9.weight',\n",
       "              tensor([1.0027, 0.9589, 0.9693, 0.9491, 0.9839, 1.0514, 0.9946, 0.9926, 0.9158,\n",
       "                      0.9550, 0.9888, 0.9887, 0.9739, 0.9597, 0.9697, 0.9779, 0.9982, 1.0476,\n",
       "                      1.0365, 0.9478, 0.9770, 0.9704, 0.9737, 0.9041, 0.9077, 0.9088, 0.9363,\n",
       "                      0.9477, 0.9769, 0.9494, 0.9482, 0.9979, 0.9952, 0.9690, 0.9680, 0.9103,\n",
       "                      0.9013, 1.0278, 0.9819, 0.9860, 0.9176, 0.9704, 0.9909, 0.9846, 1.0235,\n",
       "                      0.9628, 0.9886, 0.9707, 1.0017, 0.9671, 0.9459, 0.9892, 0.9572, 0.9753,\n",
       "                      0.9675, 0.9543, 0.9992, 0.9334, 0.9700, 0.9114, 0.9903, 0.9801, 1.0276,\n",
       "                      0.9414, 0.9772, 0.9756, 0.9134, 0.9803, 0.9752, 0.9591, 0.9800, 0.9684,\n",
       "                      0.9248, 0.9437, 0.9747, 0.9722, 0.9732, 0.9747, 0.9594, 0.9407, 0.9014,\n",
       "                      0.9783, 0.9946, 1.0117, 0.9906, 0.9820, 0.9145, 0.9869, 0.9332, 1.0114,\n",
       "                      0.9896, 0.9063, 0.9705, 0.9897, 0.9987, 0.9703, 1.0150, 0.9702, 0.9833,\n",
       "                      0.9976, 0.9195, 0.9052, 0.9259, 0.9823, 0.8683, 0.8924, 1.0027, 0.9772,\n",
       "                      0.9755, 0.9696, 0.9741, 0.9695, 0.9273, 0.9788, 0.9245, 0.9807, 0.9575,\n",
       "                      0.9935, 0.9929, 0.9787, 0.9455, 0.9800, 0.9742, 0.9654, 0.8983, 1.0125,\n",
       "                      0.9315, 0.9627])),\n",
       "             ('ICCD_features_.9.bias',\n",
       "              tensor([-6.4524e-02, -6.4464e-02, -3.8503e-02,  2.8888e-02, -2.2894e-02,\n",
       "                      -5.8948e-02, -3.2476e-02, -5.1652e-02, -1.1228e-01, -7.7146e-03,\n",
       "                       2.4768e-02, -7.0735e-02, -3.5307e-03,  4.1175e-03, -5.0853e-02,\n",
       "                       5.7377e-03, -5.4157e-02, -5.7658e-02, -2.3099e-02,  1.1475e-02,\n",
       "                      -2.2792e-02, -2.9638e-02, -5.5589e-02, -6.6543e-02,  2.3892e-02,\n",
       "                      -4.1150e-02, -4.6979e-02, -6.3884e-02, -4.0026e-02,  2.3746e-02,\n",
       "                      -3.3507e-02, -2.9176e-02, -2.2765e-02, -4.1851e-02, -1.9603e-02,\n",
       "                      -1.7332e-02,  4.9338e-02, -1.9294e-02,  2.9258e-02, -5.3543e-02,\n",
       "                      -4.2062e-02, -5.9454e-02,  4.1284e-03,  2.2043e-02, -3.9482e-02,\n",
       "                      -3.9844e-02, -5.0799e-02, -4.4550e-02, -7.3255e-02, -4.7561e-02,\n",
       "                      -4.7913e-02, -6.1677e-02,  3.5352e-02, -5.1986e-02, -3.1427e-02,\n",
       "                      -5.6080e-02, -4.7336e-02, -7.6436e-02, -4.9524e-02, -4.6167e-02,\n",
       "                      -5.3989e-02,  2.8089e-02, -5.7070e-02, -5.8715e-02, -2.0651e-02,\n",
       "                       3.2998e-02, -3.5740e-02, -2.8856e-02, -5.8581e-02, -1.0864e-02,\n",
       "                      -2.8707e-02, -6.1695e-02, -7.1517e-02, -3.9435e-02, -4.4182e-02,\n",
       "                       1.1906e-02, -8.2725e-02, -3.9781e-02, -6.0071e-02, -6.8156e-02,\n",
       "                      -3.8948e-02, -7.1036e-02, -5.5001e-02, -2.9987e-02,  9.5966e-03,\n",
       "                      -2.8112e-02, -9.1460e-05, -1.5228e-02, -4.4157e-02, -5.6089e-02,\n",
       "                      -4.5706e-02, -1.6552e-02, -5.3570e-02,  4.3816e-03,  2.6421e-02,\n",
       "                      -1.7368e-02, -3.7547e-02, -2.4535e-02,  8.9953e-03, -5.3725e-02,\n",
       "                      -4.9315e-02, -7.7369e-02, -3.0508e-02, -3.5507e-02, -9.2487e-02,\n",
       "                      -5.9544e-02, -2.4324e-02, -4.2086e-02, -3.4468e-03, -4.2301e-02,\n",
       "                      -2.0106e-02, -3.0869e-02, -5.4998e-04, -4.8762e-02, -5.4488e-02,\n",
       "                      -5.8410e-02, -1.1773e-02, -2.0799e-02, -7.5530e-03, -6.1249e-02,\n",
       "                      -3.0938e-02, -5.5945e-03, -3.9686e-02, -6.2450e-02, -3.7679e-02,\n",
       "                      -6.6230e-02, -5.8908e-02, -2.6349e-02])),\n",
       "             ('ICCD_features_.9.running_mean',\n",
       "              tensor([-7.0577e-02,  1.8980e-01, -1.7100e-01, -1.6569e-01, -1.6156e-01,\n",
       "                      -3.4418e-02, -4.7862e-02, -1.1356e-01, -1.5786e-01,  2.0809e-01,\n",
       "                      -1.4514e-01, -1.4800e-01,  3.3996e-02, -3.5949e-03,  1.4120e-01,\n",
       "                      -2.5554e-01, -4.1934e-02, -1.2305e-01, -1.4103e-01, -1.6493e-01,\n",
       "                      -8.7699e-02,  4.1098e-04, -1.4416e-05, -4.7287e-02, -2.7647e-01,\n",
       "                      -1.4585e-01, -9.7173e-02, -1.3727e-01,  1.7411e-01, -3.0010e-01,\n",
       "                      -1.0625e-01,  2.2281e-01,  5.4999e-02,  7.2534e-03, -7.5472e-02,\n",
       "                      -2.0254e-01, -2.3313e-01,  2.7118e-01, -1.9177e-01,  3.3146e-01,\n",
       "                       1.3896e-02, -4.3529e-02,  5.8291e-02, -1.7629e-01, -1.0807e-01,\n",
       "                      -2.6458e-01, -2.0189e-01, -1.7723e-01, -3.9837e-02, -9.5525e-02,\n",
       "                      -1.8277e-01,  8.4458e-02, -1.6666e-01, -1.4395e-01, -2.6283e-02,\n",
       "                       6.8661e-04,  2.9060e-03,  4.1736e-03, -9.9332e-02, -2.7634e-01,\n",
       "                      -4.2464e-03, -1.4785e-01, -6.0314e-02, -1.5226e-02, -1.4402e-03,\n",
       "                      -1.0181e-01, -2.3201e-01, -9.6040e-02, -6.8820e-02, -2.4436e-02,\n",
       "                       2.8774e-01, -1.3761e-02,  4.7112e-04, -1.6663e-01, -1.6998e-01,\n",
       "                      -1.1325e-01,  3.3324e-01,  1.1820e-01, -9.9828e-02, -4.0507e-02,\n",
       "                      -6.0518e-02,  1.7995e-01, -1.0316e-01, -1.3706e-01,  1.3103e-01,\n",
       "                      -1.4869e-01, -2.0715e-01, -6.5153e-02, -2.2650e-01, -1.3060e-01,\n",
       "                      -3.5295e-02, -2.7242e-01, -6.6170e-02,  3.6278e-02, -1.6072e-01,\n",
       "                      -4.6185e-02, -3.5214e-02, -6.9318e-02, -1.3370e-01, -7.1551e-02,\n",
       "                       9.4739e-03,  2.4231e-01, -2.1426e-01,  1.0394e-01,  1.1535e-01,\n",
       "                       1.1983e-02, -1.0368e-01,  2.1366e-01, -9.3423e-02,  1.7427e-01,\n",
       "                      -1.8838e-01,  8.4596e-02, -8.6735e-02, -7.3485e-02,  6.5779e-02,\n",
       "                       1.6378e-01, -1.3181e-01, -1.0631e-01,  1.1479e-02, -3.3424e-02,\n",
       "                      -2.5410e-01, -3.3666e-01, -5.2627e-02, -4.7203e-02, -1.1643e-01,\n",
       "                      -1.8025e-02, -2.3945e-01, -1.2187e-01])),\n",
       "             ('ICCD_features_.9.running_var',\n",
       "              tensor([ 1.9840,  8.3764,  3.9274, 14.6205,  1.2816,  1.6940,  1.3801,  1.3217,\n",
       "                       1.4092,  1.9201,  5.3981,  1.3989,  1.6252,  5.3195,  2.6239,  3.9897,\n",
       "                       2.9701,  4.1427,  3.6846, 15.0666,  1.8628,  2.8679,  2.7307,  2.7792,\n",
       "                       7.2449,  3.2043,  8.3101,  1.9435,  4.3487,  9.5198,  3.9832,  2.5577,\n",
       "                       2.4337,  0.9320,  1.9073,  4.9779,  5.6442,  2.2915,  3.5885,  6.0075,\n",
       "                       2.0925,  3.1790,  2.4990, 19.0216,  2.1917,  4.1027,  2.6581,  8.6666,\n",
       "                       2.0349,  1.9944,  3.7352,  3.8388,  4.3516,  2.5772,  2.3157,  1.1199,\n",
       "                       1.5983,  2.0809,  4.4116,  3.4352,  3.1513,  2.3439,  1.6969,  1.8735,\n",
       "                       1.1224,  8.2245,  2.9607,  1.2295,  1.1896,  1.7081,  4.8962,  4.1554,\n",
       "                       2.1412,  1.5879,  1.3597, 14.6941,  4.8183,  8.7101,  1.9791,  3.7735,\n",
       "                       3.0524,  2.4991,  1.0139,  2.4225,  6.9668,  3.4236, 10.8103,  2.9142,\n",
       "                       3.3519,  1.8448,  2.2533,  6.0073,  1.2807,  1.4048, 15.6866,  2.2945,\n",
       "                       1.7308,  1.0741,  2.4340,  1.7264,  1.9837,  4.7372,  5.6945,  1.6024,\n",
       "                       2.6861,  4.7318,  3.4721,  1.2973,  2.6110,  5.3372,  2.1507,  1.5565,\n",
       "                       3.8142,  1.8551,  1.3994,  1.8953,  1.6920,  1.8761,  1.4180,  1.7571,\n",
       "                       4.4481,  6.0099,  2.8264,  1.1340, 12.5877,  1.3082,  2.1212,  3.8751])),\n",
       "             ('ICCD_features_.9.num_batches_tracked', tensor(730)),\n",
       "             ('ICCD_features_.12.weight',\n",
       "              tensor([[[[[ 0.0181,  0.0200,  0.0268],\n",
       "                         [-0.0036,  0.0035, -0.0002],\n",
       "                         [-0.0011,  0.0110, -0.0088]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0403, -0.0442, -0.0246],\n",
       "                         [-0.0466, -0.0442, -0.0144],\n",
       "                         [-0.0362, -0.0374, -0.0118]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0147,  0.0118,  0.0253],\n",
       "                         [-0.0132, -0.0013,  0.0127],\n",
       "                         [ 0.0025,  0.0011,  0.0037]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0274, -0.0231,  0.0054],\n",
       "                         [-0.0089, -0.0161,  0.0167],\n",
       "                         [ 0.0038, -0.0022,  0.0351]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0090, -0.0249,  0.0190],\n",
       "                         [-0.0018, -0.0010, -0.0275],\n",
       "                         [ 0.0048,  0.0040,  0.0211]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0207, -0.0059, -0.0050],\n",
       "                         [ 0.0110, -0.0199,  0.0034],\n",
       "                         [-0.0092, -0.0118,  0.0197]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 0.0244, -0.0049,  0.0291],\n",
       "                         [ 0.0104,  0.0139,  0.0301],\n",
       "                         [ 0.0031,  0.0125,  0.0215]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0038,  0.0044, -0.0191],\n",
       "                         [ 0.0077,  0.0222,  0.0214],\n",
       "                         [ 0.0056, -0.0092, -0.0235]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0014, -0.0343, -0.0231],\n",
       "                         [-0.0068, -0.0194, -0.0418],\n",
       "                         [-0.0016, -0.0169, -0.0280]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0228, -0.0157,  0.0292],\n",
       "                         [-0.0075, -0.0260,  0.0431],\n",
       "                         [ 0.0253,  0.0101,  0.0506]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0093,  0.0349,  0.0184],\n",
       "                         [ 0.0020, -0.0014,  0.0239],\n",
       "                         [-0.0249,  0.0050,  0.0197]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0261, -0.0083, -0.0114],\n",
       "                         [ 0.0008, -0.0040, -0.0036],\n",
       "                         [ 0.0009, -0.0166, -0.0307]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0044,  0.0062,  0.0226],\n",
       "                         [ 0.0034, -0.0015, -0.0183],\n",
       "                         [ 0.0047,  0.0362,  0.0141]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0196, -0.0154, -0.0157],\n",
       "                         [-0.0243,  0.0045, -0.0094],\n",
       "                         [ 0.0136, -0.0301,  0.0062]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0016,  0.0241,  0.0003],\n",
       "                         [ 0.0292,  0.0107, -0.0061],\n",
       "                         [ 0.0070,  0.0407, -0.0036]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0262,  0.0087,  0.0124],\n",
       "                         [ 0.0126, -0.0008,  0.0380],\n",
       "                         [ 0.0369,  0.0056, -0.0035]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0060, -0.0096,  0.0125],\n",
       "                         [-0.0216,  0.0084, -0.0008],\n",
       "                         [-0.0142, -0.0061,  0.0007]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0207,  0.0067,  0.0044],\n",
       "                         [ 0.0177, -0.0089,  0.0380],\n",
       "                         [ 0.0087,  0.0386,  0.0215]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0544, -0.0268, -0.0279],\n",
       "                         [-0.0526, -0.0506, -0.0155],\n",
       "                         [-0.0362, -0.0314, -0.0210]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0148,  0.0121,  0.0133],\n",
       "                         [ 0.0239,  0.0242, -0.0141],\n",
       "                         [ 0.0074,  0.0355,  0.0020]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0341, -0.0268,  0.0035],\n",
       "                         [ 0.0018,  0.0055, -0.0101],\n",
       "                         [ 0.0082, -0.0141,  0.0154]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-0.0159,  0.0004, -0.0330],\n",
       "                         [-0.0338, -0.0199, -0.0312],\n",
       "                         [-0.0406, -0.0211, -0.0305]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0058,  0.0063, -0.0098],\n",
       "                         [-0.0345, -0.0086, -0.0022],\n",
       "                         [ 0.0193, -0.0068,  0.0101]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0365, -0.0402,  0.0071],\n",
       "                         [-0.0244, -0.0198, -0.0218],\n",
       "                         [-0.0283, -0.0040,  0.0033]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0002, -0.0144, -0.0111],\n",
       "                         [-0.0342,  0.0027, -0.0106],\n",
       "                         [-0.0054, -0.0045,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0031,  0.0303,  0.0345],\n",
       "                         [ 0.0297, -0.0177, -0.0190],\n",
       "                         [ 0.0048, -0.0041,  0.0145]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0240, -0.0049,  0.0029],\n",
       "                         [ 0.0036, -0.0369, -0.0264],\n",
       "                         [-0.0067, -0.0297, -0.0240]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-0.0289,  0.0081, -0.0104],\n",
       "                         [-0.0004, -0.0075, -0.0014],\n",
       "                         [ 0.0069, -0.0149,  0.0057]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0009,  0.0196,  0.0141],\n",
       "                         [ 0.0175,  0.0030,  0.0229],\n",
       "                         [ 0.0215, -0.0047, -0.0216]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0258,  0.0045, -0.0216],\n",
       "                         [-0.0101, -0.0183, -0.0157],\n",
       "                         [-0.0367, -0.0195,  0.0026]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-0.0078, -0.0099, -0.0014],\n",
       "                         [-0.0043, -0.0151,  0.0059],\n",
       "                         [ 0.0033, -0.0322, -0.0137]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0211,  0.0156,  0.0041],\n",
       "                         [ 0.0058,  0.0107, -0.0033],\n",
       "                         [-0.0130, -0.0138, -0.0246]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 0.0105, -0.0126, -0.0260],\n",
       "                         [-0.0152,  0.0008, -0.0102],\n",
       "                         [-0.0012, -0.0007, -0.0223]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-0.0233, -0.0163, -0.0192],\n",
       "                         [-0.0114,  0.0125, -0.0296],\n",
       "                         [-0.0241, -0.0146, -0.0321]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0295, -0.0414,  0.0031],\n",
       "                         [-0.0337, -0.0390, -0.0179],\n",
       "                         [-0.0079, -0.0179, -0.0429]]],\n",
       "              \n",
       "              \n",
       "                       [[[-0.0146,  0.0198, -0.0073],\n",
       "                         [-0.0209, -0.0057, -0.0152],\n",
       "                         [-0.0003, -0.0207,  0.0059]]]]])),\n",
       "             ('ICCD_features_.12.bias',\n",
       "              tensor([ 8.2881e-07, -3.3788e-07,  1.6999e-06, -4.4460e-07, -2.1692e-06,\n",
       "                      -2.5769e-07, -1.5535e-06,  9.4423e-07, -2.8468e-06,  1.6681e-06,\n",
       "                      -2.2397e-06,  1.5472e-07, -9.8309e-07,  1.2815e-06,  3.6303e-07,\n",
       "                      -1.2004e-06,  6.6031e-07,  7.2318e-07, -3.2430e-07, -3.6440e-06,\n",
       "                      -5.7229e-07, -1.6102e-06,  1.4590e-06, -1.7588e-06,  2.4296e-07,\n",
       "                      -1.7860e-06, -8.0918e-07, -1.2051e-06, -1.0876e-07,  1.2175e-06,\n",
       "                       1.0001e-05,  1.6005e-06, -4.0959e-07, -6.3320e-07, -8.8305e-07,\n",
       "                      -4.6737e-06,  1.9320e-06,  5.6381e-06, -6.0996e-07,  5.3379e-06,\n",
       "                       7.3812e-06,  2.8087e-06,  4.2127e-06,  3.0775e-07, -4.8070e-06,\n",
       "                      -1.3544e-06, -1.0809e-06, -4.9650e-07, -2.0755e-07, -1.9977e-07,\n",
       "                       1.6874e-07, -9.5312e-07,  1.5556e-06, -4.2124e-07, -1.6138e-06,\n",
       "                       2.7271e-07, -1.3717e-06, -2.9598e-07, -3.4492e-06, -2.9479e-06,\n",
       "                      -4.9063e-07, -1.1202e-06,  2.4259e-07,  1.1632e-06, -7.8562e-08,\n",
       "                      -2.6747e-06,  1.4902e-06,  1.1980e-06, -8.4579e-08,  3.3153e-06,\n",
       "                      -1.5337e-06,  8.7843e-07, -3.7325e-07, -3.4898e-06, -6.3725e-08,\n",
       "                      -3.6399e-06,  2.7519e-06, -8.5037e-07, -6.7097e-07,  6.3651e-07,\n",
       "                      -1.5170e-06,  2.3352e-06, -4.5345e-07, -7.3785e-06,  7.9193e-07,\n",
       "                       1.4020e-06,  1.5483e-06, -1.2005e-06,  1.5883e-06, -8.5912e-07,\n",
       "                       3.1048e-07, -3.7601e-06,  1.3291e-06, -7.6230e-08,  5.2482e-07,\n",
       "                      -6.1817e-07,  1.0905e-06,  1.1095e-06, -2.9123e-07, -2.5616e-06,\n",
       "                      -2.9918e-06,  8.7571e-07, -1.3302e-05,  1.2501e-06, -1.2224e-06,\n",
       "                       2.9864e-06,  3.2274e-06, -8.8551e-07, -5.1376e-07,  5.8188e-07,\n",
       "                      -1.0859e-05, -2.0435e-06,  8.4910e-07, -3.4242e-06,  1.3880e-06,\n",
       "                      -1.2906e-06, -3.7377e-06,  5.6667e-06, -2.8240e-06, -2.7553e-09,\n",
       "                       8.9889e-07,  6.5639e-06, -1.1081e-06, -7.5246e-07, -2.6367e-06,\n",
       "                      -2.1972e-06,  3.3268e-07,  1.0174e-06,  1.7333e-07,  1.8036e-07,\n",
       "                       1.4226e-06, -9.6520e-07,  1.2827e-06,  1.1316e-05,  7.2030e-07,\n",
       "                      -6.5165e-07,  6.6182e-07,  8.7084e-07, -3.1814e-06,  1.2256e-06,\n",
       "                       2.7594e-06,  2.9408e-07, -7.9859e-07, -1.9011e-06,  1.4005e-06,\n",
       "                       5.1785e-07, -1.1722e-07,  1.8545e-07, -3.3147e-06, -2.7689e-06,\n",
       "                       4.8270e-08,  6.2701e-07, -4.2408e-07,  4.8310e-06, -1.4640e-08,\n",
       "                      -1.1478e-06, -1.2702e-06, -1.5186e-06, -3.4892e-06,  8.5268e-07,\n",
       "                      -3.9119e-06, -2.7420e-06,  2.3230e-06, -3.5158e-07, -3.4712e-07,\n",
       "                      -1.6152e-08,  3.1982e-07, -8.2881e-07,  4.2951e-07, -2.0419e-06,\n",
       "                      -3.3960e-06, -4.9161e-08,  8.0023e-07, -2.7337e-06, -6.4215e-06,\n",
       "                       2.2263e-06, -4.8851e-07,  2.4186e-07, -8.1932e-07,  4.5062e-07,\n",
       "                      -1.7068e-06, -1.3140e-06, -5.9448e-07,  1.0940e-06,  6.7487e-06,\n",
       "                       1.6728e-06,  1.9139e-06,  9.7554e-08,  2.9155e-06,  2.9736e-06,\n",
       "                      -5.2809e-07,  3.0579e-06, -2.9342e-07,  5.9419e-06, -2.8404e-09,\n",
       "                       3.1763e-08, -1.8952e-06,  5.9984e-07,  1.8173e-06, -8.8482e-07,\n",
       "                       1.0818e-07,  1.9844e-06,  1.5712e-06,  1.0087e-06,  8.8163e-06,\n",
       "                       5.2625e-06,  8.2625e-08,  1.9521e-06,  1.5370e-06, -1.4299e-06,\n",
       "                      -1.0614e-05, -6.1472e-07, -5.9629e-07, -5.2753e-07,  9.5572e-07,\n",
       "                       1.5091e-06,  4.3242e-06,  3.0691e-06, -2.0210e-06,  1.8103e-06,\n",
       "                      -4.0972e-06, -1.2496e-06, -1.6344e-07,  7.6366e-07,  4.9563e-07,\n",
       "                      -4.8064e-07, -2.4739e-05,  2.1191e-06,  3.1754e-07,  2.4285e-07,\n",
       "                       5.3196e-06, -1.4040e-08,  1.1796e-06, -7.6995e-07, -8.4766e-07,\n",
       "                      -8.9938e-08,  3.1437e-06, -2.8293e-08, -2.9656e-06, -4.5982e-06,\n",
       "                      -6.5013e-09,  7.8888e-07,  6.1759e-07,  2.5872e-07, -8.1947e-07,\n",
       "                      -3.2976e-06, -1.8834e-07,  1.9874e-06,  7.9585e-07, -8.3134e-07,\n",
       "                      -1.1123e-06,  1.3092e-06, -1.3034e-06,  2.8783e-06, -1.1425e-06,\n",
       "                       7.9244e-07])),\n",
       "             ('ICCD_features_.13.weight',\n",
       "              tensor([0.9688, 0.9452, 0.9264, 0.8363, 0.9535, 0.9740, 0.9639, 0.9653, 0.9777,\n",
       "                      0.9352, 0.9766, 0.9717, 0.9297, 0.9765, 0.9255, 0.9230, 0.9802, 0.9354,\n",
       "                      0.9581, 0.9703, 0.9421, 0.9984, 0.9171, 0.9400, 0.9764, 0.9774, 0.9123,\n",
       "                      0.9526, 0.9655, 0.9608, 0.9814, 1.0138, 0.9324, 0.9001, 0.9524, 0.9940,\n",
       "                      0.9714, 0.9546, 0.8599, 0.9789, 1.0039, 0.9229, 0.9546, 0.9300, 0.9729,\n",
       "                      1.0109, 0.9604, 0.9750, 0.9926, 0.9151, 0.9271, 0.9156, 0.9529, 0.8770,\n",
       "                      0.9818, 0.9529, 0.9789, 0.9100, 0.9213, 0.9748, 0.9484, 0.9017, 0.9256,\n",
       "                      0.9245, 0.9587, 0.9540, 0.9536, 0.9604, 0.9177, 0.9123, 0.9244, 1.0043,\n",
       "                      0.9533, 0.9642, 0.9378, 0.9572, 0.9718, 0.9274, 0.9539, 0.8045, 0.9678,\n",
       "                      0.9779, 0.9118, 0.9610, 0.9322, 0.9930, 0.9353, 0.9323, 0.9325, 0.9365,\n",
       "                      0.9720, 0.9943, 0.9240, 0.9347, 1.0009, 0.9486, 0.9238, 0.9645, 1.0050,\n",
       "                      0.9445, 0.9605, 0.8483, 0.9967, 0.9481, 0.9922, 0.9754, 0.9446, 0.9578,\n",
       "                      0.9447, 0.9663, 0.9888, 0.9835, 0.9299, 1.0456, 0.9398, 0.9290, 0.8709,\n",
       "                      0.9473, 0.9918, 0.9227, 0.9391, 0.9827, 1.0153, 0.9248, 0.9478, 0.9345,\n",
       "                      0.9269, 0.9377, 0.9199, 0.9643, 0.9608, 0.9735, 0.9295, 0.9862, 0.9966,\n",
       "                      0.9545, 0.9205, 0.9655, 0.9532, 0.9511, 0.9669, 0.9387, 0.9321, 0.9584,\n",
       "                      0.9529, 0.9310, 1.0254, 0.9828, 0.9390, 0.9746, 0.9277, 0.9378, 0.9995,\n",
       "                      0.9510, 0.9433, 0.9465, 0.9564, 0.9837, 0.9678, 0.9123, 0.9511, 0.9364,\n",
       "                      0.9783, 0.8819, 0.9319, 0.9359, 0.9219, 0.9634, 0.9535, 0.9402, 0.9433,\n",
       "                      0.9603, 0.9756, 0.9535, 0.9345, 1.0153, 0.9688, 0.9604, 0.8646, 0.9780,\n",
       "                      0.9397, 0.9398, 0.8737, 0.9671, 0.9716, 0.9587, 0.9700, 0.9375, 0.9666,\n",
       "                      0.9661, 0.9357, 0.9859, 0.9370, 0.9623, 0.8504, 0.9555, 0.9550, 0.9447,\n",
       "                      0.9813, 0.8541, 0.9388, 0.9757, 0.9370, 0.9585, 0.9469, 0.9702, 0.9436,\n",
       "                      0.9419, 0.9436, 0.9786, 0.9738, 0.9557, 0.8969, 1.0261, 0.8906, 0.9353,\n",
       "                      0.9742, 0.9336, 0.9682, 0.9435, 0.9837, 0.9489, 0.9486, 0.9671, 0.9514,\n",
       "                      0.8893, 1.0041, 0.9415, 0.9191, 0.9395, 0.9868, 0.9059, 0.9428, 0.9844,\n",
       "                      0.9518, 0.9477, 0.9727, 0.9629, 0.8969, 0.9424, 0.9185, 0.9486, 0.9449,\n",
       "                      0.9110, 1.0046, 0.9478, 0.8230, 0.9448, 0.9117, 0.9197, 0.9792, 0.8782,\n",
       "                      0.9362, 0.9721, 0.9917, 0.9300])),\n",
       "             ('ICCD_features_.13.bias',\n",
       "              tensor([-0.1081, -0.0432,  0.0239,  0.1024,  0.0023, -0.0566, -0.0903, -0.0873,\n",
       "                       0.0138,  0.0635, -0.1238,  0.0666, -0.0522,  0.1197, -0.1266, -0.0929,\n",
       "                       0.0483, -0.0016, -0.0736,  0.0768, -0.1242,  0.0329, -0.0250,  0.1140,\n",
       "                       0.1585,  0.0042,  0.0058, -0.0863,  0.1013,  0.0249,  0.0839,  0.0167,\n",
       "                       0.0921, -0.0137, -0.0680,  0.0222,  0.1111, -0.0787,  0.0314,  0.0539,\n",
       "                       0.0534, -0.0524, -0.0322,  0.0636,  0.0925,  0.1460, -0.1088,  0.0527,\n",
       "                       0.0612,  0.0123,  0.0699,  0.0491,  0.1286, -0.1446,  0.1307, -0.0378,\n",
       "                      -0.1243,  0.1087, -0.0871,  0.0708, -0.1343, -0.0182,  0.0966,  0.0600,\n",
       "                      -0.1328, -0.0732,  0.0656, -0.0142,  0.0226,  0.0646, -0.0308,  0.1471,\n",
       "                      -0.0906, -0.0653,  0.0571,  0.1413, -0.0429, -0.1016,  0.1173,  0.0204,\n",
       "                      -0.0655, -0.0813,  0.0331,  0.0164,  0.0749,  0.0626,  0.0567,  0.0623,\n",
       "                       0.0915,  0.0719, -0.0744,  0.0234,  0.0361, -0.0287, -0.1191, -0.0602,\n",
       "                       0.1436,  0.1101, -0.0662,  0.1125,  0.1077, -0.0112,  0.0651, -0.0263,\n",
       "                      -0.1459, -0.0479, -0.0050,  0.1544,  0.0369,  0.0491,  0.0608, -0.0535,\n",
       "                       0.0327, -0.1197, -0.1074,  0.1404, -0.0612,  0.0018,  0.1380, -0.0412,\n",
       "                      -0.0364,  0.0913,  0.1424, -0.1040, -0.0685,  0.0700,  0.1222, -0.0899,\n",
       "                       0.0193, -0.0661,  0.1144, -0.0454, -0.0290, -0.0588,  0.1054, -0.0162,\n",
       "                       0.1237, -0.1463,  0.0447,  0.0469,  0.0662,  0.0563,  0.0810, -0.0614,\n",
       "                       0.0956,  0.0810,  0.1577,  0.0532, -0.0145, -0.0917,  0.1474, -0.0474,\n",
       "                       0.0463, -0.0732,  0.0335, -0.0687,  0.0019, -0.0912,  0.0647, -0.1417,\n",
       "                       0.1261,  0.0232, -0.1355,  0.1026, -0.0144, -0.0551,  0.1037, -0.1017,\n",
       "                      -0.0711,  0.0937,  0.0914, -0.1060,  0.0332,  0.0476, -0.1127, -0.1667,\n",
       "                      -0.0109, -0.1416,  0.0841,  0.0651,  0.0039, -0.0018,  0.0712, -0.0412,\n",
       "                      -0.0591,  0.0801,  0.1181, -0.0643, -0.0555, -0.0755,  0.0631,  0.0358,\n",
       "                       0.0839, -0.0875, -0.0152,  0.0893,  0.0565,  0.0695,  0.1097,  0.0739,\n",
       "                      -0.0305,  0.0087, -0.1108, -0.0946, -0.0006, -0.0303,  0.0780, -0.0508,\n",
       "                       0.0932, -0.0638, -0.0475, -0.1033, -0.0139,  0.1502, -0.0907,  0.0993,\n",
       "                       0.0192,  0.0413, -0.0175,  0.0124,  0.0450,  0.1387,  0.1118, -0.0451,\n",
       "                       0.0847,  0.0721,  0.0587,  0.0995,  0.1149,  0.1138,  0.0284, -0.1052,\n",
       "                       0.0213, -0.0340,  0.0278, -0.0727,  0.0681, -0.0121,  0.1013, -0.0671,\n",
       "                      -0.1110,  0.0239,  0.1174, -0.1268, -0.0518, -0.0492, -0.1018,  0.0734,\n",
       "                      -0.0738, -0.0880, -0.1270,  0.0257,  0.0491,  0.1403,  0.0482,  0.0112])),\n",
       "             ('ICCD_features_.13.running_mean',\n",
       "              tensor([ 0.0586,  0.1806,  1.2369,  0.7246,  1.2194,  0.3310,  0.9502,  0.5664,\n",
       "                      -0.7664,  0.9210, -0.2771,  0.5727,  1.5276, -0.6644, -0.0401,  0.0913,\n",
       "                      -0.3000, -0.5845,  1.3265, -0.5941, -0.3037, -0.4303,  1.0311, -0.9791,\n",
       "                      -1.8492,  1.0886, -1.3523,  0.2060, -0.1572, -0.8551, -2.7957, -0.4175,\n",
       "                       1.0733,  3.1096, -0.5061,  0.0651, -0.9917,  0.3149,  2.5261, -0.3166,\n",
       "                       0.0260, -1.6522, -0.5026, -1.6737, -0.5348,  0.3969, -1.0302,  0.5893,\n",
       "                      -0.0188, -0.5477,  0.4694,  1.4656,  1.3423,  1.4808, -0.4290,  1.1831,\n",
       "                       0.9071,  0.9071, -2.0807, -0.2969,  0.6703, -0.9442,  0.5454,  0.4516,\n",
       "                       0.0783, -1.2563,  0.9559,  0.7002, -0.9596,  1.4343,  0.9244, -0.4055,\n",
       "                       1.0313, -0.8369,  0.6111,  0.5652, -1.4940,  3.2914, -0.7131, -0.4246,\n",
       "                       0.4024,  0.5716,  2.5498, -0.4991, -0.0572, -0.0246, -0.9643, -1.4058,\n",
       "                       0.0876,  0.4319,  0.6445, -0.3171, -0.9667, -1.5097, -0.3955, -0.6180,\n",
       "                      -0.7570,  0.0370, -0.0920,  0.1578,  0.0636, -3.4942, -0.0069,  2.3291,\n",
       "                       0.3639,  0.5818, -0.3486, -0.0476, -0.7819, -0.7249,  1.0374, -0.1911,\n",
       "                       0.8872, -1.4096, -0.5240,  0.7027, -2.4166, -0.0651,  1.7370,  1.7158,\n",
       "                      -0.8716, -0.4890,  1.6909,  0.7894,  1.3165, -0.3449, -0.8187,  0.1897,\n",
       "                       2.9116, -1.9862, -0.6443,  0.8994,  2.8427,  0.9283, -0.2378, -0.8071,\n",
       "                       0.1582, -0.1209, -1.1776, -0.6796, -0.4830, -0.9160,  0.5237,  0.2359,\n",
       "                       2.2649, -1.3128,  1.1885, -0.3092,  0.9247,  0.0617,  0.9801,  1.0635,\n",
       "                      -0.8604,  0.2184, -2.0546, -0.1619,  1.1796,  0.4465, -1.5285, -0.3722,\n",
       "                       0.4958,  0.6627,  2.1504, -0.6205, -0.8605,  0.8621, -0.0971, -1.2636,\n",
       "                       0.4401,  1.7067, -0.0833, -0.3488, -1.7720,  1.9816,  0.8614,  0.3772,\n",
       "                       1.0154,  0.9692,  1.9076,  1.6347, -1.9301, -1.0851, -0.5757, -0.6141,\n",
       "                       1.6789, -0.2794, -0.7941, -0.8415,  0.4774,  0.4721, -1.8288,  0.6310,\n",
       "                      -0.1837, -0.2210,  2.5392, -0.0139,  1.0623, -0.1121, -0.8816, -0.4674,\n",
       "                      -0.4560, -1.4004,  2.9901, -0.1895,  0.1689,  0.3717, -0.4741, -0.5274,\n",
       "                       0.9683, -0.3663,  0.5559, -0.9859,  0.0511, -1.4633,  1.6611,  2.9601,\n",
       "                       2.5356,  0.8638, -1.2496, -1.5689, -0.2464,  1.5762, -0.4583, -0.2020,\n",
       "                       0.2847, -1.4007,  0.0823, -0.8140,  0.3347, -0.5351, -0.0977, -1.5755,\n",
       "                       1.0916, -0.0623, -0.8529, -0.6836, -0.1826, -0.8164, -1.1270,  1.2920,\n",
       "                      -1.1170, -1.1006, -0.9312,  1.0156,  0.8913,  0.4564,  2.4188,  0.1727,\n",
       "                       1.4268, -0.1167,  0.1419,  1.6426,  2.5131, -1.0495, -0.7074, -1.1577])),\n",
       "             ('ICCD_features_.13.running_var',\n",
       "              tensor([2.0888, 0.9918, 1.7334, 2.0513, 1.6393, 1.6851, 0.5100, 0.5980, 2.4483,\n",
       "                      0.7486, 1.1241, 0.8159, 1.6358, 0.4426, 0.6744, 1.5566, 1.4681, 1.5631,\n",
       "                      0.4479, 1.4805, 0.5953, 1.6091, 0.5445, 0.7496, 0.7573, 1.9543, 1.1436,\n",
       "                      0.7230, 0.2470, 1.8077, 0.6663, 1.8826, 1.7682, 1.1549, 1.0216, 1.7112,\n",
       "                      0.7881, 0.7807, 0.7960, 1.8419, 1.3996, 1.0141, 1.2470, 2.2275, 0.8122,\n",
       "                      0.4854, 1.0858, 1.6731, 1.8406, 0.5829, 1.9120, 1.1948, 0.5225, 1.1689,\n",
       "                      0.2742, 0.8648, 1.2646, 0.4302, 0.9255, 1.2565, 0.6345, 0.5708, 0.8237,\n",
       "                      0.6259, 0.4409, 0.8325, 1.4514, 1.7020, 0.4008, 0.5844, 1.4245, 0.3015,\n",
       "                      0.5657, 1.7222, 0.8324, 0.4558, 1.1541, 1.1682, 0.4926, 1.5446, 0.6567,\n",
       "                      0.3675, 0.8918, 1.9144, 0.7083, 1.8993, 0.9594, 0.7357, 0.7164, 0.5983,\n",
       "                      1.2670, 1.9714, 1.2693, 1.1246, 0.5791, 2.2341, 0.6332, 0.3282, 1.7031,\n",
       "                      0.4514, 0.5948, 1.8208, 1.4804, 1.0019, 0.4200, 2.0133, 1.7232, 0.3652,\n",
       "                      0.4254, 1.2324, 2.4308, 1.8922, 2.0244, 1.0257, 0.4427, 0.6663, 0.8195,\n",
       "                      1.6466, 0.4899, 0.5906, 1.5782, 0.9516, 1.1733, 0.8297, 1.2132, 1.3210,\n",
       "                      0.8097, 0.9777, 0.9308, 0.6466, 0.3396, 1.3307, 0.9597, 2.2216, 1.3071,\n",
       "                      1.9307, 1.5540, 0.4868, 0.6450, 1.6090, 2.0299, 1.5363, 0.9638, 1.4230,\n",
       "                      1.0700, 0.6426, 0.7096, 1.4317, 1.0788, 1.3366, 0.6808, 0.7706, 1.8772,\n",
       "                      1.1015, 0.5960, 0.8515, 1.5944, 1.1877, 1.4472, 1.1814, 0.5293, 1.0952,\n",
       "                      0.7909, 0.4893, 1.2020, 0.6873, 0.3639, 1.5564, 0.8365, 0.9966, 0.6590,\n",
       "                      0.5307, 1.5361, 0.8024, 0.5471, 0.6058, 1.9679, 0.3219, 0.6079, 1.5243,\n",
       "                      0.4897, 1.3501, 0.6836, 2.0685, 0.6372, 0.9768, 0.3590, 1.1126, 1.1366,\n",
       "                      1.1633, 0.8378, 1.8370, 0.4980, 0.8624, 0.9621, 0.7697, 0.4588, 0.5484,\n",
       "                      0.2641, 0.9526, 0.9903, 1.7600, 0.9415, 0.7560, 1.2376, 1.0387, 0.7824,\n",
       "                      1.8447, 0.3491, 1.6781, 1.4506, 1.1032, 0.8026, 1.0132, 0.7024, 1.0146,\n",
       "                      1.0240, 2.4275, 2.5574, 0.8838, 1.5498, 0.7626, 0.4508, 1.7524, 0.3182,\n",
       "                      0.6205, 1.3575, 0.4854, 1.1133, 0.5101, 2.0328, 0.8671, 1.2184, 2.0359,\n",
       "                      1.1657, 1.3245, 1.4438, 1.8776, 0.8257, 1.6196, 0.5657, 0.9638, 0.4934,\n",
       "                      1.7019, 1.9918, 1.9023, 1.2834, 0.9694, 0.9772, 0.6080, 0.3418, 1.1644,\n",
       "                      0.8438, 0.3823, 1.8845, 1.6407])),\n",
       "             ('ICCD_features_.13.num_batches_tracked', tensor(730)),\n",
       "             ('ICCD_features_.14.weight',\n",
       "              tensor([[[[[-8.7304e-03]],\n",
       "              \n",
       "                        [[ 2.9428e-02]],\n",
       "              \n",
       "                        [[ 7.3375e-03]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 2.6174e-02]],\n",
       "              \n",
       "                        [[ 3.1341e-02]],\n",
       "              \n",
       "                        [[-2.5535e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 1.0567e-02]],\n",
       "              \n",
       "                        [[ 1.5078e-02]],\n",
       "              \n",
       "                        [[-3.8276e-03]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-5.7711e-02]],\n",
       "              \n",
       "                        [[-1.1408e-03]],\n",
       "              \n",
       "                        [[ 5.0715e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 2.8222e-03]],\n",
       "              \n",
       "                        [[-3.8134e-02]],\n",
       "              \n",
       "                        [[-3.7199e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 2.2288e-02]],\n",
       "              \n",
       "                        [[ 1.3854e-02]],\n",
       "              \n",
       "                        [[-2.3623e-02]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 3.9315e-02]],\n",
       "              \n",
       "                        [[ 1.8248e-02]],\n",
       "              \n",
       "                        [[ 1.4974e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 1.0527e-02]],\n",
       "              \n",
       "                        [[-2.2665e-02]],\n",
       "              \n",
       "                        [[-2.1759e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 1.2418e-02]],\n",
       "              \n",
       "                        [[-1.8923e-02]],\n",
       "              \n",
       "                        [[-7.8935e-03]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-1.4243e-02]],\n",
       "              \n",
       "                        [[ 2.5780e-02]],\n",
       "              \n",
       "                        [[ 4.4424e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-2.8284e-02]],\n",
       "              \n",
       "                        [[-2.1210e-02]],\n",
       "              \n",
       "                        [[-3.0898e-03]]],\n",
       "              \n",
       "              \n",
       "                       [[[-1.2143e-02]],\n",
       "              \n",
       "                        [[ 2.2809e-02]],\n",
       "              \n",
       "                        [[-1.3671e-02]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 6.0986e-03]],\n",
       "              \n",
       "                        [[ 3.6116e-03]],\n",
       "              \n",
       "                        [[-1.4647e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-2.0833e-02]],\n",
       "              \n",
       "                        [[-2.9888e-02]],\n",
       "              \n",
       "                        [[ 7.9328e-05]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 1.4472e-03]],\n",
       "              \n",
       "                        [[ 1.2394e-02]],\n",
       "              \n",
       "                        [[-3.3509e-03]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[ 1.3317e-02]],\n",
       "              \n",
       "                        [[ 3.1582e-03]],\n",
       "              \n",
       "                        [[ 1.1934e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-2.8426e-02]],\n",
       "              \n",
       "                        [[-4.5741e-02]],\n",
       "              \n",
       "                        [[-4.0580e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-2.0334e-02]],\n",
       "              \n",
       "                        [[-2.0720e-02]],\n",
       "              \n",
       "                        [[-2.6871e-02]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 5.9562e-03]],\n",
       "              \n",
       "                        [[ 1.3392e-02]],\n",
       "              \n",
       "                        [[-1.1545e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 1.7629e-02]],\n",
       "              \n",
       "                        [[ 1.5275e-02]],\n",
       "              \n",
       "                        [[ 1.2942e-03]]],\n",
       "              \n",
       "              \n",
       "                       [[[-4.3885e-03]],\n",
       "              \n",
       "                        [[ 8.8810e-03]],\n",
       "              \n",
       "                        [[ 1.1012e-02]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-3.1925e-02]],\n",
       "              \n",
       "                        [[ 8.3426e-03]],\n",
       "              \n",
       "                        [[ 3.0029e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-2.6383e-03]],\n",
       "              \n",
       "                        [[-2.4490e-02]],\n",
       "              \n",
       "                        [[-1.8155e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 6.9219e-03]],\n",
       "              \n",
       "                        [[-7.7847e-03]],\n",
       "              \n",
       "                        [[ 5.1495e-03]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[ 6.1411e-03]],\n",
       "              \n",
       "                        [[ 4.4837e-02]],\n",
       "              \n",
       "                        [[ 8.3872e-03]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 3.9499e-02]],\n",
       "              \n",
       "                        [[ 8.8860e-03]],\n",
       "              \n",
       "                        [[-3.7615e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 2.3001e-03]],\n",
       "              \n",
       "                        [[ 5.0895e-02]],\n",
       "              \n",
       "                        [[ 1.8745e-02]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-2.4388e-02]],\n",
       "              \n",
       "                        [[-2.3001e-02]],\n",
       "              \n",
       "                        [[ 4.6075e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-8.5297e-03]],\n",
       "              \n",
       "                        [[-3.7842e-03]],\n",
       "              \n",
       "                        [[-2.4576e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-7.7185e-03]],\n",
       "              \n",
       "                        [[-7.2661e-03]],\n",
       "              \n",
       "                        [[ 5.0416e-03]]]],\n",
       "              \n",
       "              \n",
       "              \n",
       "                      [[[[-5.7466e-03]],\n",
       "              \n",
       "                        [[ 3.3032e-02]],\n",
       "              \n",
       "                        [[ 2.5023e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 2.5761e-02]],\n",
       "              \n",
       "                        [[-2.5786e-03]],\n",
       "              \n",
       "                        [[-2.2240e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-5.4948e-03]],\n",
       "              \n",
       "                        [[ 2.1898e-02]],\n",
       "              \n",
       "                        [[-4.8574e-03]]],\n",
       "              \n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "              \n",
       "                       [[[-1.6068e-02]],\n",
       "              \n",
       "                        [[-1.6681e-02]],\n",
       "              \n",
       "                        [[-1.9630e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[-2.1742e-02]],\n",
       "              \n",
       "                        [[-2.9796e-02]],\n",
       "              \n",
       "                        [[-2.0201e-02]]],\n",
       "              \n",
       "              \n",
       "                       [[[ 1.2978e-02]],\n",
       "              \n",
       "                        [[-4.3299e-02]],\n",
       "              \n",
       "                        [[-2.3615e-02]]]]])),\n",
       "             ('ICCD_features_.14.bias',\n",
       "              tensor([ 3.9200e-06,  6.2788e-07, -6.8018e-07, -7.1374e-06, -2.1015e-06,\n",
       "                       5.0160e-06,  1.1786e-05, -2.4383e-07,  1.5368e-05,  6.4186e-06,\n",
       "                       1.9849e-06,  1.4551e-06,  1.5039e-06,  8.2667e-07, -2.3530e-06,\n",
       "                      -8.7538e-07, -3.9374e-06,  5.3939e-06, -3.9277e-06,  3.8277e-06,\n",
       "                       6.6570e-07,  3.4647e-05, -8.9497e-07, -1.9935e-06, -2.5120e-06,\n",
       "                      -2.3327e-06, -1.6768e-06,  5.1469e-08,  4.8751e-06,  7.1243e-06,\n",
       "                      -8.1180e-07, -2.6064e-06, -2.9492e-06,  4.8373e-06, -1.2132e-06,\n",
       "                       3.7406e-06,  1.6042e-05,  1.6531e-06, -1.1649e-06, -8.9040e-06,\n",
       "                       3.9179e-07,  7.9211e-06,  4.8476e-06,  1.0794e-06,  7.9525e-08,\n",
       "                       2.2330e-05,  4.6368e-06,  3.2658e-06, -5.4753e-07, -4.2904e-06,\n",
       "                       2.1390e-06, -3.6534e-08, -2.4612e-07, -2.3327e-06, -7.7143e-06,\n",
       "                      -1.8678e-06,  1.5915e-06, -1.4636e-06,  8.7168e-06, -4.0567e-06,\n",
       "                      -1.6424e-06,  6.5826e-07, -3.4537e-06, -2.0190e-06,  2.1565e-06,\n",
       "                       6.7767e-07,  6.8686e-07,  9.3052e-07, -2.0637e-06,  3.1369e-06,\n",
       "                       1.0635e-06, -2.7584e-06, -1.1601e-06,  1.2111e-06,  2.1710e-06,\n",
       "                      -2.5390e-07, -1.6160e-06, -3.6693e-07, -8.6513e-07,  9.9090e-06,\n",
       "                      -5.3613e-06,  5.4421e-07, -5.3132e-06, -2.8570e-07, -2.6447e-06,\n",
       "                       5.1056e-06,  5.8128e-06,  5.6937e-06, -1.4986e-06,  3.3591e-06,\n",
       "                       1.0833e-06,  3.1261e-07, -4.7323e-06, -1.8422e-06, -9.3032e-07,\n",
       "                       1.0798e-06,  2.9097e-07,  5.4041e-07, -7.2402e-07, -3.6108e-06,\n",
       "                      -2.4789e-06, -5.0075e-06,  1.3693e-06, -3.8512e-06,  3.6472e-06,\n",
       "                      -4.9604e-06, -3.3448e-06, -8.9767e-06,  1.0889e-05,  2.0340e-06,\n",
       "                      -4.5283e-06,  3.2997e-06, -6.0992e-06,  1.1610e-06,  4.6502e-06,\n",
       "                      -9.8901e-08,  2.8854e-06, -1.2223e-05,  5.2649e-07, -1.5933e-06,\n",
       "                       3.3034e-06,  1.6205e-05,  1.7819e-06,  2.1136e-06, -7.6654e-07,\n",
       "                       1.2014e-05,  4.4559e-06, -4.1197e-06, -2.7495e-06,  2.0158e-06,\n",
       "                       7.6680e-07,  3.5700e-07,  2.9069e-06, -4.9835e-06, -9.0705e-07,\n",
       "                      -8.2132e-07,  5.1142e-06,  1.7165e-07,  4.4009e-07, -2.4002e-06,\n",
       "                       5.1128e-06, -5.7335e-06, -4.4454e-06,  4.8598e-07,  2.6703e-06,\n",
       "                      -6.0307e-06,  3.0108e-06, -3.4279e-06, -1.5071e-06, -2.8891e-06,\n",
       "                       3.4342e-07, -2.1635e-06,  1.4022e-06, -9.4562e-07,  1.0675e-06,\n",
       "                       1.4417e-06,  1.6123e-06, -6.2028e-07,  2.0256e-07, -4.7204e-07,\n",
       "                       2.4203e-06, -8.2852e-07, -2.0044e-06, -3.8205e-06,  1.0295e-05,\n",
       "                      -2.2192e-06,  1.8136e-06, -7.6411e-06,  2.6741e-06, -2.5110e-06,\n",
       "                       7.7362e-07, -5.2067e-06,  5.2366e-06, -1.6481e-07,  3.6425e-06,\n",
       "                       1.3306e-06,  1.7858e-07,  2.8182e-06, -1.0960e-06,  3.4444e-06,\n",
       "                      -1.5762e-06,  1.6438e-06, -1.7631e-06, -1.1764e-06,  1.7303e-06,\n",
       "                       2.4682e-06, -2.3996e-06, -1.3908e-07,  1.1195e-05, -1.0150e-05,\n",
       "                       7.5483e-06,  4.4175e-07, -1.8811e-05, -1.9132e-06, -7.1490e-07,\n",
       "                       3.1748e-06, -2.8475e-06, -2.1411e-06,  3.2013e-07,  3.4269e-06,\n",
       "                       5.8244e-06, -4.9752e-06, -4.6468e-06,  2.4585e-06,  7.2835e-07,\n",
       "                       6.2265e-06, -2.4899e-07,  3.0635e-06, -5.8831e-06,  3.6344e-06,\n",
       "                       5.6446e-06, -4.9052e-07, -1.9433e-06, -2.4499e-06, -2.2499e-07,\n",
       "                      -1.2247e-05, -1.4672e-05, -1.8444e-06, -6.3153e-07, -2.7047e-06,\n",
       "                      -2.1249e-06,  1.4666e-06, -8.5637e-06,  2.4413e-06, -5.5594e-06,\n",
       "                       3.3033e-07, -2.5951e-06,  1.7551e-06, -1.8536e-06,  7.1441e-06,\n",
       "                       6.5315e-06, -1.3181e-06,  9.8098e-07,  6.9794e-06,  1.0953e-05,\n",
       "                       7.6573e-07,  1.2739e-06,  1.7737e-05,  2.3374e-06, -2.9944e-06,\n",
       "                      -1.7231e-06,  6.3548e-07, -4.6357e-06, -1.1963e-05, -3.1533e-06,\n",
       "                       2.4268e-06, -1.8100e-06,  3.1790e-06, -1.8959e-07, -1.3561e-06,\n",
       "                      -2.8359e-06, -1.9805e-07,  1.8294e-07, -8.1901e-07, -1.3339e-06,\n",
       "                      -6.5477e-07])),\n",
       "             ('ICCD_features_.15.weight',\n",
       "              tensor([1.0381, 1.0364, 1.0281, 1.0349, 1.0132, 1.0967, 1.0355, 1.0049, 1.0793,\n",
       "                      1.0371, 1.0055, 1.0656, 1.0364, 0.9863, 1.0348, 1.0446, 1.0202, 1.0270,\n",
       "                      1.0242, 1.0328, 0.9906, 1.0349, 1.0646, 1.0149, 1.0528, 1.0215, 1.0141,\n",
       "                      1.0006, 0.9668, 0.9998, 1.0213, 1.0340, 1.0595, 1.0338, 1.0978, 1.0132,\n",
       "                      1.0297, 1.0486, 1.0243, 1.2199, 1.0124, 1.0185, 1.0256, 1.0264, 1.0057,\n",
       "                      1.0414, 1.0332, 1.1922, 1.0978, 1.0311, 0.9815, 1.0251, 1.0406, 1.0173,\n",
       "                      1.0939, 1.1267, 1.0068, 1.0130, 1.0394, 1.0969, 1.0399, 1.0302, 0.9728,\n",
       "                      1.0143, 1.0543, 0.9939, 1.0831, 0.9857, 1.0295, 1.1003, 1.0643, 1.0160,\n",
       "                      1.0351, 1.0954, 1.0417, 0.9891, 1.0098, 1.0444, 1.0140, 1.0212, 1.0415,\n",
       "                      1.0209, 1.0438, 0.9992, 1.1850, 1.0346, 1.0329, 1.0314, 1.0686, 1.1388,\n",
       "                      1.0207, 1.0236, 1.0909, 1.0281, 0.9719, 1.0266, 1.0281, 1.0826, 1.0005,\n",
       "                      1.0351, 1.1042, 1.0345, 1.1157, 1.0057, 1.1594, 1.0146, 0.9936, 1.0040,\n",
       "                      1.0379, 1.0141, 1.0128, 1.0293, 1.0306, 1.0178, 1.0429, 0.9754, 1.0712,\n",
       "                      1.0062, 1.0298, 1.0563, 1.0336, 1.0416, 1.0257, 1.0136, 1.0969, 1.0314,\n",
       "                      1.0179, 1.0332, 1.0245, 1.0325, 1.0033, 1.0398, 1.2005, 1.0369, 1.0294,\n",
       "                      1.0167, 1.0262, 1.0384, 1.0178, 1.0327, 1.0393, 1.0305, 1.1055, 1.0295,\n",
       "                      1.0424, 0.9933, 1.0272, 1.0221, 1.0047, 1.0189, 1.0695, 1.0022, 1.0946,\n",
       "                      1.0149, 1.0907, 1.0302, 0.9494, 1.0381, 1.0086, 1.0651, 1.0668, 0.9991,\n",
       "                      1.0371, 1.0323, 1.0175, 1.0815, 0.9520, 1.0264, 1.0318, 0.9921, 1.0320,\n",
       "                      1.0243, 1.1162, 1.0215, 1.0351, 1.0033, 1.0528, 1.0298, 1.0226, 1.0318,\n",
       "                      1.0221, 1.0299, 1.0295, 1.0287, 1.0326, 1.1225, 1.0312, 0.9677, 1.0539,\n",
       "                      1.0145, 1.0288, 1.0406, 1.0350, 1.0271, 1.1234, 1.0344, 1.0101, 0.9927,\n",
       "                      1.0364, 1.0816, 1.0331, 1.0343, 1.0245, 1.0205, 1.0271, 1.0139, 1.0778,\n",
       "                      1.0042, 1.0224, 1.0859, 1.0334, 0.9793, 1.0314, 1.0293, 0.9814, 1.0291,\n",
       "                      1.1126, 1.0373, 1.0291, 1.0278, 1.0380, 1.0725, 1.0085, 1.1474, 1.0140,\n",
       "                      1.0222, 1.0395, 1.0038, 1.0266, 1.0244, 1.0301, 1.0152, 1.0301, 1.0414,\n",
       "                      1.0302, 1.0376, 1.0772, 1.0394, 1.0729, 1.0362, 1.0341, 1.0184, 1.0242,\n",
       "                      1.0241, 1.0024, 1.1074, 1.1035, 1.0181, 1.0694, 1.0389, 1.0361, 1.1379,\n",
       "                      1.0101, 0.9700, 1.0335, 1.0113])),\n",
       "             ('ICCD_features_.15.bias',\n",
       "              tensor([-0.0088, -0.0674, -0.0191, -0.0219, -0.1223,  0.1327, -0.0402, -0.0585,\n",
       "                       0.1084, -0.0574, -0.0639,  0.0091, -0.0487, -0.0985, -0.0350, -0.0557,\n",
       "                      -0.0802, -0.0486, -0.0273, -0.0363, -0.1076, -0.0259,  0.0744, -0.0227,\n",
       "                       0.0624, -0.0557, -0.0771, -0.0741, -0.1455, -0.0355, -0.1122, -0.0601,\n",
       "                       0.0886, -0.0908,  0.1161, -0.0499, -0.0905,  0.0006, -0.0157,  0.1810,\n",
       "                      -0.0808, -0.0143, -0.0535, -0.0467, -0.0191, -0.0562, -0.0358,  0.1583,\n",
       "                       0.1143, -0.0858, -0.0565, -0.0523,  0.0674, -0.1096,  0.0547,  0.1479,\n",
       "                      -0.0385, -0.0271, -0.0798,  0.0421, -0.0824, -0.0236, -0.0885, -0.0379,\n",
       "                       0.0012, -0.0770,  0.1107, -0.0797, -0.0355,  0.0594,  0.0135, -0.1128,\n",
       "                      -0.0430,  0.0502, -0.0657, -0.0651, -0.0409, -0.0786, -0.0678, -0.0604,\n",
       "                      -0.0567,  0.0237,  0.0204, -0.0556,  0.1527, -0.0079, -0.0376, -0.0794,\n",
       "                       0.0440,  0.1438, -0.0033, -0.0787,  0.0448,  0.0128, -0.0366, -0.0419,\n",
       "                      -0.0468,  0.0744, -0.0810, -0.0469,  0.1343, -0.0635,  0.1198, -0.0242,\n",
       "                       0.1244, -0.1079, -0.1094, -0.0372, -0.0468, -0.0375, -0.0836, -0.0325,\n",
       "                      -0.0668, -0.0581, -0.0733, -0.1380,  0.1102, -0.0409, -0.0291,  0.0229,\n",
       "                      -0.0369,  0.0728, -0.0642, -0.0427,  0.0850, -0.0558, -0.0730, -0.0147,\n",
       "                      -0.0633, -0.0488, -0.0296, -0.1121,  0.1720, -0.0447, -0.0380, -0.0548,\n",
       "                      -0.0312, -0.0413,  0.0344, -0.0803, -0.0513, -0.0622,  0.0667, -0.0670,\n",
       "                      -0.0594, -0.1258,  0.0004, -0.0527, -0.0621, -0.0486,  0.0620, -0.1307,\n",
       "                       0.1114, -0.0949,  0.1279, -0.0557, -0.1397, -0.0565, -0.0379,  0.0806,\n",
       "                       0.0715, -0.0439,  0.0161, -0.0490, -0.0931,  0.1096, -0.1195, -0.0302,\n",
       "                      -0.0532, -0.1088, -0.0682, -0.0468,  0.1118,  0.0253, -0.0341, -0.0807,\n",
       "                       0.0172, -0.0293, -0.0431, -0.0344, -0.0027, -0.0429, -0.0677, -0.0349,\n",
       "                       0.0056,  0.1580, -0.0798, -0.1198,  0.0874, -0.0479, -0.0545, -0.0890,\n",
       "                      -0.0354, -0.0607,  0.1332, -0.0707, -0.0948, -0.1204, -0.0540,  0.1128,\n",
       "                      -0.0021, -0.0304, -0.0876, -0.0502, -0.0287, -0.0377,  0.0932, -0.0151,\n",
       "                      -0.0745,  0.1147, -0.0666, -0.1346, -0.1057, -0.0653, -0.0179, -0.0649,\n",
       "                       0.0976, -0.0399, -0.0295, -0.0309, -0.0674,  0.0619, -0.0752,  0.1500,\n",
       "                      -0.0664, -0.0145, -0.0146, -0.0418, -0.0135, -0.0572, -0.0447, -0.0411,\n",
       "                      -0.0936, -0.0447, -0.0492, -0.0396,  0.1037, -0.0312,  0.0246, -0.0344,\n",
       "                      -0.0592, -0.0874, -0.1023, -0.0222, -0.0451,  0.0992,  0.1375, -0.0786,\n",
       "                       0.0140, -0.0548, -0.0472,  0.1290, -0.0024, -0.0940, -0.0479, -0.0264])),\n",
       "             ('ICCD_features_.15.running_mean',\n",
       "              tensor([-7.8157e-02, -6.8229e-02,  1.2685e-01,  5.6902e-02, -6.5849e-02,\n",
       "                       4.1925e-01, -1.1433e-01, -1.0815e-01,  2.3005e-01, -2.3222e-02,\n",
       "                      -1.3084e-02,  2.1141e-01, -3.4748e-02, -9.0772e-02, -2.8520e-02,\n",
       "                      -3.9732e-02, -1.1036e-03, -8.8833e-02, -8.2979e-02, -8.3063e-02,\n",
       "                      -6.8967e-02, -1.6754e-02,  4.1743e-01,  1.8005e-01,  1.8114e-01,\n",
       "                      -7.2542e-02,  1.0794e-02, -5.3025e-02, -3.2271e-02,  1.4117e-01,\n",
       "                       2.2979e-02, -1.0208e-01,  4.1835e-01, -5.6812e-02, -6.0085e-02,\n",
       "                       7.5869e-02, -5.2769e-02,  3.1418e-01,  7.2214e-02, -6.7868e-01,\n",
       "                      -5.9122e-02,  8.9282e-02, -2.8452e-02, -7.0324e-03, -2.2097e-02,\n",
       "                      -8.4171e-02, -1.1085e-01, -6.5629e-01, -2.3607e-02, -8.3428e-02,\n",
       "                      -3.4265e-02, -3.7349e-02,  4.3295e-01, -3.5762e-02,  2.7548e-01,\n",
       "                      -4.6842e-01, -1.9259e-02,  1.8046e-02, -4.6566e-02,  4.0574e-01,\n",
       "                      -6.1975e-02, -2.8006e-02,  3.2341e-02,  9.3914e-02,  2.1840e-01,\n",
       "                      -1.0305e-01,  1.2278e-01, -1.9458e-01, -5.3751e-02,  4.6899e-01,\n",
       "                       2.2654e-01, -3.1351e-02, -1.3316e-01,  4.2614e-01, -6.2667e-02,\n",
       "                      -2.5873e-02,  1.6722e-01, -5.3696e-02, -9.6131e-03, -9.2775e-02,\n",
       "                      -3.5900e-02,  1.5850e-01, -5.9450e-03,  2.4065e-02, -6.6293e-01,\n",
       "                       3.2536e-01, -8.4638e-02, -2.5259e-02,  3.5512e-01, -2.4250e-01,\n",
       "                       2.8694e-02, -8.9862e-02,  3.5264e-01,  1.1381e-01, -2.6676e-02,\n",
       "                      -1.0892e-01,  4.2971e-02, -3.1134e-02, -4.8999e-03, -8.7695e-02,\n",
       "                       2.3003e-01, -4.9047e-02, -1.6606e-01, -7.3650e-02, -6.1712e-01,\n",
       "                      -2.9532e-02,  6.3314e-03, -2.8970e-02, -4.1875e-02, -6.4059e-02,\n",
       "                      -1.0374e-01,  1.7619e-01, -8.2969e-02, -1.1481e-01, -9.5761e-02,\n",
       "                      -3.4745e-02,  4.6878e-01,  4.3533e-02,  6.1566e-02,  4.1175e-01,\n",
       "                      -1.4252e-01,  4.5559e-01, -2.3109e-02, -4.6583e-02,  1.4493e-01,\n",
       "                       2.4591e-03, -5.7344e-02, -3.8605e-02, -5.8247e-02, -6.2448e-02,\n",
       "                      -1.2806e-01, -2.4006e-02, -5.2752e-01, -7.8066e-02, -1.3338e-01,\n",
       "                      -6.0156e-02, -1.6029e-01, -9.5209e-02,  8.6095e-02, -7.7394e-02,\n",
       "                      -1.1052e-01, -4.5742e-02,  1.7936e-01, -5.3606e-02, -5.0150e-02,\n",
       "                      -9.2608e-02, -6.6023e-02,  3.4835e-02,  2.3349e-02, -7.3056e-02,\n",
       "                      -2.7856e-01,  2.3066e-04,  2.6662e-02, -6.3667e-02,  2.3475e-01,\n",
       "                      -4.8332e-02,  2.5261e-03, -9.1001e-02, -1.4770e-02,  1.6130e-01,\n",
       "                       8.4792e-02, -9.1792e-02,  1.3383e-01, -8.0723e-02, -1.9937e-02,\n",
       "                       1.4497e-01, -2.9122e-02, -9.5543e-02, -1.0201e-01,  5.3581e-02,\n",
       "                      -5.2044e-02, -5.2093e-02, -2.3815e-01,  3.6044e-01,  2.2400e-02,\n",
       "                       4.5596e-02,  3.5139e-01, -1.3568e-01, -1.1485e-01, -7.2899e-02,\n",
       "                       6.2884e-02,  1.6502e-02,  7.8353e-03,  6.3076e-02,  1.8250e-01,\n",
       "                       3.1822e-02, -6.8221e-02, -9.4007e-02, -3.9115e-01, -7.4147e-02,\n",
       "                      -5.0548e-02, -3.1600e-02, -7.4331e-02, -1.1595e-01, -2.2381e-01,\n",
       "                      -4.2216e-02, -3.6472e-02,  1.4655e-02, -4.4772e-02,  1.4427e-01,\n",
       "                       1.8613e-01, -4.1974e-02, -5.7634e-02, -1.3590e-01, -3.9329e-02,\n",
       "                      -3.6959e-02,  2.1865e-01,  1.9846e-01, -7.2557e-02,  2.6280e-01,\n",
       "                      -2.4695e-02, -4.3454e-02, -4.1439e-02, -3.8223e-02,  1.2247e-01,\n",
       "                      -5.8573e-02, -3.7343e-01, -7.3324e-02, -1.1531e-01, -9.3015e-02,\n",
       "                      -6.0897e-02,  5.9275e-01, -8.5915e-02, -2.0244e-01, -9.4885e-02,\n",
       "                      -5.5973e-02, -1.0728e-01,  7.7808e-02,  6.8570e-02, -7.8252e-02,\n",
       "                      -8.2095e-02, -1.0068e-01, -4.6506e-02, -6.1327e-02, -7.0078e-02,\n",
       "                      -1.0731e-01,  1.2374e-01, -5.3313e-02,  3.4060e-01, -7.1473e-02,\n",
       "                      -7.3902e-02, -6.0437e-04,  7.2375e-03, -1.0264e-01,  2.5861e-02,\n",
       "                      -1.8233e-01,  7.6720e-02, -4.8186e-02,  3.6686e-01, -2.0709e-02,\n",
       "                      -7.6576e-02, -2.7339e-01, -3.9453e-02, -7.9998e-02, -6.3520e-02,\n",
       "                       1.6890e-02])),\n",
       "             ('ICCD_features_.15.running_var',\n",
       "              tensor([ 4.8734,  4.3268,  4.7724,  4.3797,  4.4879,  7.2743,  5.5239,  4.9277,\n",
       "                      10.8312,  5.2065,  7.1860,  5.9251,  5.5432,  5.0441,  4.2565,  4.4509,\n",
       "                       5.3324,  4.3164,  5.2163,  4.2413,  5.7569,  4.6878, 13.2414,  5.0298,\n",
       "                       9.4742,  4.6187,  6.4236,  6.1238,  5.8650,  5.4944,  5.4883,  4.8928,\n",
       "                       9.5228,  5.2659, 23.2676,  5.3949,  6.2412,  7.7521,  5.4058, 13.9723,\n",
       "                       4.6080,  4.7383,  3.6468,  4.1841,  5.9342,  5.5983,  5.2617, 14.6748,\n",
       "                      21.5232,  5.6569,  6.5697,  4.7975, 15.1224,  5.1614,  7.4629, 17.0878,\n",
       "                       4.4067,  5.6941,  5.7271,  7.8837,  5.2739,  5.6624,  5.0317,  3.7025,\n",
       "                       6.5624,  4.8380, 13.2470,  7.4686,  4.8096,  8.7293,  7.5894,  7.0387,\n",
       "                       4.7272,  6.1128,  4.6196,  5.8921,  6.3723,  4.7288,  4.3455,  4.8266,\n",
       "                       4.6346, 12.6937,  7.1393,  4.9695, 17.7207,  5.7156,  5.0409,  5.9025,\n",
       "                       7.6365, 24.3327,  5.5398,  4.4979,  8.0314, 12.2723, 10.8550,  4.9552,\n",
       "                       5.0029, 26.4579,  5.2987,  4.8871, 12.0041,  4.9228, 24.1330,  4.4577,\n",
       "                      11.7836,  5.7938,  5.5374,  5.6487,  5.3706,  5.0203,  4.7337,  5.0314,\n",
       "                       5.0396,  4.8128,  5.7146,  4.7635,  8.3819,  4.1267,  5.8076,  5.7509,\n",
       "                       5.2837, 14.0445,  4.5477,  4.9292,  6.7302,  4.1359,  6.8111,  4.5699,\n",
       "                       4.8571,  5.0236,  3.7752,  6.0661, 14.6423,  4.6050,  3.6841,  4.5422,\n",
       "                       4.2121,  4.5760, 10.5233,  4.5883,  4.7845,  4.6517,  8.0103,  5.3143,\n",
       "                       4.7653,  6.5422,  4.6246,  5.5701,  5.6569,  5.0400, 25.7970,  4.9853,\n",
       "                      23.5392,  4.9855,  8.8809,  4.7058,  5.3789,  5.2675,  5.5673,  8.1877,\n",
       "                      27.0867,  5.4923, 10.1912,  5.8941,  4.4093, 12.2899,  6.4159,  5.4273,\n",
       "                       5.8442,  6.3546,  4.8786,  4.5651, 13.1030,  8.7802,  4.4306,  5.3698,\n",
       "                       6.5105,  4.9986,  4.4561,  4.9233, 10.6157,  5.3317,  4.6074,  4.3244,\n",
       "                       5.2467, 10.2649,  6.1607,  7.2638, 26.0273,  5.0267,  4.7155,  6.2435,\n",
       "                       4.8421,  6.0086, 30.1634,  4.5107,  7.9074,  5.0307,  4.5757, 11.7670,\n",
       "                       5.2216,  4.7064,  7.0268,  5.0075,  5.6984,  5.3821, 29.8341,  5.9683,\n",
       "                       5.7315, 12.7180,  4.5365,  5.8872,  5.3786,  5.9482,  4.6702,  5.5559,\n",
       "                      30.0141,  5.4870,  5.2045,  4.4545,  6.2765, 11.6535,  5.3830, 39.0132,\n",
       "                       4.8471,  4.0166,  5.0717,  3.7970,  4.6339,  5.0572,  5.0361,  4.5574,\n",
       "                       4.8909,  6.1904,  5.2219,  5.6285, 11.1351,  5.1015,  6.3115,  5.0337,\n",
       "                       4.7680,  4.6736,  5.1966,  4.3628,  8.6010, 28.5303, 11.6970,  5.8919,\n",
       "                       8.0362,  4.9492,  4.7480, 13.7225,  8.0901,  6.1188,  4.8272,  3.8214])),\n",
       "             ('ICCD_features_.15.num_batches_tracked', tensor(730)),\n",
       "             ('ICCD_features_.19.weight',\n",
       "              tensor([[ 0.0607, -0.0371,  0.0711,  ...,  0.0244,  0.0611,  0.1101],\n",
       "                      [-0.0178, -0.0298,  0.0129,  ...,  0.0234,  0.0130,  0.0017],\n",
       "                      [ 0.0723,  0.0294,  0.0730,  ...,  0.0291, -0.0168,  0.0804],\n",
       "                      ...,\n",
       "                      [ 0.0170, -0.0202,  0.0361,  ..., -0.0073, -0.0332, -0.0212],\n",
       "                      [ 0.0055, -0.0554,  0.0583,  ..., -0.0050,  0.0302,  0.0291],\n",
       "                      [-0.0361, -0.0086, -0.0137,  ...,  0.0033, -0.0280, -0.0095]])),\n",
       "             ('ICCD_features_.19.bias',\n",
       "              tensor([ 2.9502e-02, -4.3155e-03,  6.0631e-02,  3.7951e-02,  1.0637e-05,\n",
       "                      -1.3098e-01, -1.5488e-02, -9.1747e-02, -1.1248e-01, -3.4606e-02,\n",
       "                       1.4740e-02, -6.0462e-03, -2.8342e-02, -1.9003e-02,  4.7617e-02,\n",
       "                       4.7661e-02, -1.4995e-02, -4.0560e-02, -1.9993e-02, -1.5992e-01,\n",
       "                       9.9905e-03, -1.0723e-02,  2.9820e-02,  1.8833e-01, -8.3261e-02,\n",
       "                       6.8837e-02,  4.9465e-02,  7.8187e-04,  1.5569e-01, -3.5088e-02,\n",
       "                      -1.4682e-02, -2.2667e-02,  3.5383e-02,  1.7169e-02, -3.0274e-02,\n",
       "                      -2.2522e-02, -1.4380e-02,  5.1341e-02,  2.6479e-02, -6.3762e-02,\n",
       "                      -1.0404e-02, -6.3918e-03,  4.3806e-02,  1.0436e-01, -5.2011e-03,\n",
       "                      -3.0125e-02, -1.0901e-01,  3.3845e-02, -5.6867e-02, -7.7555e-02,\n",
       "                       2.8603e-02, -3.1443e-02,  3.8259e-02, -5.3936e-02,  4.2583e-02,\n",
       "                      -1.2313e-02,  4.5130e-02, -5.6751e-02, -8.7637e-03, -5.0240e-02,\n",
       "                       4.8324e-02, -1.6158e-02,  1.8589e-01, -3.4638e-02])),\n",
       "             ('ICCD_features_.21.weight',\n",
       "              tensor([[-0.0438, -0.0388,  0.1246,  ...,  0.0241, -0.1589, -0.0937],\n",
       "                      [-0.0080,  0.1066, -0.1184,  ...,  0.0684,  0.0403, -0.0330],\n",
       "                      [-0.1165,  0.0031,  0.0386,  ..., -0.0003, -0.0649, -0.0313],\n",
       "                      ...,\n",
       "                      [-0.0337, -0.0760,  0.1387,  ..., -0.0841, -0.1461,  0.0044],\n",
       "                      [ 0.1178,  0.0218, -0.0511,  ..., -0.0278,  0.1669, -0.0144],\n",
       "                      [-0.0341,  0.0140,  0.0424,  ...,  0.0032, -0.0216,  0.0022]])),\n",
       "             ('ICCD_features_.21.bias',\n",
       "              tensor([-0.1286,  0.0100,  0.0245, -0.0799,  0.1965,  0.0563, -0.0274, -0.0614,\n",
       "                      -0.1391,  0.0862,  0.2866,  0.0645, -0.0453, -0.0467, -0.0043, -0.0159,\n",
       "                       0.0093,  0.0038, -0.0639,  0.0136, -0.0586,  0.0282, -0.0364,  0.0761,\n",
       "                      -0.0505, -0.1200,  0.2169,  0.0935,  0.0405,  0.0371,  0.0853, -0.0387])),\n",
       "             ('ICCD_features_.23.weight',\n",
       "              tensor([[ 0.0824, -0.0380, -0.0239,  0.0961, -0.2004, -0.1007, -0.2093, -0.1906,\n",
       "                       -0.1632,  0.1061, -0.1384,  0.0147, -0.0081, -0.2712, -0.0714, -0.0053,\n",
       "                       -0.0642,  0.0252,  0.1189,  0.0455,  0.0300,  0.2692,  0.0724, -0.1137,\n",
       "                       -0.0419,  0.1394, -0.0967,  0.1874, -0.0239,  0.0079,  0.2289, -0.0870],\n",
       "                      [ 0.2616, -0.0774,  0.0072,  0.1974, -0.3802, -0.2312, -0.0373,  0.3274,\n",
       "                       -0.0470, -0.0535,  0.3002, -0.1504, -0.0765,  0.1840,  0.1188, -0.0584,\n",
       "                       -0.1300,  0.1994,  0.2474,  0.1568,  0.1354, -0.1367,  0.1304,  0.2123,\n",
       "                       -0.0303,  0.2432, -0.1567,  0.1358,  0.0186,  0.1680, -0.0762, -0.1402],\n",
       "                      [ 0.0807, -0.0599, -0.0386,  0.1765,  0.1709,  0.0814, -0.1416, -0.1217,\n",
       "                       -0.2068,  0.2094, -0.3601, -0.1337, -0.0826,  0.1284, -0.0481, -0.1143,\n",
       "                       -0.0465,  0.1141, -0.1630,  0.0796,  0.1149,  0.1491, -0.0055,  0.0532,\n",
       "                       -0.0716,  0.0850,  0.1977,  0.0982, -0.0471,  0.1052,  0.2111, -0.1480]])),\n",
       "             ('ICCD_features_.23.bias', tensor([ 0.1441, -0.0131, -0.0451]))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d0e0d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95c5a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 24 32\n",
      "I'M TRAINING, I'M TRAINING!!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MixedICCDNet:\n\tsize mismatch for ICCD_features_.19.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([64, 38400]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m      4\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparam MLP checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(MLP_checkpoint)\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#config = best_result.config\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m best_R2, train_loss_list, test_loss_list, r2_list, best_train_predictions, best_train_actuals, best_val_predictions, best_val_actuals \u001b[38;5;241m=\u001b[39m model_train_best(config,ICCD_checkpoint\u001b[38;5;241m=\u001b[39mICCD_checkpoint, MLP_checkpoint\u001b[38;5;241m=\u001b[39mMLP_checkpoint)\n",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m, in \u001b[0;36mmodel_train_best\u001b[0;34m(config, ICCD_checkpoint, MLP_checkpoint)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ICCD_checkpoint:\n\u001b[1;32m     10\u001b[0m     weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(ICCD_checkpoint)\n\u001b[0;32m---> 11\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(weights,strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#Freeze all layers in the ICCD_features_ part\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mICCD_features_\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MixedICCDNet:\n\tsize mismatch for ICCD_features_.19.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([64, 38400])."
     ]
    }
   ],
   "source": [
    "ICCD_checkpoint ='ICCDNet_l1-64.0000_l2-32.0000_lr-0.0014_L2-0.0005.model'\n",
    "MLP_checkpoint = 'MLP_l1-48.0000_l2-32.0000_lr-0.0112_L2-0.0003.model'\n",
    "\n",
    "config = {\n",
    "        \"l1\": 64,\n",
    "        \"l2\": 32,\n",
    "        \"param_l1\": 48,\n",
    "        \"param_out\": 32,\n",
    "        \"c1\": 16,\n",
    "        \"c2\": 24,\n",
    "        \"c3\": 32,\n",
    "        \"lr\": 0.001055047107715595,\n",
    "        \"weight_decay\": 0.0018287918531623708,\n",
    "        \"ICCD checkpoint\": os.path.abspath(ICCD_checkpoint),\n",
    "        \"param MLP checkpoint\": os.path.abspath(MLP_checkpoint)\n",
    "}\n",
    "\n",
    "#\n",
    "#config = best_result.config\n",
    "\n",
    "best_R2, train_loss_list, test_loss_list, r2_list, best_train_predictions, best_train_actuals, best_val_predictions, best_val_actuals = model_train_best(config,ICCD_checkpoint=ICCD_checkpoint, MLP_checkpoint=MLP_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "744a5ad3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MixedICCDNet:\n\tsize mismatch for ICCD_features_.19.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([64, 38400]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 25\u001b[0m\n\u001b[1;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m MixedICCDNet(\n\u001b[1;32m     16\u001b[0m                      l1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,        \u001b[38;5;66;03m# MLP nodes layer 1 for ICCD features\u001b[39;00m\n\u001b[1;32m     17\u001b[0m                      l2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,        \u001b[38;5;66;03m# MLP nodes layer 2 for ICCD features\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m                      c2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m,        \u001b[38;5;66;03m# MLP nodes layer 1 for combined features\u001b[39;00m\n\u001b[1;32m     22\u001b[0m                      c3\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)        \u001b[38;5;66;03m# MLP nodes layer 1 for combined features\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m results \u001b[38;5;241m=\u001b[39m train(model,train_loader,val_loader, n_epochs, learning_rate, L2, ICCD_checkpoint, MLP_checkpoint)\n",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, n_epochs, learning_rate, L2, ICCD_checkpoint, MLP_checkpoint)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ICCD_checkpoint \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(ICCD_checkpoint)\n\u001b[0;32m----> 5\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(weights,strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#Freeze all layers in the ICCD_features_ part\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mICCD_features_\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MixedICCDNet:\n\tsize mismatch for ICCD_features_.19.weight: copying a param with shape torch.Size([64, 256]) from checkpoint, the shape in current model is torch.Size([64, 38400])."
     ]
    }
   ],
   "source": [
    "# Choose between 'Mixed', 'ICCD', or 'Params'\n",
    "features_to_use = 'Mixed' \n",
    "\n",
    "n_epochs=2000\n",
    "learning_rate = 0.001055047107715595\n",
    "L2 = 0.0018287918531623708\n",
    "\n",
    "checkpoint_name = 'Growth Kinetics Mixed Input Checkpoint'\n",
    "\n",
    "# here, we use the original checkpoints that were used in the paper, rather than the new ones created in this notebook\n",
    "\n",
    "ICCD_checkpoint = 'ICCDNet_l1-64.0000_l2-32.0000_lr-0.0014_L2-0.0005.model'\n",
    "MLP_checkpoint = 'MLP_l1-48.0000_l2-32.0000_lr-0.0112_L2-0.0003.model'\n",
    "\n",
    "model = MixedICCDNet(\n",
    "                     l1=64,        # MLP nodes layer 1 for ICCD features\n",
    "                     l2=32,        # MLP nodes layer 2 for ICCD features\n",
    "                     param_l1=48,  # MLP nodes layer 1 for parameter features\n",
    "                     param_out=32, # MLP nodes layer 2 for parameter features\n",
    "                     c1=16,        # MLP nodes layer 1 for combined features\n",
    "                     c2=24,        # MLP nodes layer 1 for combined features\n",
    "                     c3=32)        # MLP nodes layer 1 for combined features\n",
    "\n",
    "# Train the model\n",
    "results = train(model,train_loader,val_loader, n_epochs, learning_rate, L2, ICCD_checkpoint, MLP_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d074c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, val_loss_list, r2_list, best_R2, best_val_predictions,\\\n",
    "best_val_actuals,best_train_predictions, best_train_actuals = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best r2 value was:', best_R2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_loss_list, label='Train',alpha=0.8)\n",
    "ax.plot(val_loss_list,label='Test',alpha=0.8)\n",
    "\n",
    "#ax.set_ylim(0,2000)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MSE Loss')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcfbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_array = np.array(r2_list)\n",
    "labels = ['s$_0$', 's$_1$', 'J', 'mean']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(r2_array.shape[1]):\n",
    "    ax.plot(r2_array[:,i],label=labels[i],alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('r$^2$')\n",
    "ax.legend()\n",
    "ax.tick_params(axis='both')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952985b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_pred, train_actual, val_pred, val_actual, index, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    r2_train = pearsonr(train_actual[:,index], train_pred[:,index])[0]**2\n",
    "    r2_val = pearsonr(val_actual[:,index], val_pred[:,index])[0]**2\n",
    "    \n",
    "    ax.scatter(train_actual[:,index],train_pred[:,index],label='Train')\n",
    "    ax.scatter(val_actual[:,index],val_pred[:,index],label='Validation')\n",
    "    ax.plot(train_actual[:,index],train_actual[:,index],c='k')\n",
    "    \n",
    "    plt.text(0.02, 0.98, 'r$^2_{train}$ = %.4f\\nr$^2_{val}$ = %.4f' % (r2_train,r2_val),\n",
    "     horizontalalignment='left',\n",
    "     verticalalignment='top',\n",
    "     transform = ax.transAxes)\n",
    "\n",
    "    ax.legend(loc='upper center')\n",
    "        \n",
    "    ax.set_xlabel('{} actual'.format(title))\n",
    "    ax.set_ylabel('{} predicted'.format(title))\n",
    "    ax.tick_params(axis='both')\n",
    "    \n",
    "    return ax\n",
    "\n",
    "labels = ['s$_0$', 's$_1$', 'J']\n",
    "atten = [10,1,1000]\n",
    "\n",
    "for i,label in enumerate(labels):\n",
    "    ax = plot_predictions(best_train_predictions/atten[i],best_train_actuals/atten[i],\n",
    "                     best_val_predictions/atten[i], best_val_actuals/atten[i],i,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64924b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
